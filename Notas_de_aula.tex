\documentclass[reqno]{article}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{enumerate}
\usepackage{color}
\usepackage{mathabx}
\usepackage{calc}

\usepackage{dsfont} % includes bb 1
\newcommand*\1{\mathds{1}}
\usepackage[brazil]{babel}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}[theorem]{Corolário}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{proposition}[theorem]{Proposição}
\newtheorem{definition}[theorem]{Definição}
\newtheorem{question}[theorem]{Questão}
\newtheorem{notation}[theorem]{Notação}

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\Geo}{Geo}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\VT}{VT}

\def \distr {\overset{d}{\sim}}

\usepackage{etoolbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%% array for equations alignment %%%%%%%%%%%%%%%%%%%%%%%
\usepackage{array}
\newcolumntype{e}{>{\displaystyle}r @{\,} >{\displaystyle}c @{\,} >{\displaystyle}l}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% Make automatic exp{x} or e^x %%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\def\mathsettoheight#1#2%
  {\setbox\@tempboxa\hbox{{#2}}%
   #1=\ht\@temboxa
   \setbox\@temboxa\box\voidb@x}
\def\mathsettoheight#1#2%
  {\setbox\@tempboxa\hbox{$\m@th\mathpalette{}{#2}$}%
   #1=\ht\@tempboxa
   \setbox\@tempboxa\box\voidb@x}
\makeatother
\newlength\heightin
\newcommand{\ex}[1]{
\mathsettoheight\heightin{#1}
\ifdimless{\heightin}{8pt}{e^{#1}}{\exp\big\{#1\big\}}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newtheorem{example}{Exemplo}[section]
\newtheorem{exercise}[example]{Exercício}

\renewcommand*\d{\mathop{}\!\mathrm{d}}
\newcommand{\red}[1]{\color{red}\textnormal{#1}\color{black}}

\newcommand{\mcup}{\textstyle \bigcup\limits}
\newcommand{\mcap}{\textstyle \bigcap\limits}

\marginparwidth = 57pt
\def\todo#1{\marginpar{\raggedright \tiny #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% mathclap %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\clap#1{\hbox to 0pt{\hss#1\hss}}
\def\mathllap{\mathpalette\mathllapinternal}
\def\mathrlap{\mathpalette\mathrlapinternal}
\def\mathclap{\mathpalette\mathclapinternal}
\def\mathllapinternal#1#2{\llap{$\mathsurround=0pt#1{#2}$}}
\def\mathrlapinternal#1#2{\rlap{$\mathsurround=0pt#1{#2}$}}
\def\mathclapinternal#1#2{\clap{$\mathsurround=0pt#1{#2}$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Probabilidade I}
\author{Augusto Teixeira}

\maketitle

\tableofcontents

\section{Espaços mensuráveis}


Denotaremos sempre por $\Omega$ o nosso espaço amostral (à princípio qualquer conjunto).

\begin{example} \mbox{}
  \begin{enumerate}
  \item $\Omega_1 = \{1, 2, \dots, 6\}$,
  \item $\Omega_2 = [0,1]$,
  \item $\Omega_3 = \{f:[0,1] \to \mathbb{R}; \text{$f$ é contínua}\}$...
  \end{enumerate}
\end{example}

Consideraremos sempre $\Omega$'s equipados com uma $\sigma$-álgebra denotada por $\mathcal{F}$.
Mais precisamente
\begin{definition}
  Dizemos que $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ é uma $\sigma$-álgebra se
  \begin{enumerate}
  \item $\Omega \in \mathcal{F}$,
  \item $A \in \mathcal{F}$ implica que $A^c \in \mathcal{F}$ e
  \item se $A_1, A_2, \dots \in \mathcal{F}$, então $\cup_i A_i \in \mathcal{F}$.
  \end{enumerate}
\end{definition}

\begin{example} \mbox{}
  \begin{enumerate}
  \item $\mathcal{F}_1 = \mathcal{P}(\Omega_1)$,
  \item $\mathcal{F}_2 = \mathcal{B}([0,1])$ e
  \item $\mathcal{F}_3 = \mathcal{B}(C[0,1])$.
  \end{enumerate}
\end{example}

No caso acima, dizemos que $(\Omega, \mathcal{F})$ é um \emph{espaço mensurável}.

Se $\mathcal{G} \subseteq \mathcal{P}(\Omega)$, denotamos por $\sigma(\mathcal{G})$ a menor $\sigma$-álgebra contendo $\mathcal{G}$.

Elementos $A \in \mathcal{F}$ são chamados de \emph{eventos}.

\begin{example} \mbox{}
  \begin{enumerate}
  \item $\{\text{$x$ é ímpar}\} \subset \Omega_1$
  \item $[0,1/2] \subset \Omega_2$ e
  \item $\{f:[0,1] \to \mathbb{R}; f(1) \geq 0\} \subset \Omega_3$.
  \end{enumerate}
\end{example}

\begin{exercise}
  Mostre que $\{f:[0,1] \to \mathbb{R}; f(1) \geq 0\} \subset \Omega_3$ é um evento (ou seja, pertence a $\mathcal{F}_3$).
\end{exercise}

\begin{notation}
  Se $Q$ for uma condição qualquer sobre candidatos $\omega \in \Omega$, escreveremos $[\text{$\omega$ satisfaz $Q$}]$ para denotar $\{\omega \in \Omega; \text{$\omega$ stisfaz $Q$}\}$.
\end{notation}

Por exemplo, $\{f:[0,1] \to \mathbb{R}; f(1) \geq 0\}$ pode ser escrita simplesmente como $[f(1) \geq 0]$.

\todo{será que vale a pena fazer Caratheodory com continuidade no vazio? por exemplo simplifica um pouco a extensão de Kolmogorov.}

\section{Espaços de probabilidade}

\begin{definition}
  Dado $(\Omega, \mathcal{F})$ espaço mensurável, dizemos que $P:\mathcal{F} \to [0,1]$ é uma probabilidade se
  \begin{enumerate}
  \item $P(\Omega) = 1$ e
  \item sempre que $A_1, A_2, \dots \in \mathcal{F}$ forem disjuntos ($A_i \cap A_j = \varnothing$ se $i \neq j$), temos $P(\cup_i A_i) = \sum_i P(A_i)$.
  \end{enumerate}
\end{definition}

\begin{example} \mbox{}
  \begin{enumerate}
  \item $P_1(A) = \tfrac{\#A}{6}$ em $(\Omega_1, \mathcal{F}_1)$.
    Ou mais geralmente $P_1'(A) = \sum_{i \in A} p_i$, onde $p_i \geq 0$ e $\sum_i p_i = 1$.
  \item $P_2$ pode ser a medida de Lebesgue em $([0,1], \mathcal{B}([0,1]))$.
    Mais geralmente também podemos ter $P_2'(A) = \int_A \rho(x) \d x$, onde $\rho:[0,1] \to \mathbb{R}_+$, chamada densidade, é tal que $\int_{[0,1]} \rho (x) \d x = 1$.
  \end{enumerate}
\end{example}

\begin{proposition}
  Valem as afirmativas
  \begin{enumerate}
  \item Se $A \subseteq B$ então $P(A) = P(B) - P(B \setminus A) \leq P(B)$,
  \item $P(\cup_i A_i) \leq \sum_i P(A_i)$ e
  \item $P(\cup_{i=1}^n A_i) = \sum_{k = 1}^n (-1)^{k-1} \sum_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k})$.
  \end{enumerate}
\end{proposition}


\begin{proof}
  1.
  Como $A \cap (B \setminus A) = \varnothing$, então
  \begin{equation}
    \begin{split}
      P(A \cup (B \setminus A)) & = P(A \cup (B \setminus A) \cup \varnothing \cup \dots)\\
      & = P(A) + P(B \setminus A) + 0 + \dots = P(A) + P(B \setminus A).
    \end{split}
  \end{equation}

  2.
  $P(A \cup B) = P (A \cup (B \setminus A)) = P(A) + P(B \setminus A) \leq P(A) + P(B)$.
  Deixamos o caso enumerável como exercício abaixo.

  3.
  Basta mostrar a validade da equação abaixo e depois integrar com respeito a $P$.
  \begin{equation}
    \label{e:indicadora_como_produto}
    \1_A(\omega) = \sum_{k=1}^n (-1)^{k - 1} \sum_{I \subseteq \{1, \dots, n\} \atop |I| = k} \prod_{i \in I} \1_{A_i}(\omega).
  \end{equation}
  Para tanto, observe que para todo $\omega \in \Omega$,
  \begin{equation}
    (\1_A - \1_{A_1}) \cdot \dots \cdot (\1_A - \1_{A_n})(\omega) = 0.
  \end{equation}
  Logo, expandindo o produto acima obtemos
  \begin{equation}
    \1_A + \sum_{k = 1}^n \sum_{I \subseteq \{1, \dots, n\} \atop |I| = k} (-1)^k \1_{A_k}(\omega) = 0,
  \end{equation}
  que equivale a \eqref{e:indicadora_como_produto}.
\end{proof}

\begin{exercise}
  Mostre que $P(\cup_i A_i) \leq \sum_i P(A_i)$ no caso enumerável.
\end{exercise}

\begin{proposition}
  \label{p:prob_continua}
  $P$ é contínua, isto é:
  \begin{enumerate}
  \item Se $A_1 \subseteq A_2 \subseteq \dots \in \mathcal{F}$, então $\lim_n P(A_n) = P(\cup_n A_n)$.
  \item Também, se $A_1 \supseteq A_2 \supseteq \dots \in \mathcal{F}$, temos $\lim_n P(A_n) = P(\cap_n A_n)$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  1.
  Observe que
  \begin{equation}
    \cup_{m = 1}^\infty A_n = \cup_{n = 1}^\infty \Big( A_n \setminus (\cup_{i=1}^{n-1} A_i) \Big),
  \end{equation}
  que são disjuntos.
  Logo
  \begin{equation}
    \begin{split}
      P(\cup_{n = 1}^\infty A_n) & = \sum_{n = 1}^\infty P\Big( A_n \setminus (\cup_{i=1}^{n-1} A_i) \Big)\\
      & = \lim_n P(\cup_{i = 1}^n A_i) = \lim_n P(A_n).
    \end{split}
  \end{equation}

  2.
  A prova é análoga à de 1.
\end{proof}

\begin{lemma}[Borel-Cantelli - primeira parte]
  Sejam $A_1, A_2, \dots \in \mathcal{F}$ com $\sum_{i = 1}^\infty P(A_i) < \infty$.
  Então
  \begin{equation}
    P[\text{$A_i$ para infinitos $i$}] := P\big(\cap_{n = 1}^\infty (\cup_{i \geq n} A_i)\big) = 0.
  \end{equation}
\end{lemma}

\begin{proof}
  Estimamos
  \begin{equation}
    P\big(\cap_{n = 1}^\infty (\cup_{i \geq n} A_i)\big) = \lim_n P(\cup_{i \geq n} A_i) \leq \lim_n \sum_{i \geq n} P(A_i) = 0.
  \end{equation}
\end{proof}

\section{Elementos aleatórios}

Seja $(E,\mathcal{A})$ um espaço mensurável.
Nesse caso, se $X: \Omega \to E$ é $(\mathcal{F}, \mathcal{A})$-mensurável, dizemos que $X$ é um elemento aleatório em $(\Omega, \mathcal{F})$ tomando valores em $E$, ou um $E$-elemento aleatório.

\begin{example} \mbox{}
  \begin{enumerate}
  \item $X:\Omega \to \mathbb{R}$ mensurável é dita variável aleatória.
  \item $X:\Omega \to \mathbb{R}^d$ mensurável é dito vetor aleatório ($d$-dimensional).
  \item $X:\Omega \to C[0,1]$ mensurável é dita função aleatória.
  \end{enumerate}
\end{example}

Citando Kingman em seu livro Poisson Processes: ``\emph{a random elephant is a function from $\Omega$ into a suitable space of elephants.}''

Relembrando a nossa notação: $P[X \in A] = P(\{\omega \in \Omega; X(\omega) \in A\})$.

\newpage

\begin{proposition}
  Seja $X:\Omega \to E$ onde $(E, \mathcal{A})$ é um espaço mensurável com $\mathcal{A} = \sigma(\mathcal{G})$.
  Então para verificar que $X$ é um elemento aleatório, basta provar que $X^{-1}(G) \in \mathcal{F}$ para todo $G \in \mathcal{G}$.
\end{proposition}

\begin{proof}
  Teoria da medida.
\end{proof}

\begin{example}
  Se $\Omega$ e $E$ são espaços topológicos, então toda função contínua é um elemento aleatório.
\end{example}

\section{Distribuição de elementos aleatórios}


\begin{definition}
  Se $X:\Omega \to E$ é um elemento aleatório e $\Omega$ é dotado de uma probabilidade $P$, então denotamos por $X \circ P$, a chamada \emph{distribuição de $X$}, a medida de probabilidade
  \begin{equation}
    (X \circ P)(A) := P\big( \{\omega \in \Omega; X(\omega) \in A\} \big) = P[X \in A].
  \end{equation}
  no espaço mensurável $(E,\mathcal{A})$.
\end{definition}

Fica como exercício verificar que $X \circ P$ é de fato uma probabilidade em $E$.

\begin{example}
  Em $\Omega_2 = [0,1]$ com a medida de Lebesgue, seja $X:[0,1] \to \{0,1\}$ dada por $X(\omega) = \1_{[0,1/2]} (\omega)$.
  Nesse caso $X \circ P = 1/2(\delta_0 + \delta_1)$.
\end{example}

Duas notações importantes nesse contexto são:
\begin{enumerate}
\item Dizemos que $X \distr Y$, quando $X \circ P = Y \circ P'$.
Note que $X$ e $Y$ nem ao menos precisam pertencer ao mesmo espaço de probabilidade para dizermos que são \emph{igualmente distribuídos}, mas precisam ser elementos aleatórios de mesmo tipo (ou seja, possuir o mesmo contradomínio).
\item Escrevemos $X \distr \mu$, que lê-se \emph{$X$ é distribuída como $\mu$}, onde $\mu$ é uma probabilidade em $E$, caso $X \circ P = \mu$.
\end{enumerate}

\section{Sistemas $\lambda$-$\pi$}

\begin{definition}
  Dizemos que uma classe $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\pi$-sistema se for fechado por interseções finitas, isto é: para todos $A, B \in \mathcal{A}$ temos $A \cap B \in \mathcal{A}$.
\end{definition}

\begin{definition}
  Dizemos que $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\lambda$-sistema, se
  \begin{enumerate}
  \item $\Omega \in \mathcal{A}$,
  \item Sempre que $A \in \mathcal{A}$ temos $A^c \in \mathcal{A}$ e
  \item para $A_1, A_2, \dots \in \mathcal{A}$ disjuntos dois a dois, temos $\cup_i A_i \in \mathcal{A}$.
  \end{enumerate}
\end{definition}

Definimos para $\mathcal{A} \subseteq \mathcal{P}(~W)$, o menor $\lambda$-sistema contendo $\mathcal{A}$, ou seja
\begin{equation}
  \lambda(\mathcal{A}) = \mcap_{\text{$\mathcal{B}$ $\lambda$-sistema} \atop \mathcal{A} \subseteq \mathcal{B}} \mathcal{B}.
\end{equation}
É fácil ver que $\lambda(\mathcal{A})$ é sempre um $\lambda$-sistema.

\todo{rever a posição deste teorema no texto.}

\begin{theorem}[Dynkin]
  \label{t:dynkin}
  Se $\mathcal{A}$ é um $\pi$-sistema, então $\lambda(\mathcal{A}) = \sigma(\mathcal{A})$.
\end{theorem}

\todo{Dar intuição da prova: passo de redução (basta mostrar que $\lambda(\mathcal{A})$ é $\pi$-sistema), motivar def de $\mathcal{B}$ e $\bar{\mathcal{B}}$.}

\begin{proof}
  Obviamente, $\lambda(\mathcal{A}) \subseteq \sigma(\mathcal{A})$.
  Portanto basta provar a inclusão inversa.
  Definimos primeiramente $\mathcal{B} = \big\{B \in \lambda(\mathcal{A}); \text{$B \cap A \in \lambda(\mathcal{A})$ para todo $A \in \mathcal{A}$})\big\}$ e iremos mostrar que
  \begin{equation}
    \label{e:B_igual_lambda}
    B = \lambda(\mathcal{A}).
  \end{equation}
  Obviamente, $\mathcal{A} \subseteq \mathcal{B}$, pois $\mathcal{A}$ é um $\pi$-sistema.
  Então basta mostrar que $\mathcal{B}$ é um $\lambda$-sistema.
  \begin{enumerate}
  \item $\Omega$ obviamente pertence a $\mathcal{B}$.
  \item Se $B \in \mathcal{B}$ e $A \in \mathcal{A}$, então $B^c \cap A = A \setminus(B \cap A) = (A^c \cup (B \cap A))^c$.
    Mas como $B \in \mathcal{B}$, $(B \cap A) \in \lambda(\mathcal{A})$ e usando o fato que $\lambda$-sistemas são fechados por complementos e uniões disjuntas, $B^c \cap A \in \lambda(\mathcal{A})$.
    Como isso vale para todo $A \in \mathcal{A}$, temos $B^c \in \mathcal{B}$ por definição.
  \item Se $B_1, B_2, \dots \in \mathcal{B}$ são disjuntos e $A \in \mathcal{A}$, então
    \begin{equation}
      \big(\cup_i B_i \big) \cap A = \cup_i \big(B_i \cap A\big) \in \lambda(\mathcal{A}),
    \end{equation}
    pois a união acima é disjunta.
    Logo $\cup_i B_i \in \mathcal{B}$.
  \end{enumerate}
  Isso mostra que $\mathcal{B}$ é um $\lambda$-sistema contido em $\lambda(\mathcal{A})$, mostrando \eqref{e:B_igual_lambda}.

  No próximo passo, definimos $\bar{\mathcal{B}} = \{A \in \lambda(A); \text{$B \cap A \in \lambda(A), \; \forall B \in \lambda(A)$}\}$ e mostraremos que $\bar{\mathcal{B}}$ é tanto um $\pi$-sistema quanto um $\lambda$-sistema que contém $\mathcal{A}$.
  Primeiramente, observe que $\mathcal{A} \subseteq \bar{\mathcal{B}}$ pois $\mathcal{B} = \lambda(\mathcal{A})$ (lebre da definição de $\mathcal{B}$).

  Mostraremos agora que
  \begin{equation}
    \label{e:B_barra_pi}
    \text{$\bar{\mathcal{B}}$ é um $\pi$-sistema}.
  \end{equation}
  De fato, sejam $A_1, A_2 \in \bar{\mathcal{B}}$ e $B \in \lambda(A)$.
  Então $(A_1 \cap A_2) \cap B = (A_1 \cap B) \cap A_2 \in \lambda(\mathcal{A})$, donde $A_1 \cap A_2$ pertence a $\bar{\mathcal{B}}$.
  Finalmente mostraremos que
  \begin{equation}
    \label{e:B_barra_lambda}
    \text{$\bar{\mathcal{B}}$ é um $\lambda$-sistema}.
  \end{equation}
  Para tanto, verificaremos
  \begin{enumerate}
  \item $\Omega \in \bar{\mathcal{B}}$, que é claro.
  \item Tomando $A \in \bar{\mathcal{B}}$ e $B \in \lambda(\mathcal{A})$, $A^c \cap B = B \setminus (A cap B) = \big(B^c \cup (A \cap B)\big)^c \in \lambda(\mathcal{A})$, por um argumento análogo ao apresentado para $\mathcal{B}$.
    Logo $A^c \in \bar{\mathcal{B}}$.
  \item Também o caso de uniões disjuntas é bastante análogo ao caso para $\mathcal{B}$.
  \end{enumerate}
  Isso mostra que $\bar{\mathcal{B}}$ é um $\lambda$-sistema.

  Para terminar a prova, precisamos apenas mostrar que $\sigma(\mathcal{A}) \subseteq \bar{\mathcal{B}}$, pois $\bar{\mathcal{B}} \subseteq \lambda(\mathcal{A})$.
  Para tanto basta ver que $\bar{\mathcal{B}}$ é uma $\sigma$-álgebra.
  Como essa família já é um $\lambda$ e $\pi$-sistema, basta considerarmos uniões arbitrárias em $\bar{\mathcal{B}}$.

  Seja $A_1, A_2, \dots \in \bar{\mathcal{B}}$ e defina $B_n = \cup_{i=1}^n A_i = (\cap_{i=1}^n A_i^c)^c \in \bar{\mathcal{B}}$.
  Escrevemos portanto
  \begin{equation}
    \cup_n A_n = \cup_n \big(A_n \setminus B_{n-1} \big),
  \end{equation}
  que é uma união disjunta de termos em $\bar{\mathcal{B}}$, logo está em $\bar{\mathcal{B}}$.
  Isso mostra que $\bar{\mathcal{B}}$ é uma $\sigma$-álgebra, concluindo a prova do teorema.
\end{proof}

\subsection{Aplicação}

\begin{proposition}
  \label{p:P12_equal_pi}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega, \mathcal{F})$, tais que $P_1(A) = P_2(A)$ para todo $A \in \mathcal{A}$ e $\mathcal{A}$ é um $\pi$-sistema, então $P_1(B) = P_2(B)$ para todo $B \in \lambda(\mathcal{A})$.
\end{proposition}

\begin{proof}
  Seja $\mathcal{B} = \{A \in \mathcal{F}; P_1(A) = P_2(A)\}$.
  É fácil ver que $\mathcal{B}$ é um $\lambda$-sistema.
  Logo $\mathcal{B}$ contém $\lambda(\mathcal{A})$ que é igual a $\sigma(\mathcal{A})$ por Dynkin.
\end{proof}

\begin{corollary}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2)$, tais que
  \begin{equation}
    P_1(A_1 \times A_2) = P_2(A_1 \times A_2), \text{ para todos $A_1 \in \mathcal{F}_1$, $A_2 \in \mathcal{F}_2$,}
  \end{equation}
  então $P_1 = P_2$.
\end{corollary}

\begin{proof}
  Obviamente as caixas do tipo $A_1 \times A_2$ formam um $\pi$-sistema que gera $\mathcal{F}_1 \otimes \mathcal{F}_2$ (por definição).
\end{proof}

\begin{example}
  Observe portanto que é importante que $\mathcal{A}$ seja um $\pi$-sistema na Proposição~\ref{p:P12_equal_pi}.
  Imagine por exemplo que $\Omega = \{0,1\}^2$ e $P_1 = \tfrac 14 \sum_{x \in \Omega} \delta_x$ e $P_2 = \tfrac 12 (\delta_{(0,0)} + \delta_{(1,1)})$.
  Nesse caso
  \begin{equation}
    P_1(A) = P_2(A) = 1/2 = P_1(B) = P_2(B),
  \end{equation}
  com $A = \{(0,0), (0,1)\}$ e $B = \{(0,0), (1,0)\}$.
  Contudo, $P_1 \neq P_2$, mesmo tendo $\mathcal{P}(\Omega) = \sigma(\{A,B\})$.
\end{example}

\section{Construção de espaços de probabilidade}

\subsection{Caso $\Omega$ enumerável}

Se $\Omega = \{\omega_1, \omega_2, \dots\}$, então podemos definir $\mathcal{A} = \mathcal{P}(\Omega) (= \sigma(\{\omega_i\}_{i \geq 1}))$.
Assim, dados $(p_\omega)_{\omega \in \Omega}$ tais que
\begin{enumerate}
\item $p_\omega \geq 0$ para todo $\omega \in \Omega$ e
\item $\sum_{\omega \in \Omega} p_\omega = 1$,
\end{enumerate}
definimos $P(A) = \sum_{\omega \in A} p_\omega$ que claramente define uma probabilidade.

\begin{example} \mbox{}
  \begin{enumerate}
  \item Dado $p \in [0,1]$, definimos a medida $\Ber(p)$ (em homenagem a Bernoulli) em $\{0,1\}$ com $p_1 = p, p_0 = 1-p$.
  \item Dados $n \geq 1$ e $p \in [0,1]$, definimos a medida $\Bin(n,p)$ (de binomial) em $\Omega = \{0, 1, \dots, n\}$ com
    \begin{equation}
      p_i = \binom ni p^i (1-p)^{n-i}, \text{ para $i \in \Omega$.}
    \end{equation}
  \item Dado $p \in (0,1]$, em $\Omega = \{0, 1, \dots\}$ definimos a medida $\Geo(p)$ em $\Omega$ induzida pelos pesos
  \begin{equation}
    p_i = (1-p)^i p, \text{ para $i \geq 1$.}
  \end{equation}
  \end{enumerate}
\end{example}

\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ e $p_\omega = \tfrac 1{2^n}$ para todo $\omega \in \Omega$ (ou seja a probabilidade uniforme).
  Considere $X: \Omega \to \{0,1, \dots, n\}$ dada por $X(\omega_1, \dots, \omega_n) = \sum_{i=1}^n \omega_i$.
  Obtenha a distribuição $X \circ P$.
  Dê um exemplo de medida em $\omega$ para a qual a distribuição de $X$ seja $\Bin(n,p)$.
\end{exercise}


\subsection{Caso absolutamente contínuo}

Seja $(\Omega, \mathcal{F}, \mu)$ um espaço de medida e $\rho:\Omega \to \mathbb{R}_+$ mensurável com $\int \rho(x) \mu(\d x) = 1$.
Então podemos definir a probabilidade induzida
\begin{equation}
  \label{e:absolutamente_cont}
  P(A) = \int_A \rho(x) \mu(\d x).
\end{equation}
Nesse caso, chamamos $\rho$ de a densidade de $P$ com respeito a $\mu$.
Uma outra possível notação para a equação acima é $\d P = \rho(x) \d \mu$ (lembrando a derivada de Radon-Nikodim).

Observe que o caso discreto pode ser definido em termos de uma densidade, onde $\rho(\omega) = p_\omega$ e $\mu$ é a medida da contagem em $\Omega$.

\begin{example}
  Vários exemplos podem ser obtidos via \eqref{e:absolutamente_cont} se tomamos $\Omega \subseteq \mathbb{R}$ e $\mu$ a medida de Lebesgue restrita a $\Omega$.
  Nesses casos, escrevemos $P = \rho(x) \d x$ em $\Omega$.
  Alguns exemplos importantes são:
  \begin{enumerate}
  \item Para $a < b \in \mathbb{R}$, definimos a medida $U[a,b]$ usando $\rho(x) = \tfrac{1}{b-a}\1_{[a,b]}(x)$.
  \item Para $\lambda > 0$, definimos a medida $\Exp(\lambda)$ (chamada exponencial de parâmetro $\lambda$) por meio da densidade $\rho(x) = \tfrac{1}{\lambda} \exp\{-\lambda x\}$ em $[0,\infty)$.
  \end{enumerate}
\end{example}

\newpage

Podemos também usar a distribuição de um elemento aleatório para construir outras probabilidades.

\begin{example}
  Considere por exemplo $X:[0,2\pi] \to \mathbb{C}$ dada por $X(t) = \exp\{-i t\}$.
  A distribuição $X \circ P$ de $X$ segundo $U_{[0,2\pi]}$ é o que chamamos de distribuição uniforme em $S^1$, também denotada por $U_{S^1}$.
\end{example}

\begin{exercise}
  Mostre que $U_{S^1}$ não é absolutamente contínua com respeito à medida de Lebesgue em $\mathbb{C} \sim \mathbb{R}^2$.
\end{exercise}

\begin{exercise}
  Mostre que $U_{S^1}$ é invariante por rotações rígidas de $\mathbb{C}$, isto é, se $T:\mathbb{C} \to \mathbb{C}$ é uma isometria linear, então $T \circ U_{S^1} = U_{S^1}$.
\end{exercise}

\begin{exercise}
  Construa uma probabilidade em $S^2$ invariante por rotações.
\end{exercise}

\subsection{O caso $\Omega = \mathbb{R}$}

Será importante nesse curso entender a distribuição de variáveis aleatórias.
Para tanto, precisaremos de uma boa ferramenta para descrever probabilidades em $\mathbb{R}$.

\begin{definition}
  Dada $P$ em $\mathbb{R}$, definimos $F_P:\mathbb{R} \to [0,1]$ por $F_P(x) = P\big((-\infty, x]\big)$.
  Essa função é chamada a função de distribuição acumulada de $P$.
\end{definition}

\begin{notation}
  Se $X:\Omega \to \mathbb{R}$ é uma variável aleatória num espaço $(\Omega, \mathcal{F}, P)$, denotamos por $F_X$ a função de distribuição acumulada correspondente à distribuição $X \circ P$.
\end{notation}

\begin{example}
  \begin{equation}
  F_{U_{[0,1]}} =
  \begin{cases}
    0 & \text{ se $x \leq 0$,}\\
    x & \text{ se $x \in [0,1]$ e}\\
    1 & \text{ se $x \geq 1$.}
  \end{cases}
\end{equation}
\end{example}

\begin{exercise}
  Calcule $F_{\Exp(\lambda)}$.
\end{exercise}

\begin{proposition}
  \label{p:propried_F}
  $F_P$ (e obviamente $F_X$) satisfazem:
  \begin{enumerate}
  \item $\lim_{x \to -\infty} F(x) = 0$, $\lim_{x \to \infty} F(x) = 1$,
  \item $F$ é monótona não-decrescente e
  \item $F$ é contínua à direita e possui limite à esquerda.
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{enumerate}
  \item Se $x_n \to -\infty$ monotonamente, então $A_n = (-\infty, x_n]$ são encaixados e de interseção vazia.
    Logo, pela Proposição~\ref{p:prob_continua}, temos $P(A_n) \to 0$.
    O outro caso é análogo.
  \item Se $x \leq x'$ então $(-\infty, x] \subseteq (-\infty,x']$, donde $F(x) \leq F(x')$.
  \item Continuidade à direita (càd) - Se $x_n \downarrow x$ monotonamente, então $A_n = (-\infty, x_n] \downarrow (-\infty, x]$ (eles são encaixados).
    Logo $F(x_n) \to F(x)$.

    Limite à esquerda (làg do francês) - Segue do fato de $F$ ser monótona e limitada.
  \end{enumerate}
\end{proof}

\begin{theorem}
  Se $F$ satisfaz as três propriedades listadas na Proposição~\ref{p:propried_F}, então existe uma única $P$ em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ tal que $F = F_P$.
\end{theorem}

\begin{proof}
  A unicidade de tal $P$ segue da Proposição~\ref{p:P12_equal_pi} (consequêcia do Teorema de Dynkin), pois se $P$ e $P'$ são tais que $F_{P} = F_{P'}$, então temos que $P\big( (-\infty, x] \big) = P'\big( (-\infty, x] \big)$.
  Mas a classe de intervalos semi-infinitos da forma $(-\infty, x]$ forma um $\pi$-sistema que gera a $\sigma$-álgebra dos borelianos, logo $P = P'$.

  Para construir uma $P$ tal que $F_P = F$, definiremos primeiramente a inversa generalizada de $F$, $S:(0,1) \to \mathbb{R}$ por
  \begin{equation}
    S(u) = \sup \{x \in \mathbb{R}; F(x) < u\}.
  \end{equation}
\begin{figure}[htbp]
\centering
\begin{tikzpicture}[scale=.8]
\draw (0,1) -- (10,1);
\draw (0,4) -- (10,4); % second line
\draw plot [smooth,tension=.5] coordinates{(0, 4.4) (2.5, 4.5) (5,5) (7.5, 5.5) (10, 5.6)};
\draw plot [smooth,tension=.5] coordinates{(0, 1.4) (2.5, 1.5) (5,1.8)};
\draw plot [smooth,tension=.5] coordinates{(5, 2.3) (7.5, 2.5) (10,2.6)};
\draw[dotted] (0,5) -- (5,5) -- (5,4);
\draw[dotted] (0,2) -- (5,2) -- (5,1);
\draw [fill,color=white] (5,1.8) circle [radius=0.05];
\draw (5,1.8) circle [radius=0.05];
\draw [fill] (5,2.3) circle [radius=0.05];
\node at (0,5) [left]{$u$};
\node at (0,2) [left]{$u$};
\node at (5,1) [below]{$S(u)$};
\node at (5,4) [below]{$S(u)$};
\end{tikzpicture}
\caption{\small Ilustração da definição de $S(u)$.}
\label{f:Rk_good}
\end{figure}

Seja $P = S \circ U_{[0,1]}$, isto é $P(A) = U_{[0,1]}(S^{-1}(A))$ e mostraremos que $F_P = F$.
Para tanto, basta ver que
\begin{equation}
  \label{e:pseudo_inversa}
  \{u; S(u) \leq x\} = \{u; u \leq F(x)\}, \text{ para todo $x \in \mathbb{R}$}.
\end{equation}
Pois se tivermos a igualdade acima, $F_P(x) = U_{[0,1]}[S \leq x] = U_{[0,1]} [u \leq F(x)] = F(x)$.

Vamos agora checar \eqref{e:pseudo_inversa} observando que:
\begin{enumerate}
\item Se $u \leq F(x)$ então todo $x'$ tal que $F(x') < u$ é menor que $x$.
  Logo $S(u) \leq x$.
\item Por outro lado, se $u > F(x)$ então existe $x' > x$ tal que $F(x') < u$ (pois $F$ é càd), donde $S(u) > x$.
\end{enumerate}
Isos prova \eqref{e:pseudo_inversa}, terminando a prova da proposição.
\end{proof}


\section{Independência}

\begin{definition}
  Dados dois eventos $A, B \in \mathcal{F}$, dizemos que eles são independentes se
  \begin{equation}
    P(A \cap B) = P(A) P(B).
  \end{equation}
\end{definition}

\begin{example}
  Se $\Omega = \{1, \dots, 6\}$ com $P(A) = \#A/6$ então os eventos $A = [\omega é impar]$ e $B = [\omega \geq 5]$ satisfazem
  \begin{equation}
    P(A \cap B) = P(\{5\}) = 1/6 = (1/2) (1/3) = P(A) P(B).
  \end{equation}
  Logo tais eventos são independentes.
\end{example}


\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ com $P(A) = \#A/2^n$ e $X_i(\omega_1, \dots, \omega_n) = \omega_i$ para $i = 1, \dots, n$.
  Mostre que
  \begin{equation}
    P[X_i = a, X_j = b] = P[X_i = A] P[X_j = B],
  \end{equation}
  onde $[A,B]$ denota a interseção $[A] \cap [B]$.
\end{exercise}

\subsection{Coleções de eventos}

\begin{definition}
  Sejam $A_1, A_2, \dots, A_k$ eventos.
  Dizemos que eles formam uma coleção independente se para todo $I \subseteq \{1, \dots, k\}$ não vazio
  \begin{equation}
    P\Big( \mcap_{i \in I} A_i \Big) =  \prod\limits_{i \in I} P(A_i).
  \end{equation}
\end{definition}

Vale observar que independência dois a dois não implica independência.
Mais precisamente
\begin{example}
  Seja $\Omega = \{1,2,3,4\}$ com $P(A) = \# A/4$ e sejam os seguintes eventos: $A_1 = \{1,2\}$, $A_2 = \{2,3\}$ e $A_3 = \{1,3\}$.
  Nesse caso,
  \begin{enumerate}
  \item $P(A_i) = 1/2$ para $i = 1, 2, 3$,
  \item $P(A_i \cap A_j) = 1/4$ para todo $i \neq j$ mas
  \item $P(A_1 \cap A_2 \cap A_3) = 0 \neq 1/8 = P(A_1) P(A_2) P(A_3)$.
  \end{enumerate}
\end{example}

\begin{definition}
  Dizemos que uma coleção infinita de eventos $A_1, A_2, \dots$ é independente se toda sub-coleção finita de tais eventos forem independentes.
\end{definition}

\begin{lemma}
  Se $A_1, A_2, \dots$ forem independentes, então
  \begin{equation}
    P\Big( \mcap_{i} A_i \Big) = \prod\limits_{i} P(A_i).
  \end{equation}
\end{lemma}

\begin{proof}
  Temos,
  \begin{equation}
    P\Big( \mcap_{i} A_i \Big) = \lim_n P\Big( \mcap_{i = 1}^n A_i \Big) = \lim_n \prod\limits_{i=1}^n P(A_i) = \prod\limits_{i} P(A_i)
  \end{equation}
\end{proof}

\begin{proposition}
  $\{B;B \text{ ind de } A\}$ é $\lambda$-sistema....
\end{proposition}

\begin{corollary}
  Se $B$ ind de $A$ para todo $B \in \mathcal{B}$, $\pi$-sistema.
  Então $B$ ind de $A$ para todo $B in \sigma(\mathcal{B})$.
\end{corollary}

\subsection{Independência de $\sigma$-álgebras}

\begin{definition}
  Dadas $\sigma$-algebras $\mathcal{F}_1, \dots, \mathcal{F}_k \subseteq \mathcal{F}$.
  Dizemos que elas são independentes se todos $A_1 \in \mathcal{F}_1, \dots, A_k \in \mathcal{F}_k$ o sejam.
  Nessa definição podemos tomar uma coleção infinita.
\end{definition}

\begin{exercise}
  Em um espaço produto $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2, P_1 \otimes P_2)$, podemos definir
  \begin{equation}
    \begin{split}
      \bar{\mathcal{F}}_1 & = \{A \times \Omega_2; A \in \mathcal{F}_1\},\\
      \bar{\mathcal{F}}_2 & = \{\Omega_2 \times B; B \in \mathcal{F}_2\}.
    \end{split}
  \end{equation}
  Mostre que essas $\sigma$-álgebras são independentes.
\end{exercise}

Podemos extender o conceito de independência a elementos aleatórios.
Isto é
\begin{definition}
  Dizemos que $X_1, \dots, X_k$ são elementos aleatórios independentes se as respectivas $\sigma$-álgebras: $\sigma(X_1), \dots, \sigma(X_k)$ o forem.
\end{definition}

Quando $X_1, \dots, X_k$ são elementos aleatórios independentes e com a mesma distribuição, escrevemos que $X_i$ são i.i.d. (independentes e identicamente distribuídos).

\begin{exercise}
  Com a notação do exercício anterior, mostre que as funções $X_i:\Omega_1 \times \Omega_2 \to \Omega_i$ dadas por
  \begin{equation}
    X_1(x,y) = x \text{ e } X_2 (x,y) = y,
  \end{equation}
  são elementos aleatórios e são independentes.
\end{exercise}

\begin{exercise}
  Mostre que as coordenadas canônicas do exercício anterior no caso $X_i: \mathbb{R}^2 \to \mathbb{R}$ não são independentes segundo a medida $U_{S^1}$.
  Mas o são segundo $U_{[0,1]^2}$ (que é a medida de Lebesgue em $\mathbb{R}^2$ restrita a $[0,1]^2$).
\end{exercise}

\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ com $P(A) = \#A/2^n$ e $X_i(\omega_1, \dots, \omega_n) = \omega_i$ para $i = 1, \dots, n$.
  Mostre que os $X_i$ são independentes.
\end{exercise}

\begin{exercise}
  Sejam $(X_i)_{i \geq 1}$ elementos aleatórios independentes em espaços $(E_i)_{i \geq 1}$, respectivamente.
  Mostre que para funções mensuráveis $(f_i)_{i \geq 1}$ temos que $(f_i(X_i))_{i \geq 1}$ são independentes.
\end{exercise}

\begin{exercise}
  Mostre que se $X, Y$ são elementos aleatórios e se $X$ é constante quase certamente então $X$ e $Y$ são independentes.
\end{exercise}

\begin{lemma}[Borel-Cantelli - segunda parte]
  Se $A_1, A_2, \dots \in \mathcal{F}$ são independentes e $p_i = P(A_i)$ satisfazem $\sum_i p_i = \infty$, então
  \begin{equation}
    P[A_i \text{ infinitas vezes}] = 1.
  \end{equation}
\end{lemma}

\begin{proof}
  Queremos mostrar que
  \begin{equation}
    P \Big( \big(\mcap_n \mcup_{i=n}^\infty A_i\big)^c \Big) = 0,
  \end{equation}
  mas
  \begin{equation}
    P \Big( \big(\mcap_n \mcup_{i=n}^\infty A_i\big)^c \Big) = P \Big(\mcup_n \mcap_{i=n}^\infty A_i^c \Big) \leq \sum\limits_n P \Big(\mcap_{i=n}^\infty A_i^c \Big).
  \end{equation}
  Logo basta mostrar que a probabilidade à direita é zero para todo $n$.
  Mas
  \begin{equation}
    \begin{split}
      P \Big(\mcap_{i=n}^\infty A_i^c \Big) & = \prod\limits_{i=n}^\infty P(A_i^c) = \prod\limits_{i=n}^\infty (1 - p_i)\\
      & \leq \prod\limits_{i=n}^\infty \exp\{-p_i\} = \exp\big\{- \sum_{i=n}^\infty p_i\big\} = 0.
    \end{split}
  \end{equation}
  Terminando a prova do lemma.
\end{proof}

\newpage

\begin{exercise}
  Seja um espaço produto de medidas $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2, \mu_1 \otimes \mu_2)$ e defina a probabilidade $P$ atravéz de
  \begin{equation}
    \d P = \rho(x,y) \d (\mu_1 \otimes \mu_2).
  \end{equation}
  Mostre nesse caso que as coordenadas canônicas $X_1$ e $X_2$ são independentes se e somente se existem $\rho_1$ e $\rho_2$ em $\Omega_1$ e $\Omega_2$ respectivamente, tais que $\rho(x,y) = \rho_1(x) \rho_2(y)$ quase certamente com respeito a $\mu_1 \otimes \mu_2$.
\end{exercise}



\section{Espaços produto infinito}
\label{s:Omega_produto}

Dada uma coleção de espaços $E_1, E_2, \dots$, definimos o espaço produto
\begin{equation}
  \Omega = \bigtimes_{i\geq 1} E_i = \big\{(\omega_1, \omega_2, \dots); \omega_i \in E_i \text{ para todo $i \geq 1$}\big\}.
\end{equation}

Sejam $X_i:\Omega \to E_i$, definidos para $i = 1, 2, \dots$ por
\begin{equation}
  X_i(\omega_1, \omega_2, \dots) = \omega_i,
\end{equation}
que chamamos de coordenadas canonicas associadas ao produto $\Omega$.

Se cada $E_i$ é dotado de uma $\sigma$-álgebra $\mathcal{A}_i$, então definimos
\begin{equation}
  \mathcal{F} = \sigma(X_i; i \geq 1),
\end{equation}
que é claramente uma a $\sigma$-álgebra em $\Omega$.
Chamamos $\mathcal{F}$ de $\sigma$-álbegra canônica.

\begin{exercise}
  Mostre que em $(\mathbb{R}^{\mathbb{N}},\mathcal{F})$ temos que os conjuntos
  \begin{enumerate}
  \item $A = \{ \liminf_n X_n \text{ existe}\}$,
  \item $B = \{ \lim_n X_n = 4\}$ e
  \item $C = \{ \lim_n \tfrac{1}{n} X_n \text{ existe}\}$
  \end{enumerate}
  são todos mensuráveis (eventos) com respeito a $\mathcal{F}$.
  Além disso $Y = \1_A \liminf_n X_n$ é uma variável aleatória em $(\Omega, \mathcal{F})$.
\end{exercise}

\begin{exercise}
  Verifique que,
  \begin{enumerate}
  \item $\mathcal{F} = \sigma\big(A_1 \times \dots \times A_k \times E_{k+1} \times E_{k+2} \times \dots; k \geq 1, A_i \in \mathcal{A}_i, i \leq k\big)$, os chamados eventos retangulares e
  \item $\mathcal{F} = \sigma\big(A \times E_{k+1} \times E_{k+2} \times \dots; k \geq 1, A \in \mathcal{A}_i \otimes \dots \otimes \mathcal{A}_k\big)$ eventos cilíndricos.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Considere o grafo $(\mathbb{Z}^d, \mathcal{E})$, com $\mathcal{E} = \{ \{x,y\}; d(x,y) = 1 \}$, onde $d(x,y)$ representa a distância euclideana.
  Tome em $\Omega = \{0,1\}^\mathcal{E}$ a $\sigma$-álgebra produto e mostre que o seguinte conjunto é mensurável (ou seja é um evento)
  \begin{equation}
    \text{Perc} = \Big[
    \begin{array}{c}
      \text{existe uma sequência divergente $0 = x_0, x_1, \dots \in \mathbb{Z}^d$}\\
      \text{com $e_i = \{x_i, x_{i+1}\} \in \mathcal{E}$ e $X_{e_i} = 1$ para todo $i \geq 0$}
    \end{array}
\Big].
  \end{equation}
\end{exercise}

\begin{definition}
  Seja $\Omega = \bigtimes E_i$ um espaço produto (infinito ou finito) dotado de uma probabilidade $P$.
  Se $X_i$ é uma coordenada canônica, então chamamos a probabilidade $X_i \circ P$ de \emph{distribuição marginal} de $P$ na coordenada $i$.
\end{definition}

\begin{theorem}[Extensão de Kolmogorov]
  \label{t:extens_kolmog}
  Seja para cada $n \geq 1$ uma medida de probabilidade $P_n$ em $\mathbb{R}^n$ tal que seja satisfeita a seguinte condição de compatibilidade
  \begin{equation}
    \label{e:consist_kolmog}
    P_{n+1} (I_1 \times I_n \times \mathbb{R}) = P_n (I_1 \times \dots \times I_n), \text{ para $I_i = (-a_i, b_i]$, $i \leq n$}.
  \end{equation}
  Note que os intervalos do tipo $(-\infty, b_i]$, $(a_i, \infty)$ e $\mathbb{R}$ também são permitidos.
  Então existe uma única probabilidade $P$ no espaço produto infinito $(\Omega, \mathcal{F})$ tal que $P(A \times \mathbb{R} \times \dots) = P_n (A)$ para todo $n$ e todo boreliano $A$ de $\mathbb{R}^n$.
\end{theorem}

\begin{proof}
  Seja a seguinte classe de conjuntos
  \begin{equation}
    \mathcal{S} = \big\{I_1 \times \dots \times I_n \times \mathbb{R} \times \dots; n \geq 1 \text{ e } I_i = (a_i, b_i] \text{ para $i \leq n$} \big\}.
  \end{equation}
  Claramente, $\mathcal{S}$ é uma semi-álgebra, isto é,
  \begin{enumerate}
  \item se $A, B \in \mathcal{S}$, então $A \cap B \in \mathcal{S}$ e
  \item se $A \in S$, então $A^c = \bigcup_{i = 1}^k A_i$ para algum $k$ e $A_i \in \mathcal{S}$
  \end{enumerate}

  Definimos portanto $\mathcal{S}' = \big\{ \bigcup_{i=1}^k A_i; k \geq 1 \text{ e $A_i \in S$ disjuntos}\big\}$ que claramente é uma álgebra.
  Podemos agora colocar
  \begin{equation}
    P(A) = \sum_{i=1}^k P(A_i), \quad \text{para $A = \mcup_{i=1}^n A_i \in \mathcal{S}'$}.
  \end{equation}
  Note que essa definição independe da escolha da decomposição de $A$, já que $P_k$ é uma probabilidade em $\mathbb{R}^k$.

  Gostaríamos agora de utilizar o teorema da extensão de Carathéodory.
  Para tanto, precisamos mostrar que
  \begin{equation}
    \text{se $A = \mcup_{i=1}^\infty A_i \in \mathcal{S}' \;\;$ é uma união disjunta, então $\;\; \textstyle{P(A) = \sum\limits_{i=1}^\infty P(A_i)}$}.
  \end{equation}

  Definimos o ``resto da união'' por
  \begin{equation}
    B_n = A \setminus \mcup_{i=1}^n A_i.
  \end{equation}
  Claramente
  \begin{enumerate}
  \item $B_n \downarrow \varnothing$ e
  \item $B_n \in \mathcal{S}'$, pois $\mathcal{S}'$ é uma álgebra.
  \end{enumerate}

  Logo podemos escrever a união disjunta $A = \bigcup_{i=1}^n A_i \cup B_n$ e por definição
  \begin{equation}
    P(A) = \sum_{i=1}^n P(A_i) + P(B_n),
  \end{equation}
  de forma que basta mostrar que
  \begin{equation}
    \label{e:B_n_cont_vazio}
    \lim_n P(B_n) = 0.
  \end{equation}

  Supondo por contradição que $P(B_n) \downarrow \delta > 0$, gostaríamos de mostrar que sua interseção não pode ser vazia.
  Como $B_n \in \mathcal{S}'$, podemos escrever
  \begin{equation}
    B_n = \mcup_{i=1}^{l_n} \;\; (a_1^i, b_1^i] \times \dots \times (a_{l_n}^i, \dots, b_{l_n}^i] \times \mathbb{R} \times \dots
  \end{equation}
  onde a união acima é disjunta e os intervalos são possivelmente ilimitados.
  Podemos obviamente supor que
  \begin{equation}
    \label{e:l_n_monotona}
    \text{$l_n$ são não-decrescentes e tendem a infinito.}
  \end{equation}

  A fim de obter um ponto na interseção de $B_n$, gostaríamos de aproximá-lo usando conjuntos compactos.
  Para tanto definimos os conjuntos $C_n$ tais que $\widebar{C_n} \subseteq B_n$ e
  \begin{equation}
    C_n = \mcup_{i=1}^{l_n} \;\; \big(\tilde a_1^i, \tilde b_1^i\big] \times \dots \times \big(\tilde a_{l_n}^i, \tilde b_{l_n}^i\big] \times \mathbb{R} \times \dots
  \end{equation}
  com $\tilde a_j^i$ e $\tilde b_j^i$ finitos, de forma que
  \begin{equation}
    P(B_n \setminus C_n) \leq \frac{\delta}{2^{l_n + 1}},
  \end{equation}
  o que pode ser feito graças à continuidade de $P_{l_n}$.


  Introduzindo $D_n = \bigcap_{i=1}^n C_i$, temos
  \begin{equation}
    P(B_n \setminus D_n) \leq \sum_{i=1}^n P(B_n \setminus C_i) \leq \frac{\delta}2,
  \end{equation}
  donde $\lim_n P(D_n) \geq \delta/2$.
  De forma que os $D_n$ são encaixados e não vazios.

  Escrevemos,
  \begin{equation}
    \begin{split}
      C_n & = C_n^* \times \mathbb{R} \times \mathbb{R} \times \dots\\
      D_n & = D_n^* \times \mathbb{R} \times \mathbb{R} \times \dots,
    \end{split}
  \end{equation}
  onde $C_n^*, D_n^* \subseteq \mathbb{R}^{l_n}$ e
  \begin{equation}
    D_n^* = \underbrace{C_n^*}_{\mathclap{\text{pré-compacto}}} \mcap \Big( \mcap_{i=1}^{n-1} C_i^* \times \mathbb{R}^{l_n - l_i} \Big),
  \end{equation}
  de forma que os $D_n^*$ são pré-compactos e não vazios.

  Para cada $n \geq 1$ considere um $\omega^n \in D_n^* \subseteq \mathbb{R}^{l_n}$.
  Usando um argumento de diagonal de Cantor, podemos obter um $\omega \in \Omega$ e uma sub-sequência de $\omega^{n_j}$ que convirja para $\omega \in \Omega$ coordenada a coordenada (observe que $\omega^{n_j} \in \mathbb{R}^{l_{n_j}}$).
%  Tomando subsequências se necessário, podemos supor que $\omega^n$ converge coordenada a coordenada a um certo $\omega \in \Omega$.

  Para terminar a contradição, vamos mostrar que $\omega \in \bigcap_m B_m$.
  Fixado $m \geq 1$, para obter $\omega = (\omega_1, \omega_2, \dots) \in B_m$, basta ver que $\omega \in \widebar{C_m} = \widebar{C_m^*} \times \mathbb{R} \times \dots$
  Mas como $(\omega_1, \dots, \omega_{l_m})$ são o limite (com $n_j \geq m$) de $(\omega^{n_j}_1, \dots, \omega^{n_j}_{l_m}) \in C_m^*$, então é óbvio que $\omega \in \widebar{C_m}$, terminando a prova do teorema por contradição.
\end{proof}

\begin{example}
  Se $(\Omega_i, \mathcal{F}_i, P_i)$ são espaços de probabilidade, podemos definir $\mathbb{P}_n = \bigotimes_{i=1}^n P_i$ (relembrando, $\mathbb{P}_n$ é a única distribuição em $\Omega_1 \times \dots \times \Omega_n$ tal que $\mathbb{P}_n(A_1 \times \dots \times A_n) = \prod_{i=1}^n P_i(A_i)$).
  Não é difícil verificar que essa lei satisfaz as equações de consistência \eqref{e:consist_kolmog}.
  Desta forma, podemos construir uma única $\mathbb{P}$ em $\bigtimes_{i \geq 1} \Omega_i$ para os quais as coordenadas canônicas $X_i$ são independentes e possuem distribuições marginais $P_i$.
  Denotamos nesse caso $\mathbb{P} = \bigotimes_{i \geq 1} P_i$.
\end{example}

\begin{exercise}
  Mostre que se $p > 0$ e $\mathbb{P} = \bigotimes_{i \geq 1} \Ber(p)$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n = 1$ quase certamente.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $\mathbb{P} = \bigotimes_{i \geq 1} U_{[0,1]}$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n = 1$ quase certamente.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $\mathbb{P} = \bigotimes_{i \geq 1} \Exp(i)$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n < \infty$ quase certamente.}
  \end{equation}
\end{exercise}

\newpage

\section{Espaços canônicos}


\begin{definition}
  Uma função $\phi:E \to E'$ entre dois espaços mensuráveis é dita bi-mensurável quando $\phi$ é mensurável e injetiva, $\phi(E)$ for mensurável e a sua inversa $\phi^{-1}:f(E) \to E$ também for mensurável.
\end{definition}

\begin{definition}
  Dizemos que o espaço mensurável $(E, \mathcal{A})$ é canônico se existe uma função $\phi: E \to \mathbb{R}$ bi-mensurável.
\end{definition}

\begin{theorem}
  Sejam $E_1, E_2, \dots$ espaços mensuráveis canônicos.
  Então o Teorema~\ref{t:extens_kolmog} (da extensão de Kolmogorov) também é válido no espaço produto $\Omega = E_1 \times E_2 \times \dots$ se a condição de consistência \eqref{e:consist_kolmog} for válida com $I_j$ substituídos por eventos quaiquer em $E_j$.
\end{theorem}

\begin{proof}
  Sejam $\phi_i: E_i \to \mathbb{R}$ bijeções bi-mensuráveis e defina $\psi_n: E_1 \times \dots \times E_n \to \mathbb{R}^n$ por $\psi_n(\omega_1, \dots, \omega_n) = \big(\phi_1(\omega_1), \dots, \phi_n(\omega_n)\big)$.
  Assim podemos introduzir as medidas de probabilidade
  \begin{equation}
    \bar{P_n} = \psi_n \circ P_n, \text{ em $\mathbb{R}^n$}.
  \end{equation}
  É fácil verificar que as $\bar P_n$ são consistentes como em \eqref{e:consist_kolmog}.
  Logo, existe $\bar{P}$ em $(\mathbb{R}^\mathbb{N}, \mathcal{F})$ extendendo $\bar{P_n}$.

  Finalmente, consideramos o mapa $\Phi: \bigtimes_{i=1}^\infty \phi_i(E_i) \to \Omega$ dado por
  \begin{equation}
    \Phi(\phi_1(\omega_1), \phi_2(\omega_2), \dots) = (\omega_1, \omega_2, \dots).
  \end{equation}
  Resta mostrar que a medida $P = \Phi \circ \bar{P}$ extende as probabilidades $P_n$:
  \begin{equation}
    \begin{split}
      P\big(A_1 \times \dots & \times A_n \times E_{n+1} \times \dots\big) = \bar{P} \big(\Phi^{-1}(A_1 \times \dots \times A_n \times E_{n+1} \times \dots)\big)\\
      & = \bar{P} \big( \phi_1(A_1) \times \dots \times \phi_n(A_n) \times \phi_{n+1}(E_{n+1}) \times \dots \big)\\
      & = \bar{P}_n (\phi_1(A_1) \times \dots \times \phi_n(A_n))\\
      & = P_n \big(\psi_n^{-1}\big(\phi_1(A_1) \times \dots \times \phi_n(A_n)\big)\big) = P_n(A_1 \times \dots \times A_n),
    \end{split}
  \end{equation}
  concluindo a prova do teorema.
\end{proof}

A seguir daremos um exemplo de espaço canônico que é importante para a seção seguinte.

\begin{lemma}
  \label{l:NN_canonico}
  O espaço produto $E = \mathbb{N} \times \mathbb{N} \times \dots$, dotado da $\sigma$-álgebra produto é canônico.
\end{lemma}

\begin{proof}
  Primeiramente definimos em $E$ a métrica de Hamming:
  \begin{equation}
    \label{e:hamming_distance}
    d(x,y) = \sum_{i \geq 1} \frac{1}{2^{i + 1}} \1_{x_i \neq y_i}.
  \end{equation}
  Fica como exercício mostrar um homeomorfismo entre $(E,d)$ e um boreliano de $\mathbb{R}$.
\end{proof}

\subsection{Espaços poloneses}

Nessa seção mostraremos que uma grande coleção de espaços conhecidos são canônicos.

\begin{definition}
  Um espaço métrico $(E,d)$ é dito polonês se é separável e completo.
\end{definition}

\begin{example} \mbox{}
  \begin{enumerate}
  \item Todo espaço enumerável $\Omega$ pode ser feito em um espaço métrico polonês de forma que a $\sigma$-álgebra de Borel seja $\mathcal{P}(\Omega)$.
  \item $\mathbb{R}^n$ e $C([0,1])$ são notoriamente poloneses.
  \end{enumerate}
\end{example}

\begin{lemma}
  Se $(E_i, d_i)$ são espaços métricos poloneses para $i = 1, 2, \dots$ então $E = \bigtimes_i E_i$ com a métrica
  \begin{equation}
    \label{e:metrica_produto}
    d(x,y) = \sum_i \frac{1}{2^{i+1}} \frac{d_i(x_i, y_i)}{1 + d_i(x_i, y_i)}
  \end{equation}
  também é polonês.
\end{lemma}

\begin{proof}
  Exercício.
\end{proof}

Outros exemplos de espaços poloneses são dados pelo seguinte lema, que também será útil para provar o resultado principal desta seção.

\begin{lemma}
  \label{l:sub_polones}
  Seja $(E,d)$ um espaço polonês e $G, F \subseteq E$ um aberto e um fechado de $E$ respectivamente.
  Então, existe uma métrica $d'$ em $F \cap G$ tal que
  \begin{enumerate}
  \item $d$ e $d'$ são equivalentes (induzem a mesma noção de convergência),
  \item $d(x,y) \leq d'(x,y)$ para todo $x, y \in F \cap G$ e
  \item $(F \cap G, d')$ é polonês.
  \end{enumerate}
\end{lemma}

\begin{proof}
  A primeira observação simple é que $F \cap G$ é separável com respeito a $d$.
  Isso segue do fato de separabilidade ser equivalente à existência de uma base enumerável.

  Vamos definir em $G \times G$
  \begin{equation}
    d'(x,y) = d(x,y) + \Big| \frac{1}{d(x,G^c)} - \frac{1}{d(y,G^c)} \Big|,
  \end{equation}
  onde $d(x,A) = \inf\{d(x,x'); x' \in A\}$.

  Não é difícil ver que com a definição acima (e deixamos como exercício) que
  \begin{enumerate}
  \item as métricas $d$ e $d'$ são equivalentes em $G$,
  \item $F \cap G$ é separável quando dotado da métrica $d'$,
  \item $(F \cap G, d')$ é completo.
  \end{enumerate}
\end{proof}


\begin{example}
  Um importante exemplo é dado por espaços produto.
  Sejam $(E_i, d_i)$ espaços poloneses para $i \geq 1$ e introduza em $E = \bigtimes_i E_i$ a métrica $d$ definida em \eqref{e:metrica_produto}.
  Então, se $A_1 \subseteq E_1$, $\dots$, $A_k \subseteq E_k$ forem abertos, o retângulo $R = A_1 \times \dots \times A_k \times E_{k+1} \times \dots$ é aberto.
  Dessa forma vemos que tanto $R$ como $R^c$ podem ser dotados de métricas com as quais se tornam espaços poloneses.
  Além disso tais métricas podem ser escolhidas satisfazendo as hipóteses do Lema~\ref{l:sub_polones}
\end{example}

\begin{lemma}
  \label{l:particao_polones}
  Seja $(E, d)$ um espaço polonês e $r > 0$.
  Então existe uma partição $A_0, A_1, \dots$ de $A$ e métricas $d_0, d_1, \dots$ nesses respectivos subconjuntos de forma que para todo $i \geq 0$,
  \begin{enumerate}
  \item $(A_i, d_i)$ são espaços poloneses disjuntos,
  \item $d_i$ e $d$ são equivalentes em $A_i$ e $d_i \geq d$ e finalmente
  \item o diâmetro de $A_i$ (com respeito a $d$) é menor ou igual a $r$.
  \end{enumerate}
  Observe que alguns (possivelmente infinitos) $A_i$ podem ser vazios.
\end{lemma}

\begin{proof}
  Obtemos atravéz da separabilidade de $E$, uma coleção de bolas $(B_i)_{i \geq 0}$ com diâmetros limitados por $r$ e cobrindo $E$.
  Então definimos
  \begin{equation}
    A_0 = B_0, \quad \text{e} \quad A_n = B_n \setminus \mcup_{i=0}^{n-1} B_i \quad \text{para $n \geq 1$.}
  \end{equation}

  Agora podemos dotar cada um dos $A_i$ com a métrica $d_i$ obtida pelo Lema~\ref{l:sub_polones} (observe para tanto que os $A_i$ são dados por interseções de um aberto com um fechado).
  As propriedades enunciadas no lema são trivialmente satisfeitas.
\end{proof}

\begin{theorem}
  Todo espaço polonês $(E, d)$ é canônico.
\end{theorem}

\begin{proof}
  Pelo Lema~\ref{l:NN_canonico}, basta construir uma função bi-mensurável $\phi:E \to \mathbb{N}^\mathbb{N}$ e depois compô-la com uma função bi-mensurável $\phi':\mathbb{N}^\mathbb{N}$.

  Para começar, construiremos uma partição encaixada de $E$.
  Mais precisamente, defina os conjuntos de índice
  \begin{equation}
    M_n = \mathbb{N}^n \quad \text{para $n \geq 1$ e} \quad M = \cup_n M_n.
  \end{equation}

  Vamos definir borelianos $A_m$ de $E$ e métricas $d_m$ em $A_m$ para cada $m \in M$.
  Faremos isso da seguinte forma:
  \begin{enumerate}
  \item se $m = i \in M_1$, então definimos $A_1, A_2, \dots$ e $d_1, d_2, \dots$ como no Lema~\ref{l:particao_polones} com $r = 1$,
  \item se $(A_m, d_m)$ já foi definido para algum $m \in I_n$, então utilizamos o Lema~\ref{l:particao_polones} com $r = 1/n$ para particionar o conjunto $A_m$ (com a métrica $d_m$) em $A_{(m,1)}, A_{(m,2)}, \dots$ com suas respectivas métricas $d_{(m,1)}, d_{(m,2)}, \dots$
  \end{enumerate}
  Obviamente suporemos que são válidas as propriedades de tais métricas garantidas pelo Lema~\ref{l:particao_polones}.

  Podemos desde já definir $\phi:E \to \mathbb{N}^\mathbb{N}$ e para tanto, considere $x \in E$.
  Indutivamente
  \begin{enumerate}
  \item como $\{A_m\}_{m \in M_1}$ formam uma partição de $E$, podemos definir $\phi_1(x)$ como sendo o único índice tal que $x \in A_{\phi_1(x)}$,
  \item se já encontramos $\phi_1(x), \dots, \phi_n(x)$ tal que $x \in A_{(\phi_1(x), \dots \phi_n(x))}$, então o fato que particionamos o último conjunto na definição de $A_m$, $m \in M_{n+1}$ nos garante que podemos definir unicamente $\phi_{n+1}(x)$ de forma a continuar a indução.
  \end{enumerate}
  Da maneira acima já obtivemos $\phi(x) = (\phi_1(x), \phi_2(x), \dots)$.

  Para terminar, devemos mostrar que $\phi$ é bi-mensurável.

  Isso começa com a prova de que $\phi$ é injetiva.
  Se $\phi(x) = \phi(y)$, então existe uma sequência $m_n \in M_n$ tal que $x, y \in A_{m_n}$ para todo $n$.
  Mas isso não é possível dado que o diâmetro de $A_{m_{n+1}}$ é menor ou igual a $1/n$ na métrica $d_{m_n} \geq d$.
  Isso mostra que $x = y$.

  Vejamos agora que $\phi$ é mensurável.
  %Lembramos que em $\mathbb{N}^\mathbb{N}$ colocamos a métrica de Hamming definida em \eqref{e:hamming_distance}).
  Seja $w \in \mathbb{N}^\mathbb{N}$ tal que $\phi(x) = w$ e tome $G \subseteq \mathbb{N}^\mathbb{N}$ com $G = \{(w_1, \dots, w_l)\} \times \mathbb{N}^\mathbb{N}$ (esses conjuntos geram a $\sigma$-álgebra canônica em $\mathbb{N}^\mathbb{N}$).
  Claramente, $\phi^{-1}(G) = A_{(\phi_1(x), \dots, \phi_l(x))}$, de forma que mostramos que $\phi$ é mensurável.

  Para mostrar que $\phi^{-1}:\phi(E) \to E$ é mensurável, veremos que ela é de fato contínua.
  Dado $n \geq 1$, tomamos $\delta < 2^{-n}$.
  Se $w, w' \in \phi(E)$ são tais que $d(w, w') < \delta$ em $\mathbb{N}^\mathbb{N}$, então $w_i = w'_i$ para todo $i \leq n$, de forma que $\phi^{-1}(w)$ e $\phi^{-1}(w')$ pertencem a $A_{(w_1, \dots, w_n)}$.
  A continuidade de $\phi^{-1}$ segue do fato que o diâmetro de $A_{(w_1, \dots, w_n)}$ é no máximo $1/n$ (com respeito a $d_{(w_1, \dots, w_n)}$ e portanto com respeito a $d$).

  Vale lembrar que precisamos mostrar que $\phi(E)$ é mensurável.
  Para tanto, afirmamos que
  \begin{equation}
    \label{e:phiE_mensur}
    \phi(E) = \mathbb{N}^\mathbb{N} \setminus \mcup_{w_1, \dots, w_k} \{w_1\} \times \{w_k\} \times \mathbb{N} \times \dots,
  \end{equation}
  onde a união acima é tomada sobre todos $k \geq 1$ e $w_1, \dots, w_k$ tais que $A_{w_1, \dots, w_k}$ é vazio.
  A igualdade acima implica a mensurabilidade de $\phi$ instantaneamente.

  Dado $w \in \phi(E)$ existe $x \in E$ tal que $\phi(x) = w$.
  Como $x \in A_{w_1, \dots, w_n}$ para todo $n \geq 1$, esses conjuntos não são vazios.
  Logo $w$ não pertence à união em \eqref{e:phiE_mensur}, mostrando o lado ($\subseteq$) da inclusão.
  Finalmente, suponha que $w = (w_1, w_2, \dots)$ é tal que para todo $k \geq 1$, $A_{w_1, \dots, w_k} \neq \varnothing$.
  Tomamos portanto $x_k \in A_{w_1, \dots, w_k}$, com $k \geq 1$ e vamos mostrar que
  \begin{equation}
    \text{$(x_k)_{k \geq n}$ é Cauchy em $A_{w_1, \dots, w_n}$ para todo $n$.}
  \end{equation}
  De fato, dado $n \geq 1$, temos que, para todo $k \geq n + 1$, $x_k \in A_{w_1, \dots, w_{n+1}}$ (cujo $d_{w_1, \dots, w_{n}}$-diâmetro é menor que $1/n$), logo $x_k$ é uma sequência de Cauchy em $A_{w_1, \dots, w_n}$ com sua respectiva distância.
  Tomamos $x = \lim_n x_k$ com respeito à distância $d$ e para terminar a prova do teorema, basta motrar que $\phi(x) = w$, ou em outras palavras,
  \begin{equation}
    \label{e:x_in_Aw}
    x \in \mcap_n A_{w_1, \dots, w_n}, \text{ para todo $n \geq 1$.}
  \end{equation}
  Mas claramente
  \begin{enumerate}
  \item $x \in A_\varnothing = E$ e
  \item se $x \in A_{w_1, \dots, w_n}$, então como $x_k$ é Cauchy em $A_{w_1, \dots, w_{n+1}}$, temos que $x_k$ converge a um certo $x' \in A_{w_1, \dots, w_{n+1}}$ na métrica $d_{w_1, \dots, w_{n+1}}$.
    Como essa métrica é equivalente a tanto $d_{w_1, \dots, w_n}$ quanto $d$ em $A_{w_1, \dots, w_n}$, temos que $x = x' \in A_{w_1, \dots, w_n}$.
  \end{enumerate}
  Isso conclui por indução a prova de \eqref{e:x_in_Aw} e consequentemente do teorema.
\end{proof}

\newpage

\section{Probabilidades condicionais}

\begin{definition}
  Se $(\Omega, \mathcal{F}, P)$ é espaço de probabilidade e $B \in \mathcal{F}$ é tal que $P(B) > 0$, então definimos a probabilidade $P(\cdot | B): \mathcal{F} \to [0,1]$ por
  \begin{equation}
    \label{e:P_condicional}
    P(A | B) = \frac{P(A \cap B)}{P(B)},
  \end{equation}
  chamada probabilidade condicional dado o evento $B$.
\end{definition}

Obviamente $P(\cdot | B)$ é uma probabilidade em $(\Omega, \mathcal{F})$ e podemos entendê-la de duas formas: como uma normalização ou como uma tentativa de sucesso.
Explicaremos abaixo cada uma dessas interpretações.

Quando restringimos o espaço amostral $\Omega$ ao conjunto $B$ (como em $P(A \cap B)$), temos uma sub-probabilidade, isto é possivelmente $P(\Omega \cap B) < 1$.
Logo podemos entender o denominador de \eqref{e:P_condicional} como uma normalização para obtermos novamente uma probabilidade.

Mas a interpretação mais natural de \eqref{e:P_condicional} é dada pela seguinte proposição.
Para enunciá-la, considere $(\Omega, \mathcal{F}, P)$ um espaço de probabilidade e defina o produto
\begin{equation}
  \bar{\Omega} = \bigtimes_{i=1}^\infty \Omega, \qquad \bar{\mathcal{F}} = \bigotimes_{i=1}^\infty \mathcal{F} \quad \text{e} \quad \bar P = \bigotimes_{i=1}^\infty P.
\end{equation}
Na verdade tal produto está bem definido mesmo quando $\Omega$ não é canônico, mas deixaremos isso pra uma outra vez.

\begin{proposition}
  Na situação acima, seja $B \in \mathcal{F}$ com $P(B) > 0$ e defina $T:\bar{\Omega} \to \mathbb{N}$ por $T(\omega) = \inf \{n \geq 1; X_n(\omega) \in B\}$, onde os $X_n$ são as coordenadas canônicas. Então $T < \infty$ quase certamente e
  \begin{equation}
    \text{$X_{T(\omega)}(\omega)$ é um elemento aleatório em $\Omega$ com distribuição $P(\cdot | B)$.}
  \end{equation}
\end{proposition}

A intuição desta proposição é que se repetimos o experimento $(\Omega, \mathcal{F}, P)$ independentemente até obter uma amostra em $B$, essa terá a distribuição condicional.

\begin{proof}
  Sejam os eventos $A_n = [X_n \in B]$, $n \geq 1$ que são claramente independentes segundo $\bar{P}$.
  Logo, como $\sum_n \bar{P}(A_n) = \sum_n P(B) = \infty$, temos pelo Lema de Borel-Cantelli (segunda parte) que $\bar{P}(\text{$A_n$ infinitas vezes}) = 1$, logo $T < \infty$ quase certamente.

  Para ver que $X_{T(\omega)}(\omega)$ é um elemento aletório, basta escrever
  \begin{equation}
    [X_{T} \in A] = \mcup_{t=1}^\infty [X_t \in A, T = t],
  \end{equation}
  e observar que tanto $[X_t \in A]$ quanto $[T = t] = [X_1 \not \in B, \dots, X_{t-1} \not \in B, X_t \in B]$ são mensuráveis.

  Finalmente podemos usar a decomposição (disjunta) acima para calcular
  \begin{equation}
    \begin{split}
      \bar{P}[X_T \in A] & = \sum_{t=1}^\infty \bar{P} [X_t \in A, T = t]\\
      & = \sum_{t=1}^\infty \bar{P} [X_t \in A, X_t \in B, X_s \not \in B \text{ for $s < t$}]\\
      & = \sum_{t=1}^\infty P(A \cap B) P(B^c)^{t-1} = \frac{P(A \cap B)}{1-P(B^c)} = P(A | B),
    \end{split}
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{exercise}
  Seja $\lambda > 0$ e $X \distr \Exp(\lambda)$ (lembrando $\d (X \circ P) = \lambda \exp\{- \lambda x\} \d x$).
  Mostre que as variáveis com distribuição exponencial não possuem memória, ou seja:
  \begin{equation}
    P[X > t + s | X > t] = P [X > s], \text{ para todo $s, t > 0$}.
  \end{equation}
  Ou em outras palavras, sabendo que $X$ é maior que $t$, a distribuição condicional de $X - t$ ainda é $\Exp(\lambda)$.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 2-5, Ex: 5, 10, 21, 22 (a) e (b).
\end{exercise}

\begin{exercise}
  Porta dos desesperados...
\end{exercise}

\begin{exercise}
  $P(\cdot|A|B) = P(\cdot|B|A)$.
\end{exercise}

\section{Regra de Bayes}

Frequentemente definimos um espaço de probabilidade atravéz de probabilidades condicionais.
Consideramos por exemplo um exame médico para detectar uma doença, nesse caso temos
\begin{equation}
  \Omega = \{(\text{doente}, +), (\text{doente}, -), (\text{saudável}, +), (\text{saudável}, -)\},
\end{equation}
com obviamente a $\sigma$-álgebra das partes.

Contudo, ao contrário do que fizemos anteriormente, não daremos probabilidades $p_\omega \in [0,1]$ para cada $\omega \in \Omega$.
Poderíamos por exemplo fornecer
\begin{equation}
  \label{e:exame_medico}
  P(\text{doente}) = 0.005, \quad P( + | \text{saudável}) = 0.01, \quad P( - | \text{doente}) = 0.05.
\end{equation}
Obviamente podemos obter as probabilidades dos complementos dos eventos acima.
As probabilidades acima podem ser facilmente estimadas num laboratório e as duas últimas são chamadas respectivamente de probabilidades de \emph{falso positivo} e \emph{falso negativo}.
Outra vantagem da representação em \eqref{e:exame_medico} é que as probabilidades descritas são mais ``compartimentadas'' no seguinte sentido.
Note que $P(\text{doente})$ somente depende da população em questão, enquanto as outras duas dependem apenas do exame e não da população.
Isso não pode ser dito das probabilidades de pontos individuais em $\Omega$.

Agora fica fácil construir nosso espaço de probabilidade escrevendo, para $r \in \{+, -\}$ e $e \in \{\text{saudável}, \text{doente}\}$,
\begin{equation}
  P(\{(r,e)\}) = P(r \cap e) = P(r | e) P(e).
\end{equation}
E as probabilidades do lado direito da equação acima estão todas determinadas em \eqref{e:exame_medico} (possivelmente tomando complementos).

Contudo, o que estamos interessado muitas vezes é em como interpretar resultados de um exame.
Por exemplo, quanto vele $P(\text{doente} | +)$?
Isso nos é fornecido em geral pela regra de Bayes enunciada na seguinte

\begin{proposition}
  Se $A_1, A_2, \dots$ formam uma partição (finita ou não) de $\Omega$ e $B \in \mathcal{F}$ tem probabilidade positiva, então
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{\sum_j P(A_j) P(B | A_j)}.
  \end{equation}
\end{proposition}

\begin{proof}
  Basta notar que
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{P(B)} = \frac{P(A_i) P(B | A_i)}{\sum_j P(B \cap A_j)} = \frac{P(A_i) P(B | A_i)}{\sum_j P(A_j) P(B | A_j)}.
  \end{equation}
\end{proof}

\begin{exercise}
  Utilize a fórmula acima para calcular $P(\text{doente} | +)$ com os dados em \eqref{e:exame_medico}.
  Comente o resultado.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 1, Ex: 18 e 19.
\end{exercise}

\newpage

\section{Esperança}

\begin{definition}
  Se $X$ é uma variável aleatória com $\int_\Omega |X| \d \omega < \infty$, dizemos que $X$ é integrável e definimos
  \begin{equation}
    E(X) = \int_\Omega X(\omega) P(\d \omega),
  \end{equation}
  a chamada esperança de $X$.
  Nesse caso também dizemos que $X \in \mathcal{L}^1$.
\end{definition}

Quando $X \geq 0$, também podemos supor que $E(X)$ está bem definida, mesmo que possivelmente tomando valor infinito.

Não demonstraremos algumas propriedades conhecidas da integração de Lebesgue, tais como
\begin{enumerate}
\item $E(X + \alpha Y) = E(X) + \alpha E(Y)$ (se estiverem bem definidas),
\item Valem os Teoremas de Convergência (Monótona e Limitada).
\end{enumerate}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^1$ e $P[X > x] = 0$, então $E(X) \leq x$.
\end{exercise}

\begin{lemma}
  A esperança de uma variável aleatória $X \in \mathcal{L}^1$ depende somente de sua distribuição.
  Mais precisamente
  \begin{equation}
    E(X) = \int x (X \circ P) (\d x).
  \end{equation}
\end{lemma}

\begin{proof}
  Vamos mostrar que
  \begin{equation}
    E\big(f(X)\big) = \int f(x) (X \circ P) (\d x),
  \end{equation}
  para toda $f: \mathbb{R} \to \mathbb{R}$ mensurável tal que $f(X) \in \mathcal{L}^1$.

  Para $f = \1_A$, temos
  \begin{equation}
    E\big(f(X)\big) = P[X \in A] = (X \circ P) (A),
  \end{equation}
  por definição de $X \circ P$.

  Agora podemos extender o teorema para funções $f$ simples por linearidade, depois para funções positivas usando o Teorema da Convergência Monótona e finalmente escrevemos $x = x \1_{[0, \infty)} - (-x) \1_{(-\infty,0)}$.
\end{proof}

Vamos mostrar uma fórmula bastante simples de integração de variáveis tomando valores em um conjunto enumerável.
Se $X \in \{x_1, x_2, \dots\}$ $P$-quase certamente, então
\begin{equation}
  \begin{split}
    E(X) & = \int_\Omega X P(\d \omega) = \int \sum_i \1_{[X = x_i]} X P(\d \omega) + \int_{\{x_1, x_2, \dots\}^c} X P(\d \omega)\\
    & = \sum_i \int_{[X = x_i]} x_i P(\d \omega) + 0 = \sum_i x_i P[X = x_i].
  \end{split}
\end{equation}

Para nos acostumar à notação de probabilidade, vamos agora mostrar o mesmo resultado da seguinte forma
\begin{equation}
  \begin{split}
    E(X) & = E\Big(\sum_i X \1_{[X = x_i]}\Big) + E(X \1_{\{x_1, x_2, \dots\}^c})\\
    & = \sum_i E[X; X = x_i] + 0 = \sum_i x_i P[X = x_i].
  \end{split}
\end{equation}
Que é certamente muito útil quando nos habituamos a ela.

Observe que acima usamos a notação $E[X; \mathcal{Q}] = E(X \1_{[\mathcal{Q}]})$.
Também utilizaremos $E[X; \mathcal{Q}_1, \mathcal{Q}_2, \dots] = E(X \1_{[\mathcal{Q}_1, \mathcal{Q}_2, \dots]})$

\begin{example}
  Se $X \overset{d}\sim \Ber(p)$, então $E(X) = 0 \cdot P[X = 0] + 1 P[X = 1] = 0 + p = p$.
\end{example}

\begin{example}
  Seja $X \overset{d}\sim \Bin(n,p)$, então, para calcular $E(X)$, basta calcular $E(Y)$ onde $X \overset{d}\sim Y$.
  Como vimos anteriormente, se $Z_1, Z_2, \dots, Z_n$ são variáveis i.i.d. (relembrando: independentes e identicamente distribuídos) com $Z_1 \overset{d}\sim \Ber(p)$, então $Y = \sum_i Z_i \overset{d}\sim \Bin(n,p)$.
  Logo
  \begin{equation}
    E(X) = E(Y) = \sum_i E(Z_i) = n p.
  \end{equation}
\end{example}

Se $d(X \circ P) = \rho(x) \d x$ (com $\rho \geq 0$ e $\int \rho(x) \d x = 1$), então
\begin{equation}
  E(X) = \int x (X \circ P)(\d x) = \int x \rho(x) \d x.
\end{equation}

\begin{example}
  Se $X \overset{d}\sim U_{[0,1]}$, então $d(X \circ P) = \1_{[0,1]} \d x$, donde $E(X) = \int_0^1 x \d x = 1/2$.
\end{example}

\begin{proposition}
  \label{p:espera_acumulada}
  Se $X \geq 0$ $P$-q.c., então
  \begin{equation}
    E(X) = \int_0^\infty P[X > x] \d x) = \int_0^\infty 1 - F(x) \d x.
  \end{equation}
\end{proposition}

\begin{proof}
  \begin{equation}
    \begin{split}
      E(X) & = E \Big( \int_0^X 1 \d x \Big) = E \Big( \int_0^\infty \1_{[x < X]} \d x \Big)\\
      & \overset{\text{Fubini}}= \int_0^\infty E(\1_{[x < X]}) \d x = \int_0^\infty P[x < X] \d x.
    \end{split}
  \end{equation}
\end{proof}

\begin{example}
  Se $X \overset{d}\sim \Exp(\lambda)$, então
  \begin{equation}
    P[X \geq x] = \int_x^\infty \lambda e^{-\lambda t} \d t = e^{-\lambda x},
  \end{equation}
  donde
  \begin{equation}
    E(X) = \int_0^\infty e^{-\lambda x} \d x = \frac{1}{\lambda}.
  \end{equation}
\end{example}

\begin{exercise}
  Se $X \in \mathcal{L}^1$ e $P[X \geq x] = P[X \leq -x]$ para todo $x \geq 0$, então $E(X) = 0$.
\end{exercise}

\subsection{Desigualdade de Markov}

\begin{theorem}
  Se $X \geq 0$ $P$-q.c., então para todo $x > 0$,
  \begin{equation}
    P[X \geq x] \leq \frac{E(X)}{x}.
  \end{equation}
\end{theorem}

\begin{proof}
  Sabemos que $X \geq x \1_{[X \geq x]}$, logo
  \begin{equation}
    E(X) \geq x E(\1_{[X \geq x]}) = x P[X \geq x],
  \end{equation}
  que termina a prova.
\end{proof}

\begin{example}
  Sejam $n$ patos e $m$ caçadores.
  Cada caçador escolhe um pato aleatorea e uniformemente e atira (abatendo-o com probabilidade $p$).
  Seja $X = \# \{\text{patos vivos}\}$, que pode ter uma distribuição complicada de calcular, mas
  \begin{equation}
    \begin{split}
      E(X) &= E \Big( \sum_{i=1}^n \1_{[\text{pato $i$ vive}]} \Big) = \sum_{i=1}^n P[\text{pato $i$ vive}]\\
      &= n P[\text{pato $1$ vive}] = P\Big( \mcap_{j=1}^m [\text{caçador $j$ não mata pato $1$}] \Big)\\
      &= n P[\text{caçador $j$ não mata pato $1$}]^m = n \Big(1 - \frac{p}{n}\Big).
    \end{split}
  \end{equation}
  Observe que
  \begin{enumerate}
  \item acima obtivemos uma igualdade e
  \item $[\text{pato $i$ vive}]$, $i = 1, \dots, n$ não são independentes.
  \end{enumerate}

  Finalmente estimamos (digamos para $n$ par)
  \begin{equation}
    \begin{split}
      & P[\text{patos para o jantar} \leq n/2] = P[X \geq n/2] \leq \frac{E(X)}{n/2}\\
      & \qquad = 2 \frac{n}{n} \Big( 1 - \frac{p}{n}\Big)^m \leq 2 \exp \{- \frac{pm}{n}\}.
    \end{split}
  \end{equation}
\end{example}


\newpage

\subsection{Esperança e independência}

\begin{proposition}
  Sejam $X$ e $Y$ variáveis aleatórias independentes e em $\mathcal{L}^2$, então
  \begin{equation}
    E(XY) = E(X) E(Y).
  \end{equation}
\end{proposition}

\begin{proof}
  Obviamente o resultado acima é válido para funções indicadoras, pois $\1_A \1_B = \1_{A \cap B}$.
  Por linearidade, o resultado também vale para funções simples e usando o Teorema da Convergência Monótona podemos extendê-lo para funções positivas.
  Finalmente, decompomos $X = X_+ - X_-$ e $Y = Y_+ - Y_-$ e lembramos que ambas estão em $\mathcal{L}^2$ para concluir a prova.
\end{proof}

\begin{exercise}
  Mostre que $E(XY)$, $E(X/Y)$, $E(X + Y)$... dependem apenas da distribuição de $(X,Y) \in \mathbb{R}^2$.
\end{exercise}

\section{Variância}


Na seção anterior, limitamos $P[X > a]$ usando $E(X)$ (se $X \geq 0$).
Esse método é chamado de \emph{método do primeiro momento}, de acordo com a seguinte
\begin{definition}
  Dada uma variável aleatória $X$, definimos o seu $k$-ésimo momento como $E(X^k)$, para $k = 1, 2, \dots$
\end{definition}

Então, por exemplo, se $X \in \mathcal{L}^k$ e $X \geq 0$, podemos estimar
\begin{equation}
  P[X \geq x] = P [X^k \geq x^k] \leq \frac{E(X^k)}{x^k}, \text{ para qualquer $k \geq 1$.}
\end{equation}
Observe que quando o $k$-ésimo momento de $X$ é finito, a razão acima decai mais rápido quando $x$ diverge.

\begin{exercise}
  Mostre uma fórmula análoga à da Proposição~\ref{p:espera_acumulada}.
\end{exercise}

\begin{exercise}
  Mostre que se a distribuição de $X \in \mathcal{L}^2$ tem densidade $\rho$, então
  \begin{equation}
    E(f(X)) = \int f(x) \rho(x) \d x.
  \end{equation}
\end{exercise}

Um caso bastante importante ocorre quando $k = 2$, por várias razões que descreveremos abaixo.

Digamos que estamos interessados em aproximar uma variável aleatória por uma constante de forma a minimizar o erro da aproximação.
Uma possível formulação desse problema é encontrar $a$ de forma a minimizar
\begin{equation}
  E\Big( (X - a)^2 \Big) = E(X^2) - 2 a E(X) + a^2.
\end{equation}
Essa equação obviamente possui um único mínimo em $a = E(X)$.
Ao erro da aproximação acima damos o nome de variância

\begin{definition}
  Dada uma variável aleatória $X \in \mathcal{L}^2$, definimos sua variância como
  \begin{equation}
    \Var(X) = E \Big( \big(X - E(X)\big)^2 \Big) = E(X^2) - E(X)^2.
  \end{equation}
\end{definition}

Observe pelas definições alternativas dadas acima que
\begin{enumerate}
\item $\Var(X) \geq 0$ e
\item $E(X^2) \geq E(X)^2$.
\end{enumerate}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^2$, então $\Var(X) = 0$ se e somente se $X = a$ quase certamente.
\end{exercise}

Obviamente
\begin{equation}
  \Var(a X) = E(a^2 X^2) - E(aX)^2 = a^2 \Var(X).
\end{equation}

Podemos alternativamente entender a variância da seguinte meneira.
Sejam $X$ e $Y$ variáveis aleatórias independentes em $\mathcal{L}^2$ de mesma distribuição.
Então,
\begin{equation}
  E\big( (X - Y)^2 \big) = E(X^2) - 2 E(XY) + E(X^2) = E(X^2) - E(X)^2 = \Var(X).
\end{equation}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^2$, então $\Var(X + b) = \Var(X)$.
\end{exercise}

\begin{exercise}
  Calcule $Var(X)$ quando $X$ tem distribuições $\Ber(p)$, $U[0,1]$ ou $\Exp(\lambda)$.
\end{exercise}

A seguinte proposição mostra que a variância é uma maneira de estimar o quanto uma variável aleatória se desvia de sua média.
\begin{proposition}
  Se $X \in \mathcal{L}^2$ e $a > 0$, então
  \begin{equation}
    P [ |X - E(X)| > a] \leq \frac{\Var(X)}{a^2}.
  \end{equation}
\end{proposition}

\begin{proof}
  A desigualdade segue trivialmente da cota de Markov, ao observarmos que
  \begin{enumerate}
  \item $|X - E(X)| \geq 0$,
  \item $|X - E(X)| > a$ se e somente se $|X - E(X)|^2 > a^2$ e
  \item $E\big(|X - E(X)|^2\big) = E\big((X - E(X))^2\big) = \Var(X)$.
  \end{enumerate}
\end{proof}


Para variáveis aleatórias de média zero, a variância nada mais é que $E(X^2)$, ou em outras palavras $\lVert X \rVert^2_2$, o quadrado de sua norma em $\mathcal{L}^2$.
Isso nos motiva a olhar mais de perto para o produto interno em $\mathcal{L}^2$, que se traduz a $E(XY)$.
Mas para não nos restringirmos a variáveis de média zero, introduzimos a seguinte

\begin{definition}
  Se $X, Y$ são variáveis em $\mathcal{L}^2$, definimos
  \begin{equation}
    \Cov(X,Y) = E\Big( \big(X - E(X)\big) \big(Y - E(Y)\big) \Big) = E(XY) - E(X)E(Y).
  \end{equation}
\end{definition}

Uma observação importante é que
\begin{equation}
  \text{se $X$ e $Y$ em $\mathcal{L}^2$ são independentes, então $\Cov(X,Y) = 0$.}
\end{equation}

\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $\mathbb{R}^2$.
  Já vimos que elas não são independentes sob a distribuição $U_{S^1}$.
  Mostre que mesmo assim $\Cov(X_1, X_2) = 0$.
\end{exercise}

Uma outra propriedade bastante importante da variância é que ela se comporta bem com somas, no seguinte sentido
\begin{proposition}
  Se $X_1, \dots, X_n$ são variáveis em $\mathcal{L}^2$, então
  \begin{equation}
    \Var(X_1 + \dots + X_n) = \sum_{i=1}^n \Var(X_i) + \sum_{i \neq j} \Cov(X_i, X_j).
  \end{equation}
  Em particular, se as variáveis $X_i$ forem independentes duas a duas, então
  \begin{equation}
    \Var(X_1 + \dots + X_n) = \sum_{i=1}^n \Var(X_i).
  \end{equation}
\end{proposition}

\begin{proof}
  Basta fazer o tedioso desenvolvimento
  \begin{equation}
    \begin{split}
      \Var\Big(\sum_i X_i\Big) & = E \Big( \Big(\sum_i X_i - E\Big(\sum_i X_i\Big)\Big)^2\Big)\\
      & = E \Big( \Big(\sum_i X_i - E(X_i)\Big)^2\Big)\\
      & = \sum_{i, j = 1}^n E \big(X_i - E(X_i)\big) E\big(X_j - E(X_j)\big),
    \end{split}
  \end{equation}
  o que termina a prova ao separarmos $i = j$ de $i \neq j$.
\end{proof}

\begin{exercise}
  Calcule $\Var(X)$ quando $X \overset{d}\sim \Bin(n, p)$.
\end{exercise}


Definimos a distribuição geométrica de parâmetro $p \in (0,1]$ por
\begin{equation}
  \Geo(p) = \sum_{i = 1}^\infty \delta_i (1-p)^i p.
\end{equation}

\begin{exercise}
  Calcule $E(X)$ quando $X \overset{d}\sim \Geo(p)$.
\end{exercise}

\begin{exercise}
  Calcule $\lim_{p \to 0} F_p(x)$ onde $F_p$ é a função de distribuição acumulada de $p X_p$ com $X_p \overset{d}\sim \Geo(p)$.
  Você reconhece esse limite?
\end{exercise}

\begin{exercise}
  \label{x:geo_time}
  Sejam $Y_i$, para $i \geq 1$ i.i.d. com distribuição $\Ber(p)$ e defina
  \begin{equation}
    T = \inf\{i; Y_i = 1\}.
  \end{equation}
  Mostre que $T \overset{d}\sim \Geo(p)$.
\end{exercise}

\section{Lei fraca dos grandes números}

\begin{theorem}
  \label{t:lei_fraca}
  Se $X_1, X_2, \dots$ são i.i.d.s em $\mathcal{L}^2$ e definimos
  \begin{equation}
    S_n = \sum_{i=1}^n X_i,
  \end{equation}
  então para todo $\varepsilon > 0$
  \begin{equation}
    \lim_{n \to \infty} P \Big[\Big| \frac{S_n}{n} - E(X_1)\Big| > \varepsilon \Big] = 0.
  \end{equation}
  Ou seja, $\tfrac{S_n}{n} \to E(X_1)$ em medida (que também chamamos de ``em probabilidade'').
\end{theorem}

\begin{proof}
  Sabemos que
  \begin{equation}
    P \Big[\Big| \frac{S_n}{n} - E(X_1)\Big| > \varepsilon \Big] \leq \frac{\Var(\tfrac{S_n}{n})}{\varepsilon^2},
  \end{equation}
  pois $E(S_n/n) = 1/n E(X_1 + \dots + X_n) = E(X_1)$.

  Mas como $\Var(S_n/n) = 1/n^2 \Var (X_1 + \dots + X_n) = n/n^2 \Var(X_1)$, temos o resultado.
\end{proof}

Observe que nós apenas utilizamos que as variáveis $X_i$ eram independentes duas a duas.


\newpage

\begin{corollary}
  Se $A_1, A_2, \dots$ são eventos independentes dois a dois com $P(A_i) = p \in [0,1]$ para todo $i$, então
  \begin{equation}
    \lim_{n \to \infty} P \Big[ \Big| \frac{\#\{i \leq n; \omega \in A_i\}}{n} - p \Big| > \varepsilon \Big] = 0,
  \end{equation}
  ou em outras palavras a proporção de ensaios onde o evento $A_i$ ocorre converge em probabilidade para $p$.
\end{corollary}

\begin{proof}
  Basta tomar $X_i = \1_{A_i}$ no Teorema~\ref{t:lei_fraca}.
\end{proof}

\todo{explicar o ditado dos ``ovos no mesmo cesto''}

\section{Método do segundo momento}

Vimos como a Lei Fraca dos Grandes Números seguiu de uma estimativa de segundo momento (mais precisamente usando a variância).

Nessa seção iremos mostrar como esse método é mais geral, se aplicando mesmo em situações onde as variáveis não são necessariamente independentes duas a duas.

\subsection{Aplicação em grafos aleatórios}

Seja $V_n = \{1, \dots, n\}$ com $n \geq 3$ e $\mathcal{E}_n = \big\{ \{x,y\} \subseteq V_n; x \neq y \big\}$.
Chamamos o par $(V_n, \mathcal{E}_n)$ de grafo completo em $n$ vértices.

Definimos em um certo espaço de probabilidade $P_n$, as variáveis aleatórias $(X_e)_{e \in \mathcal{E}_n}$ de maneira i.i.d. com distribuição $\Ber(p)$, onde $p \in [0,1]$.
Essas variáveis induzem um subgrafo aleatório $(V_n, \mathcal{E}_n')$, onde
\begin{equation}
  \mathcal{E}_n' = \big\{ e \in \mathcal{E}_n; X_e = 1 \big\}.
\end{equation}
Dizemos que os elos $e$, tais que $X_e = 1$ são abertos.

Definimos nesse espaço a variável aleatória
\begin{equation}
  T_n = \#\big\{\text{triângulos em $(V_n, \mathcal{E}_n')$}\big\}.
\end{equation}
Essa variável claramente pode ser escrita como
\begin{equation}
  T_n = \sum_{x,y,z \in V_n \text{ distintos}} \1_{A_{\{x,y,z\}}},
\end{equation}
onde $A_{\{x,y,z\}} = \big[\text{\{x,y,z\} formam um triângulo em $(V_n, \mathcal{E}_n')$}\big]$.

Gostaríamos de entender algo sobre a distribuição de $T_n$ e começamos calculando
\begin{equation}
  \begin{split}
    E^n(T_n) & = \sum_{\{x,y,z\} \text{ distintos}} P^n(A_{\{x,y,z\}})\\
    & = \binom{n}{3} p^3 = \frac{n(n-1)(n-2)}{6}p^3.
  \end{split}
\end{equation}
Logo, $P[T_n > a] \leq n(n-1)(n-2)p^3/6a$.
Mais ainda,
\begin{equation}
  \begin{split}
    E^n(T_n^2) & = \sum_{\{x,y,z\} \text{ distintos}} \quad \sum_{\{x',y',z'\} \text{ distintos}} P^n(A_{\{x,y,z\}} \cap A_{\{x',y',z'\}})\\
    & = \underbrace{\binom{n}{6} \binom{6}{3} p^6}_{\text{todos distintos}} + \underbrace{\binom{n}{5} \binom{5}{3} \binom{3}{1} p^6}_{\text{$1$-comum}} + \underbrace{\binom{n}{4} \binom{3}{2} \binom{4}{3} p^5}_{\text{$2$ em comum}} + \underbrace{\binom{n}{3}p^3}_{\text{iguais}}
  \end{split}
\end{equation}
Donde
\begin{equation}
  \Var^n(T_n) = \frac{1}{36} n^6 p^6 - \frac{1}{36} n^6 p^6 + c n^5 p^5 + ... \leq c (n^5 p^5 + n^3 p^3),
\end{equation}
para todos $p \in [0,1]$ e $n \geq 1$ se escolhemos bem a constante $c > 0$.

Isso nos permite por exemplo estimar o que acontece em alguns regimes, como por exemplo, se $p = 1/2$, então
\begin{equation}
  E^n(T_n) = \frac{n(n-1)(n-2)}{48},
\end{equation}
que cresce como $n^3$, e $\Var^n(T_n) \leq c n^5$, logo
\begin{equation}
  P^n\Big[ \Big|T_n - E^n(T_n)\Big| > \varepsilon n^3 \Big] \leq \frac{\Var^n(T_n)}{\varepsilon^2 n^6} \leq \frac{c}{\varepsilon^2 n}.
\end{equation}

\newpage

\section{Distribuições conjuntas}

\newpage

\section{Lei forte dos grandes números}

\begin{theorem}[Lei Forte dos Grandes Números]
  \label{t:LFGN}
  Sejam $X_1, X_2, \dots$ i.i.d. em $\mathcal{L}^1$, com $m = E(X_1)$.
  Então,
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n X_n = m, \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

Antes de começar a prova, buscando inspiração no Teorema das Três Séries, mostraremos que basta considerar versões truncadas das variáveis $X_i$.
Isso é feito no próximo

\begin{lemma}
  \label{l:LFGN}
  Sejam $Y_i = X_i \1_{[|X_i| \leq i]}$.
  Então, para demonstrar o Teorema~\ref{t:LFGN}, basta provar que
  \begin{equation}
    \lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n Y_i = m, \text{ $P$-quase certamente.}
  \end{equation}
\end{lemma}

\begin{proof}[Prova do Lema~\ref{l:LFGN}]
  Consideramos os eventos $A_i = [X_i \neq Y_i]$.
  Obviamente,
  \begin{equation}
    \sum_i P(A_i) = \sum_i P[|X_i| \geq i] \leq \int_0^\infty P[|X_i| \geq t] \d t = E\big(|X_i|) < \infty.
  \end{equation}
  Logo, pelo Lema de Borel-Cantelli, temos que $P$-quase certamente $A_i$ acontece apenas finitas vezes.
  Digamos que $A_i$ não acontece para $i > N(\omega)$.
  Dessa forma, para qualquer $n \geq 1$,
  \begin{equation}
    \Big|\frac{1}{n}\sum_{i=1}^n (X_i - Y_i)\Big| \leq \frac{1}{n}\sum_{i=1}^n |X_i - Y_i| \leq \frac{1}{n} \sum_{i \leq N(\omega)} |X_i|,
  \end{equation}
  que converge para zero $P$-quase certamente, mostrando o resultado.
\end{proof}

O próximo passo para a prova da Lei Forte dos Grandes Números é cuidar da esperança das novas variáveis $Y_i$.
\begin{lemma}
  \label{l:lim_Z_n_LFGN}
  Sejam $Z_i = Y_i - E(Y_i)$, para $i \geq 1$ como acima.
  Então, para demosntrar o Teorema~\ref{t:LFGN}, basta mostrar que
  \begin{equation}
    \label{e:lim_Z_n_LFGN}
    \lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n Z_i = 0, \text{ $P$-quase certamente.}
  \end{equation}
\end{lemma}

\begin{proof}
  Supondo a convergência em \eqref{e:lim_Z_n_LFGN}, sabemos que
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n Y_i - E(Y_i) = 0, \text{ $P$-quase certamente.}
  \end{equation}
  Mas $E(Y_i) = E(X_i \1_{[|X_i| \leq i]})$ que converge a $E(X_i) = m$, pelo Teorema da Convergência Dominada, donde concluímos que
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n E(Y_i) = m.
  \end{equation}
  Dessa forma, obtemos que $\tfrac 1n \sum_{i=1}^n Y_i$ converge quase certamente a $m$, concluindo a prova do Teorema~\ref{t:LFGN} por meio do Lema~\ref{l:LFGN}.
\end{proof}

Gostaríamos de utilizar os teoremas das séries para mostrar a convergência de $\tfrac 1n \sum_{n} Z_n$, mas obviamente, o fator $\tfrac 1n$ que precede a soma nos impede de fazê-lo.
O próximo resultado é um simples exercício de análise real, que nos permite reduzir a prova de \eqref{e:lim_Z_n_LFGN} para uma simples convergência de uma série sem pré-fatores.

\begin{lemma}[Lema de Kronecker]
  Suponha que $x_n \in \mathbb{R}$ e $b_n > 0$ sejam tais que $b_n \uparrow \infty$ e $\sum_{i=1}^\infty \frac{x_i}{b_i}$ convirja a $s \in \mathbb{R}$.
  Então
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{b_n} \sum_{i=1}^n x_i = 0.
  \end{equation}
\end{lemma}

\begin{proof}
  Definindo $s_0 = 0$ e $s_n = \tfrac{x_1}{b_1} + \dots + \tfrac{x_n}{b_n}$, temos, por integração por partes,
  \begin{equation}
    \sum_{i=1}^n x_i = \sum_{i=1}^n b_i \frac{x_i}{b_i} = \sum_{i=1}^n b_i s_{i} - \sum_{i=1}^n b_i s_{i-1} = b_n s_n + \sum_{i=1}^{n-1} (b_{i} - b_{i+1}) s_{i}.
  \end{equation}
  Escolhemos agora, para qualquer $\varepsilon > 0$, um $n_0 \geq 1$ tal que $|s_n - s| < \varepsilon$ para todo $n \geq n_0$.
  Dessa forma,
  \begin{equation*}
    \begin{split}
      \frac{1}{b_n} \sum_{i=1}^n x_i & = s_n - \frac{1}{b_n}\sum_{i=1}^{n-1} (b_{i+1} - b_{i}) s_{i}\\
      & = s_n - \frac{1}{b_n}\underbrace{\sum_{i=1}^{n_0-1} (b_{i+1} - b_{i})}_{\Delta_{n_0}} s_{i} - \frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_{i}) s_{i}\\
      & = \underbrace{s_n}_{\to s} - \underbrace{\frac{1}{b_n}\Delta_{n_0}}_{\to 0} - \underbrace{\frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_i) s}_{= \tfrac{(b_n - b_{n_0})s}{b_n} \to s} - \underbrace{\frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_{i}) (s_{i} - s)}_{\leq \varepsilon\tfrac{(b_n - b_{n_0})}{b_n} \leq \varepsilon},
    \end{split}
  \end{equation*}
  onde os limites indicados acima representam o que acontece quando $n \to \infty$.
  A prova segue do fato de $\varepsilon$ ter sido escolhido arbitrariamente.
\end{proof}

Estamos agora em posição de finalizar a
\begin{proof}[Prova do Teorema~\ref{t:LFGN}]
  De acordo com o Lema de Kronecker e o Lema~\ref{l:lim_Z_n_LFGN}, é suficiente mostrar que
  \begin{equation}
    \sum_{i=1}^n \frac{Z_i}{i}, \text{ converge quase certamente}.
  \end{equation}
  Por outro lado, como os $Z_i$'s tem média zero, o Teorema de Uma Série diz que é suficiente mostrar que
  \begin{equation}
    \sum_{i=1}^n \Var\Big(\frac{Z_i}{i}\Big) = \sum_{i=1}^n \frac{1}{i^2} \Var(Z_i) < \infty.
  \end{equation}
  Isso segue da seguinte estimativa
  \begin{equation}
    \begin{split}
      \sum_{i=1}^n \frac{1}{i^2} \Var(Z_i) & = \sum_{i=1}^n \frac{1}{i^2} \Var(Y_i) \leq \sum_{i=1}^n \frac{1}{i^2} E\big( X_i^2 \1_{[|X_i| \leq i]}\big)\\
      & = \sum_{i=1}^n \frac{1}{i^2} \sum_{k=1}^{i} E\big( X_i^2 \1_{[k-1 < |X_i| \leq k]}\big)\\
      & = \sum_{k=1}^n E\big( X_1^2 \1_{[k-1 < |X_i| \leq k]}\big) \sum_{i=k}^{n} \frac{1}{i^2}\\
      & \leq 2 \sum_{k=1}^n \frac{1}{k} E\big( X_1^2 \1_{[k-1 < |X_i| \leq k]}\big)\\
      & \leq 2 \sum_{k=1}^n E\big( X_1 \1_{[k-1 < |X_i| \leq k]}\big) \leq 2E(X_1) < \infty.
    \end{split}
  \end{equation}
  Isso nos permite concluir a prova de \eqref{e:lim_Z_n_LFGN} via o Lema de Kronecker.
  Consequentemente, obtemos o Teorema~\ref{t:LFGN} via o Lema~\ref{l:lim_Z_n_LFGN}.
\end{proof}

\newpage

\section{Lei $\{0, 1\}$ de Kolmogorov}

Ao estudarmos o Lema de Borel-Cantelli, vimos que, se os eventos $(A_i)_{i \geq 1}$ são independentes, então a probabilidade de $[A_i \text{ infinitas vezes}]$ somente pode assumir os valores zero ou um (dependendo da somabilidade de $P(A_i)$).
Nessa seção iremos estudar outros tipos de evento que assumem apenas esses dois valores.
Esperamos que esse fenômeno se torne intuitivo ao final dessa discussão.

No que se segue, consideraremos um espaço mensurável $\Omega = \times_{i=1}^\infty E$, com a $\sigma$-álgebra canônica $\mathcal{F}$, isto é a $\sigma$-álgebra gerada pelas coordenadas canõnicas $(X_i)_{i=1}^\infty$.
\begin{definition}
  Dizemos que um evento $A \in \mathcal{F}$ é caudal se
  \begin{equation}
    A \in \sigma\big( X_i; i \geq n\big), \text{ para todo $n \geq 1$}.
  \end{equation}
  Também introduzimos a classe $\mathcal{F}_\infty$ de tais eventos, que claramente é uma $\sigma$-álgebra, pois pode ser escrita como
  \begin{equation}
    \mathcal{F}_\infty = \mcap_{n \geq 1} \sigma\big( X_i; i \geq n\big).
  \end{equation}
\end{definition}

Vejamos que, dados $A_i \in \sigma(X_i)$, $i \geq 1$, temos que $[A_i \text{ infinitas vezes}]$ é caudal.
Para tanto, basta observar que para todo $n \geq 1$, temos que
\begin{equation*}
  [A_i \text{ infinitas vezes}] = \big[\#\{i \geq 1; \omega \in A_i\} = \infty\big] = \big[\#\{i \geq n; \omega \in A_i\} = \infty\big],
\end{equation*}
que obviamente pertence a $\sigma(X_i; i \geq n)$.

\begin{exercise}
  Mostre que em $\Omega = \mathbb{R}^{\infty}$, são caudais os seguintes eventos
  \begin{enumerate}
  \item $[X_i \text{ converge}]$,
  \item $\big[\tfrac{1}{n} \sum_{i=1}^n X_i \text{ converge}\big]$ e
  \item $[\#\{i \geq 1; X_i > 0\} < \infty]$.
  \end{enumerate}
\end{exercise}

Podemos agora enunciar o pricipal teorema dessa seção

\begin{theorem}[Lei $\{0,1\}$ de Kolmogorov]
  Se $\Omega = E^{\infty}$, onde $E$ é um espaço canônico, for provido de uma lei produto $P = \otimes_{i=1}^\infty P_i$, então todo evento caudal tem probabilidade $0$ ou $1$ sob $P$.
\end{theorem}

Quando uma $\sigma$-álgebra $\mathcal{F}$ satisfaz $P(A) \in \{0,1\}$ para todo $A \in \mathcal{F}$, dizemos que $\mathcal{F}$ é trivial.
Uma outra maneira de enunciar a conclusão do teorema acima é dizer que a $\sigma$-álgebra caudal $\mathcal{F}_\infty$ é trivial.

\begin{proof}
  A idéia da prova, apesar de soar um pouco estranha, é mostrar que se $A \in \mathcal{F}_\infty$, então $A$ é independente de si mesmo.
  Em outras palavras, $P(A) = P(A \cap A) = P(A)^2$, donde $P(A) \in \{0,1\}$.
  Mas vamos com calma.

  Fixe $k \geq 1$, $A \in \mathcal{F}_\infty$ e $B \in \sigma(X_1, \dots, X_k)$.
  Nesse caso, como $A \in \sigma(X_{k+1}, X_{k+2}, \dots)$, temos que $A$ e $B$ são independentes.
  Fixe agora $A \in \mathcal{F}_\infty$ e considere a classe
  \begin{equation}
    \mathcal{B}_A = \{B \in \mathcal{F}; \text{ $B$ é independente de $A$}\}.
  \end{equation}
  Já sabemos que $\sigma(X_1, \dots, X_k) \subseteq \mathcal{B}_A$ para todo $k \geq 1$.

  Obviamente $\Omega$ é independente de $A$, assim como $B^c \in \mathcal{B}_A$ sempre que $B \in \mathcal{B}_A$.
  Além disso, suponha que $B_1, B_2, \dots$ in $\mathcal{B}_A$ são disjuntos, então,
  \begin{equation*}
    P\big( (\mcup_i B_i) \cap A \big) = P\big( \mcup_i (B_i \mcap A) \big) \overset{\text{disj.}}= \sum_i P(B_i \mcap A) \overset{\text{indep.}}= P(A) P(\mcup_i B_i).
  \end{equation*}
  Logo $\mathcal{B}_A$ é um $\lambda$-sistema.

  Lembrando que $\mathcal{B}_A$ contém o $\pi$-sistema $\bigcup_k \sigma(X_1, \dots, X_k)$, isto é dos eventos cilíndricos, temos que todos eventos são indepentes de $A$, inclusive o próprio $A$.
  Isso termina a prova do teorema.
\end{proof}

\section{Momentos exponenciais}

Nessa seção desenvolveremos uma outra técnica para estimar a probabilidade de uma variável aleatória se desviar de sua esperança.

Já vimos o método do primeiro, segundo e quarto momento para controlar uma soma de variáveis independentes.
Um exemplo disso foi visto na estimativa
\begin{equation}
  P\Big[ \sum_{i=1}^n (X_i - E(X_i)) \geq a \Big] \leq \frac{\sum_i \Var (X_i)}{a^2}.
\end{equation}

Em geral, quanto maior o momento, melhor a estimativa do decaimento para a probabilidade de que uma variável se desvie de sua esperança.
Nessa seção iremos para momentos exponenciais, que em um certo sentido produzem estimativas ótimas para o comportamento assintótico da probabilidade de desvio.

Note que se quisermos um erro pequeno mas considerável (como por exemplo $\sim 0.01$), o método do segundo momento é muito bom, como veremos posteriormente.
Mas se quisermos um erro realmente muito pequeno (em situações concretas, algo como $10^{-12}$ por exemplo), certamente teremos que aumentar bastante o valor de $n$, mas quanto?
As cotas de segundo momento são muito ruins para esse tipo de estimativa, nos levando a escolher um $n$ maior que o necessário.
Abaixo, desenvolveremos um método mais eficiente para responder a essa pergunta, obviamente sob certas hipóteses na distribuição das variáveis aleatórias.

\begin{definition}
  Dada uma variável aleatória $X$, definimos sua transformada de Laplace como
  \begin{equation}
    \phi_X(s) = E(\ex{s X}) \in (0, \infty],
  \end{equation}
  para todos $s \in \mathbb{R}$.
  Essa transformada também é chamada \emph{função geradora de momentos} de $X$.
\end{definition}

\begin{exercise}
  Calcule a função geradora de momentos das distribuições $\Ber(p)$, $\Exp(\lambda)$ e $U_{[0,1]}$.
\end{exercise}

\begin{proposition}
  \label{p:propried_phi}
  Se $E(\ex{\delta |X|}) < \infty$, então
  \begin{enumerate}
  \item $X \in \mathcal{L}^p$ para todo $p \geq 1$,
  \item $\phi_X(s) < \infty$ para todo $s \in (-\delta, \delta)$,
  \item $\phi_X(s)$ é $C^\infty$ em $(-\delta, \delta)$ e
  \item $\phi_X^{(n)}(s) = E(X^n \ex{sX})$.
  \end{enumerate}
\end{proposition}

A última conclusão da proposição acima justifica a nomenclatura \emph{função geradora de momentos}.

\begin{proof}
  Obviamente, para todo $p \geq 1$ existe $c > 0$ tal que $\ex{\delta |x|} \geq c |x|^p$, donde $X \in \mathcal{L}^p$.
  Além disso, para todo $s \in (-\delta, \delta)$, $\phi_X(s) = E(\ex{s X}) \leq E(\ex{\delta |X|}) < \infty$, donde \textit{2.} segue imediatamente.

  Fixando $s \in \mathbb{R}$, vamos agora calcular
  \begin{equation}
    \begin{split}
      \frac{\phi_X(s + h) - \phi_X(s)}{h} & = \frac{E\big(\ex{(s+h)X} - \ex{sX}\big)}{h}\\
      & = E\Big(\ex{sX} \frac{\ex{hX} - 1}{h}\Big).
    \end{split}
  \end{equation}
  Lembrando que $|\tfrac{1}{y}(e^y - 1)| \leq c e^{|y|}$, para todo $y \in \mathbb{R}$, temos que para $h < (\delta - |s|)/2$, o integrando acima é dominado por $c |X| \ex{\smash{\tfrac{\delta + |s|}{2} |X|}} \in \mathcal{L}^1$, logo podemos usar o Teorema da Convergência Dominada para trocar o limite $h \to 0$ com a esperança, obtendo
  \begin{equation}
    \phi_X'(s) = E(X \ex{sX}).
  \end{equation}

  Note que para todo $\varepsilon > 0$ e $k \geq 1$, $|x|^k \leq c(k) \ex{\varepsilon |x|}$, isso nos permite repetir o argumento acima indutivamente para obter \textit{3.} e \textit{4.}
\end{proof}

Lembramos que ao usarmos o método do segundo momento, nos foi bastante útil o fato que a variância se comporta bem com relação a somas independentes.
Mais precisamente, $\Var(X_1 + \dots + X_k) = \Var(X_1) + \dots + \Var(X_k)$.

Uma outra propriedade importante da função geradora de momentos é que ela se comporta bem com respeito à somas independentes.
\begin{proposition}
  Se $X_1, \dots, X_n$ são variáveis aleatórias independentes com $\phi_{X_i}(s) < \infty$ para todo $i \leq k$ e $|s| < \delta$, então
  \begin{equation}
    \phi_{X_1 + \dots + X_k}(s) = \phi_{X_1}(s) \dotsm \phi_{X_k}(s), \text{ para todos $|s| < \delta$.}
  \end{equation}
\end{proposition}

\begin{proof}
  Basta observar que
  \begin{equation}
    \begin{split}
      E(\exp & \{s(X_1 + \dots + X_k)\}) = E(\ex{sX_1} \dotsm \ex{sX_k}))\\
      & = E\big(\ex{sX_1}) \dotsm E(\ex{sX_k}\big) = \phi_{X_1}(s) \dotsm \phi_{X_k}(s),
    \end{split}
  \end{equation}
  usando Fubini.
\end{proof}

Consideraremos agora uma sequência $X_1, X_2, \dots$ de variáveis i.i.d. com $\phi_{X_1}(s) < \infty$ para $|s| < \delta$.
Então podemos tentar estimar, para $a > 0$ e $|s| < \delta$,
\begin{equation*}
  \begin{split}
    P \Big[ & \frac{X_1 + \dots + X_n}{n} - E(X_1) \geq a \Big] = P \Big[ X_1 + \dots + X_n \geq (a + E(X_1)) n \Big]\\
    & \quad = P \Big[ \ex{s(X_1 + \dots + X_n)} \geq \ex{s (a + E(X_1)) n}\Big]\\
    & \quad \leq \phi_{X_1 + \dots + X_n}(s) \ex{-s (a + E(X_1))n } = \phi_{X_1}^n(s) \ex{-s (a + E(X_1))n }.
  \end{split}
\end{equation*}
O primeiro fator na estimativa acima pode crescer exponencialmente com $n$, enquanto o segundo decresce.
Gostaríamos que o comportamento do segundo predominasse, o que podemos concluir do seguinte argumento.

Sabemos que $\phi_{X_1}(s)$ é diferenciável em zero e que $\phi'_{X_1}(0) = E(X_1)$.
Logo, existe $s > 0$ tal que $\phi_{X_1}(s) < 1 + (E(X_1) + \tfrac{a}{2}) s$, donde
\begin{equation*}
  \begin{split}
    P \Big[ & \frac{X_1 + \dots + X_n}{n} - E(X_1) \geq a \Big] = P \Big[ X_1 + \dots + X_n \geq (E(X_1) + a) n \Big]\\
    & \quad \leq \big(1 + (E(X_1) + \frac{a}{2})s \big)^n \ex{-s (E(X_1) + a)n }\\
    & \quad \leq \exp\Big\{ s \Big( E(X_1 + \frac{a}{2} - E(X_1) - a) n \Big) \Big\} = \ex{-san/2}.
  \end{split}
\end{equation*}
Isso nos garante um decaimento exponencial da probabilidade da média dos $X_i$ se desviar da esperança.

\begin{exercise}
  Aplique o método acima para variáveis $X_i$ i.i.d. com distribuição $\Ber(1/2)$ e encontre $s(a)$ que otimize o decaimento da probabilidade $P\big[\sum_{i=1}^n X_i > (1/2 + a) n \big]$.
\end{exercise}

Poderíamos nos perguntar se a cota acima é suficientemente boa.
Talvez pudéssemos esperar um decaimento ainda melhor que exponencial.
Para responder a essa pergunta, vamos considerar o seguinte exemplo.
Sejam $(X_i)_{i \geq 1}$ variáveis i.i.d. com $X_1 \distr \Ber(1/2)$.
Nesse caso temos por exemplo
\begin{equation}
  P\Big[ \big| \frac{X_1 + \dots + X_n}{n} - \frac 12 \big| \geq \frac 14\Big] \geq P[X_i = 1, \forall i \leq n] = 2^{-n}.
\end{equation}
Dessa forma, sabemos que não podemos esperar um decaimento melhor que exponencial, mesmo para variáveis bem simples (como Bernoulli) que satisfazem $\phi_X(s) < \infty$ para todo $s \in \mathbb{R}$.

Note que para variáveis com distribuição $\Ber(1/2)$, temos cotas exponenciais em $n$ (superior e inferior), mas elas possuem expoentes diferentes.
Resta agora tentar entender qual é o expoente correto para o decaimento da probabilidade $P[X_1 + \dots + X_n \geq n(E(X_1) + a)]$, o que será feito na próxima seção.

\newpage

\section{Princípio de Grandes Desvios}
\label{s:PGD}

A primeira tarefa nossa será otimizar a estimativa grosseira feita na seção anterior.
Essas estimativas são chamadas de \emph{estimativas de grandes desvios}, pois se referem a probabilidades que a média empírica de $X_i$ se desvie de sua esperança por um valor constante $a$.
Futuramente no curso estudaremos as probabilidades de que esse desvio seja de ordem $a_n \to 0$ que são chamados de \emph{desvios moderados} ou \emph{flutuações}, dependendo se a probabilidade de desvio converge a zero ou não.

\begin{theorem}[Princípio de Grandes Desvios - cota superior]
  \label{t:PGDleq}
  Sejam $X_1, X_2, \dots$ variáveis aleatórias i.i.d. tais que $\phi_{X_1}(s) < \infty$, para todo $s \in (-\delta, \delta)$.
  Então, para $a > 0$,
  \begin{equation}
    P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \leq \ex{-\psi_{X_1}(m + a) n},
  \end{equation}
  onde $m = E(X_1)$ e
  \begin{equation}
    \psi_{X_1}(b) = \sup_{s \geq 0} \big\{ bs - \log \big( \phi_{X_1}(s) \big) \big\}.
  \end{equation}
\end{theorem}

É importante observar que para estimar $P\big(X_1 + \dots + X_n \leq (m - a)n\big)$, basta considerarmos $X'_i = -X_i$ ao utilizar o teorema acima.

%Antes de provar o teorema, vamos fazer uma breve observação sobre como a função geradora de momentos se comporta com respeito a soma de constantes.
%Isso nos permitirá centrar as variáveis para nossas estimativas.
%
%\begin{lemma}
%  \label{l:phi_Xmaisb}
%  Seja $X$ uma variável aleatória tal que para algum $s_0 > 0$ tenhamos $\phi_{X}(s) < \infty$ para todo $s \in (-\delta, \delta)$.
%  Então
%  \begin{equation}
%    \log\big(\phi_{X - b}(s)\big) = \log\big(\phi_{X}(s)\big) -bs < \infty, \text{ para todo $s \leq s_0$.}
%  \end{equation}
%\end{lemma}

%\begin{proof}
%  Basta observar que
%  \begin{equation}
%    \phi_{X - b}(s) = E\big( \ex{s(X-b)} \big) = \ex{-sb} E\Big( \ex{sX}\Big) = \ex{-sb} \phi_X(s),
%  \end{equation}
%  e tomar logarítmos de ambos os lados para obter o resultado.
%\end{proof}

\begin{proof}
  Já sabemos que, para todo $s \geq 0$,
  \begin{equation}
    \begin{split}
      P\big[ X_1 & + \dots + X_n \geq \big(m + a \big) n \big] \leq \phi_{X_1}^n (s) \ex{-s (m + a) n}\\[1mm]
      & = \ex{ \log \big( \phi_{X_1}(s)\big) n - s(m + a) n}\\
      & = \ex{ - \big( (m + a)s - \log \big( \phi_{X_1}(s)\big) \big) n}\\
%      & \overset{\text{Lema}~\ref{l:phi_Xmaisb}\;\;}= & \ex{ \log \big( \phi_{X_1 - m}(s) \big) n - s a n}\\
%      & = & \ex{ - \big(as -\log \big( \phi_{X_1 - m}(s) \big) \big) n}
    \end{split}
  \end{equation}
  O que termina a prova do teorema se tomamos o ínfimo em $s \geq 0$.
\end{proof}

\begin{exercise}
  Calcule $\psi_X(a)$ quando $X$ é distribuída como $U_{[0,1]}$ e $\Exp(\lambda)$.
\end{exercise}

Vamos agora tomar um exemplo concreto para análise.
Sejam $X_1, X_2, \dots$ variáveis aleatórias i.i.d. com distribuição $\Ber(1/2)$, donde
\begin{equation}
  \phi_{X_1}(s) = \frac{1}{2} (1 + e^s) \quad \text{e} \quad \psi_{X_1}(b) = \sup_{s \geq 0} \{bs - \log(1 + e^s) + \log(2) \}.
\end{equation}
Um cálculo simples nos mostra que, se $b < 1$, o mínimo acima é atingido no único ponto $s_{\text{max}} = \log(\tfrac{b}{1-b})$.
Portanto, podemos concluir do Teorema~\ref{t:PGDleq} que
\begin{equation}
  \begin{split}
    P[X_1 + \dots & + X_n > 1/2 + a] \leq \ex{- \psi_{X_1}(s_{\text{max}})n}\\
    & = \exp\Big\{-n \Big(b \log(b) + (1-b)\log(1-b) + \log(2) \Big)\Big\}
  \end{split}
\end{equation}
Note que $P[X_1 + \dots + X_n = n] = 2^{-n} = \ex{-\log(2)n} = \ex{-\psi_{X_1}(1-)n}$.
Isso nos dá um forte indício de que talvez nossas cotas superiores não estejam tão longe de ser precisas.
Para confirmar essa hipótese, precisamos obter cotas inferiores parecidas.

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}[scale=3]
    \draw[->] (-0.2,0) -- (1.2,0) node[right] {$b$};
    \draw[-] (1,0.02) -- (1,-0.02) node[below] {$1$};
    \draw[-] (0.02,{ln(2)}) -- (-0.02,{ln(2)}) node[left] {$\log(2)$};
    \node[below left] at (0,0) {$0$};
    \draw[->] (0,-0.2) -- (0,1.1) node[above] {$\psi_{X}(b)$};
    \draw[domain=0.0001:0.9999,smooth,variable=\x,blue] plot ({\x},{\x*ln(\x) + (1 - \x)*ln(1 - \x) + ln(2)});
    \draw[->] (1.8,0) -- (3.2,0) node[right] {$b$};
    \draw[-] (3,0.02) -- (3,-0.02) node[below] {$1$};
    \node[below left] at (2,0) {$0$};
    \draw[->] (2,-0.2) -- (2,1.6) node[above] {$\psi_{X'}(b)$};
    \draw[domain=2.0001:2.9999,smooth,variable=\x,blue] plot ({\x},{(\x-2)*ln((\x - 2)/0.75) + (1 - \x + 2)*ln((1 - \x + 2)/(0.25))});
    \draw[-,dotted] (3,{ln(4/3)}) -- (1.98,{ln(4/3)}) node[left] {$\log(4/3)$};
    \draw[-] (2.02,{ln(4)}) -- (1.98,{ln(4)}) node[left] {$\log(4)$};
  \end{tikzpicture}
  \caption{Funções taxa $\psi_{X}(b)$ de uma variável $X$ com distribuição $\Ber(1/2)$, e $\psi_{X'}(b)$ de uma variável com distribuição $\Ber(3/4)$, para $b \in (0,1)$.}
\end{figure}

Antes de buscar cotas inferiores para as probabilidades de desvio, vamos estabelecer algumas propriedades da função $\psi_X(b)$.
Primeiramente, quando podemos dizer que o supremo na definição de $\psi_X$ é atingido em algum $s_{\text{max}}$?
Certamente, esse nem sempre é o caso, por exemplo se $X = m$ quase certamente, então $\phi_X(s) = e^{sm}$ e o supremo definindo $\psi_X(b)$ não é atingido se $b \neq m$.

\begin{lemma}
  \label{l:smax_PGD}
  Seja $X$ uma variável aleatória tal que $\phi_X(s) < \infty$ para todo $s \in (-\delta, \delta)$.
  Supondo $a \geq 0$ é tal que $P[X > m + a] > 0$, então existe $s_{\text{max}} \geq 0$ tal que $\psi_X(m + a) = (m + a)s_{\text{max}} - \log\big(\phi_X(s_\text{max})\big)$.
\end{lemma}

\begin{proof}
  Por hipótese, existe $b > m + a$ tal que $p = P[X \geq b] > 0$, donde $\phi_X(s) \geq p e^{s(m+a)}$.
  Dessa forma, $(m + a)s - \log\big( \phi_X(s) \big) \leq (m + a - b)s - \log(p)$, que converge a menos infinito quando $s$ diverge.
  Isso, junto com a continuidade de $\phi_X$ implica a existência do $s_{\text{max}}$ desejado.
\end{proof}

\begin{exercise}
  Suponha que se $\phi_{X}(s)$ é finita para todo $s \in (-\delta, \delta)$ e mostre que
  \begin{enumerate}
  \item na definição de $\psi_{X}(a)$, poderíamos tomar o ínfimo em todos $s \in \mathbb{R}$ (ao invéz de $s \geq 0$) sem mudar o valor de $\psi_X(a)$,
  \item a função $\psi_{X}(s)$ é não negativa, semi-contínua inferior e convexa em seu domínio e
  \item $\psi_X(a)$ se anula somente em $a = 0$ e $\psi_X$ é crescente no seu domínio.
  \end{enumerate}
\end{exercise}

Buscaremos agora cotas inferiores para a probabilidade de obter um grande desvio.
Gostaríamos que essas estimativas fossem o mais próximas possíveis das estimativas superiores obtidas acima.
Certamente não podemos obter algo como
\begin{equation}
  \label{e:PGDgeq_falso}
  `` P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \geq \exp\{-\psi_{X_1}(a) n\} ",
\end{equation}
pois senão isso nos daria uma igualdade o que é impossível, pois perdemos um pouco de precisão ao utilizar a desigualdade de Markov na cota superior.

Contudo, gostaríamos de entender se ao menos o expoente $\psi_{X_1}(a)$ na cota superior também desempenha algum papel na cota inferior.
Isso é confirmado no seguinte resultado

\begin{theorem}[Princípio de Grandes Desvios - cota inferior]
  \label{t:PGDgeq}
  Sejam $X_1, X_2, \dots$ variáveis aleatórias i.i.d. com $\phi_{X_1}(s) < \infty$, para todo $s \in \mathbb{R}$.
  Então, para todo $a > 0$,
  \begin{equation}
    \liminf_{n \to \infty} \frac{1}{n} \log P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \geq -\psi_{X_1}(m + a),
  \end{equation}
  onde novamente $m = E(X_1)$ e $\psi_{X_1}(b)$ é definida como no Teorema~\ref{t:PGDleq}.
\end{theorem}

Note que o resultado do teorema acima é mais fraco que o que vemos na equação \eqref{e:PGDgeq_falso}, mas mostra que $\psi_{X_1}(a)$ é realmente o expoente correto no decaimento da probabilidade de grandes desvios.

A idéia da prova é transformar a distribuição de $X_i$, usando uma exponencial como derivada de Radon-Nikodim.
Essa nova distribuição possuirá esperança maior $m + a$, de forma que se tomamos a média de variáveis i.i.d. $X'_1, \dots, X'_n$ distribuídas dessa forma, obteremos algo que se concentra acima de $m + a$.
Finalmente, o preço pago para que as variáveis $X_i$ se comportem como as $X'_i$ será aproximadamente $\ex{-\psi_{X_1}(m + a)}$, como desejado para nossa cota inferior.

\begin{proof}
  Primeiramente, consideraremos o caso $P[X_1 \leq m + a] = 1$.
  Nesse caso, temos
  \begin{equation*}
    \begin{split}
      P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] & = P[X_i = m + a, \text{ para todo $i \leq n$}]\\
      & = P[X_1 = m + a]^n.
    \end{split}
  \end{equation*}
  Donde o limite acima é igual a $\log(P[X_1 = m + a])$.

  Mas por outro lado,
  \begin{equation*}
    \begin{split}
      - \psi_{X_1}(m + a) & = \inf_{s \geq 0} \big\{ \log\big(E(\ex{s (X_1)})\big) - (m + a)s \big\} = \inf_{s \geq 0} \big\{ \log\big(E(\ex{s (X_1 - m - a)})\big) \big\}\\
      & \leq \liminf_{s \to \infty} \; \log\big(E(\ex{s (X_1 - m - a)})\big) = \log \big(P[X_1 = m + a]\big),
    \end{split}
  \end{equation*}
  pelo Teorema da Convergência Dominada, demonstrando o teorema nesse caso especial.

  Suponhamos agora que $P[X_1 > m + a] > 0$, o que implica que para $b > m + a$ suficientemente próximo de $m + a$, temos $P[X_1 > b] > 0$.
  Observe que basta mostrar que para tais $b$ e para todo $\delta > 0$,
  \begin{equation}
    \label{e:PGD_perto_b}
    \lim_n \frac{1}{n} \log \Big(P\Big[\frac{X_1 + \dots + X_n}{n} \in (b - \delta, b + \delta) \Big]\Big) \geq -\psi_{X_1}(b),
  \end{equation}
  pois a função $\psi_{X_1}(b)$ é convexa, portanto contínua.

  Vamos definir uma nova distribuição $\nu$ atravéz da derivada de Radon-Nikodim
  \begin{equation}
    \d \nu = \frac{1}{Z_\sigma} \ex{\sigma x} (X_1 \circ P) (\d x).
  \end{equation}
  Observamos primeiramente que o valor de $\sigma$ ainda não foi escolhido.
  Além disso após escolhido $\sigma$, teremos que calcular a constante de normalização $Z_{\sigma}$ de forma que $\nu$ seja uma probabilidade.

  Escolheremos $\sigma \geq 0$ como no Lema~\ref{l:smax_PGD}, isto é, tal que $\psi_{X_1}(b) = b\sigma - \log\big( \phi_{X_1}(\sigma) \big)$.
  Isso nos dá imediatamente que $Z_\sigma = E[\ex{\sigma X_1}] = \phi_{X_1}(\sigma)$.
  Por diferenciabilidade de $\phi_{X_1}$, o máximo deve ser assumido em um ponto de derivada zero, ou seja
  \begin{equation}
    b = \frac{\phi_{X_1}'(\sigma)}{\phi_{X_1}(\sigma)} \overset{\text{Prop.~\ref{p:propried_phi}}}= \frac{E(X \ex{\sigma X})}{E(\ex{\sigma X})} = \frac{E(X \ex{\sigma X})}{Z_\sigma} = \int x \nu(\d x).
  \end{equation}
  Isso implica que se uma variável aleatória tem distribuição $\nu$, sua esperança é $b$.
  Obviamente uma tal variável aleatória $X'$ satisfaz obrigatoriamente $\phi_{X'}(s) < \infty$ para todo $s \geq 0$, donde $X' \in \mathcal{L}^p$ para todo $p > 1$.

  Como prometido, consideramos variáveis $X_1', X_2', \dots$ i.i.d. com distribuição $\nu$.
  Pela lei fraca dos grandes números, para qualquer $\delta > 0$,
  \begin{equation}
    \lim_n P\Big[ \frac{X_1' + \dots + X_n'}{n} \in (b-\delta,b+\delta) \Big] = 1.
  \end{equation}

  Finalmente vamos relacionar essa probabilidade à probabilidade definida em termos de $X_i$, na qual estamos interessados.
  \begin{equation*}
    \begin{split}
      P\Big[ & \frac{X_1 + \dots + X_n}{n} \in (b-\delta, b+\delta) \Big] = \int_{x_i; \big| \tfrac{1}{n} \sum_{i \leq n} x_i - b\big| < \delta} \;\; \bigotimes_{i=1}^n (X_1 \circ P)(\d x_i)\\
      & = Z_\sigma^n \int_{x_i; \big| \tfrac{1}{n} \sum_{i \leq n} x_i - b \big| < \delta} \;\; \ex{-\sigma \textstyle{\sum_{i=1}^n x_i}} \bigotimes_{i=1}^n (X_1' \circ P)(\d x_i)\\[2mm]
      & \geq Z_\sigma^n \exp\{-(b + \delta) \sigma n\} P\Big[ \frac{X_1' + \dots + X_n'}{n} \in (b-\delta,b+\delta) \Big].
    \end{split}
  \end{equation*}
  Tomando o logarítmo, dividindo por $n$ e tomando o liminf quando $n$ vai a infinito, recuperamos
  \begin{equation}
    \begin{split}
      \lim_n \frac{1}{n} \log \Big(P\Big[ & \frac{X_1 + \dots + X_n}{n} \in (b - \delta,b +  \delta) \Big] \Big) \geq \log(Z_\sigma) - (b + \delta) \sigma\\
      & = \log(\phi_{X_1}(\sigma)) - (b + \delta) \sigma = -\psi_{X_1}(\sigma) - \delta \sigma.
    \end{split}
  \end{equation}
  Como isso vale para todo $\delta > 0$, provamos \eqref{e:PGD_perto_b} o que conclui a prova do teorema.
\end{proof}


\begin{exercise}
  Mostre o Teorema~\ref{t:PGDgeq} no caso em que $\phi_{X_1}(s) < \infty$, para todo $s \in (-\delta, \delta)$.
\end{exercise}

\newpage

\section{O Teorema Central do Limite}

Até esse momento, já estudamos bastante somas de variáveis aleatórias independentes.
Agora estudaremos esse tópico pela última vez, mas atravéz de uma técnica bastante elegante, que certamente inspira vários trabalhos em probabilidade.

\subsection{A distribuição normal}

Começaremos estudando de maneira sistemática o que acontece quando somamos duas variáveis aleatórias i.i.d. em termos de distribuição.
Isso pode ser visto como um operador no espaço de distribuições em $\mathbb{R}$ que definiremos a seguir.
Estaremos interessados nos pontos fixos de tal operador, mas antes, vamos fazer uma observação simples que evitará trivialidades.

\begin{lemma}
  Sejam $X$ e $Y$ variáveis aleatórias em $\mathcal{L}^2$, i.i.d. com distribuição $\mu$.
  Nesse caso, se $X + Y$ também tem distribuição $\mu$, então $\mu = \delta_0$.
\end{lemma}

\begin{proof}
  Sabemos que
  \begin{equation}
    \begin{split}
      E(X + Y) & = E(X) + E(Y) = 2 E(X) \text{ e}\\
      \Var(X + Y) & = \Var(X) + \Var(Y) = 2 \Var(X).
    \end{split}
  \end{equation}
  Mas como $X + Y$ tem a mesma distribuição de $X$, então $E(X) = 2 E(X)$ e $\Var(X) = 2 \Var(X)$, donde ambas são zero.
  Usando o método dos segundo momento, para todo $a > 0$,
  \begin{equation}
    P[|X| \geq a] \leq \frac{\Var(X)}{a^2} = 0,
  \end{equation}
  terminando a prova de que $X = 0$ quase certamente.
\end{proof}

A intuição dessa prova é que quando somamos duas variáveis não determinísticas, a incerteza da soma (medida atravéz da variância) tende a aumentar.
Dessa forma não podemos continuar com a mesma distribuição.

Mas existe uma maneira simples de tornar esse problema bastante interessante novamente.
Digamos que $X$ e $Y$ pertencem a $\mathcal{L}^2$ e são i.i.d.
Então
\begin{equation}
  \Var(X + Y) = 2 \Var(X) = \Var(\sqrt{2} X).
\end{equation}
Então podemos nos perguntar se

\begin{question}
  \label{q:ponto_fixo_soma}
  Existe alguma distribuição não trivial $\mu$ em $\mathcal{L}^2$ tal que, se $X$ e $Y$ são independentes e distribuídas de acordo com $\mu$, temos
  \begin{equation}
    \frac{X + Y}{\sqrt{2}} \distr \mu \; ?
  \end{equation}
\end{question}

Para tentar responder essa questão, vamos estudar mais a fundo qual é a distribuição da soma de duas variáveis aleatórias independentes.
Para isso, considere a distribuição $(X,Y) \circ P$ do par, que coincide com $\mu \otimes \mu$, nos dando
\begin{equation}
  P\Big[ \frac{X + Y}{\sqrt{2}} \leq z \Big] = \mu \otimes \mu \big( \big\{(x, y); \tfrac{x + y}{\sqrt{2}} \leq z \big\} \big).
\end{equation}

Note também que a transformação linear $(x,y) \mapsto \tfrac{1}{\sqrt{2}}\big(x + y, x - y\big)$ é uma rotação rígida em $\mathbb{R}^2$, o que nos motiva a propor a pergunta mais simples.

\begin{question}
  Existe alguma distribuição não trivial $\mu$ em $\mathcal{L}^2$ tal que, se $X$ e $Y$ são independentes e distribuídas de acordo com $\mu$, temos que a distribuição do par $(X,Y)$ é invariante por rotações?
\end{question}

Ainda estamos numa busca não rigorosa de tal distribuição, então vamos supor algumas outras propriedades, como por exemplo que $\mu$ seja absolutamente contínua com respeito a Lebesgue, isto é $\d \mu = f(x) \d x$.
Nesse caso, já vimos que $(X, Y) \circ f(x) f(y) \d x \d y$ e no fundo estamos procurando uma função $f$ tal que
\begin{equation}
  f(x) f(y) = h(x^2 + y^2), \text{ para todo $x, y \in \mathbb{R}$ e alguma $h: \mathbb{R}_+ \to \mathbb{R}_+$.}
\end{equation}
Se $g = \log f$ e $k = \log h$, no fundo buscamos $g(x) + g(y) = k(x^2 + y^2)$.
Como ainda não estamos preocupados com unicidade de $\mu$ por enquanto, apenas existência, podemos simplesmente tomar $g(x) = \alpha x^2 - \beta$.

Como gostaríamos que $f(x) = \ex{\alpha x^2 - \beta}$ fosse uma densidade, ou seja $\int f \d x = 1$.
Para isso, precisamos que $\alpha$ seja negativo e, fixado $\alpha$, o valor de $\beta$ já estará determinado por normalização.
Tudo isso motiva finalmente a seguinte

\begin{definition}
  Dizemos que $X$ tem distibuição normal canônica, se
  \begin{equation}
    \label{e:normal_canonica}
    X \distr \frac{1}{\sqrt{2 \pi}} \exp \big\{-x^2/2\big\} \d x.
  \end{equation}
  Além disso, para $m \in \mathbb{R}$ e $\sigma \geq 0$, dizemos que $Y \distr \mathcal{N}(m, \sigma^2)$ se $Y$ tem a mesma distribuição de $\sigma X + m$, onde $X$ tem distribuição normal canônica ($\mathcal{N}(0, 1)$).
\end{definition}

Muitas vezes chamamos essa distribuição de gaussiana, obviamente em homenagem a Gauss.
Note que $\mathcal{N}(m, 0) = \delta_m$.

Vamos rapidamente observar que a definição acima realmente descreve uma distribuição de probabilidade, ou seja que a integral da densidade acima é um.
Para tanto, vamos usar um truque conhecido, que consiste em retornar ao plano.
Obviamente,
\begin{equation}
  \begin{split}
    \Big(\int \exp \big\{-x^2/2\big\} \d x\Big)^2 & = \int \int \exp \big\{-(x^2 + y^2)/2\big\} \d x \d y\\
    & = \int_0^{2 \pi} \int_0^\infty \exp \{ - r^2 / 2 \} r \d r \d \theta \overset{2 s \; = \; r^2}= 2 \pi.
  \end{split}
\end{equation}
Donde a constante em \eqref{e:normal_canonica} está de fato correta.

\begin{exercise}
  Mostre que a distribuição $\mathcal{N}(m, \sigma^2)$, tem densidade
  \begin{equation}
    \frac{1}{\sigma \sqrt{2 \pi}} \ex{-(x - m)^2/(2 \sigma^2)}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $Y \distr \mathcal{N}(m, \sigma^2)$, então $Y$ tem esperança $m$ e variância $\sigma^2$.
\end{exercise}

Para confirmar que de fato as distribuições normais se comportam bem com respeito a somas independentes, apresentamos o seguinte resultado.

\begin{proposition}
  \label{p:soma_normais}
  Se $X \distr \mathcal{N}(m, \sigma^2)$ e $Y \distr \mathcal{N}(\bar{m}, \bar{\sigma}^2)$ são independentes, então $X + Y$ tem distribuição $\mathcal{N}(m + \bar{m}, (\sigma + \bar{\sigma})^2)$.
\end{proposition}

\begin{proof}
  O caso em que $\sigma$ ou $\bar{\sigma}$ se anulam é trivial, portanto vamos considerar que ambas são positivas.
  Não é difícil ver que podemos também supor que $m = \bar{m} = 0$.
  Podemos então calcular
  \begin{equation}
    P[X + Y \leq a] = P[\sigma W + \bar{\sigma} Z \leq a],
  \end{equation}
  onde $W$ e $Z$ são independentes com distribuição $\mathcal{N}(0,1)$.
  Assim, a probabilidade acima pode ser escrita como
  \begin{equation}
    \label{e:soma_normal}
    \mathcal{N}(0,1) \otimes \mathcal{N}(0,1) \Big( \big\{ (w,z) \in \mathbb{R}^2; \sigma w + \bar{\sigma} z \leq a \big\} \Big).
  \end{equation}
  Agora aplicaremos a rotação rígida $A: \mathbb{R}^2 \to \mathbb{R}^2$ dada por
  \begin{equation}
    A(w,z) = \frac{1}{\sqrt{\sigma^2 + \bar{\sigma}^2}} \big( \sigma w + \bar{\sigma} z, \bar{\sigma} w - \sigma z \big).
  \end{equation}

  Como sabemos que a densidade $f$ de $(W,Z)$ é invariante por $A$, ou seja $f \circ A = f$, então podemos escrever \eqref{e:soma_normal} como
  \begin{equation*}
    \begin{split}
      \mathcal{N}(0,1) & \otimes \mathcal{N}(0,1) \Big( A \big(\big\{ (w,z) \in \mathbb{R}^2; \sigma w + \bar{\sigma} z \leq a \big\} \big) \Big)\\
      & = \mathcal{N}(0,1) \otimes \mathcal{N}(0,1) \Big( \Big\{(w,z); \frac{1}{\sqrt{\sigma^2 + \bar{\sigma}^2}}w \leq a \Big\} \Big)\\
      & = \mathcal{N}(0,1) \big( (-\infty, a \sqrt{\sigma^2 + \bar{\sigma}^2} \big] \big) = \mathcal{N}(0,\sigma^2 + \bar{\sigma}^2) \big( (-\infty, a \big] \big),
    \end{split}
  \end{equation*}
  terminando a prova da proposição.
\end{proof}

\todo{Fazer as iteradas do operador convolução, isso nos dá a normalizada com $\sqrt{2^j}$, depois trocamos $2^j$ por $n$.}

Podemos obter um corolário interessante sobre a soma de várias normais i.i.d.
\begin{corollary}
  \label{c:normaliz_normais}
  Sejam $X_1, X_2, \dots$ variáveis aleatórias i.i.d. com distribuição $\mathcal{N}(m,\sigma^2)$, então
  \begin{equation}
    X_1 + \dots + X_n \distr \mathcal{N}(nm, n \sigma^2).
  \end{equation}
  Como consequência
  \begin{equation}
    \frac{\sum_{i=1}^n X_i - n E(X_1)}{\sigma \sqrt{n}} \distr \mathcal{N}(0,1).
  \end{equation}
\end{corollary}

Lembrando da Lei dos Grandes Números, se dividimos a soma dos $X_i - E(X_i)$ por $n$, essa fração vai a zero quase certamente,
O que concluímos acima é que podemos dividir por $\sqrt{n}$ e teremos um limite não trivial (nem zero, nem infinito).

Mais uma observação curiosa: nossa motivação para a definição da distribuição normal passou por invariância por rotações e podemos extender essa invariância para $n$ normais independentes.
Note que a somar as coordenadas canônicas é equivalente a multiplicar pelo vetor $(1,1,\dots,1)$, que tem norma euclideana $\sqrt{n}$.

Uma outra maneira de entender o corolário acima é que a normal é um ponto fixo da operação seguinte
\begin{enumerate}
\item tome uma distribuição $\mu \in \mathcal{L}^2$,
\item considere $X_1, \dots, X_n$ i.i.d. com distribuição $\mu$ e
\item retorne a distribuição de
  \begin{equation}
    \frac{X_1 + \dots + X_n - n E(X_1)}{\sqrt{\Var(X_1) n}}.
  \end{equation}
\end{enumerate}

Na Questão~\ref{q:ponto_fixo_soma}, nos perguntamos quais seriam os outros possíveis pontos fixos dessa operação e será isso considerado depois.
Mas uma outra questão bastante importante é se o ponto fixo $\mathcal{N}(0,1)$ é atrator, ou seja se começando com outras distribuições poderíamos nos aproximar de $\mathcal{N}(0,1)$ à medida que $n$ cresce.

Isso é estudado no Teorema Central do Limite (TCL) que provaremos posteriormente.
Mas antes, precisamos desenvolver uma boa definição de convergência para distribuições o que será o nosso próximo tópico.

\todo{Mencionar que queremos saber se o ponto fixo $\mathcal{N}(0,1)$ é atrator.}

\newpage

\subsection{Convergência fraca}

Em muitos casos é importante ter uma noção de convergência de medidas de probabilidade.
Supondo por exemplo no espaço mensurável $(E,\mathcal{A})$, tenhamos uma sequência de probabilidades $\mu_n$ e gostaríamos de saber se ela converge a uma determinada $\mu$.

Um candidato natural para dara sentido a essa convergência poderia se a distância de variação total entre duas medidas
\begin{equation}
  d_{\VT}(\mu,\nu) = \sup_{A \in \mathcal{A}} |\mu(A) - \nu(A)|.
\end{equation}
Não é difícil mostrar que a definição acima induz uma métrica, mas ela possui alguns problemas que descreveremos a seguir.

\begin{exercise}
  Mostre que $d_{\VT}$ define uma métrica.
\end{exercise}

\begin{exercise}
  Sejam $\mu$ e $\nu$ absolutamente contínuas com respeito a uma medida fixa $\eta$, tendo densidades $\rho$ e $\pi$ respectivamente.
  Encontre uma fórmula para $d_{\VT}(\mu, \nu)$ em termos das densidades.
  Essa fórmula nos remete a qual distância entre funções?
\end{exercise}

Digamos que o espaço amostral $E$ já seja provido de uma métrica $d$ e $\mathcal{A}$ seja a $\sigma$-álgebra dos borelianos em $E$.
Qualquer que seja a noção de convergência que iremos considerar, gostaríamos de dizer que $\delta_{x_n}$ converge a $\delta_x$ sempre que $x_n \to x$ em $E$.
Esse porém não é o caso para $d_{\VT}$, pois se $x_n \neq x$ para todo $n$ e $\{x\} \in \mathcal{A}$, teríamos
\begin{equation}
  d_{\VT}(\delta_{x_n}, \delta_x) \geq |\delta_{x_n}(\{x\}) - \delta_{x}(\{x\}) | = |0 - 1| = 1.
\end{equation}

Aqueles que já viram o conceito de convergência fraca acharão natural que a convergência de $\mu_n$ para $\mu$ seja definida em termos da convergência de $\int f \d \mu_n$ para $\int f \d \mu$.
Porém, como mencionamos no exemplo das medidas $\delta_{x_n}$ acima, gostaríamos também de a convergência respeitasse a topologia original do espaço $E$, o que torna natural a seguinte

\begin{definition}
  Dizemos que uma sequência de medidas de probabilidade $\mu_n$ converge fracamente (ou converge em distribuição) para uma probabilidade $\mu$ se
  \begin{equation}
    \lim_{n \to \infty} \int f \d \mu_n = \int f \d \mu, \text{ para toda $f:E \to \mathbb{R}$ contínua e limitada.}
  \end{equation}
  Essa convergência muitas vezes é denotada por $\mu_n \Rightarrow \mu$.
\end{definition}

Essa definição fica ainda mais natural para aqueles que conhecem o Teorema da Representação de Riesz.
Com isso em mente, podemos relacionar a convergência em distribuição com a convergência fraca$^*$ no espaço de medidas finitas.

\begin{exercise}
  Mostre que em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, temos que $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n} \Rightarrow U_{[0,1]}$.
\end{exercise}

\begin{exercise}
  Considere a função $\phi$ do espaço de medidas em $([0,1], \mathcal{B}([0,1]))$ nele mesmo, dada pelo seguinte:
  \begin{equation}
    \phi(\mu)(A) = \tfrac{1}{2} \big( \mu(A/3) + \mu(A/3 + 2/3) \big).
  \end{equation}
  Identifique o limite em distribuição de $\phi^{(n)}(\delta_0)$.
  Mostre que
  \begin{enumerate}[\quad a)]
  \item a função de distribuição acumulada associada ao limite é contínua,
  \item o limite não é absolutamente contínuo com respeito à medida de Lebesgue.
  \end{enumerate}
\end{exercise}

O próximo resultado é bastante útil para provar convergência fraca, pois nos fornece uma coleção de equivalências muitas vezes mais fáceis de verificar.

\begin{theorem}[Teorema de Portmanteau]
  \label{t:portmanteau}
  Sejam $(\mu_n)_{n \geq 1}$ e $\mu$ medidas de probabilidade em $(E, \mathcal{A})$.
  São equivalentes:
  \begin{enumerate}
  \item[a)] $\mu_n \Rightarrow \mu$,
  \item[a')] $\int f \d \mu_n \to \int f \d \mu$, para toda $f$ unifmormemente contínua e limitada,
  \item[b)] $\limsup_n \mu_n(F) \leq \mu(F),$ para todo $F \subseteq E$ fechado,
  \item[b')] $\liminf_n \mu_n(G) \geq \mu(G),$ para todo $F \subseteq E$ aberto,
  \item[c)] $\lim_n \mu_n(A) = \mu(A),$ para todo $A \in \mathcal{A}$ com $\mu(\partial A) = 0$.
  \end{enumerate}
\end{theorem}

Para memorizar o teorema acima, é conveniente lembrar dos dois exemplos:
\begin{enumerate}[\quad i)]
  \item se $x_n \to x$ com $x_n \neq x$, $F = \{x\}$ e $G = B(x, \delta) \setminus \{x\}$ temos, para $n$ grande,
    \begin{equation}
      \mu_n(F) = \mu(G) = 0 < 1 = \mu(F) = \mu_n(G),
    \end{equation}
  \item em $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, seja $\mu_{2n} = \delta_n$ e $\mu_{2n+1} = \mu = \delta_0$.
    Obviamente $\mu_n$ não converge fracamente a $\mu$. Contudo, para todo $A \in \mathcal{B}(\mathbb{R})$,
    \begin{equation}
      \begin{split}
        \liminf_n \mu_n (A) & \leq \liminf_n \mu_{2n}(A) = \mu(A) \text{ e}\\
        \limsup_n \mu_n (A) & \geq \limsup_n \mu_{2n}(A) = \mu(A).
      \end{split}
    \end{equation}
\end{enumerate}

\begin{proof}[Prova do Teorema~\ref{t:portmanteau}]
  Obviamente, $(a \Rightarrow a')$, pois $a')$ somente supõe a convergência das integrais para funções $f$ que sejam uniformemente contínuas, portanto é um requisito mais fraco que $a)$.

  Observamos também que $(b \Leftrightarrow b')$.
  De fato, basta tomarmos complementos e observar a mudança nos sinais das desigualdades.

  Então, para a prova do teorema, basta mostrar que $(a' \Rightarrow b)$, $(b + b' \Rightarrow c)$ e $(c \Rightarrow a)$.

  Começamos com $(a' \Rightarrow b)$ e para tanto, consideramos $F \subseteq E$ fechado.
  Seja $\delta > 0$ e defina a função $f_\delta: E \to \mathbb{R}$ dada por
  \begin{equation}
    f_\delta (x) = \max \Big\{ 1 - \frac{d(x, F)}{\delta}, 0 \Big\}.
  \end{equation}
  Claramente, $f$ é uniformemente contínua e vale $\1{F} \leq f_\delta \leq \1{B(F,\delta)}$.
  Dessa desigualdade, temos $\limsup_n \mu_n(F) \leq \limsup_n \int f_\delta \d \mu_n = \int f_\delta \d \mu \leq \mu(B(F,\delta))$.
  Tomando agora o limite com $\delta \to 0$, obtemos $b)$ por continuidade da probabilidade $\mu$.


  Para mostrar $(b + b' \Rightarrow c)$, seja $A \in \mathcal{A}$ tal que $\mu(\partial A) = 0$.
  Nesse caso, sabemos que
  \begin{equation*}
    \limsup_n \mu_n(A) \leq \limsup_n \mu_n(\bar A) \leq \mu (\bar A) = \mu (\mathring{A}) \leq \liminf \mu_n (\mathring{A}) \leq \liminf_n \mu_n (A),
  \end{equation*}
  o que mostra o limite em $c)$.

  Finalmente, resta mostrar $(c \Rightarrow a)$ e, para tanto, consideramos uma função $f: E \to \mathbb{R}$ contínua e limitada.
  Digamos, com $\lVert f \rVert_\infty = M$.

  Sabemos que os conjuntos $\{f^{-1}(\{a\})\}_{a \in \mathbb{R}}$ são disjuntos, logo os conjuntos $f^{-1}(\{a\})$ podem ter medida $\mu$ positiva apenas para uma coleção enumerável de valores $a \in \mathbb{R}$.
  Obtemos assim uma coleção finita $b_0 < b_1 < \dots < b_k$, tal que
  \begin{equation}
    \begin{array}{c}
      b_0 < -M \text{ e } b_k > M, \quad b_{i+1} - b_i \leq \delta \text{ e}\\
      \mu\big(f^{-1} (\{b_i\}) \big) = 0 \text{ para todo $i \leq k$}.
    \end{array}
  \end{equation}

  \begin{figure}[!h]
    \centering
    \begin{tikzpicture}[scale=3]
      \draw[->,gray,very thin] (-1,0) -- (1.4,0) node[right,black] {$x$};
      \draw[->,gray,very thin] (0.08,-0.2) -- (0.08,1.3) node[above,black] {$f(x)$};
      \draw[domain=-.8:1.2,smooth,variable=\x,blue] plot ({\x},{ 1/(1 + 10 * \x * \x) });
      \foreach \x in {5,7} { \draw[-,dashed,gray,very thin] ({-sqrt(1 / \x - 0.1)},0) -- ({-sqrt(1 / \x - 0.1)},0.1*\x) -- ({sqrt(1 / \x - 0.1)}, 0.1*\x) -- ({sqrt(1 / \x - 0.1)}, 0); }
      \foreach \x in {-1,1,3,5,7,9,11} { \draw[thick] (.06,0.1*\x) -- (.1, 0.1*\x); }
      \draw[thick] ({-sqrt(1 / 5 - 0.1)},0) -- ({-sqrt(1 / 7 - 0.1)},0);
      \draw[thick] ({sqrt(1 / 5 - 0.1)},0) -- ({sqrt(1 / 7 - 0.1)},0);
    \end{tikzpicture}
    \caption{Uma função contínua e limitada $f$, os pontos $b_i$ e um conjunto $A_i$.}
  \end{figure}

  Iremos aproximar $f$ por uma função da forma $f_\delta = \sum_{i} b_i \1_{A_i}$, onde os conjuntos $A_i = f^{-1}\big( [b_i, b_{i+1}) \big)$ são disjuntos.
  Obviamente $f_\delta \leq f \leq f_\delta + \delta$, donde
  \begin{equation*}
    \liminf \int f_\delta \d \mu_n \leq \liminf \int f \d \mu_n \leq \limsup \int f \d \mu_n \leq \liminf \int f_\delta \d \mu_n + \delta.
  \end{equation*}
  Mas como $\int f_\delta \d \mu_n = \sum_i b_i \mu_n (A_i)$, a prova estará concluida se mostrarmos que $\mu_n (A_i) \to \mu(A_i)$ para todo $i \leq k$.
  Isso segue de $d)$, pois $\partial A_i \subseteq f^{-1}(\{b_i, b_{i+1}\})$, que tem medida zero.
\end{proof}

\begin{exercise}
  Lembrando que em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, temos $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n} \Rightarrow U_{[0,1]}$, use o ítem $d)$ do Teorema~\ref{t:portmanteau} para dar uma caracterização dos conjuntos Riemann-mensuráveis.
  Mais precisamente, encontre os conjuntos $A \subseteq \mathbb{R}$ tais que $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n}(A)$ converge para a medida de Lebesgue de $A$.
\end{exercise}

\newpage

Nós algumas vezes denotamos $X_n \Rightarrow X$ quando $X_n$ e $X$ são elementos aleatórios de $(\Omega, \mathcal{F}, P)$ para descrever a convergência fraca de suas respectivas distribuições.
Mais precisamente, $X_n \circ P \Rightarrow X \circ P$.

\subsection{Convergência fraca em $\mathbb{R}$}

No caso especial em que $E = \mathbb{R}$, temos vários outras maneiras de caracterizar convergência em distribuição.
A primeira é dada pela seguinte

\begin{proposition}
  \label{p:conv_distr_suave}
  Se $\int g \d \mu_n$ converge para $\int g \d \mu$ para toda $g \in C^3$ limitada e com as três primeiras derivadas limitadas, então $\mu_n \Rightarrow \mu$.
\end{proposition}

\begin{proof}
  Primeiramente, vamos ver que podemos nos concentrar em uma porção compacta da reta.

  Para isso fixe um $\varepsilon > 0$ e tome $M'$ tal que $\mu\big( [-M', M'] \big) > 1 - \varepsilon / 3$.
  Tomando uma função $g$ satisfazendo as hipóteses do teorema e tal que $\1{[-M',M']} \leq g \leq \1{[-M'-1,M'+1]}$, concluimos que
  \begin{equation}
    \mu_n \big( [-(M'+1), M'+1] \big) \geq 1 - \varepsilon/2,
  \end{equation}
  para todo $n$ suficientemente grande.
  Se tomamos $M \geq M'$ suficientemente grande, podemos obter a cota acima para todo $n$ (com $M$ no lugar de $M'+1$ e $\varepsilon$ no lugar de $\varepsilon/2$).

  Fixamos agora uma $f: \mathbb{R} \to \mathbb{R}$ contínua e limitada.
  Sabemos que é possível aproximar $f$ por uma função $g \in C^3$ de suporte compacto, com $\lVert g \rVert_\infty \leq 2 \lVert f \rVert_\infty$ e $|g - f| \leq \varepsilon/M$ uniformemente no intervalo $[-M,M]$.
  Essa $g$ certamente satisfaz as hipóteses do teorema.

  Portanto,
  \begin{equation*}
    \begin{split}
      \Big| \int f \d \mu_n - \int f \d \mu\Big| & \leq 2 \varepsilon \lVert f \rVert_\infty + \Big| \int_{-M}^M f \d \mu_n - \int_{-M}^M f \d \mu\Big|\\
      & \leq 2 \varepsilon \lVert f \rVert_\infty + \frac \varepsilon{M} 2 M + \Big| \int_{-M}^M g \d \mu_n - \int_{-M}^M g \d \mu\Big|\\
      & \leq 2 \varepsilon \lVert f \rVert_\infty + 2 \varepsilon + \Big| \int g \d \mu_n - \int \d \mu\Big|.
    \end{split}
  \end{equation*}
  Como o último termo converge a zero e $\varepsilon$ foi escolhido arbitrariamente, isso conclui a prova da proposição.
\end{proof}

\newpage

\subsection{O TCL para uma sequência i.i.d.}

\begin{theorem}
  \label{:tcl_iid}
  Considere num espaço $(\Omega, \mathcal{F}, P)$, uma sequência $X_1, X_2, \dots$ de variáveis aleatórias i.i.d. em $\mathcal{L}^3$.
  Nesse caso, se definimos $m = E(X_1)$ e $\sigma^2 = \Var(X_1)$, temos
  \begin{equation}
    \frac{\sum_{i=1}^n (X_i - m)}{\sigma \sqrt{n}} \Rightarrow \mathcal{N}(0,1).
  \end{equation}
\end{theorem}

\begin{proof}
  Primeiramente, observe que podemos supor que $m = 0$, pois de qualquer forma iremos subtrair a média da distribuição na qual nos interessamos.
  Uma outra observação importante é que podemos supor $\sigma = 1$, pois no caso geral de qualquer forma estamos somando $X_i/\sigma$ no enunciado.

  Como vimos na Proposição~\ref{p:conv_distr_suave}, basta mostrar a convergência das integrais de funções $g \in C^3$, que possuam todas as três primeiras derivadas limitadas.
  Considerando a função
  \begin{equation}
    \phi^n(x_1, \dots, x_n) := g\Big(\frac{x_1 + \dots + x_n}{\sqrt{n}} \Big),
  \end{equation}
  nos basta provar a convergência de números reais
  \begin{equation}
    \label{e:tcl_limite_phi}
    \lim_n \int \phi^n(X_1, \dots, X_n) \d P = \int g(s) \mathcal{N}(0,1)(\d s).
  \end{equation}

  Vale lembrar que no Corolário~\ref{c:normaliz_normais} já estabelecemos algo mais forte para variáveis normais.
  Mais precisamente, suponha que extendemos nosso espaço de probabilidade para $(\Omega', \mathcal{F}', P')$, onde exista uma sequência $Y_1, Y_2, \dots$ de variáveis aleatórias i.i.d. com distribuição $\mathcal{N}(0,1)$ independente de $X_1, X_2, \dots$
  Então,
  \begin{equation}
    \int \phi^n(Y_1, \dots, Y_n) \d P' = \int g(s) \mathcal{N}(0,1) (\d s),
  \end{equation}
  o que tornaria o limite em \eqref{e:tcl_limite_phi} trivial para tais variáveis.
  A nossa estratégia será aproximar $\phi^n(X_1, \dots, X_n)$ por $\phi(Y_1, \dots, Y_n)$, e faremos isso trocando uma variável de cada vez.

  Para entender o que acontece quando trocamos uma das variáveis $X_i$ por $Y_i$, temos que expandir $g$ em série de potências, isto é, escrever
  \begin{equation}
    g(s) = g(s_0) + g'(s_0)(s - s_0) + g''(s_o)(s-s_0)^2/2 + r_{s_0}(s - s_0),
  \end{equation}
  onde $r_{s_0}(h)/h^3$ é limitada por $M$, uniformemente em $h$ e $s_0$ em consequência das nossas suposições sobre $g$.

  Denotando $z_i = (y_1, \dots, y_{i-1}, x_i, \dots x_n)$, $z_i^o := (y_1, \dots, y_{n-1}, 0, x_{n+1}, \dots, x_n)$ e $s_i^o = y_1 + \dots + y_{n-1} + x_{n+1} + \dots x_n$, temos
  \begin{equation}
    \phi^n(z_i) %& = \phi^n(z_i^o) + \frac{\partial \phi^n}{\partial x_i} (z_i^o) x_i + \frac{\partial^2 \phi^n}{\partial x_i^2} (z_i^o) \frac{x_i^2}{2} + r_z(x_i)\\
    = \phi^n(z_i^o) + g' \Big( \frac{s_i^o}{\sqrt{n}} \Big) \frac{x_i}{\sqrt{n}} + g'' \Big( \frac{s_i^o}{\sqrt{n}} \Big) \frac{x_i^2}{2n} + r_{\frac{s_i^o}{\sqrt{n}}} \Big( \frac{x_i}{\sqrt{n}} \Big),
  \end{equation}
  Nós propositalmente expandimos $\phi^n$ até ordem dois, pois $X_i$ e $Y_i$ possuem os mesmos momentos de ordem um ($m=0$) e dois ($\sigma^2=1$).

  Integrando os dois lados da igualdade acima com respeito a $Z_i \circ P$ (denotamos como antes, $Z_i = (Y_1, \dots, Y_{i-1}, X_i, \dots, X_n)$ e $Z_i^o$, $S_i^o$ analogamente), teremos
  \begin{equation}
    \int \phi^n(Z_i) \d P' = \int \phi^n(Z_i^o) \d P' + \frac{1}{2n} v_i + k_i,
  \end{equation}
  onde as quantidades $v$ e $k$, se escrevem como
  \begin{equation}
    v_i = \int g'' \Big( \frac{S_i^o}{\sqrt{n}} \Big) \d P' \quad \text{ e } \quad k_i = \int r_{S_i^o/\sqrt{n}} \Big(\frac{X_i}{\sqrt{n}}\Big) \d P'.
  \end{equation}
  Note que $v_i$ não depende de $X_i$ e que
  \begin{equation}
    |k_i| \leq \Big| \int \Big(\frac{X_i^3}{n^{3/2}}\Big) \Big(\frac{n^{3/2}}{X_i^3}\Big) r_{S_i^o/\sqrt{n}} \Big(\frac{X_i}{\sqrt{n}}\Big) \d P' \Big| \leq \frac{M}{n^{3/2}} E(|X_i^3|).
  \end{equation}

  As observações acima são o ponto mais importante da prova de que essa aproximação funciona e uma outra maneira de colocá-las é a seguinte.
  Como $X_i$ e $Y_i$ possuem os dois primeiros momentos iguais, os dois primeiros termos de Taylor coincidem após a integração (o primeiro se anula e o segundo é $v_i$ tanto para $X_i$ quanto para $Y_i$).
  O resto é de ordem muito pequena para influir no limite.

  De fato, se retiramos o termo $Y_i$ de $Z_{i+1}$, fazendo a mesma expansão que para $X_i$, obtemos
  \begin{equation}
    \int \phi^n(Z_{i+1}) \d P' = \int \phi^n(Z_i^o) \d P' + \frac{1}{2n} v_i + k'_i,
  \end{equation}
  com o termo de ordem superior $k'_i$ sendo definido exatamente como $k_i$, mas com $Y_i$ no lugar de $X_i$.

  Estamos prontos agora para a computação final
  \begin{equation*}
    \begin{split}
      \Big| \int \phi^n & (X_1, \dots, X_n) \d P - \int g(s) \mathcal{N}(0,1)(\d s) \Big| = \Big| \int \phi^n(Z_0) \d P' - \int \phi^n(Z_n) \d P' \Big|\\
      & \leq \sum_{i=0}^{n-1} \Big| \int \phi^n(Z_{i}) \d P' - \int \phi^n(Z_{i+1}) \d P' \Big| = \sum_{i=0}^{n-1} |k_i - k'_i|\\
      & \leq n \frac{M}{n^{3/2}} \big(E(|X_1|^3) + E(|Y_1|^3) \big),
    \end{split}
  \end{equation*}
  que claramente converge a zero, provando o teorema.
\end{proof}

\begin{corollary}
  A $\mathcal{N}(0,1)$ é a única distribuição $\mu$ que possui esperança zero, variância $1$ e é tal que se $X, Y$ são i.i.d. com distribuição $\mu$, então $(X + Y)/\sqrt{2}$ possuem distribuição $\mu$.
\end{corollary}

\begin{proof}
  Usando a invariância enunciada acima, temos que
  \begin{equation}
    \frac{X_1 + \dots + X_{2^k}}{\sqrt{2^k}} \distr \mu.
  \end{equation}
  Mas pelo Teorema central do limite, a distribuição dessa combinação de $X_i$ deve convergir a $\mathcal{N}(0,1)$, logo temos $\mu = \mathcal{N}(0,1)$.
\end{proof}

\newpage

\section{Núcleos de transição}

Já focamos bastante energia em variáveis aleatórias independentes.
Por exemplo, estudamos em detalhes o que acontece com a soma de tais variáveis.
Agora passaremos a estudar elementos aleatórios dependentes e o primeiro passo para isso é obter um método geral de construí-los.

Definiremos agora um núcleo de transição.
Intuitivamente, ele nos dá um meio de usar um elemento aleatório em um espaço para induzir uma probabilidade em outro espaço.
Um exemplo em que poderíamos utilizar essa construção seria intuitivamente o seguinte.
Digamos que uma moeda foi danificada acidentalmente, e isso fez com que sua probabilidade retornar \emph{cara} tenha se modificado para algum $P \in [0,1]$.
Como modelaríamos um lançamento dessa moeda, se $P$ também fosse aleatório?

Sejam $(E_1, \mathcal{A}_1)$ e $(E_2, \mathcal{A}_2)$ espaços mensuráveis.

\begin{definition}
  Um núcleo de transição entre $E_1$ e $E_2$ é uma função
  \begin{equation}
    K: E_1 \times \mathcal{A}_2 \to [0,1],
  \end{equation}
  tal que
  \begin{enumerate}[\quad a)]
  \item para todo $y \in E_1$, $K(y,\cdot)$ é uma probabilidade em $(E_2, \mathcal{A}_2)$ e
  \item para todo $A \in \mathcal{A}_2$, a função $K(\cdot, A): E_1 \to [0,1]$ é $\mathcal{A}_1$-mensurável.
  \end{enumerate}
\end{definition}

\begin{example}
  \label{x:moeda_danificada}
  Daremos agora o exemplo de uma moeda danificada de maneira arbitrária (possivelmente aleatóriamente).
  Nesse caso, seja $E_1 = [0,1]$ e $E_2 = \{0,1\}$ com as $\sigma$-álgebras naturais e defina
  \begin{equation}
    K(p, A) = \big( (1-p)\delta_0 + p \delta_1 \big) (A).
  \end{equation}
\end{example}

Vamos verificar que $K$ definido acima é um núcleo.
De fato,
\begin{enumerate}[\quad i)]
\item $K(p, \cdot)$ é a distribuição Bernoulli com parâmetro $p$, que obviamente é uma probabilidade,
\item além disso, $K(\cdot, \{0\}) = 1-p = 1 - K(\cdot,\{1\})$, que obviamente é mensurável.
Isso prova que esse $K$ específico é um núcleo
\end{enumerate}

\begin{example}[Discreto]
  \label{x:nucleo_discreto}
  Seja $E_1 = \{y_i\}_{i \geq 1}$ e $E_2 = \{z_j\}_{j \geq 1}$.
  Se $p: E_1 \times E_2 \to [0,1]$ é tal que para todo $y \in E_1$ temos $\sum_{j} p(y, z_j) = 1$, então
  \begin{equation}
    K(y, A) := \sum_{j \in A} p(y, z_j) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Nesse caso $p(y,z)$ representa a probabilidade que a segunda coordenada seja $z$, se a primeira é $y$.
\end{example}

\begin{exercise}
  Mostre que se $E_1$ e $E_2$ são enumeráveis então todo núcleo entre $E_1$ e $E_2$ pode ser escrito na forma do exemplo acima.
\end{exercise}

\begin{example}[Absolutamente contínuo]
  Digamos que $E_1$ e $E_2$ sejam dotados de medidas $\mu_1$ e $\mu_2$ $\sigma$-finitas.
  Seja $\rho: E_1 \times E_2 \to \mathbb{R}_+$ mensurável e tal que para $\mu_1$-quase todo $y \in E_1$, tenhamos que $\int_{E_2} \rho(y, z) \mu_2(\d z) = 1$.
  Então
  \begin{equation}
    K(y, A) := \int_A \rho(y, z) \mu_2(\d z) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Note que $K(\cdot, A)$ está bem definido para $\mu_2$-quase todo ponto por Fubini.
\end{example}

\begin{exercise}
  Prove que os dois exemplos acima de fato definem um núcleo.
\end{exercise}

Tipicamente, definimos os núcleos de transição introduzindo $K(y, \cdot)$ como sendo uma medida que depende de $y$.
Nesse caso, uma das condições para que $K$ seja um núcleo está automaticamente satisfeita, restando apenas mostrar que $K(\cdot, A)$ é mensurável para quaisquer $A \in \mathcal{A}_2$.
Mas obviamente o conjunto $\mathcal{A}_2$ pode ser muito complexo, então gostaríamos de nos restringir a verificar que $K(\cdot, A)$ é mensurável para os conjuntos $A$ em uma classe rica o suficiente.

\begin{proposition}
  \label{p:K_nucleo_na_classe}
  Seja $K:E_1 \times \mathcal{A}_2 \to [0,1]$, tal que $K(y, \cdot)$ é uma medida para todo $y \in E_1$.
  Se $K(\cdot, A)$ é mensurável para dodo $A \in \mathcal{G}$, onde $\mathcal{G}$ é um $\pi$-sistema que gera $\mathcal{A}_2$, então $K$ é um núcleo de transição.
\end{proposition}

\begin{proof}
  Como de costume, vamos definir
  \begin{equation}
    \mathcal{B} = \{B \in \mathcal{A}_2; K(\cdot, B) \text{ é $\mathcal{A}_1$-mensurável}\}.
  \end{equation}
  Obviamente, como $K(y, \cdot)$ é uma probabilidade, vale que
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{B}$, pois a função constante igual a um é mensurável.
  \item Se $B \in \mathcal{B}$, então $B^c \in \mathcal{B}$, pois $1 - f$ é mensurável se $f$ o é.
  \item E se $B_1, B_2, \dots \in \mathcal{B}$ são disjuntos, então $\cup_i B_i \in \mathcal{B}$, pois a soma de funções mensuráveis também é mensurável.
  \end{enumerate}

  A discussão acima mostra que $\mathcal{B}$ é um $\lambda$-sistema que contém o $\pi$-sistema $\mathcal{G}$.
  Daí, vemos que $\mathcal{A}_2 = \sigma(\mathcal{G}) \subseteq \mathcal{B}$, provando a proposição.
\end{proof}

\begin{exercise}
  Seja $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por $K(y, \cdot) = U_{[y - 1,y + 1]}$.
  Mostre que $K$ define um núcleo de transição.
\end{exercise}

Apesar de interessante, a definição acima ainda não nos permitiu definir espaços de probabilidade novos.
Isso será possibilitado pelo próximo resultado, que pode ser visto como uma generalização do Teorema de Fubini.

\begin{theorem}[Fubini para Núcleos de Transição]
  \label{t:fubini}
  Dado um núcleo $K$ de $(E_1, \mathcal{A}_1)$ para $(E_2, \mathcal{A}_2)$ e uma probabilidade $P_1$ em $E_1$, existe uma única probabilidade $P$ em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$ tal que
  \begin{equation}
    \label{e:fubini}
    \int_{E_1 \times E_2} f dP = \int_{E_1} \int_{E_2} f(y,z) K(y, \d z) P_1 (\d y),
  \end{equation}
  para toda $f:E_1 \times E_2 \to \mathbb{R}_+$.
  Em particular, $P(A_1 \times A_2) = \int_{A_1} K(y, A_2) P_1 (\d y)$.
  Nesse caso escrevemos $P = P_1 \star K$.
\end{theorem}

Antes de iniciar a prova do teorema, vamos ver que as integrais do lado direito de \eqref{e:fubini} estão bem definidas.
Para isso, definimos para $y \in E_1$ a função fatiadora $\phi_y: E_2 \to E_1 \times E_2$ dada por $\phi_y(z) = (y, z)$.
Obviamente essa função é mensurável, pois
\begin{equation}
  \phi^{-1}(A_1 \times A_2) =
  \begin{cases}
    \varnothing, \quad & \text{ se $y \not \in A_1$ e}\\
    A_2, & \text{ se $y \in A_1$}.
  \end{cases}
\end{equation}
Dessa forma, para definirmos $\int f(y,z) K(y, \d z)$, introduzimos $f_y: A_2 \to \mathbb{R}_+$ dada por $f(z) = f(y,z)$, que é mensurável pois $f_y = f \circ \phi_y$.

Assim, a integral que gostaríamos de definir se torna $\int f_y(z) K(y, \d z)$, que está obviamente bem definida.
Porém resta a pergunta, será que essa expressão define uma função mensurável de $y$?

\begin{lemma}
  Se $K$ é um núcleo de transição, então para toda $f: E_1 \times E_2 \to \mathbb{R}_+$ que seja $\mathcal{A}_1 \otimes \mathcal{A}_2$ mensurável, temos que $g^f:A_1 \to \mathbb{R}_+$ dada por $g^f(y) = \int f_y(z) K(y, \d z)$ é $\mathcal{A}_1$-mensurável.
\end{lemma}

\begin{proof}
  Se $f = \1_{A_1 \times A_2}$ para $A_i \in \mathcal{A}_i$, $i = 1,2$, então $g^f(y) = K(y, A_2) \1_{A_1}$, que obviamente é mensurável pois $K$ é um núcleo.

  Definimos $\mathcal{D} = \{B \in \mathcal{A}_1 \otimes \mathcal{A}_2; g^{\1_B} \text{ é $\mathcal{A}_1$-mensurável}\}$.
  É fácil ver que $\mathcal{D}$ é um $\lambda$-sistema que contém o $\pi$-sistema dos retângulos, logo $\mathcal{D} = \mathcal{A}_1 \otimes \mathcal{A}_2$.

  Acabamos de ver que $g^f$ é mensurável para toda $f$ indicadora, donde o mesmo vale para $f$ simples por linearidade e para toda $f$ positiva pelo Teorema da Convergência Monótona (lembre que limite de funções mensuráveis é mensurável).
\end{proof}

Estamos prontos agora para fornecer a
\begin{proof}[Demonstração do Teorema~\ref{t:fubini}]
  Já sabemos que a integral do lado direito de \eqref{e:fubini} está bem definida (assumindo possivelmente o valor infinito).
  A unicidade vale obviamente pois a probabilidade de conjuntos do tipo $A_1 \times A_2$ definem $P$ de maneira inequívoca.


  Só nos resta mostrar que
  Isto é
  \begin{equation}
    P(B) = \int_{E_1} \int_{E_2} \1_{B} K(y, \d z) P_1 (\d y),
  \end{equation}
  nos define uma probabilidade em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$.

  De fato,
  \begin{enumerate}[\quad a)]
  \item $P(\Omega) = \int_{E_1} \int_{E_2} 1 K(y, \d z) = 1$ obviamente e
  \item se $B_1, B_2, \dots \in \mathcal{A}_1 \otimes \mathcal{A}_2$ são disjuntos, então definimos $f^i = \1_{B_i}$ e $f = \sum_i f^i$ e observamos o seguinte.
    A função fatiadora $f_y$ é igual a $\sum_i f^i_y$, donde
    \begin{equation}
      \begin{split}
        P(B) & = \int_{E_1} \int_{E_2} f_y(z) K(y, \d z) P_1(\d y)\\
        & = \int_{E_1} \sum_i \int_{E_2} f^i_y(z) K(y, \d z) P_1(\d y) = \sum_i P(B).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que demonstra o teorema.
\end{proof}

\begin{exercise}
  Considere duas probabilidades $P_i$ em $(E_i, \mathcal{A}_i)$ para $i = 1,2$ e $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dado por $K(y,A) = P_2(A)$.
  Mostre que $K$ é núcleo e que $P_1 \star K = P_1 \otimes P_2$.
  Relacione esse resultado ao Teorema de Fubini clássico para produtos de medidas.
\end{exercise}

\begin{exercise}
  Considere o núcleo do Exemplo~\ref{x:moeda_danificada} e calcule:
  \begin{enumerate}[\quad a)]
  \item $U_{[0,1]} \star K [X_2 = 1]$,
  \item $P_1 \star K [X_2 = 1]$, onde $\d P_1 = 2x \d x$ e
  \item encontre a distribuição de $X_1 \circ \big( U_{[0,1]} \star K [\; \cdot \; | X_2 = 1] \big)$. Interprete o resultado.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Seja $P = P_1 \star K$ como acima e $Q(\cdot) = P[\cdot | X_2 = 1]$.
  Calcule
  \begin{equation}
    \int_{[0,1] \times \{0,1\}} X_1 \d Q
  \end{equation}
\end{exercise}

\begin{exercise}
  Considere $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dada por $K(p, \cdot) = \Exp(p)$.
  Mostre que $K$ é núcleo de transição e calcule $U_{[0,1]}[X_2 > 1] \star K$.
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $E_2$ e $\{y\} \in \mathcal{A}_1$ satisfaz $P_1(\{y\}) > 0$, mostre que
  \begin{equation}
    P_1 \star K [X_2 \in \cdot | X_1 = y] = K(y, \cdot).
  \end{equation}
  Ou em outras palavras, $K$ nos dá a distribuição condicional de $X_2$ dado $X_1 = y$.
\end{exercise}

Posteriormente extenderemos o resultado acima para o caso $P_1(\{y\}) = 0$, mas isso demandará algum esforço.

\newpage

Vamos introduzir uma última notação com respeito a núcleos de transição.
Muitas vezes, não estamos interessados na distribuição conjunta de $P_1 \star K$ em $E_1 \times E_2$, mas apenas na distribuição marginal da segunda coordenada.
No exemplo do martelo, talvez poderíamos estar interessados apenas na distribuição final da moeda.
Nesse caso, é conveniente escrever
\begin{equation}
  \label{e:P1_K}
  P_1 K := X_2 \circ (P_1 \star K).
\end{equation}

\subsection{Cadeias de Markov}

Um exemplo de como usar núcleos de transição é a construção de Cadeias de Markov.
Esse tipo de processo é bastante útil em diversas aplicações, desde a biologia até a computação.

Considere um espaço mensurável canônico fixo $(E, \mathcal{A})$ e seja $K$ um núcleo de $E$ nele mesmo.
Seria bastante intuitivo agora iterar $K$ (já que ele está no mesmo espaço) e obter uma medida em $\Omega = \times_{i=1}^\infty E$ com a $\sigma$-álgebra canônica.

Para começar esse procedimento, seja $\mu_0$ uma medida inicial em $(E, \mathcal{A})$.
Podemos então definir $\mu_1 = \mu_0 \star K$ o que é o primeiro passo da nossa construção, porém observe que não podemos escrever ``$\mu_2 = \mu_1 \star K$'', pois $\mu_1 \star K$ é uma medida em $(E^2, \mathcal{A}^{\otimes 2})$.
Vamos com calma então.

Observe que
\begin{equation}
  \mu_1(A_0 \times A_1) = \int_{A_0} \int_{A_1} K(x_0, \d x_1) \mu_0(\d x_0),
\end{equation}
ou em outras palavras o valor de $x_0$ determina a distribuição de $x_1$.
Gostaríamos agora que $x_1$ determinasse a distribuição de $x_2$ via $K$, como por exemplo assim
\begin{equation}
  \mu_2(A_0 \times A_1 \times A_2) = \int_{A_0} \int_{A_1} \int_{A_2} K(x_1, \d x_2) K(x_0, \d x_1) \mu_0 (\d x_0).
\end{equation}
Mas essa notação é bastante carregada à medida que iteramos.

Para tornar essa notação mais simples, definimos a projeção $\phi_n:E^n \to E$ por $\phi_n(x_0, \dots, x_{n-1}) = x_{n-1}$.
Também precisamos de $K_n: E^n \times \mathcal{A} \to [0,1]$ dado por
\begin{equation}
  K_n(\vec{x},A) = K\big(\phi_n(\vec{x}), A\big) \quad \big(= K(x_{n-1}),A) \big).
\end{equation}
O fato de $K_n$ ser um núcleo de transição segue imediatamente dessa propriedade para $K$.

Note que, nessa notação, estamos dizendo que para irmos de $E^n$ para $E^{n+1}$ iremos olhar apenas para a última coordenada, na qual aplicaremos o núcleo $K$.
Isso é o ponto mais importante que caracteriza uma Cadeia de Markov: a distribuição do estado futuro da cadeia depende apenas do estado atual e não do passado.
Em alguns contextos essa propriedade é chamada de ausência de memória.

Podemos finalmente definir
\begin{equation}
  \label{e:Pn_Markov}
  \mu_{n+1} = \mu_n \star K^n, \text{ para todo $n \geq 1$}.
\end{equation}
Mas resta a questão sobre a existência de uma $\mu^\infty$ que será respondida com ajuda do próximo

\begin{lemma}
  As probabilidades $\mu_n$ definidas em \eqref{e:Pn_Markov} são compatíveis, isto é $\mu_{n+1}(A \times E) = \mu_n(A)$ para todo $A \in \mathcal{A}^{\otimes n}$.
\end{lemma}

\begin{proof}
  Basta observar que
  \begin{equation}
    \mu_{n+1}(A \times E) = \mu_n \star K (A \times E) = \int_{A} \underbrace{K_n (\vec{x}, E)}_1 \mu_n(\d \vec{x}) = \mu_n(A).
  \end{equation}
  Provando o lema.
\end{proof}

Logo, o Teorema da Extensão de Kolmogorov (lembre que supusemos $(E, \mathcal{A})$ canônico) nos fornece uma única $P$ em $(\Omega, \mathcal{F})$ tal que
\begin{equation}
  (X_0, \dots, X_n) \circ P = \mu_n, \text{ para todo $n \geq 0$}.
\end{equation}
Lembramos novamente que $X_i$ denotam as projeções canônicas em $\Omega = \times_{i=1}^\infty E$.

Chamamos o processo $X_1, X_2, \dots$ sob a lei $P$ de Cadeia de Markov com distribuição inicial $\mu_0$ e núcleo de transição $K$.

\begin{example}
  Suponha que $E$ seja enumerável.
  Nesse caso recordamos do Exemplo~\ref{x:nucleo_discreto} que o núcleo pode ser representado por uma matriz $\big(p(x,y)\big)_{x,y \in E}$ que nos retorna a probabilidade de saltar de $x$ a $y$.
  Além disso, a distribuição inicial $\mu_0$ é determinada por $P(\{x\}) = p_0(x)$, para alguma sequência $\big(p_0(x)\big)_{x \in E}$.
\end{example}

\begin{exercise}
  Mostre que no exemplo acima temos
  \begin{equation}
    P(X_0 = x_0, \dots, X_n = x_n) = p_0(x_0) p(x_0, x_1) \dots p(x_{n-1}, x_n).
  \end{equation}
\end{exercise}

\begin{exercise}
  Defina $K:\mathbb{R}^2 \times \mathcal{B}(\mathbb{R}^2) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) = U_{S^1}(A - x).
  \end{equation}
  Nesse contexto,
  \begin{enumerate}[\quad a)]
  \item mostre que $K$ é um núcleo de transição e,
  \item considerando a cadeia com distribuição inicial $\mu_0 = \delta_0$ em $\mathbb{R}^2$ e núcleo $K$, mostre que $X_2$ tem distribuição absolutamente contínua com respeito a Lebesgue e calcule sua densidade.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Mostre que para qualquer núcleo de transição $K$ entre $E$ e $E$, existe um núcleo de transição $\bar K$ entre $E$ e $\Omega = \prod_{i=1}^\infty$, tal que para toda medida inicial $\mu_0$, temos que $\mu_0 \star K$ é a distribuição de uma Cadeia de Markov começando de $\mu_0$ e com transição dada por $K$.
  Esse núcleo é útil se quisermos mudar a distribuição inicial $\mu_0$ e uma notação bastante comum para esse núcleo é $P_{x}(\cdot) = \bar K(x, \cdot)$.
\end{exercise}

Vamos terminar essa seção dando uma interpretação bastante interessante para os núcleos de transição em analogia à álgebra linear.
Fixe um núcleo de transição $K$ entre $E$ e $E$, uma medida inicial $\mu$ e uma função limitada $f: E \to \mathbb{R}$.
Relembre a notação em \eqref{e:P1_K} e defina $K f: E \to \mathbb{R}$ dada por
\begin{equation}
  K f(x):= \int f(y) K(x, \d y),
\end{equation}
que é obviamente limitada e já vimos ser mensurável no Teorema de Fubini.

Então temos dois operadores definidos para núcleos, a multiplicação à esquerda por uma medida em $E$ ($\mu K$ que também é uma medida em $E$) e a multiplicação à direita por uma função limitada e mensurável ($K f$ que também é uma função limitada e mensurável).
Podemos pensar em $f$ como um vetor coluna e $\mu$ como um vetor linha, nesse caso $K$ faria o papel de uma matriz.
Essa analogia é real se $E$ for um espaço enumerável.

\begin{exercise}
  No contexto de cadeias de Markov,
  \begin{enumerate}[\quad a)]
  \item mostre a relação de associatividade $\mu (K f) = (\mu K) f$,
  \item defina para todo $n$ o núcleo $K^{(n)}$ iterado (de $E$ em $E$), de forma que $\mu K^{(n)} f$ ainda seja associativa.
  \item Mostre que a medida $\mu K^{(n)}$ é a distribuição de $X_n$ se começamos de $\mu$,
  \item que a função $K^{(n)} f (\cdot)$ é o valor esperado de $f$ no tempo $n$ se começamos no zero do ponto $\cdot$ e finalmente que
  \item o número real $\mu K^{(n)} f$ é a esperança de $f$ no tempo $n$ se começamos de $\mu$.
  \end{enumerate}
\end{exercise}

\newpage

\section{Esperança condicional}

Como já foi dito anteriormente, a estrutura de $\sigma$-álgebra tem um papel muito importante na área de probabilidade.
Durante o curso de Teoria da Medida, muitas vezes o conceito de $\sigma$-álgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conteúdo realmente interessante do curso.
Em alguns momentos, chegamos a desejar que tudo fosse mensurável e não tivéssemos que nos preocupar com tais formalidades.

No estudo que iniciaremos agora, nos restringiremos a sub-$\sigma$-álgebras $\mathcal{F}'$ próprias de $\mathcal{F}$ propositalmente.
Ficará claro portanto, que o estudo de $\sigma$-álgebras e mensurabilidade não é uma mera tecnicalidade, mas sim uma ferramenta importante.

Em algum sentido (que ficará claro no decorrer do texto) essas sub-$\sigma$-álgebras representarão uma forma de ``informação incompleta''.
Daremos sentido a frases como ``nós temos conhecimento apenas da $\sigma$-álgebra $\mathcal{F}'$''.

Mas antes lembraremos um lema básico de Teoria da Medida.

\begin{lemma}
  \label{l:f_igual_fp}
  Se $f, f'$ são funções mensuráveis tais que
  \begin{equation}
    \int_A f \d \mu = \int_A f' \d \mu, \text{ para todo $A \in \mathcal{F}'$,}
  \end{equation}
  então $f = f'$ $\mu$-quase certamente.
\end{lemma}

\begin{proof}
  Aplicando a hipótese para $A = [f > f']$, vemos que
  \begin{equation}
    \int_A f - f' \d \mu = 0,
  \end{equation}
  mas no conjunto $A$ acima, o integrando é positivo.
  Portanto, $f = f'$, $\mu$-quase certamente em $A$.
  Aplicando o mesmo raciocínio para $[f < f']$ obtemos que $f = f'$ quase certamente.
\end{proof}

O lema acima nos diz que se soubermos integrar $f$ em todos os eventos $A$, então podemos recuperar a função $f$ propriamente dita.
O que aconteceria se soubéssemos integrar $f$ apenas para eventos $A$ em uma sub-$\sigma$-álgebra?
É isso que estudaremos à partir de agora.

\begin{definition}
  \label{d:esperanca_condicional}
  Seja uma variável aleatória $X \in \mathcal{L}^1(P)$ e uma sub-$\sigma$-álgebra $\mathcal{F}' \subseteq \mathcal{F}$.
  Dizemos que uma variável aleatória $Y$ é a esperança condicional de $X$ com respeito a $\mathcal{F}'$ (ou dada $\mathcal{F}'$) se
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $E(X \1_{A}) = E(Y \1_{A})$ para todo $A \in \mathcal{F}'$.
  \end{enumerate}
  Nesse caso, escrevemos
  \begin{equation}
    Y = E(X | \mathcal{F}').
  \end{equation}
\end{definition}

Observe que faz sentido escrever $E\big(Y|\mathcal{F}'\big)(\omega)$, pois $E(X|\mathcal{F}')$ é uma variável aleatória.

Interpretamos informalmente a definição acima como ``$Y$ é a melhor aproximação $\mathcal{F}'$-mensurável de $X$''.
Ou $Y$ é a melhor aproximação que podermos fazer de $X$ se ``conhecemos apenas $\mathcal{F}'$''.

\begin{example}
  \label{x:EXF_trivial}
  Se $\mathcal{F}' = \{\varnothing, \Omega\}$, então $Y = E(X)$ (uma variável aleatória constante) é esperança condicional de $X$ dado $\mathcal{F}'$, pois
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável (por ser constante). Além disso
  \item $E(X \1_\varnothing) = 0 = E(Y \1_\varnothing)$ e $E(X \1_\Omega) = E(X) = E(Y \1_\Omega)$.
  \end{enumerate}
\end{example}

Uma propriedade muito importante que segue da Definição~\ref{d:esperanca_condicional} é dada pela seguinte

\begin{proposition}
  \label{p:ec_em_L1}
  Se $Y$ satisfaz as $a)$ e $b)$ em Definição~\ref{d:esperanca_condicional}, então $Y \in \mathcal{L}^1(P)$.
\end{proposition}

\begin{proof}
  Tomamos $A = [Y \geq 0]$ e $A' = [Y \leq 0]$ que estão em $\mathcal{F}'$ e estimamos
  \begin{equation}
    \int |Y| \d P = \int_A Y \d P + \int_{A'} Y \d P = \int_A X \d P + \int_{A'} X \d P \leq \int |X| \d P < \infty
  \end{equation}
  O que mostra a proposição.
\end{proof}

Além do Exemplo~\ref{x:EXF_trivial} trivial acima, quando podemos esperar que existam esperanças condicionais?

\begin{theorem}
  Dada $X \in \mathcal{L}^1(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$ uma $\sigma$-álgebra, então existe a esperança condicional $E(X|\mathcal{F}')$.
  Além disso ela é única $P$-quase certamente.
\end{theorem}

\begin{proof}
  Vamos primeiro mostrar a unicidade quase certa.
  Para isso, supomos que existam $Y$ e $Y'$ satisfazendo as condições da Definição~\ref{d:esperanca_condicional} (logo em $\mathcal{L}^1$).
  Iremos proceder como no Lema~\ref{l:f_igual_fp} acima, definindo $A = [Y > Y']$, donde concluímos que
  \begin{equation}
    E\big( (Y - Y')\1_{A} \big) = E(Y \1_{A}) - E(Y' \1_{A}) = 0.
  \end{equation}
  Mas como $Y > Y'$ em $A$, vemos que $Y \leq Y'$ quase certamtente.
  A prova da unicidade pode ser completa trocando os papéis de $Y$ e $Y'$ acima.

  Vamos agora para a prova da existência.
  Como $X \in \mathcal{L}^1(P)$, podemos introduzir
  \begin{equation}
    \mu(A) = E(X \1_{A}),
  \end{equation}
  que define uma medida com sinal em $(\Omega, \mathcal{F})$, com variação total finita.

  Caso o leitor não se sinta familiarizado com o conceito de medida com sinal, poderá decompor $X$ em partes positiva e negativa e proceguir sem problemas.

  Um passo importante da prova é observar que $\mu$ também define uma medida no espaço $(\Omega, \mathcal{F}')$.
  Estamos portanto propositalmente restringindo nossa $\sigma$-álgebra.
  Como $P(A) = 0$ implica que $\mu(A) = 0$, temos que $\mu \ll P$ e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada $Y:\Omega \to \mathbb{R}$ tal que
  \begin{enumerate}
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $\mu(A) = \int_A Y \d P$.
  \end{enumerate}
  Agora é só observar que as afirmações acima correspondem às condições da Definição~\ref{d:esperanca_condicional}.
\end{proof}


Observe que a condição de $\mathcal{F}'$-mensurabilidade é essencial para a unicidade.
De fato, $X$ obviamente satisfaz a segunda condição da Definição~\ref{d:esperanca_condicional}, mas não necessariamente a primeira.


\subsection{Propriedades básicas da esperança condicional}

Nessa seção justificaremos, em certa medida, a nomenclatura ``esperança condicional''.
Faremos isso mostrando que ela satisfaz várias propriedades que já conhecemos para a esperança tradicional.

Mas como podemos mostrar propriedades simples tais como a linearidade da esperança condicional?
Vamos começar com um exemplo

\begin{proposition}
  Se $X, X' \in \mathcal{L}^1(P)$, então
  \begin{equation}
    E(X + X'|\mathcal{F}') = E(X|\mathcal{F}') + E(X'|\mathcal{F}'), \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

Note que a igualdade acima é uma igualdade entre variáveis aleatórias.

\begin{proof}
  Sabemos que $Y = E(X|\mathcal{F}') + E(X'|\mathcal{F}')$ é uma variável aleatória bem definida.
  Mais do que isso, sabemos que ela é uma candidata muito boa a $E(X + X'|\mathcal{F}')$.
  Logo, por unicidade da esperança condicional, basta verificar que $Y$ satisfaz as condições da Definição~\ref{d:esperanca_condicional} com respeito a $X + X'$.
  De fato
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável, por ser uma soma de duas variáveis $\mathcal{F}'$-mensuráveis e
  \item por linearidade da esperança (não da esperança condicional), temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E\big( E(X|\mathcal{F}')\1_A + E(X'|\mathcal{F}')\1_A \big)\\
        & = E\big( E(X|\mathcal{F}')\1_A\big) + E\big(E(X'|\mathcal{F}')\1_A \big)\\
        & = E(X \1_A) + E(X' \1_A) = E\big( (X + X') \1_A \big).
      \end{split}
    \end{equation}
  \end{enumerate}
  Isso termina a prova do proposição.
\end{proof}

\begin{exercise}
  Dados $X \in \mathcal{L}^1$ e $\alpha \in \mathbb{R}$, mostre que $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$.
\end{exercise}

Uma outra propriedade bem simples da esperança condicional é a monotonicidade.

\begin{lemma}
  \label{l:ec_mono}
  Se $X \geq X'$ em $\mathcal{L}^1(P)$, então
  \begin{equation}
    E(X|\mathcal{F}') \geq E(X'|\mathcal{F}'), \text{$P$-quase certamente.}
  \end{equation}
  Em particular, se $X \geq 0$, então $E(X|\mathcal{F}') \geq 0$ quase certamente.
\end{lemma}

\begin{proof}
  Seja $A = [E(X'|\mathcal{F}') - E(X|\mathcal{F}') > 0]$, que pertence a $\mathcal{F}'$.
  Então
  \begin{equation}
    0 \leq E\big( (E(X'|\mathcal{F}') - E(X|\mathcal{F}')) \1_A \big) = E\big((X' - X) \1_A\big) \leq 0,
  \end{equation}
  o que implica que $P(A) = 0$.
\end{proof}



\begin{proposition}
  \label{p:EZX_ZEX}
  Se $X, ZX \in \mathcal{L}^1(P)$, com $Z \in \mathcal{F}'$, temos
  \begin{equation}
    E(XZ|\mathcal{F}') = Z E(X|\mathcal{F}') \text{ $P$-quase certamente}.
  \end{equation}
  Em particular, $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$, para todo $\alpha \in \mathbb{R}$.
  Uma outra consequência interessante é que $Z E(X|\mathcal{F}')$ estará automaticamente em $\mathcal{L}^1$.
\end{proposition}

De maneira bastante informal, vamos dar uma intuição para o resultado acima.
Ao considerarmos a esperança condicional dada $\mathcal{F}'$, nós já conhecemos as variáveis aleatórias $\mathcal{F}'$-mensuráveis, portanto elas se comportam como constantes.

\begin{proof}
  Mais uma vez, basta verificar que $Z E(X|\mathcal{F}')$ satisfaz as condições que definem a esperança condicional.
  A primeira é trivial, pois $Z E(X|\mathcal{F}')$ é $\mathcal{F}'$-mensurável por ser um produto de funções $\mathcal{F}'$-mensuráveis.

  Para provar a segunda condição, começamos com o caso $Z = \1_B$, implicando que $B \in \mathcal{F}'$, donde
  \begin{equation*}
    E\big(ZE(X|\mathcal{F}') \1_A \big) = E\big( E(X|\mathcal{F}') \1_{A \cap B}\big) = E(X \1_{A \cap B}) = E(ZX \1_A).
  \end{equation*}
  Por linearidade, já sabemos que o resultado vale para funções $Z$ simples e gostaríamos de extender para quaisquer $Z$ positivas via Teorema da Convergência Monótona.
  Um problema aqui é que mesmo que $Z$ seja positiva, não sabemos se $E(X|\mathcal{F}')$ também será positiva.

  Portanto, trataremos primeiramente do caso $X \geq 0$.
  Para tais $X$, sabemos pelo Lema~\ref{l:ec_mono} que $E(X|\mathcal{F}') \geq 0$ quase certamente.
  Daí, podemos concluir que $Z E(X|\mathcal{F}') = E(ZX|\mathcal{F}')$ para toda $Z \geq 0$, podemos aproximá-la por baixo por $Z_n$ simples e, pelo Teorema da Convergência Monótona,
  \begin{equation}
    \begin{array}{e}
      E\big( Z E(X|\mathcal{F}') \big) & \overset{\text{TCM}}= & \lim_n E\big( Z_n E(X|\mathcal{F}') \big)\\
      & = & \lim_n E\big( E(Z_n X|\mathcal{F}') \big) \overset{\text{TCM}}= E\big( E(ZX|\mathcal{F}') \big).
    \end{array}
  \end{equation}
  O que mostra o resultado sempre que $X \geq 0$.

  Além disso, pela Proposição~\ref{p:ec_em_L1}, sabemos que $Z E(X|\mathcal{F}') \in \mathcal{L}^1$.
  Podemos finalmente concluir a prova decompondo $X = X_+ - X_-$ e a linearidade.
\end{proof}

Para corroborar nossa afirmação que a esperança condicional é uma aproximação da variável aleatória, fornecemos o seguinte

\begin{lemma}
  Se $X \in \mathcal{L}^2(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$, então $E(X|\mathcal{F}')$ é a projeção ortogonal de $X$ no espaço vetorial $H_{\mathcal{F}'}$.
  Onde $H_{\mathcal{F}'} = \{Y \in \mathcal{L}^2; Y \text{ é $\mathcal{F}'$-mensurável}\}$.
\end{lemma}

\begin{proof}
  Temos que verificar que $X - E(X|\mathcal{F}')$ é ortogonal a $H_{\mathcal{F}'}$.
  Ou seja, mostrar que para todo $Z \in H_{\mathcal{F}'}$, temos
  \begin{equation}
    E\big( XZ - E(X|\mathcal{F}') Z \big) = 0.
  \end{equation}
  Note que não é claro que essa esperança faz sentido, pois não sabemos que $ZE(X|\mathcal{F}') \in \mathcal{L}^1$.
  Mas isso segue facilmente da Proposição~\ref{p:EZX_ZEX}.

  Agora sim, se $Z = \1_{A}$ para algum $A \in \mathcal{F}'$, essa afirmação segue da definição de $E(X|\mathcal{F}')$.
  Finalmente podemos extender esse resultado a funções simples, positivas e finalmente a todas $Z \in H_{\mathcal{F}'}$.
\end{proof}

Vimos acima uma metodologia que se repete frequentemente.
Digamos que queremos provar que uma determinada expressão nos dá a esperança condicional de algo.
Podemos começar provando esse resultado para funções indicadoras, depois para funções simples usando a linearidade provada acima.

Porém ainda falta um ingrediente bastante importante para construir ou verificar que determinadas variáveis são esperanças condicionais.

\begin{theorem}[Convergência Monótona para Esperanças Condicionais]
  \label{t:TCM_EC}
  Se $X_n \uparrow X$, todas em $\mathcal{L}^1(P)$, então
  \begin{equation}
    \lim_n E(X_n|\mathcal{F}') = E(X|\mathcal{F}').
  \end{equation}
\end{theorem}

\begin{proof}[Demonstração do Teorema~\ref{t:TCM_EC}]
  Sabemos que $E(X_{n+1} | \mathcal{F}') \geq E(X_n|\mathcal{F}')$, logo $E(X_n|\mathcal{F}') \uparrow Y$.
  Vamos demosntrar que $Y = E(X|\mathcal{F}')$.
  \begin{enumerate}
  \item Por ser um limite de funções $\mathcal{F}'$ mensuráveis, $Y$ é $\mathcal{F}'$-mensurável.
  \item Dado $A \in \mathcal{F}'$, temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E(\lim_n E(X_n |\mathcal{F}') \1_A) \overset{\text{TCM}}= \lim_n E\big( E(X_n|\mathcal{F}') \1_A \big)\\
        & = \lim_n E(X_n \1_A) \overset{\text{TCM}}= E(X \1_A).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que termina a prova do teorema.
\end{proof}

\newpage

No que segue, muitas vezes escreveremos $E(X|Z)$ para representar $E(X|\sigma(Z))$.

\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $E_1 \times E_2$ e $\d P = \rho(x,y) \d \mu_1 \d \mu_2$, onde $\rho:E_1 \times E_2 \to \mathbb{R}_+$ é uma densidade.
  Dê sentido à expressão abaixo e mostre que elá é $E(X_1|X_2)$:
  \begin{equation}
     \frac{\int x\rho(x, X_2) \mu_1(\d x)}{\int \rho(x, X_2) \mu_1(\d x)}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Seja $E$ enumerável com uma $\sigma$-álgebra $\mathcal{F}'$.
  Mostre que
  \begin{equation}
    \mathcal{F}' = \sigma(A_i, i \geq 1), \text{ com $A_i \subseteq E$ disjuntos}.
  \end{equation}
  Suponha que todos conjuntos $A_i$ tem probabilidade positiva e mostre que
  \begin{equation}
    E(X|\mathcal{F}') = \sum_i E^i(X) \1_{A_i},
  \end{equation}
  onde $E^i$ é a esperança com respeito à probabilidade $P(\cdot|A_i)$.
  Em breve extenderemos esse tipo de resultado a espaços quaisquer.
\end{exercise}

\newpage

Uma outra propriedade que a esperança condicional herda da integral é a

\begin{proposition}[Desigualdade de Jensen]
  Se $\phi:\mathbb{R} \to \mathbb{R}$ é convexa, $X, \phi(X) \in \mathcal{L}^1(P)$, então
  \begin{equation}
    \phi\big( E(X|\mathcal{F}') \big) \leq E\big( \phi(X) | \mathcal{F}' \big).
  \end{equation}
\end{proposition}

\begin{proof}
  Se $\phi$ for uma função linear, o resultado segue da linearidade que já provamos para a esperança condicional.
  Além disso, se temos uma função $\psi:\mathbb{R} \to \mathbb{R}$ linear e tal que $\psi(x) \leq \phi(x)$ para todo $x \in \mathbb{R}$, então
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq E\big( \psi(X) | \mathcal{F}' \big) = \psi \big( E(X|\mathcal{F}') \big).
  \end{equation}
  Tomamos finalmente o supremo em todas as $\psi$ lineares com $\psi \leq \phi$ dos dois lados da desigualdade acima, obtendo
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq \sup_{\psi \leq \phi \atop \psi \text{ linear}} \psi \big( E(X|\mathcal{F}') \big) = \phi \big( E(X|\mathcal{F}') \big),
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{corollary}
  Se $X \in \mathcal{L}^1(P)$, então $\big| E(X|\mathcal{F}') \big| \leq E\big(|X| \big| \mathcal{F}' \big)$.
\end{corollary}

Uma outra propriedade interessante da esperança condicional diz respeito a sua relação com independência.

\begin{proposition}
  Se $X \in \mathcal{L}^1(P)$ é independente de $\mathcal{F}'$, então
  \begin{equation}
    E(X|\mathcal{F}') = E(X) \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

\begin{proof}
  Funções constantes são sempre mensuráveis. Além disso, se $A \in \mathcal{F}'$, então
  \begin{equation}
    E(X \1_A) = E(X) P(A) = E\big( E(X) \1_A \big),
  \end{equation}
  concluindo a prova.
\end{proof}

Terminamos essa seção com o que chamamos da propriedade de torre da esperança condicional.

\begin{proposition}
  Se $\mathcal{F}' \subseteq \mathcal{F}''$ são ambas sub-$\sigma$-álgebras de $\mathcal{F}$, então para $X \in \mathcal{L}^1(P)$, temos
  \begin{equation}
    \label{e:ec_torre}
    E\big( E(X|\mathcal{F}') \big| \mathcal{F}'' \big) = E(X|\mathcal{F}') = E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big),
  \end{equation}
  ou em outras palavras, independentemente da ordem, prevalece a condição na menor $\sigma$-álgebra.
  Consequentemente, $E\big( E(X|\mathcal{F}') \big) = E(X)$.
\end{proposition}

\begin{proof}
  Como $E(X|\mathcal{F}')$ é $\mathcal{F}''$-mensurável, a Proposição~\ref{p:EZX_ZEX}, aplicada com $X = 1$, mostra a primeira igualdade em \eqref{e:ec_torre}.

  Falta mostrar que $E\big( E(X|\mathcal{F}'') \big| \mathcal{F}'\big)$ é a esperança condicional de $X$ dada $\mathcal{F}'$.
  Obviamente ela é $\mathcal{F}'$-mensurável, e nos resta verificar a segunda condição.
  Mas para todo $A \in \mathcal{F}'$, lembrando que $A$ também pertence a $\mathcal{F}''$ e usando a definição de esperança condicional duas vezes,
  \begin{equation}
    E\Big( E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big) \1_A \Big) = E\big( E(X | \mathcal{F}'')  \1_A \big) = E(X \1_A).
  \end{equation}
  O que termina a prova da proposição.
\end{proof}

\begin{lemma}
  \label{l:f_g_circ_X}
  Se $X: \Omega \to E$ é um elemento aleatório e $f:\Omega \to \mathbb{R}$ é $\sigma(X)$-mensurável, então existe uma $g:E \to \mathbb{R}$ mensurável tal que $f = g \circ X$.
\end{lemma}

\begin{proof}
  Como de costume, consideramos primeiramente o caso $f = \1_A$
  Claramente $A$ tem que pertencer a $\sigma(X)$, ou seja $A = X^{-1}(B)$ para algum $B \in \mathcal{A}$.
  Neste caso colocamos $g = \1_B$, donde obtemos $f(\omega) = 1 \Leftrightarrow \omega \in A \Leftrightarrow X(\omega) \in B \Leftrightarrow g \circ X = 1$.

  No caso em que $f$ é simples, temos $f = \sum_i a_i (g_i \circ X) = (\sum_i a_i g_i) \circ X$.
  Se $f$ é positiva, então ela é um limite crescente de funções do tipo $g_n \circ X$, além disso podemos tomar $g_n$ crescentes, pois
  \begin{equation}
    f_{n+1} = f_{n+1} \vee f_{n} = (g_{n+1} \circ X) \vee (g_n \circ X) = (g_n \vee g_{n+1}) \circ X.
  \end{equation}

  Finalmente usamos a linearidade da composição novamente para resolver o caso geral $f = f_+ - f_-$.
\end{proof}

Se $X: \Omega \to E$ é elemento aleatório, então $E(Y|\sigma(X))$ é obviamente $\sigma(X)$-mensurável.
Pelo lema anterior, $E(Y|\sigma(X)) = g \circ X$ para alguma $g: E \to \mathbb{R}$.
Nesse caso denotamos
\begin{equation}
  E(Y|X = x) = g(x).
\end{equation}

\begin{exercise}
  Mostre que $g$ é única $X \circ P$-quase certamente.
\end{exercise}

\newpage

Gostaríamos de dizer que $E(Y|X = x)$ satisfaz alguma propriedade que justifique essa notação.
Apesar de que apenas na próxima seção poderemos justificar completamente essa nomenclatura, nesse momento já podemos mostrar a seguinte relação
\begin{equation*}
  E(Y) = E\big( E(Y | X) \big) = E\big( E(Y | X = x) \circ X \big) = \int E(Y| X = x) (X \circ P) (\d x).
\end{equation*}
Em outras palavras, para integrar $Y$, basta conhecermos a distribuição de $X$ e a esperança condicional de $Y$, dado que $X = x$.

\begin{exercise}
  Sejam $X$ e $Y$ as coordenadas canônicas em $E_1 \times E_2$, com a probabilidade $P = \mu_1 \otimes \mu_2$ e seja $f:E_1 \times E_2 \to \mathbb{R}$ em $\mathcal{L}^1(P)$.
  Mostre que
  \begin{equation}
     E(f|X = x) = \int f(x, y) \mu_2(\d y).
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $\mathbb{R}$ e $P_1$ é uma probabilidade em $E_1$, mostre que em $P_1 \star K$ temos
  \begin{equation}
    E(X_2|X_1 = x_1) = \int x_2 K(x_1, \d x_2).
  \end{equation}
\end{exercise}

Um outro resultado bastante importante é o seguinte

\begin{theorem}[Teorema da Convergência Dominada para Esperanças Condicionais]
  Se $X_n \to X$ e existe $Y \in \mathcal{L}^1(P)$ tal que $|X_n| \leq Y$ para todo $n$, então
  \begin{equation}
    E(X_n | \mathcal{F}) \to E(X|\mathcal{F}) \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

\begin{proof}
  Seja $Z_n = \sup_{k \geq n} |X_k - X|$ o erro máximo à partir de $n$.
  Claramente, $Z_n \downarrow 0$ quase certamente e além disso
  \begin{equation}
    |Z_n| \leq \sup_{k \geq 1} |X_k| + |X| \leq 2 Y,
  \end{equation}
  donde $E(Z_n) \to E(0) = 0$, quase certamente pelo Teorema da Convergência Dominada.

  Obviamente $E(Z_n|\mathcal{F})$ é uma sequência positiva e não-crescente, logo decresce quase certamtente para algum $Z$.
  Daí,
  \begin{equation}
    \big| E(X_n | \mathcal{F}) - E(X | \mathcal{F}) \big| \leq E(Z_n | \mathcal{F}) \downarrow Z \geq 0.
  \end{equation}
  Mas $E(Z) \leq E\big( E(Z_n|\mathcal{F}) \big) = E(Z_n)$.
  Como $E(Z_n)$ vai a zero pelo Teorema da Convergência Dominada, temos que $Z = 0$ quase certamente como gostaríamos.
\end{proof}

\section{Probabilidade Condicional Regular}

Já sabemos definir por exemplo $E(\1_A|X = x)$.
Gostaríamos porém de garantir que essa expressão definisse uma probabilidade em $A$, e chamaríamos essa probabilidade de $P(A|X = x)$.
Mas certamente gostaríamos que $P(\cdot|X = x)$ fosse uma função $\sigma$-aditiva.
Essa especulação parece promissora, por exemplo se $A$ e $B$ são disjuntos,
\begin{equation*}
  P(A \cup B |\mathcal{F}') = E(\1_{A \cup B} | \mathcal{F}') = E(\1_A|\mathcal{F}') + E(\1_{B}|\mathcal{F}') = P(A|\mathcal{F}') + P(B|\mathcal{F}').
\end{equation*}
Ótimo, mas ainda temos o seguinte problema.

Lembramos que a equação acima está bem definida apenas quase certamente.
Poderíamos portanto garantir que para uma classe enumerável de conjuntos $A \in \mathcal{F}$, essa aditividade fosse satisfeita.
Porém, a $\sigma$-álgebra $\mathcal{F}$ é frequentemente não enumerável, portanto não conseguimos a $\sigma$-aditividade plena.
Isso pode ser contornado se o espaço for canônico, como afirma o nosso próximo resultado.

\begin{theorem}
  \label{t:prob_cond_reg_F}
  Seja $X: \Omega \to E$ um elemento aleatório tomando valores em um espaço canônico $E$ e $\mathcal{F}'$ uma sub-$\sigma$-álgebra qualquer.
  Então existe um núcleo $K$ entre $\Omega$ e $E$, tal que para todo $B$
  \begin{equation}
    K(\omega, B) = E\big(\1_{[X \in B]} | \mathcal{F}'\big) (\omega) \text{ $P$-quase certamente.}
  \end{equation}
  A esse núcleo, damos o nome Probabilidade Condicional Regular (dada $\mathcal{F}'$), que é denotada por $P(X \in \cdot|\mathcal{F}')$.
\end{theorem}

\begin{proof}
  Primeiramente observamos que podemos assumir sem perda de generalidade que $E = \mathbb{R}$.
  De fato, suponha que já conhecemos o resultado pra variáveis aleatórias e somos dados $X$ tomando valores em $E$ canônico.
  Como $E$ é canônico, existe uma bijeção $\phi:E \to \mathbb{R}$ bi-mensurável, com imagem mensurável logo $\phi \circ X$ é variável aletória.

  Dessa forma, existe o núcleo $K'(\omega, \cdot) = P(\phi \circ X \in \cdot | \mathcal{F}')(\omega)$ e podemos definir
  \begin{equation}
    K(\omega, \cdot) = \phi^{-1} \circ K'(\omega, \cdot),
  \end{equation}
  que será um núcleo entre $\Omega$ e $E$ pois $\phi^{-1}$ é mensurável.
  Para mostrar que $K = P(X \in \cdot|\mathcal{F}')$, tome $B \in \mathcal{A}$ e observe que
  \begin{equation}
    \begin{split}
      K(\omega, B) & = K'\big(\omega, (\phi^{-1})^{-1}(B)\big) = K'\big(\omega, \phi(B)\big)\\
      & = E \big( \1_{[\phi \circ X \in \phi(B)]} | \mathcal{F} \big) = E \big( \1_{[X \in B]} | \mathcal{F} \big),
    \end{split}
  \end{equation}
  terminando a prova de que é suficiente considerar o caso $E = \mathbb{R}$.

  Vamos agora considerar $X$ uma variável aleatória e definimos para cada $q \in \mathbb{Q}$,
  \begin{equation}
    F(\omega, q) = E(\1_{[X \leq q]} | \mathcal{F}')(\omega),
  \end{equation}
  que é mensurável e bem definida quase certamente.

  Observamos que
  \begin{enumerate}[\quad a)]
  \item $F(\omega, q) \in [0,1]$, $P$-quase certamente para todo $q \in \mathbb{Q}$, pois $\1_{[X \leq q]} \in [0,1]$.
  \item Se $q \leq q'$, então $F(\omega, q) \leq F(\omega, q')$, $P$-quase certamente, pois $\1_{[X \leq q]} \leq \1_{[X \leq q']}$.
  \item Se escolhemos $q_n = n$ (analogamente $q_n = -n$), então $F(\omega, n) \to 1$ (analogamente $F(\omega, -n) \to 0$), $P$-quase certamente, pois $[X \leq n] \uparrow \Omega$ e pelo Teorema da Convergência Monótona para esperanças condicionais.
  \end{enumerate}
  Tomando a interseção de todos $q \in \mathbb{Q}$ para o ítem $a)$, todos $q, q' \in \mathbb{Q}$ no ítem $b)$ e os dois casos do ítem $c)$, encontramos um evento quase certo $\Omega'$ onde valem os três ítens acima.
  Para os pontos de medida nula $\omega \in \Omega \setminus \Omega'$, podemos redefinir $F(\omega, p)$ como uma função de distribuição acumulada fixa $F_0$.
  Dessa forma valem os ítens $a)$, $b)$ e $c)$ para todos pontos de $\Omega$.
  Note também que após essa redefinição, ainda obtemos $F(\cdot, q)$ mensurável para todo $q \in \mathbb{Q}$, pois redefinimos $F$ como sendo uma constante em um conjunto mensurável.

  Vamos agora extender as definições acima para $\hat{F}:\Omega \times \mathbb{Q}$
  \begin{equation}
    \hat{F}(\omega, x) = \lim_{q \downarrow x} F(\omega, q),
  \end{equation}
  que existe pois $F$ é monótona e limitada.
  Assim obtivemos que $\hat{F}(\omega, x)$ satisfaz as três condicões acima para todo ponto, o que caracteriza uma função acumulada de distribuição.
  Existe portanto para todo $\omega \in \Omega$ uma medida $\mu_\omega$ na reta tal que
  \begin{equation}
    \mu_\omega\big((-\infty, x]\big) = \hat{F}(\omega,x),
  \end{equation}
  e definimos $K(\omega, A) = \mu_\omega(A)$.

  Exercício: mostre que $\hat{F}$ é contínua à direita.

  Pela Proposição~\ref{p:K_nucleo_na_classe}, já sabemos que $K$ é um núcleo de transição, pois $K\big(\cdot, (-\infty, q]\big)$ é mensurável para todo $q$ e esses conjuntos formam um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$.

  Finalmente, precisamos verificar que $K$ é a prometida esperança condicional.
  Para tanto, fixado $B \in \mathcal{B}(\mathbb{R})$, gostaríamos de ver que
  \begin{equation}
    K(\omega, B) = E(\1_{[X \in B]} | \mathcal{F}')(\omega), \text{ $P$-quase certamente.}
  \end{equation}
  Definindo como $\mathcal{G} \subseteq \mathcal{B}(\mathbb{R})$ a classe onde isso vale, já vimos que $\mathcal{G}$ contém $(-\infty, q]$ para $q \in \mathbb{Q}$ pois $K(\omega, B) = \hat{F}(\omega, q)$ quase certamtente.
  Mas $\mathcal{G}$ é um $\lambda$-sistema pelo Teorema da Convergência Monótona para esperanças condicionais.
  Já que $\mathcal{G}$ contém um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$, terminamos a prova do teorema.
\end{proof}

Interpretamos $P(X \in \cdot| \mathcal{F}')$ da seguinte forma.
Se alguém tiver acesso à $\sigma$-álgebra $\mathcal{F}'$ (por exemplo se $\mathcal{F}' = \sigma(Y)$ e o pessoa for capaz de observar o valor de $Y(\omega)$), ela pode não saber o valor de $X(\omega)$, mas já sabe a nova distribuição condicional de $X$: $P(X \in \cdot|\mathcal{F}')(\omega)$.

\begin{exercise}
  Se $X$ é variável aleatória então
  \begin{equation}
    E(X|\mathcal{F}') = \int x P(X \in \d x|\mathcal{F}'), \text{ $P$-q.c.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $\Omega = E_1 \times E_2$ com $E_2$ canônico é dotado da probabilidade $\d P = \rho(x_1, x_2) \mu_1 \otimes \mu_2 (\d x_1 \d x_2)$, então
  \begin{equation}
    P(X_2 \in A|X_1) = \frac{\int_A \rho(X_1, x_2) \mu_2(\d x_2)}{\int \rho(X_1, x_2) \mu_2(\d x_2)},
  \end{equation}
  $P$-quase certamtente.
\end{exercise}

\newpage

Uma das grandes vantagens de ter um núcleo de transição a determinar uma distribuição conjunta, como é o caso quando obtemos uma probabilidade condicional regular, é que podemos usar a versão generalizada de Fubini.
Antes, nós somente podiamos usar Fubini para espaços produto.

Vamos introduzir nosso último conceito de condicionais.

\begin{definition}
  Dado $X:\Omega \to E$ um elemento aleatório, dizemos que um núcleo $K: E \times \mathcal{F} \to [0,1]$ é uma \emph{probabilidade condicional regular dado $X$} se
  \begin{equation}
    \label{e:K_prob_cond_reg_X}
    K\big( X(\omega), A\big) = E(\1_A|\sigma(X)), \text{ $P$-quase certamente.}
  \end{equation}
  Nesse caso escrevemos $K(x, A) = P(A|X = x)$.
\end{definition}

A existência de tais condicionais não decorre imediatamente do Teorema~\ref{t:prob_cond_reg_F}, já que o Lema~\ref{l:f_g_circ_X} não se aplica para núcleos de transição.
A principal dificuldade de adaptarmos esse lema para núcleos vem do fato de que a imagem de uma função mensurável não é necessariamente mensurável.

Contudo, não estamos muito longe de obter a existência das condicionais definidas acima.

\begin{theorem}
  \label{t:prob_cond_reg_X}
  Sejam $\Omega$ e $E$ espaços mensuráveis e $X: \Omega \to E$ um elemento aleatório.
  Então se $\Omega$ é canônico, existe $P(A|X = x)$, a probabilidade condicional regular dada $X$.
\end{theorem}

Observe que a hipótese de ser canônico é sobre $\Omega$!

\begin{proof}
  Definimos o elemento aleatório $X^\star: \Omega \to \Omega \times E'$ dado por $X^\star (\omega) = (\omega, X(\omega))$.
  Como $X^\star$ é claramente mensurável, ele induz uma probabilidade natural em $\Omega \times E$, mais precisamente $P^\star = X^\star \circ P$.

  Introduzimos também em $\Omega \times E$ as projeções canônicas $\pi_\Omega$ e $\pi_E$.
  Utilizamos agora o Teorema~\ref{t:prob_cond_reg_F} para obter um núcleo $K^\star$ de $\Omega \times E$ em $\Omega$ que dá a probabilidade condicional regular de $\pi_\Omega$ (com respeito a $P^\star$) dada $\sigma(\pi_E)$, ou seja
  \begin{equation}
    K^\star(\cdot, A) = E^\star \big(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E) \big) \text{ $P^\star$-q.c.}
  \end{equation}
  Mas como $K^\star(\cdot, A)$ é $\sigma(\pi_E)$-mensurável, podemos usar o Lema~\ref{l:f_g_circ_X} para obter uma $g_A: E \to \Omega \times E$ tal que
  \begin{equation}
    K^\star\big( (\omega, x), A \big) = g_A (\pi_E(\omega, x)) = g_A(x).
  \end{equation}
  Em particular, o lado esquerdo da equação acima não depende de $\omega$.
  Podemos finalmente definir $K(x, A) = g_A(x)$.

  Vemos facilmente que $K$ é um núcleo, pois toda $g_A$ é mensurável e $K(x, \cdot) = K^\star\big( (\omega, x), \cdot \big)$, que é uma medida.
  Finalmente, temos que verificar \eqref{e:K_prob_cond_reg_X}.
  \begin{equation}
    \begin{split}
      K(X(\omega), A) & = g_A(X(\omega)) = K^\star \big( (\omega, X(\omega)), A \big) = K^\star (X^\star(x), A)\\
      & \overset{\text{$P^\star$-q.c.}}= E^\star \big(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E) \big) \circ X^\star.
    \end{split}
  \end{equation}
  Agora somente resta nos ver que essa é uma versão de $E(\1_A|\sigma(X))$, que segue da conta
  \begin{equation}
    \begin{split}
      E\big( E^\star(& \1_{[\pi_\Omega \in A]} | \sigma(\pi_E)) \circ X^\star \1_{[X \in B]}\big)\\
      & = E^\star \big( E^\star(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E)) \1_{[\pi_E \in B]}\big)\\
      & = E^\star ( \1_{[\pi_\Omega \in A, pi_E \in B]} ) = E(\1_A \1_{[X \in B]}),
    \end{split}
  \end{equation}
  como gostaríamos.
\end{proof}

\subsection{Princípio da substituição}

No próximo resultado, veremos como o conceito abstrato de probabilidade condicional regular pode nos ajudar a fazer cálculos envolvendo variáveis dependentes.

\begin{theorem}
  Dado $X: \Omega \to E$ um elemento aleatório, se existe $P(\cdot | X = x)$ (em particular se $\Omega$ é canônico), então a medida $P(\cdot | X = x)$ tem suporte no conjunto $[X = x] \subseteq \Omega$, $X \circ P$-quase certamente.
\end{theorem}

\begin{proof}
  Seja $G \in \Omega \times E$ dado por $G = \{(\omega, x); X(\omega) \neq x\}$.
  Como $G = [\pi_\Omega \neq X \circ \pi_E]$, sabemos que $G$ é mensurável.
  Para $x \in E$, denotamos por $G'_x$ as fatias $\{\omega \in \Omega; (\omega, x) \in G\}$ (que coincidem com $[X = x]^c$) e que são $\mathcal{F}$-mensuráveis para quase todo $x \in E$, como foi visto no Teorema de Fubini.

  Com essa notação, vemos que
  \begin{equation}
    \begin{split}
      0 = E^\star (\1_G) & = \int P^\star(G | \pi_E = x) (\pi_E \circ P^\star) (\d x)\\
      & = \int K(x, G'_x) (X \circ P) (\d x)\\
      & = \int P\big( [X = x]^c | X = x \big) (X \circ P) (\d x).
    \end{split}
  \end{equation}
  Mas como o integrando acima é não-negativo, ele deve ser zero $(X \circ P)$-quase certamente, finalizando a prova do teorema.
\end{proof}


\end{document}
