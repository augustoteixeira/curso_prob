\RequirePackage{nag}
\documentclass[reqno, draft]{book}
\usepackage{amssymb, amsmath, amsthm}

\usepackage{wasysym}

%%%%%%%%%%%%%%%%%%%%%%%%%% TOC including bibliog %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[nottoc]{tocbibind}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%% TOC in odd pages only %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{afterpage}
\AtBeginDocument{\addtocontents{toc}{\protect\afterpage\protect\cleardoublepage}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Headers %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\headheight}{16pt}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE]{\leftmark}
\fancyhead[LO]{}
\fancyhead[RO]{\rightmark}
\fancyhead[RE]{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Mark badboxes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\overfullrule=5pt
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[final]{microtype}

\usepackage{titlesec}
\titleformat
{\chapter} [display]
{\bfseries\LARGE\itshape} {\chaptername~\thechapter} {0.5ex}
{ \vspace{2ex}
  \rule{\textwidth}{1pt}
  \vspace{2ex}
  \centering
}[\vspace{-0.5ex}\rule{\textwidth}{0.3pt}]

\usepackage[margin=10pt,font=small,labelfont=bf]{caption}

\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
%\pgfplotsset{compat=1.11}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}

\usepackage{ifthen}
\usepackage{ifdraft}


\usepackage{makeidx}
\makeindex
%\usepackage{imakeidx}
%\makeindex[columns=2, title=Alphabetical Index]

\usepackage[obeyDraft]{todonotes}

%%%%%%%%%%%%%%%%%%%%%%%%%% trying lualatex %%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage[charter]{mathdesign}  % sets the math font
%\usepackage{fontspec}
%\setmainfont{TeX Gyre Bonum}
%\def\mathds{}
%\def\widebar{\bar}
%\usepackage{newtxtext,newtxmath}
\usepackage{mathpazo}
\usepackage{dsfont} % includes bb 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumerate}
\usepackage{color}
\usepackage{calc}

%%%%%%%%%%%%%%%%%%% Define self-sufficient widebar %%%%%%%%%%%%%%%%%
\makeatletter
\let\save@mathaccent\mathaccent
\newcommand*\if@single[3]{%
  \setbox0\hbox{${\mathaccent"0362{#1}}^H$}%
  \setbox2\hbox{${\mathaccent"0362{\kern0pt#1}}^H$}%
  \ifdim\ht0=\ht2 #3\else #2\fi
  }
%The bar will be moved to the right by a half of \macc@kerna, which is computed by amsmath:
\newcommand*\rel@kern[1]{\kern#1\dimexpr\macc@kerna}
%If there's a superscript following the bar, then no negative kern may follow the bar;
%an additional {} makes sure that the superscript is high enough in this case:
\newcommand*\widebar[1]{\@ifnextchar^{{\wide@bar{#1}{0}}}{\wide@bar{#1}{1}}}
%Use a separate algorithm for single symbols:
\newcommand*\wide@bar[2]{\if@single{#1}{\wide@bar@{#1}{#2}{1}}{\wide@bar@{#1}{#2}{2}}}
\newcommand*\wide@bar@[3]{%
  \begingroup
  \def\mathaccent##1##2{%
%Enable nesting of accents:
    \let\mathaccent\save@mathaccent
%If there's more than a single symbol, use the first character instead (see below):
    \if#32 \let\macc@nucleus\first@char \fi
%Determine the italic correction:
    \setbox\z@\hbox{$\macc@style{\macc@nucleus}_{}$}%
    \setbox\tw@\hbox{$\macc@style{\macc@nucleus}{}_{}$}%
    \dimen@\wd\tw@
    \advance\dimen@-\wd\z@
%Now \dimen@ is the italic correction of the symbol.
    \divide\dimen@ 3
    \@tempdima\wd\tw@
    \advance\@tempdima-\scriptspace
%Now \@tempdima is the width of the symbol.
    \divide\@tempdima 10
    \advance\dimen@-\@tempdima
%Now \dimen@ = (italic correction / 3) - (Breite / 10)
    \ifdim\dimen@>\z@ \dimen@0pt\fi
%The bar will be shortened in the case \dimen@<0 !
    \rel@kern{0.6}\kern-\dimen@
    \if#31
      \overline{\rel@kern{-0.6}\kern\dimen@\macc@nucleus\rel@kern{0.4}\kern\dimen@}%
      \advance\dimen@0.4\dimexpr\macc@kerna
%Place the combined final kern (-\dimen@) if it is >0 or if a superscript follows:
      \let\final@kern#2%
      \ifdim\dimen@<\z@ \let\final@kern1\fi
      \if\final@kern1 \kern-\dimen@\fi
    \else
      \overline{\rel@kern{-0.6}\kern\dimen@#1}%
    \fi
  }%
  \macc@depth\@ne
  \let\math@bgroup\@empty \let\math@egroup\macc@set@skewchar
  \mathsurround\z@ \frozen@everymath{\mathgroup\macc@group\relax}%
  \macc@set@skewchar\relax
  \let\mathaccentV\macc@nested@a
%The following initialises \macc@kerna and calls \mathaccent:
  \if#31
    \macc@nested@a\relax111{#1}%
  \else
%If the argument consists of more than one symbol, and if the first token is
%a letter, use that letter for the computations:
    \def\gobble@till@marker##1\endmarker{}%
    \futurelet\first@char\gobble@till@marker#1\endmarker
    \ifcat\noexpand\first@char A\else
      \def\first@char{}%
    \fi
    \macc@nested@a\relax111{\first@char}%
  \fi
  \endgroup
}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%% array for equations alignment %%%%%%%%%%%%%%%%%%%%%
\usepackage{array}
\newcolumntype{e}{>{\displaystyle}r @{\,} >{\displaystyle}c @{\,} >{\displaystyle}l}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[notcite,notref]{showkeys}

\usepackage{hyperref}
\hypersetup{final}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

%%%%%%%%%%%%%%%%%%%%%% Optional filling text %%%%%%%%%%%%%%%%%%%%%%%
\newif\ifboxrepeat \boxrepeattrue
\newcount\badnesspar
\newcount\tmpnum
\def\testbadnesspar#1{\par
   \setbox0=\vbox{#1\par
   \global\badnesspar=0
   \loop
      \setbox0=\lastbox
      \ifvoid0 \boxrepeatfalse \else
         \unskip \unpenalty \setbox0=\hbox to\hsize{\unhbox0}
         \ifnum\badness > \badnesspar \global\badnesspar=\badness \fi
      \fi
      \ifboxrepeat \repeat
   }
}
\def\choosepar{\par\def\tmp{}\tmpnum=2000000 \chooseparA}
\def\chooseparA#1{\ifx^#1^\tmp \else
   \testbadnesspar{#1}
   \ifnum\tmpnum>\badnesspar \tmpnum=\badnesspar \def\tmp{#1}\fi
   \expandafter\chooseparA \fi
}
\def\chooseoptpar#1{%
   \def\opt##1##2{##1}
   \testbadnesspar{#1}\tmpnum=\badnesspar
   \def\opt##1##2{##2}
       \testbadnesspar{#1}
   \ifnum\badnesspar>\tmpnum \def\opt##1##2{##1}\fi
   #1\par
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%% New commands %%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand*\1{\mathds{1}}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}[theorem]{Corolário}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{proposition}[theorem]{Proposição}
\newtheorem{scholia}[theorem]{Escólio}
\newtheorem{definition}[theorem]{Definição}
\newtheorem{question}[theorem]{Questão}
\newtheorem{notation}[theorem]{Notação}
\newtheorem{example}{Exemplo}[section]
\newtheorem{exercise}[example]{Exercício}

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\Geo}{Geo}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\VT}{VT}

\def \iid{i.i.d.~}
\def \distr{\sim_d}
\renewcommand*\d{\mathop{}\!\mathrm{d}}
\DeclareMathOperator*{\mcup}{{\textstyle \bigcup}}
\DeclareMathOperator*{\mcap}{{\textstyle \bigcap}}
\newcommand*\bigtimes{\tikz[baseline=0, scale=.3]{
\draw[opacity=0] (-.1,-.1) rectangle (1.1, 1.1);
\draw[line width=.5pt] (0,0) -- (1,1) (1,0) -- (0,1);}
}


\newcommand{\todosec}[2]{\ifdraft{\vfill \pagebreak \subsection{#1} #2 \vfill \pagebreak}{}}

%%%%%%%%%%%%%%%%%%%%%%% array paragraph %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{calc}
\def\arraypar#1{\parbox[c]{\textwidth - 2cm}{\centering #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% create text displays %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{environ}
\NewEnviron{display}{
\begin{equation}\begin{array}{c}
  \arraypar{\BODY}
\end{array}\end{equation}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% Make automatic exp{x} or e^x %%%%%%%%%%%%%%%%%%%%%%
\usepackage{etoolbox}
\makeatletter
\def\mathsettoheight#1#2%
  {\setbox\@tempboxa\hbox{{#2}}%
   #1=\ht\@temboxa
   \setbox\@temboxa\box\voidb@x}
\def\mathsettoheight#1#2%
  {\setbox\@tempboxa\hbox{$\m@th\mathpalette{}{#2}$}%
   #1=\ht\@tempboxa
   \setbox\@tempboxa\box\voidb@x}
\makeatother
\newlength\heightin
\newcommand{\ex}[1]{
\mathsettoheight\heightin{#1}
\ifdimless{\heightin}{8pt}{e^{#1}}{\exp\big\{#1\big\}}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% mathclap %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\clap#1{\hbox to 0pt{\hss#1\hss}}
\def\mathllap{\mathpalette\mathllapinternal}
\def\mathrlap{\mathpalette\mathrlapinternal}
\def\mathclap{\mathpalette\mathclapinternal}
\def\mathllapinternal#1#2{\llap{$\mathsurround=0pt#1{#2}$}}
\def\mathrlapinternal#1#2{\rlap{$\mathsurround=0pt#1{#2}$}}
\def\mathclapinternal#1#2{\clap{$\mathsurround=0pt#1{#2}$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Notas de aula: Probabilidade I}
\author{Augusto Teixeira}

\frontmatter

\maketitle

\mbox{}
\thispagestyle{empty}

\newpage

\setcounter{page}{1}

\addcontentsline{toc}{chapter}{Prefácio}
...

\newpage

\thispagestyle{empty}

\tableofcontents

\mainmatter

\chapter{Fundamentos}

A probabilidade moderna se baseia fortemente na Teoria da Medida e supomos durante esse curso que o leitor esteja bem familiarizado com conceitos tais como: Medida de Lebesgue, extensões de medida e teoremas de convergência.
Iremos agora justificar brevemente a escolha da Teoria da Medida para o estudo de probabilidade.

No início da Teoria da Probabilidade, a maioria dos fenômenos estudados apresentava apenas um número finito de resultados possíveis, como por exemplo ao se jogar um dado de seis lados ou sortear uma carta em um baralho.
Em tais casos é desnecessário o uso de ferramentas sofisticadas pra modelar tais situações.
Por exemplo, podemos simplesmente dizer que a probabilidade de se obter cada um dos lados do dado é igual a $1/6$.

Mas digamos por exemplo que queremos um modelo para estudar o volume de chuva em uma cidade durante um ano.
Obviamente, esse volume poderia ser qualquer número real positivo e não podemos simplesmente atribuir valores positivos de probabilidade a cada número real (lembramos que somas não enumeráveis de termos positivos são sempre infinitas).
Mas como podemos continuar nossa modelagem se nem ao menos podemos dizer qual é a probabilidade de chover um determinado volume esse ano, por exemplo $(\pi/19)mm$?

A solução para tal dilema, se baseia no fato de que na verdade nunca estamos interessados no exato resultado do nosso experimento.
Gostaríamos sim de responder perguntas do tipo: qual é a probabilidade de que chova entre zero e $37mm$?
Estamos portanto interessados em atribuir probabilidades não a valoers exatos do experimento, mas a certos conjuntos de possíveis valores.
Chamamos tais conjuntos de \emph{eventos}. \index{evento}

Voltando ao caso do dado de seis lados, poderíamos nos interessar por exemplo pela probabilidade dos seguintes eventos: o lado sorteado foi ímpar ($P(\{1,3,5\}) = 1/2$) ou o lado serteado foi dois ($P(\{2\}) = 1/6$).
E percebemos rapidamente que para eventos disjuntos a probabilidade de sua união é a soma de suas probabilidades (no caso acima, $P(\{1,2,3,5\}) = 1/2 + 1/6 = 2/3$).
Esse caráter aditivo da probabilidade certamente nos remete aos conceitos básicos de Teoria da Medida.
Vamos agora formalizar a discussão acima com mais calma, sob a ótica dessa teoria.

\section{Espaços mensuráveis}

Denotaremos sempre por $\Omega$ o nosso \emph{espaço amostral} \index{espaco@espaço!amostral} (à princípio qualquer conjunto).
Um ponto nesse espaço corresponde por exemplo a um possível resultado do nosso experimento aleatório.

\begin{example} Possíveis exemplos de espaço amostral
  \label{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $\Omega_1 = \{1, 2, \dots, 6\}$,
  \item $\Omega_2 = \mathbb{R}_+$,
  \item $\Omega_3 = \{f:[0,1] \to \mathbb{R}; \text{$f$ é contínua}\}$.
  \end{enumerate}
\end{example}
Os exemplos acima poderiam ser usados em modelar por exemplo: o resultado de um dado, o volume anual de chuva em uma cidade e o comportamento ao longo do dia do preço de uma ação na bolsa de valores.

Consideraremos sempre $\Omega$'s equipados com uma \emph{$\sigma$-álgebra} \index{sigma-algebra@$\sigma$-álgebra} denotada por $\mathcal{F}$.
Mais precisamente
\begin{definition}
  Dizemos que $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ é uma $\sigma$-álgebra se
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{F}$,
  \item $A \in \mathcal{F}$ implica que $A^c \in \mathcal{F}$ e
  \item se $A_1, A_2, \dots \in \mathcal{F}$, então $\cup_i A_i \in \mathcal{F}$.
  \end{enumerate}
\end{definition}
Nesse caso, dizemos que $(\Omega, \mathcal{F})$ é um \emph{espaço mensurável} \index{epaco@espaço!mensuravel@mensurável} e os elementos $A \in \mathcal{F}$ são chamados de \emph{eventos}. \index{evento}

Se $\mathcal{G} \subseteq \mathcal{P}(\Omega)$ (que chamamos de uma classe ou família), denotamos por $\sigma(\mathcal{G})$ a \emph{$\sigma$-álgebra gerada por $\mathcal{G}$} \index{sigma-algebra@$\sigma$-álgebra!gerada por G@gerada por $\mathcal{G}$}, que é a menor $\sigma$-álgebra contendo $\mathcal{G}$.
Um exemplo importante é dado pela \emph{$\sigma$-álgebra de Borel} \index{sigma-algebra@$\sigma$-álgebra!de borel}, gerada pelos abertos de uma topologia em $\Omega$.

\begin{example} Típicos exemplos de $\sigma$-álgebra correspondentes aos espaços amostrais do Exemplo~\ref{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $\mathcal{F}_1 = \mathcal{P}(\Omega_1)$,
  \item $\mathcal{F}_2 = \mathcal{B}([0,1])$ e
  \item $\mathcal{F}_3 = \mathcal{B}(C[0,1])$.
  \end{enumerate}
\end{example}

\begin{example} Alguns eventos de $\mathcal{F}_1, \mathcal{F}_2$ e $\mathcal{F}_3$ acima
  \begin{enumerate}[\quad a)]
  \item $\{\text{$x$ é ímpar}\}, \{1\} \subset \Omega_1$
  \item $[0,1/2], \{0\}, (\mathbb{Q} \cap [0,1]) \subset \Omega_2$ e
  \item $\{f:[0,1] \to \mathbb{R}; f(1) > 0\} \subset \Omega_3$.
  \end{enumerate}
\end{example}

\begin{exercise}
  Mostre que $\{f:[0,1] \to \mathbb{R}; f(t) \geq 0 \text{ para todo $t \in [0,1]$}\} \subset \Omega_3$ é um evento (ou seja, pertence a $\mathcal{F}_3$).
\end{exercise}

\begin{notation}
  Se $Q$ for uma condição qualquer sobre candidatos $\omega \in \Omega$, escreveremos $[\text{$\omega$ satisfaz $Q$}]$ \index{[omega satisfaz Q]@$[\text{$\omega$ satisfaz $Q$}]$} para denotar $\{\omega \in \Omega; \text{ $\omega$ satisfaz $Q$}\}$.
\end{notation}

Por exemplo, $\{f:[0,1] \to \mathbb{R}; f(1) > 0\}$ pode ser escrita simplesmente como $[f(1) > 0]$.

\section{Espaços de probabilidade}

Agora estamos prontos para introduzir o conceito moderno do que é uma probabilidade.

\begin{definition}
  Dado $(\Omega, \mathcal{F})$ espaço mensurável, dizemos que $P:\mathcal{F} \to [0,1]$ é uma \emph{probabilidade} \index{probabilidade} se
  \begin{enumerate}[\quad a)]
  \item $P(\Omega) = 1$ e
  \item sempre que $A_1, A_2, \dots \in \mathcal{F}$ forem disjuntos ($A_i \cap A_j = \varnothing$ se $i \neq j$), temos
    \begin{equation}
      P\big({\mcup\nolimits_i} A_i\big) = \sum_i P(A_i).
    \end{equation}
  \end{enumerate}
\end{definition}

Obviamente, isso nada mais é que uma medida que associa massa um ao espaço todo.

\begin{example} Probabilidades nos espaços do Exemplo~\ref{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $P_1(A) = (\#A)/6$ em $(\Omega_1, \mathcal{F}_1)$.
    Ou mais geralmente $P_1'(A) = \sum_{i \in A} p_i$, onde $p_i \geq 0$ e $\sum_i p_i = 1$.
  \item $P_2$ pode ser a medida de Lebesgue em $([0,1], \mathcal{B}([0,1]))$.
    Mais geralmente também podemos ter $P_2'(A) = \int_A \rho(x) \d x$, onde $\rho:[0,1] \to \mathbb{R}_+$, chamada densidade, é tal que $\int_{[0,1]} \rho (x) \d x = 1$.
  \item $P_3 = \delta_{0}$, que atribui o valor um se o evento contém a função identicamente nula ($f \equiv 0$) e zero caso contrário.
  \end{enumerate}
\end{example}
Obviamente o terceiro exemplo é bastante artificial (e inútil).
Mas futuramente, estaremos protos para introduzir medidas bem interessantes no espaço $(\Omega_3, \mathcal{F}_3)$.

\begin{proposition}
  Valem as afirmativas
  \begin{enumerate}[\quad a)]
  \item Se $A \subseteq B$ então $P(A) = P(B) - P(B \setminus A) \leq P(B)$,
  \item A cota da união:
    \begin{equation}
      P\big(\mcup\nolimits_i A_i\big) \leq \smash{\sum\limits_i} P(A_i)
    \end{equation}
  \item e o que chamamos de princípio da \emph{inclusão e exclusão} \index{inclusao e exclusao@inclusão e exclusão}
    \begin{equation}
      P\big(\mcup\nolimits_{i \leq n} A_i\big) = \smash{\sum\limits_{k = 1}^n} (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}).
    \end{equation}
  \end{enumerate}
\end{proposition}

\begin{proof}
  $a)$ Como $A \cap (B \setminus A) = \varnothing$, então
    \begin{equation}
      \begin{split}
        P(A \cup (B \setminus A)) & = P(A \cup (B \setminus A) \cup \varnothing \cup \dots)\\
        & = P(A) + P(B \setminus A) + 0 + \dots = P(A) + P(B \setminus
        A).
      \end{split}
    \end{equation}

  $b)$ $P(A \cup B) = P (A \cup (B \setminus A)) = P(A) + P(B \setminus
    A) \leq P(A) + P(B)$.
    Deixamos o caso enumerável como exercício abaixo.

  $c)$ Basta mostrar a validade da equação abaixo e depois integrar com
    respeito a $P$.
    \begin{equation}
      \label{e:indicadora_como_produto}
      \1_A(\omega) = \sum_{k=1}^n (-1)^{k - 1} \sum_{\substack{I \subseteq \{1, \dots, n\}\\|I| = k}} \prod_{i \in I} \1_{A_i}(\omega).
    \end{equation}
    Para tanto, observe que para todo $\omega \in \Omega$,
    \begin{equation}
      (\1_A - \1_{A_1}) \cdot \dots \cdot (\1_A - \1_{A_n})(\omega) = 0.
    \end{equation}
    Logo, expandindo o produto acima obtemos
    \begin{equation}
      \1_A + \sum_{k = 1}^n \sum_{\substack{I \subseteq \{1, \dots, n\}\\|I| = k}} (-1)^k \1_{A_k}(\omega) = 0,
    \end{equation}
    que equivale a \eqref{e:indicadora_como_produto}.
\end{proof}

\begin{exercise}
  Mostre que $P\big(\mcup\nolimits_i A_i\big) \leq \sum_i P(A_i)$ no caso enumerável.
\end{exercise}

\begin{exercise}
  Mostre que
  \begin{equation*}
    \begin{split}
      P\big( \mcup\nolimits_{i=1}^n A_i \big) & \leq \sum\limits_{k = 1}^m (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}) \text{ se $m$ é ímpar e}\\
      P\big( \mcup\nolimits_{i=1}^n A_i \big) & \geq \sum\limits_{k = 1}^m (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}) \text{ se $m$ é par.}
    \end{split}
  \end{equation*}
\end{exercise}



\begin{exercise}
  Seja $n \geq 1$ um número inteiro e considere $\Omega = \{0, 1\}^n$, o hipercubo de dimensão $n$ (cada $\omega \in \Omega$ pode ser visto como uma função $\omega:\{1, \dots, n\} \to \{0,1\}$).
  Para cada $i \in \{1, \dots, n\}$, definimos o evento $A_i = \{ \omega \in \Omega; \omega(i) = 1 \}$.
  Dadas duas probabilidades $P$ e $P'$ em $(\Omega, \mathcal{P}(\Omega))$, mostre que se $P(B) = P'(B)$ para todos conjuntos $B$ dados por interseções de $A_i$'s, então $P = P'$.
\end{exercise}

\begin{proposition}
  \label{p:prob_continua}
  Toda probabilidade $P$ é contínua, isto é:
  \begin{enumerate}[\quad a)]
  \item Se $A_1 \subseteq A_2 \subseteq \dots \in \mathcal{F}$, então $\lim_n P(A_n) = P(\mcup\nolimits_n A_n)$.
  \item Também, se $A_1 \supseteq A_2 \supseteq \dots \in \mathcal{F}$, temos $\lim_n P(A_n) = P(\mcap\nolimits_n A_n)$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  $a)$ Observe que
  \begin{equation}
    \mcup_{m = 1}^\infty A_n = \mcup_{n = 1}^\infty \Big( A_n \setminus \big( \mcup_{i=1}^{n-1} A_i \big) \Big),
  \end{equation}
  que são disjuntos.
  Logo
  \begin{equation}
    \begin{split}
      P\big(\mcup\nolimits_{n = 1}^\infty A_n\big) & = \sum_{n = 1}^\infty P\Big( A_n \setminus \big(\mcup\nolimits_{i=1}^{n-1} A_i \big) \Big)\\
      & = \lim_n P({\mcup\nolimits_{i = 1}^n} A_i) = \lim_n P(A_n).
    \end{split}
  \end{equation}

  $b)$ A prova é análoga à de 1.
\end{proof}

\begin{lemma}[Borel-Cantelli - primeira parte]
  Sejam $A_1, A_2, \dots \in \mathcal{F}$ satisfazendo $\sum_{i = 1}^\infty P(A_i) < \infty$.
  Então
  \begin{equation}
    P[\text{$A_i$ para infinitos $i$}] := P\big({\mcap\nolimits_{n = 1}^\infty} ({\mcup\nolimits_{i \geq n}} A_i)\big) = 0.
  \end{equation}
\end{lemma}

\begin{proof}
  Estimamos
  \begin{equation}
    P \Big( {\mcap_{n = 1}^\infty} \big({\mcup\nolimits_{i \geq n}} A_i \big) \Big) = \lim_n P \big( {\mcup\nolimits_{i \geq n}} A_i \big) \leq \lim_n {\textstyle\sum\limits_{i \geq n}} P(A_i) = 0.
  \end{equation}
  O que termina a prova do lemma.
\end{proof}

Imagine que jogamos todos os dias em uma loteria e que nossa probabilidade de ganhar no dia $i$ é $p_i$.
Então se $\sum_i p_i < \infty$, sabemos que certamente não ganharemos infinitas vezes.

\section{Sistemas \texorpdfstring{$\lambda$-$\pi$}{lambda-pi}}

Uma importante ferramenta para provar fatos teóricos sobre probabilidades é o Teorema de Dynkin que apresentaremos nessa seção.
Ele trata de classes de eventos que não são necessariamente $\sigma$-álgebras, mas sistemas $\sigma$ ou $\pi$ como definidos abaixo.

\begin{definition}
  Dizemos que uma classe $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\pi$-sistema \index{pi sistema@$\pi$-sistema} se for fechado por interseções finitas, isto é: para todos $A, B \in \mathcal{A}$ temos $A \cap B \in \mathcal{A}$.
\end{definition}

\begin{definition}
  Dizemos que $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\lambda$-sistema, \index{lambda sistema@$\lambda$-sistema} se
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{A}$,
  \item Sempre que $A \in \mathcal{A}$ temos $A^c \in \mathcal{A}$ e
  \item para $A_1, A_2, \dots \in \mathcal{A}$ disjuntos dois a dois, temos $\cup_i A_i \in \mathcal{A}$.
  \end{enumerate}
\end{definition}

\begin{exercise}
  \label{x:lambda_nao_sigma}
  Dê um exemplo de $\lambda$-sistema que não seja uma $\sigma$-álbebra.
\end{exercise}

Definimos para $\mathcal{A} \subseteq \mathcal{P}(~W)$, o menor $\lambda$-sistema contendo $\mathcal{A}$, ou seja
\begin{equation}
  \lambda(\mathcal{A}) = \bigcap_{\substack{\text{$\mathcal{B}$ $\lambda$-sistema}\\\mathcal{A} \subseteq \mathcal{B}}} \mathcal{B}.
\end{equation}
É fácil ver que $\lambda(\mathcal{A})$ é sempre um $\lambda$-sistema.

\begin{theorem}[Dynkin]
  \index{Teorema!de Dynkin}
  \label{t:dynkin}
  Se $\mathcal{A}$ é um $\pi$-sistema, então $\lambda(\mathcal{A}) = \sigma(\mathcal{A})$.
\end{theorem}

Note pelo Exercício~\ref{x:lambda_nao_sigma} que a hipótese de que $\mathcal{A}$ é um $\pi$-sistema é necessária em geral.

\begin{proof}
  Obviamente, basta mostrar é que $\lambda(\mathcal{A})$ é fechado por uniões não necessariamente disjuntas.
  Na verdade, vamos ver que é suficiente provar que
  \begin{equation}
    \label{e:lambda_is_pi}
    \lambda(\mathcal{A}) \text{ é um $\pi$-sistema}.
  \end{equation}
  De fato, caso isso seja provado teremos que $\lambda(\mathcal{A})$ é fechado por diferenças (pois $A \setminus B = A \cap B^c$).
  Assim, podemos mostrar que $\lambda(\mathcal{A})$ é fechado por uniões enumeráveis, pois se $A_1, A_2, \dots \in \lambda(\mathcal{A})$, definimos $B_n = \cup_{i=1}^n A_i = (\cap_{i=1}^n A_i^c)^c \in \lambda(\mathcal{A})$ e escrevemos
  \begin{equation}
    \mcup_n A_n = \mcup_n \big(A_n \setminus B_{n-1} \big),
  \end{equation}
  que é uma união disjunta de termos em $\lambda(\mathcal{A})$, logo está em $\lambda(\mathcal{A})$.
  Isso mostra que $\lambda(\mathcal{A})$ é uma $\sigma$-álgebra e que de fato é suficiente demonstrar \eqref{e:lambda_is_pi}.

  Vamos primeiramente mostrar que $\lambda(\mathcal{A})$ é fechado por interseções com $\mathcal{A}$.
  Para tanto, definimos $\mathcal{B} = \big\{B \in \lambda(\mathcal{A}); \text{$B \cap A \in \lambda(\mathcal{A})$ para todo $A \in \mathcal{A}$})\big\}$ e veremos que
  \begin{equation}
    \label{e:B_igual_lambda}
    B = \lambda(\mathcal{A}).
  \end{equation}
  Obviamente, $\mathcal{A} \subseteq \mathcal{B}$, pois $\mathcal{A}$ é um $\pi$-sistema.
  Então basta mostrar que $\mathcal{B}$ é um $\lambda$-sistema.
  \begin{enumerate}[\quad a)]
  \item $\Omega$ obviamente pertence a $\mathcal{B}$.
  \item Se $B \in \mathcal{B}$ e $A \in \mathcal{A}$, então $B^c \cap A = A \setminus(B \cap A) = (A^c \cup (B \cap A))^c$.
    Mas como $B \in \mathcal{B}$, $(B \cap A) \in \lambda(\mathcal{A})$ e usando o fato que $\lambda$-sistemas são fechados por complementos e uniões disjuntas, $B^c \cap A \in \lambda(\mathcal{A})$.
    Como isso vale para todo $A \in \mathcal{A}$, temos $B^c \in \mathcal{B}$ por definição.
  \item Se $B_1, B_2, \dots \in \mathcal{B}$ são disjuntos e $A \in \mathcal{A}$, então
    \begin{equation}
      \big(\mcup\nolimits_i B_i \big) \cap A = \mcup_i \big(B_i \cup A\big) \in \lambda(\mathcal{A}),
    \end{equation}
    pois a união acima é disjunta.
    Logo $\mcup_i B_i \in \mathcal{B}$.
  \end{enumerate}
  Isso mostra que $\mathcal{B}$ é um $\lambda$-sistema com $\mathcal{A} \subseteq \mathcal{B} \subseteq \lambda(\mathcal{A})$, mostrando \eqref{e:B_igual_lambda}.

  No próximo passo, definimos $\bar{\mathcal{B}} = \{A \in \lambda(A); \text{$B \cap A \in \lambda(A), \; \forall B \in \lambda(A)$}\}$ e mostraremos que
  \begin{equation}
    \label{e:Bbar_igual_lambda}
    \bar{\mathcal{B}} = \lambda(\mathcal{A}),
  \end{equation}
  que vai na direção de provar \eqref{e:lambda_is_pi}.

  Primeiramente, observe que $\mathcal{A} \subseteq \bar{\mathcal{B}}$ pois $\mathcal{B} = \lambda(\mathcal{A})$ (veja a definição de $\mathcal{B}$).
  Mostraremos agora que
  \begin{equation}
    \label{e:B_barra_lambda}
    \text{$\bar{\mathcal{B}}$ é um $\lambda$-sistema}.
  \end{equation}
  Para tanto, verificaremos
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \bar{\mathcal{B}}$, que é claro.
  \item Tomando $A \in \bar{\mathcal{B}}$ e $B \in \lambda(\mathcal{A})$, $A^c \cap B = B \setminus (A \cap B) = \big(B^c \cup (A \cap B)\big)^c \in \lambda(\mathcal{A})$, por um argumento análogo ao apresentado para $\mathcal{B}$.
    Logo $A^c \in \bar{\mathcal{B}}$.
  \item Também o caso de uniões disjuntas é bastante análogo ao feito para $\mathcal{B}$.
  \end{enumerate}
  Isso mostra que $\bar{\mathcal{B}}$ é um $\lambda$-sistema com $\mathcal{A} \subseteq \bar{\mathcal{B}} \subseteq \lambda(\mathcal{A})$, estabelecendo \eqref{e:B_barra_lambda}.

  Finalmente mostraremos que
  \begin{equation}
    \label{e:B_barra_pi}
    \text{$\bar{\mathcal{B}}$ é um $\pi$-sistema}.
  \end{equation}
  De fato, sejam $A_1, A_2 \in \bar{\mathcal{B}}$ e $B \in \lambda(A)$.
  Então $(A_1 \cap A_2) \cap B = (A_1 \cap B) \cap A_2 \in \lambda(\mathcal{A})$, donde $A_1 \cap A_2$ pertence a $\bar{\mathcal{B}}$.
  Logo temos por \eqref{e:B_barra_pi} e \eqref{e:B_barra_lambda} que $\lambda(\mathcal{A})$ é um $\pi$-sistema, ou seja \eqref{e:lambda_is_pi}, terminando a prova do teorema.
\end{proof}

\subsection{Igualdade de probabilidades}

\begin{proposition}
  \label{p:P12_equal_pi}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega, \mathcal{F})$, tais que $P_1(A) = P_2(A)$ para todo $A \in \mathcal{A}$ e $\mathcal{A}$ é um $\pi$-sistema, então $P_1(B) = P_2(B)$ para todo $B \in \lambda(\mathcal{A})$.
\end{proposition}

\begin{proof}
  Seja $\mathcal{B} = \{A \in \mathcal{F}; P_1(A) = P_2(A)\}$.
  É fácil ver que $\mathcal{B}$ é um $\lambda$-sistema.
  Logo $\mathcal{B}$ contém $\lambda(\mathcal{A})$ que é igual a $\sigma(\mathcal{A})$ por Dynkin.
\end{proof}

\begin{corollary}
  \label{c:produto_e_unico}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2)$, tais que
  \begin{equation}
    P_1(A_1 \times A_2) = P_2(A_1 \times A_2), \text{ para todos $A_1 \in \mathcal{F}_1$, $A_2 \in \mathcal{F}_2$,}
  \end{equation}
  então $P_1 = P_2$.
\end{corollary}

\begin{proof}
  Obviamente as caixas do tipo $A_1 \times A_2$ formam um $\pi$-sistema que gera $\mathcal{F}_1 \otimes \mathcal{F}_2$ (por definição).
\end{proof}

\begin{example}
  Observe portanto que é importante que $\mathcal{A}$ seja um $\pi$-sistema na Proposição~\ref{p:P12_equal_pi}.
  Imagine por exemplo que $\Omega = \{0,1\}^2$ e $P_1 = \tfrac 14 \sum_{x \in \Omega} \delta_x$ e $P_2 = \tfrac 12 (\delta_{(0,0)} + \delta_{(1,1)})$.
  Nesse caso
  \begin{equation}
    P_1(A) = P_2(A) = 1/2 = P_1(B) = P_2(B),
  \end{equation}
  com $A = \{(0,0), (0,1)\}$ e $B = \{(0,0), (1,0)\}$.
  Contudo, $P_1 \neq P_2$, mesmo tendo $\mathcal{P}(\Omega) = \sigma(\{A,B\})$.
\end{example}


\section{Elementos aleatórios}

Muitas vezes não estamos interessados no resultado exato do nosso experimento aleatório, mas sim em uma determinada medição ou função de $\omega \in \Omega$.
Por exemplo, no caso do Exemplo~\ref{x:espacos_amostrais} $c)$, talvez não nos interesse toda a função $f$, mas apenas o seu valor no fim do dia $f(1)$.
Essas medições são ditas elementos aleatórios que definimos à seguir.

Seja $(E,\mathcal{A})$ um espaço mensurável.
Nesse caso, se $X: \Omega \to E$ é uma função $(\mathcal{F}, \mathcal{A})$-mensurável, dizemos que $X$ é um \emph{elemento aleatório} \index{elemento aleatorio@elemento aleatório} em $(\Omega, \mathcal{F})$ tomando valores em $E$, ou um $E$-elemento aleatório.

\begin{example} Consideramos os casos
  \begin{enumerate}[\quad a)]
  \item $X:\Omega \to \mathbb{R}$ mensurável é dita variável aleatória. \index{variavel aleatoria@variável aleatória}
  \item $X:\Omega \to \mathbb{R}^d$ mensurável é dito vetor aleatório ($d$-dimensional).
  \item $X:\Omega \to C[0,1]$ mensurável é dita função aleatória.
  \end{enumerate}
\end{example}
Seguindo a motivação do Exemplo~\ref{x:espacos_amostrais} $c)$, poderia ser que, por exemplo, estivéssemos interessados apenas na variável aleatória $X:\Omega_3 \to \mathbb{R}$ dada por $X(f) = f(1)$.

\begin{exercise}
  Mostre que $X:\Omega_3 \to \mathbb{R}$ dada por $X(f) = f(1)$ é uma variável aleatória.
\end{exercise}

Citando Kingman em seu livro Poisson Processes: ``\emph{a random elephant is a function from $\Omega$ into a suitable space of elephants.}''

Relembrando a nossa notação: $P[X \in A] = P(\{\omega \in \Omega; X(\omega) \in A\})$.

\begin{proposition}
  Seja $X:\Omega \to E$ onde $(E, \mathcal{A})$ é um espaço mensurável com $\mathcal{A} = \sigma(\mathcal{G})$.
  Então para verificar que $X$ é um elemento aleatório, basta provar que $X^{-1}(G) \in \mathcal{F}$ para todo $G \in \mathcal{G}$.
\end{proposition}

\begin{proof}
  Teoria da Medida.
\end{proof}

\begin{example}
  Se $\Omega$ e $E$ são espaços topológicos dotados das correspondentes $\sigma$-álgebras de Borel, então toda função contínua é um $E$-elemento aleatório.
\end{example}

\subsection{Distribuição de elementos aleatórios}

\begin{definition}
  Se $X:\Omega \to E$ é um elemento aleatório e $\Omega$ é dotado de uma probabilidade $P$, então denotamos por $X \circ P$, a chamada \emph{distribuição de $X$} \index{distribuicao@distribuição}, a medida de probabilidade
  \begin{equation}
    (X \circ P)(A) := P\big( \{\omega \in \Omega; X(\omega) \in A\} \big) = P[X \in A].
  \end{equation}
  no espaço mensurável $(E,\mathcal{A})$.
\end{definition}

Fica como exercício verificar que $X \circ P$ é de fato uma probabilidade em $E$.

\begin{exercise}
  Seja $X:[0,1] \to \{0,1\}$ dada por $X(\omega) = \1_A (\omega)$.
  Nesse caso, mostre que $X \circ P = \Ber(p)$ para algum $p \in [0,1]$.
  Calcule o valor de $p$.
\end{exercise}

Duas notações importantes nesse contexto são:
\begin{enumerate}[\quad a)]
\item Dizemos que $X \distr Y$, \index{X d Y@$X \distr Y$} quando $X \circ P = Y \circ P'$.
Note que $X$ e $Y$ nem ao menos precisam pertencer ao mesmo espaço de probabilidade para dizermos que são \emph{igualmente distribuídos}, mas precisam ser elementos aleatórios de mesmo tipo (ou seja, possuir o mesmo contradomínio).
\item Escrevemos $X \distr \mu$, \index{X d mu@$X \distr \mu$} que lê-se \emph{$X$ é distribuída como $\mu$}, onde $\mu$ é uma probabilidade em $E$, caso $X \circ P = \mu$.
\end{enumerate}

\begin{exercise}
  Sejam $X$ e $Y$ variáveis aleatórias tais que $X$ é nula quase certamente.
  Mostre que $X + Y$ tem a mesma distribuição de $Y$.
\end{exercise}

O exercício acima é bastante simples, mas o usaremos para fazer uma importante observação sobre como são enunciados tipicamente os resultados de probabilidade.

Raramente encontramos teoremas que explicitam qual é o espaço de probabilidades $\Omega$ em questão.
Como no exercício acima, o contexto de um teorema frequentemente é dado apenas em termos de elementos aleatórios em $\Omega$ e de suas distribuições.
Dessa forma, podemos utilizar o resultado em vários contextos diferentes, desde que possamos encontrar elementos aleatórios que satisfaçam as hipóteses.
Com o tempo, passamos até mesmo a considerar menos relevante a escolha específica do espaço amostral, focando cada vez mais na distribuição de seus elementos aleatórios.



\chapter{Construção de espaços de probabilidade}

Nessa seção descreveremos diversas maneiras diferentes de construir um espaço de probabilidade, dando diversos exemplos de como elas podem ser usadas na modelagem de diferentes processos reais.

\section{Caso enumerável}

Quando $\Omega$ é finito ou enumerável, tipicamente definimos sobre $\Omega$ a $\sigma$-álgebra das partes, ou seja $\mathcal{F} = \mathcal{P}(\Omega) = \sigma(\{\omega\}_{\omega \in \Omega})$.
Além disso podemos definir probabilidades sobre $(\Omega, \mathcal{F})$ de maneira simples tomando $(p_\omega)_{\omega \in \Omega}$ tais que
\begin{enumerate}[\quad a)]
\item $p_\omega \geq 0$ para todo $\omega \in \Omega$ e
\item $\sum_{\omega \in \Omega} p_\omega = 1$.
\end{enumerate}
De fato, nesse caso definimos $P(A) = \sum_{\omega \in A} p_\omega$ que claramente define uma probabilidade.

\begin{exercise}
  Mostre que se $\Omega$ é finito ou enumerável, toda probabilidade sobre $(\Omega, \mathcal{P}(\Omega))$ é dada como na descrição acima.
\end{exercise}

\begin{example} \mbox{}
  \begin{enumerate}[\quad a)]
  \item Dado $p \in [0,1]$, definimos a medida $\Ber(p)$ \index{distribuicao@distribuição!de Bernoulli} (em homenagem a Bernoulli) em $\{0,1\}$ com $p_1 = p, p_0 = 1-p$.
  \item Dados $n \geq 1$ e $p \in [0,1]$, definimos a medida $\Bin(n,p)$ \index{distribuicao@distribuição!binomial} (binomial) em $\Omega = \{0, 1, \dots, n\}$ com
    \begin{equation}
      p_i = \binom ni p^i (1-p)^{n-i}, \text{ para $i \in \Omega$.}
    \end{equation}
  \item Dado $p \in (0,1]$, em $\Omega = \{0, 1, \dots\}$ definimos a medida $\Geo(p)$ \index{distribuicao@distribuição!geometrica@geométrica} (geométrica) em $\Omega$ induzida pelos pesos
  \begin{equation}
    p_i = (1-p)^i p, \text{ para $i \geq 1$.}
  \end{equation}
  \end{enumerate}
\end{example}

\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ e $p_\omega = \tfrac 1{2^n}$ para todo $\omega \in \Omega$ (ou seja a probabilidade uniforme).
  Considere $X: \Omega \to \{0,1, \dots, n\}$ dada por $X(\omega_1, \dots, \omega_n) = \sum_{i=1}^n \omega_i$.
  Obtenha a distribuição $X \circ P$.
  Dê um exemplo de medida em $\omega$ para a qual a distribuição de $X$ seja $\Bin(n,p)$.
\end{exercise}

%\todosec{Tópico: Método Probabilístico}{Pedir ao Rob um exemplo bem básico e interessante, como soluções de $x + y = z$ em $\mathbb{N}$.}

\vfill
\pagebreak

\subsection{Tópico: Método Probabilístico}



Uma importante ferramenta em várias áreas da matemática, tais como Teoria dos Números, Combinatória e Teoria da Computação é o que chamamos de Método Probabilístico. \index{Metodo Probabilistico@Método Probabilístico}

Em várias situações, nós precisamos de mostrar a existência de objetos satisfazendo determinadas propriedades, mas não temos informação suficiente ou capacidade para construí-los explicitamente.
Nesse caso, podemos recorrer ao Método Probabilístico, que simplesmente nos sugere tomar um objeto aleatório de uma maneira esperta e mostrar que com probabilidade positiva as propriedades desejadas serão satisfeitas.
Esse método, apesar de muito ingênuo, é muito eficiente e em diversos casos provê os melhores exemplos conhecidos de certos objetos (para embaraço da comunidade científica).

Nessa seção daremos um exemplo em Teoria dos Números provido primeiramente por Erdõs\footnote{Somos gratos a Robert Morris por sugerir esse teorema como exemplo do Método Probabilístico.}.

\begin{theorem}[Erdös]
  Para todo conjunto finito $A \subset \mathbb{N}$, existe um sub-conjunto $B \subseteq A$ satisfazendo
  \begin{enumerate}[\quad a)]
  \item $\# B \geq \frac{\#A}{3}$ e tal que
  \item não existem $x, y$ e $z \in B$ com $x + y = z$.
  \end{enumerate}
  A propriedade $b)$ acima é o que chamamos de um conjunto ser livre de somas. \index{conjunto!livre de somas}
\end{theorem}

Certamente não temos muita informação sobre $A$, então vamos usar o método probabilístico para a prova desse teorema.

\begin{proof}
  Fixamos $p$ um número primo maior que três vezes o maior elemento de $A$ e considere o espaço $\mathbb{Z}_p$ dos inteiros módulo $p$.
  Seja $X$ um elemento aleatório de $\mathbb{Z}_p$ com distribuição uniforma, isto é $U_{\{0, \dots, p-1\}}$.
  \begin{exercise}
    Mostre que para todo $a \in A$, a multiplicação por $a$ é uma bijeção em $\mathbb{Z}_p$, ou seja
    \begin{equation}
      \mathbb{Z}_p \cdot a = \mathbb{Z}_p.
    \end{equation}
    onde o produto $\mathbb{Z}_p \cdot a$ é entendido elemento a elemento.
    Conclua que
    \begin{equation}
      P \Big[ X \cdot a \in \big[\tfrac p3, \tfrac {2p}3\big) \Big] \geq \frac 13.
    \end{equation}
  \end{exercise}
  Definimos o conjunto aleatório $\mathcal{B} = (X \cdot A) \cap [\tfrac p3, \tfrac {2p}3)$, que obviamente é livre de somas.
  Basta portanto mostrar que com probabilidade positiva $\# \mathcal{B} \geq \tfrac{\#A}3$, que segue do seguinte argumento.
  \begin{equation*}
    \int \# \mathcal{B} \d P = \int \sum_{a \in A} \1_{\big[ X \cdot a \in [p/3, 2p/3) \big]} \d P = \sum_{a \in A} P \Big[ X \cdot a \in \big[\tfrac p3, \tfrac {2p}3\big) \Big] \geq \frac{\# A}3,
  \end{equation*}
  mas para qualquer variável aleatória, $\int X \d P \geq x$ implica que $P[X \geq x] > 0$.
\end{proof}

\todo{Adicionar contexto histórico: citar artigo Erdos e o Annals of Math que mostra que não é possível com $\#A(1/3 + \varepsilon)$.}




\vfill
\pagebreak


\section{Caso absolutamente contínuo}

Uma outra maneira simples de definir um espaço de probabilidade, é partindo de um espaço de medida.
Seja $(\Omega, \mathcal{F}, \mu)$ um espaço de medida e $\rho:\Omega \to \mathbb{R}_+$ uma função mensurável com $\int \rho(x) \mu(\d x) = 1$.
Então podemos definir a probabilidade induzida
\begin{equation}
  \label{e:absolutamente_cont}
  P(A) = \int_A \rho(x) \mu(\d x).
\end{equation}
Nesse caso, chamamos $\rho$ de a \emph{densidade} \index{densidade} de $P$ com respeito a $\mu$.
Uma outra possível notação para a equação acima é $\d P = \rho(x) \d \mu$ \index{dP@$\d P = \rho \d \mu$} (lembrando a derivada de Radon-Nikodim).

Observe que o caso discreto pode ser definido em termos de uma densidade, onde $\rho(\omega) = p_\omega$ e $\mu$ é a medida da contagem em $\Omega$.

\begin{example}
  Vários exemplos podem ser obtidos via \eqref{e:absolutamente_cont} se tomamos $\Omega \subseteq \mathbb{R}$ e $\mu$ a medida de Lebesgue restrita a $\Omega$.
  Nesses casos, escrevemos $P = \rho(x) \d x$ em $\Omega$.
  Alguns exemplos importantes são:
  \begin{enumerate}[\quad a)]
  \item Para $a < b \in \mathbb{R}$, definimos a medida $U[a,b]$ \index{distribuicao@distribuição!uniforme} usando $\rho(x) = \tfrac{1}{b-a}\1_{[a,b]}(x)$.
  \item Para $\lambda > 0$, definimos a medida $\Exp(\lambda)$ \index{distribuicao@distribuição!exponencial} (chamada exponencial de parâmetro $\lambda$) por meio da densidade $\rho(x) = \lambda \exp\{-\lambda x\}$ em $[0,\infty)$.
  \end{enumerate}
\end{example}

Podemos também usar a distribuição de um elemento aleatório para construir outras probabilidades, como mostra o seguinte exemplo.

\begin{example}
  Considere por exemplo $X:[0,2\pi] \to \mathbb{C}$ dada por $X(t) = \exp\{-i t\}$.
  A distribuição $X \circ P$ de $X$ segundo $U_{[0,2\pi]}$ é o que chamamos de distribuição uniforme em $S^1$, também denotada por $U_{S^1}$.
\end{example}

\begin{exercise}
  Mostre que $U_{S^1}$ não é absolutamente contínua com respeito à medida de Lebesgue em $\mathbb{C} \sim \mathbb{R}^2$.
\end{exercise}

\begin{exercise}
  Mostre que $U_{S^1}$ é invariante por rotações rígidas de $\mathbb{C}$, isto é, se $T:\mathbb{C} \to \mathbb{C}$ é uma isometria linear, então $T \circ U_{S^1} = U_{S^1}$.
\end{exercise}

\begin{exercise}
  Construa uma probabilidade em $S^2$ invariante por rotações.
\end{exercise}

\section{Funções acumuladas de distribuição}

Um caso muito importante de espaço amostral é $\Omega = \mathbb{R}$, principalmente por nos ajudar a entender distribuições de variáveis aleatórias.
Para tanto, precisaremos de uma boa ferramenta para descrever probabilidades em $\mathbb{R}$.

\begin{definition}
  Dada $P$ em $\mathbb{R}$, definimos $F_P:\mathbb{R} \to [0,1]$ por $F_P(x) = P\big((-\infty, x]\big)$.
  Essa função é chamada a \emph{função de distribuição} acumulada de $P$. \index{funcao de distribuicao@função de distribuição}
\end{definition}

\begin{notation}
  Se $X:\Omega \to \mathbb{R}$ é uma variável aleatória num espaço $(\Omega, \mathcal{F}, P)$, denotamos por $F_X$ \index{FX@$F_X$} a função de distribuição acumulada correspondente à distribuição $X \circ P$.
\end{notation}

Lembramos que uma probabilidade em $\mathbb{R}$ é uma função $P:\mathcal{B}(\mathbb{R}) \to [0,1]$ e o domínio dessa função é bastante complicado.
Por exemplo se quisermos representar uma distribuição de uma variável aleatória no computador atravéz dessa função $P$, teríamos problemas.
Contudo, a função $F_P$ (ou $F_X$) é muito mais simples de ser compreendida ou representada, por seu domínio ser $R$.

\begin{example}
  Não é difícil verificar que
  \begin{equation}
    F_{\delta_{x_0}} =
    \begin{cases}
      0 & \text{ se $x < x_0$,}\\
      1 & \text{ se $x \geq x_0$}
    \end{cases}
  \end{equation}
  e que
  \begin{equation}
    F_{U_{[0,1]}} =
    \begin{cases}
      0 & \text{ se $x \leq 0$,}\\
      x & \text{ se $x \in [0,1]$ e}\\
      1 & \text{ se $x \geq 1$.}
    \end{cases}
  \end{equation}
\end{example}

\begin{exercise}
  Calcule $F_{\Exp(\lambda)}$.
\end{exercise}

\begin{proposition}
  \label{p:propried_F}
  $F_P$ (e obviamente $F_X$) satisfazem:
  \begin{enumerate}[\quad a)]
  \item $\smash{\lim\limits_{x \to -\infty}} F(x) = 0$, $\smash{\lim\limits_{x \to \infty}} F(x) = 1$,
  \item $F$ é monótona não-decrescente e
  \item $F$ é contínua à direita e possui limite à esquerda (càdlàg, do francês). \index{cadlag@càdlàg}
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{enumerate}[\quad a)]
  \item Se $x_n \to -\infty$ monotonamente, então $A_n = (-\infty, x_n]$ são encaixados e de interseção vazia.
    Logo, pela Proposição~\ref{p:prob_continua}, temos $P(A_n) \to 0$.
    O outro caso é análogo.
  \item Se $x \leq x'$ então $(-\infty, x] \subseteq (-\infty,x']$, donde $F(x) \leq F(x')$.
  \item Continuidade à direita (càd) - Se $x_n \downarrow x$ monotonamente, então $A_n = (-\infty, x_n] \downarrow (-\infty, x]$ (eles são encaixados).
    Logo $F(x_n) \to F(x)$.

    Limite à esquerda (làg) - Segue do fato de $F$ ser monótona e limitada. \qedhere
  \end{enumerate}
\end{proof}

\begin{theorem}
  Se $F$ satisfaz as três propriedades listadas na Proposição~\ref{p:propried_F}, então existe uma única $P$ em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ tal que $F = F_P$.
\end{theorem}

Poderíamos usar o Teorema da Extensão de Caratheodory para provar tal resultado, de maneira similar ao que foi feito no caso da Medida de Lebesgue.
Mas escolhemos abaixo um método mais simples, que parte da existência de $U_{[0,1]}$.

\begin{proof}
  A unicidade de tal $P$ segue da Proposição~\ref{p:P12_equal_pi} (consequêcia do Teorema de Dynkin), pois se $P$ e $P'$ são tais que $F_{P} = F_{P'}$, então temos que $P\big( (-\infty, x] \big) = P'\big( (-\infty, x] \big)$.
  Mas a classe de intervalos semi-infinitos da forma $(-\infty, x]$ forma um $\pi$-sistema que gera a $\sigma$-álgebra dos borelianos, logo $P = P'$.

  Para construir uma $P$ tal que $F_P = F$, definiremos $S:(0,1) \to \mathbb{R}$, a inversa generalizada de $F$, por
  \begin{equation}
    S(u) = \sup \{x \in \mathbb{R}; F(x) < u\}.
  \end{equation}
  \begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=.8]
      \draw (0,1) -- (10,1);
      \draw (0,4) -- (10,4); % second line
      \draw plot [smooth,tension=.5] coordinates{(0, 4.4) (2.5, 4.5) (5,5) (7.5, 5.5) (10, 5.6)};
      \draw plot [smooth,tension=.5] coordinates{(0, 1.4) (2.5, 1.5) (5,1.8)};
      \draw plot [smooth,tension=.5] coordinates{(5, 2.3) (7.5, 2.5) (10,2.6)};
      \draw[dotted] (0,5) -- (5,5) -- (5,4);
      \draw[dotted] (0,2) -- (5,2) -- (5,1);
      \draw [fill,color=white] (5,1.8) circle [radius=0.05];
      \draw (5,1.8) circle [radius=0.05];
      \draw [fill] (5,2.3) circle [radius=0.05];
      \node at (0,5) [left]{$u$};
      \node at (0,2) [left]{$u$};
      \node at (5,1) [below]{$S(u)$};
      \node at (5,4) [below]{$S(u)$};
    \end{tikzpicture}
    \caption{\small Ilustração da definição de $S(u)$.}
    \label{f:Rk_good}
  \end{figure}

  Seja $P = S \circ U_{[0,1]}$, isto é $P(A) = U_{[0,1]}(S^{-1}(A))$ e mostraremos que $F_P = F$.
  Para tanto, basta ver que
  \begin{equation}
    \label{e:pseudo_inversa}
    \{u \in [0,1]; S(u) \leq x\} = \{u \in [0,1]; u \leq F(x)\}, \text{ para todo $x \in \mathbb{R}$}.
  \end{equation}
  Pois isso implicaria que $F_P(x) = U_{[0,1]}[S \leq x] = U_{[0,1]} [u \leq F(x)] = F(x)$.

  Vamos agora checar \eqref{e:pseudo_inversa} observando que:
  \begin{enumerate}[\quad a)]
  \item Se $u \leq F(x)$ então todo $x'$ tal que $F(x') < u$ é menor que $x$.
    Logo $S(u) \leq x$.
  \item Por outro lado, se $u > F(x)$ então existe $x' > x$ tal que $F(x') < u$ (pois $F$ é càd), donde $S(u) > x$.
  \end{enumerate}
  Isos prova \eqref{e:pseudo_inversa}, terminando a prova da proposição.
\end{proof}

\begin{exercise}
  Mostre o resultado acima usando o Teorema de Extensão de Caratheodory.
\end{exercise}

\section{Espaços produto finito}

Dados espaços $\Omega_1, \dots, \Omega_n$ com suas respectivas $\sigma$-álgebras $\mathcal{F}_1, \dots, \mathcal{F}_n$, podemos definir o espaço mensurável produto $(\bar{\Omega}, \bar{\mathcal{F}})$ da seguinte forma
\begin{equation}
  \bar{\Omega} = \bigtimes_{i=1}^n \Omega_i \quad \text{e} \quad \bar{\mathcal{F}} = \sigma \Big( A_1 \times \cdots \times A_n; \; A_i \in \mathcal{F}_i, \text{ para $i \leq n$} \Big).
\end{equation}

\begin{proposition}
  Se $(\Omega_1, \mathcal{F}_1, P_1), \dots, (\Omega_n, \mathcal{F}_n, P_n)$ são espaços de probabilidade, então existe uma única probabilidade $\widebar{P}$ no espaço mensurável $(\bar{\Omega}, \bar{\mathcal{F}})$ tal que
  \begin{equation}
    \widebar{P}(A_1 \times \cdots, \times A_n) = \prod_{i=1}^n P_i(A_i), \text{ para todos $A_i \in \mathcal{F}_i$, $i \leq n$.}
  \end{equation}
  Essa probabilidade é chamada probabilidade produto.
\end{proposition}

\begin{proof}
  Teoria da Medida.
\end{proof}

Note que a unicidade do produto pode ser concluída por exemplo usando o Corolário~\ref{c:produto_e_unico}.

\begin{exercise}
  Mostre que o produto de $n$ cópias de $(\{0,1\}, \mathcal{P}(\{0,1\}), \Ber(1/2))$ é a distribuição uniforme em $\{0,1\}^n$.
\end{exercise}

\section{Independência}

Nossa intuição nos diz que quando jogamos duas moedas, o resultado de cada uma delas não deve depender um do outro.
Dessa forma, a probabilidade de obtermos um determinado resultado (como por exemplo duas caras) deve ser um quarto, ou seja meio vezes meio.

Em geral, definimos dois eventos como independentes da seguinte forma.

\begin{definition}
  Dizemos que dois eventos $A, B \in \mathcal{F}$, são \emph{independentes} \index{independencia@independência!de eventos} se
  \begin{equation}
    P(A \cap B) = P(A) P(B).
  \end{equation}
\end{definition}

\begin{example}
  Se $\Omega = \{1, \dots, 6\}$ é dotada da $\sigma$-álgebra das partes e e $P(A) = \#A/6$, então os eventos $A = [\omega \text{ é impar}]$ e $B = [\omega \geq 5]$ satisfazem
  \begin{equation}
    P(A \cap B) = P(\{5\}) = 1/6 = (1/2) (1/3) = P(A) P(B).
  \end{equation}
  Logo tais eventos são independentes.
\end{example}


\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ com $P(A) = \#A/2^n$ e $X_i(\omega_1, \dots, \omega_n) = \omega_i$ para $i = 1, \dots, n$.
  Mostre que
  \begin{equation}
    P[X_i = a, X_j = b] = P[X_i = A] P[X_j = B],
  \end{equation}
  onde $[A,B]$ denota a interseção $[A] \cap [B]$.
\end{exercise}

\subsection{Coleções de eventos}

\todo{discutir a alternativa $I = \{1,\dots, k\}$ que é ruim (basta adicionar $\varnothing$ que qq coisa fica indep).}

\begin{definition}
  Sejam $A_1, A_2, \dots, A_k$ eventos.
  Dizemos que eles formam uma coleção independente \index{independencia@independência!de eventos} se para todo $I \subseteq \{1, \dots, k\}$ não vazio
  \begin{equation}
    P\big( \mcap\nolimits_{i \in I} A_i \big) =  \prod\limits_{i \in I} P(A_i).
  \end{equation}
\end{definition}

Vale observar que independência dois a dois não implica independência.
Mais precisamente
\begin{example}
  Seja $\Omega = \{1,2,3,4\}$ com $P(A) = \# A/4$ e sejam os seguintes eventos: $A_1 = \{1,2\}$, $A_2 = \{2,3\}$ e $A_3 = \{1,3\}$.
  Nesse caso,
  \begin{enumerate}[\quad a)]
  \item $P(A_i) = 1/2$ para $i = 1, 2, 3$,
  \item $P(A_i \cap A_j) = 1/4$ para todo $i \neq j$ mas
  \item $P(A_1 \cap A_2 \cap A_3) = 0 \neq 1/8 = P(A_1) P(A_2) P(A_3)$.
  \end{enumerate}
\end{example}

\begin{definition}
  Dizemos que uma coleção infinita de eventos $A_1, A_2, \dots$ é independente \index{independencia@independência!de eventos} se toda sub-coleção finita de tais eventos forem independentes.
\end{definition}

\begin{lemma}
  Se $A_1, A_2, \dots$ forem independentes, então
  \begin{equation}
    P\Big( \mcap_{i} A_i \Big) = \prod\limits_{i} P(A_i).
  \end{equation}
\end{lemma}

\begin{proof}
  De fato,
  \begin{equation*}
    P\Big( \mcap_{i} A_i \Big) = \lim_n P\Big( \mcap_{i = 1}^n A_i \Big) = \lim_n \prod\limits_{i=1}^n P(A_i) = \prod\limits_{i} P(A_i). \qedhere
  \end{equation*}
\end{proof}

\begin{exercise}
  Mostre que se $A \in \mathcal{F}$, então $\{B \in \mathcal{F}; B \text{ é independente de } A\}$ é um $\lambda$-sistema.
\end{exercise}

\begin{exercise}
  Mostre que se $B$ é independente de $A$ para todo $B \in \mathcal{B}$, com $\mathcal{B}$ um $\pi$-sistema, então $B$ é independente de $A$ para todo $B \in \sigma(\mathcal{B})$.
\end{exercise}

\subsection{Independência de \texorpdfstring{$\sigma$}{sigma}-álgebras}

\begin{definition}
  Dadas $\sigma$-algebras $\mathcal{F}_1, \dots, \mathcal{F}_k \subseteq \mathcal{F}$.
  Dizemos que elas são independentes \index{independencia@independência!de sigma-algebras@de $\sigma$-álgebras} se todos $A_1 \in \mathcal{F}_1, \dots, A_k \in \mathcal{F}_k$ o são.
  Nessa definição podemos tomar uma coleção infinita.
\end{definition}

\begin{exercise}
  Em um espaço produto $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2, P_1 \otimes P_2)$, podemos definir
  \begin{equation}
    \begin{split}
      \bar{\mathcal{F}}_1 & = \{A \times \Omega_2; A \in \mathcal{F}_1\},\\
      \bar{\mathcal{F}}_2 & = \{\Omega_2 \times B; B \in \mathcal{F}_2\}.
    \end{split}
  \end{equation}
  Mostre que essas $\sigma$-álgebras são independentes.
\end{exercise}

Podemos extender esse conceito a elementos aleatórios, ou seja:
\begin{definition}
  Dizemos que $X_1, \dots, X_k$ são elementos aleatórios independentes \index{independencia@independência!de elementos} se as respectivas $\sigma$-álgebras $\sigma(X_1), \dots, \sigma(X_k)$ o forem.
\end{definition}

Quando $X_1, \dots, X_k$ são elementos aleatórios independentes e com a mesma distribuição, escrevemos que $X_i$ são \iid (independentes e identicamente distribuídos).

\begin{exercise}
  Com a notação do exercício anterior, mostre que as funções $X_i:\Omega_1 \times \Omega_2 \to \Omega_i$ dadas por
  \begin{equation}
    X_1(x,y) = x \text{ e } X_2 (x,y) = y,
  \end{equation}
  são elementos aleatórios e são independentes.
\end{exercise}

\begin{exercise}
  Mostre que as coordenadas canônicas do exercício anterior no caso $X_i: \mathbb{R}^2 \to \mathbb{R}$ não são independentes segundo a medida $U_{S^1}$.
  Mas o são segundo $U_{[0,1]^2}$ (que é a medida de Lebesgue em $\mathbb{R}^2$ restrita a $[0,1]^2$).
\end{exercise}

\begin{exercise}
  Seja $\Omega = \{0,1\}^n$ com $P(A) = \#A/2^n$ e $X_i(\omega_1, \dots, \omega_n) = \omega_i$ para $i = 1, \dots, n$.
  Mostre que os $X_i$ são independentes.
\end{exercise}

\begin{exercise}
  Sejam $(X_i)_{i \geq 1}$ elementos aleatórios independentes tomando valores em espaços $(E_i)_{i \geq 1}$, respectivamente.
  Mostre que para funções mensuráveis $(f_i)_{i \geq 1}$ temos que $(f_i(X_i))_{i \geq 1}$ são independentes.
\end{exercise}

\begin{exercise}
  Mostre que se $X, Y$ são elementos aleatórios e se $X$ é constante quase certamente então $X$ e $Y$ são independentes.
\end{exercise}

\begin{exercise}
  Sejam $X$ e $Y$ variáveis aleatórias independentes com distribuição $\Exp(1)$, calcule a distribuição de
  \begin{enumerate}[\quad a)]
  \item $\min\{X,Y\}$ e
  \item $X + Y$.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Seja um espaço produto de medidas $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2, \mu_1 \otimes \mu_2)$ e defina a probabilidade $P$ atravéz de
  \begin{equation}
    \d P = \rho(x,y) \d (\mu_1 \otimes \mu_2).
  \end{equation}
  Mostre nesse caso que as coordenadas canônicas $X_1$ e $X_2$ são independentes se e somente se existem $\rho_1$ e $\rho_2$ em $\Omega_1$ e $\Omega_2$ respectivamente, tais que $\rho(x,y) = \rho_1(x) \rho_2(y)$ quase certamente com respeito a $\mu_1 \otimes \mu_2$.
\end{exercise}

\begin{exercise}
  Sejam $X, Y$ vari\'aveis aleat\'orias tais que
  \begin{equation}
    P[X \leq x, Y \leq y] =
    \begin{cases}
      0 & \quad \text{if $x < 0$,}\\
      (1-e^{-x}) \Big(\frac 12 + \frac 1\pi \tan^{-1} y \Big), & \quad \text{if $x \geq 0$}.
    \end{cases}
  \end{equation}
  \begin{enumerate}[\quad a)]
  \item Mostre que a distribui\c{c}\~ao conjunta $\mu_{(X,Y)}$ \'e
    absolutamente cont\'inua com rela\c{c}\~ao \`a medida de Lebesgue em
    $\mathbb{R}^2$.
  \item Mostre que $X$ e $Y$ s\~ao independentes.
  \end{enumerate}
\end{exercise}

\todo{mandar para depois de produtos infinitos?}

\begin{lemma}[Borel-Cantelli - segunda parte]
  Se $A_1, A_2, \dots \in \mathcal{F}$ são independentes e $p_i = P(A_i)$ satisfazem $\sum_i p_i = \infty$, então
  \begin{equation}
    P[A_i \text{ infinitas vezes}] = 1.
  \end{equation}
\end{lemma}

\begin{proof}
  Queremos mostrar que
  \begin{equation}
    P \Big( \big(\mcap_n \mcup_{i=n}^\infty A_i\big)^c \Big) = 0,
  \end{equation}
  mas
  \begin{equation}
    P \Big( \big(\mcap_n \mcup_{i=n}^\infty A_i\big)^c \Big) = P \Big(\mcup_n \mcap_{i=n}^\infty A_i^c \Big) \leq \sum\limits_n P \Big(\mcap_{i=n}^\infty A_i^c \Big).
  \end{equation}
  Logo basta mostrar que a probabilidade à direita é zero para todo $n$.
  Mas
  \begin{equation}
    \begin{split}
      P \Big(\mcap_{i=n}^\infty A_i^c \Big) & = \prod\limits_{i=n}^\infty P(A_i^c) = \prod\limits_{i=n}^\infty (1 - p_i)\\
      & \leq \prod\limits_{i=n}^\infty \exp\{-p_i\} = \exp\big\{- \sum_{i=n}^\infty p_i\big\} = 0.
    \end{split}
  \end{equation}
  Terminando a prova do lemma.
\end{proof}

\todosec{Tópico: Uma dinâmica em \texorpdfstring{$[0,1]$}{[0,1]}}{fazer dinâmica 2x mod 1 e relações Lebesgue[0,1] com produtos de bernoulli}

\vfill
\newpage

\subsection{Tópico: Lei dos pequenos números}

Nessa seção estudaremos como se comportam limites de algumas variáveis aleatórias bastante importantes, mas primeiramente, uma breve intuição.

Apesar de que descreveremos a nossa motivação a partir desse exemplo do estudo de um material radioativo, podemos encontrar aplicações com justificativas bastante semelhantes para outros problemas, como: chegada de carros em um sinal de trânsito, número de mutações em um gene, número de mortes por ano em uma faixa etária...

Digamos que estamos observando um material radioativo que esporadicamente emite fótons que podemos detectar atravéz de um aparelho.
A razão dessas emissões pode ser aproximada pelo seguinte modelo.
Na amostra temos um número $n$ grande de átomos instáveis ($n \sim 10^{23}$) e em um determinado tempo de observação, cada um deles tem probabilidade muito baixa de decair emitindo um fóton (digamos $p \sim 10^{-23}$).
Nesse caso, supondo que todos decidam emitir de maneira independente, temos para $p \in [0,1]$,
\begin{equation}
  \label{e:Poisson_setup}
  \Omega_n = \{0,1\}^n, \quad \mathcal{F}_n = \mathcal{P}(\Omega) \quad \text{e} \quad P_p = \otimes_{i=1}^n Ber(p).
\end{equation}
Dessa forma, o número total de emissões observadas para $\omega = (\omega_1, \dots, \omega_n) \in \Omega$ é
\begin{equation}
  \label{e:Xn_Poisson}
  X_n(\omega) = \sum_{i=1}^n \omega_i.
\end{equation}
E gostaríamos de entender como se comporta essa distribuição, que nada mais é que $\Bin(n,p)$.

Uma primeira tentativa seria modelar esse processo dizendo que o número de átomos $n$ é tão grande, que somente estamos interessados no comportamento assimtótico quando $n$ vai para infinito.
Mas para manter o número de emissões sob controle, também gostaríamos que $p = p_n$, que converge a zero.
Poderíamos por exemplo escolher
\begin{equation}
  p_n = \frac \lambda n.
\end{equation}
Mas a discussão que se segue é muito mais geral que essa escolha específica.

Como estaremos interessados em um regime assimtótico da distribuição de $X_p$ (lembre que apesar do espaço amostral de $X_n$ variar com $n$, sua distribuição é sempre uma probabilidade em $\mathbb{N}$).
Mas para falar de regimes assimtóticos, precisamos de definir uma noção de distância entre duas distribuições em $\mathbb{N}$.

\begin{definition}
Dadas duas distribuições $\mu_1$ e $\mu_2$ em $(\Omega, \mathcal{A})$, definimos
\begin{equation}
  \lVert \mu_1 - \mu_2 \rVert_{\VT} = \sup_{A \in \mathcal{A}} |\mu_1(A) - \mu_2(A)|,
\end{equation}
\index{mu1 - mu2@$\lVert \mu_1 - \mu_2 \rVert$} chamada de distância em variação total \index{variacao total@variação total} entre $\mu_1$ e $\mu_2$.
\end{definition}

No nosso caso, $\Omega$ é enumerável.
Vamos ver que nesse caso é possível reescrever a definição acima de modo a ver mais facilmente que se trata de uma distância no espaço de probabilidades em $\Omega$.

\begin{lemma}
\label{l:vt_l1}
Se $\Omega = \{x_1, x_2, \dots\}$, então podemos escrever
\begin{equation}
  \lVert \mu_1 - \mu_2 \rVert_{\VT} = \frac{1}{2} \sum_{i} |\mu_1(x_i) - \mu_2(x_i)|.
\end{equation}
\end{lemma}

\begin{proof}
Para mostrar que o lado esquerdo é maior ou igual ao direito, escolhemos $A = \{ x \in \Omega; \mu_2(x) \leq \mu_1(x)\}$. Assim
\begin{equation}
  \begin{split}
    \sum_{x \in A} \mu_1(x) - \mu_2(x) & = |\mu_1(A) - \mu_2(A)|\\
    & = |\mu_1(A^c) - \mu_2(A^c)| = \sum_{x \in A^c} \mu_2(x) - \mu_1(x),
  \end{split}
\end{equation}
donde
\begin{equation}
  \lVert \mu_1 - \mu_2 \rVert_{\VT} \geq |\mu_1(A) - \mu_2(A)| = \frac{1}{2} \sum_{i} |\mu_1(x_i) - \mu_2(x_i)|.
\end{equation}

Na outra direção, observe que para todo $B \subseteq \Omega$,
\begin{equation}
  \begin{split}
    \sum_{i} |\mu_1(x_i) - \mu_2(x_i)| & \geq \sum_{x \in B} \mu_1(x) - \mu_2(x) + \sum_{x \in B^c} \mu_1(x) - \mu_2(x)\\
    & = \mu_1(B) - \mu_2(B) + (1 - \mu_2(B)) - (1 - \mu_1(B))\\
    & = 2(\mu_1(B) - \mu_2(B)).
  \end{split}
\end{equation}
O que termina a prova do lema.
\end{proof}

Fica agora claro que $\lVert \mu_1 - \mu_2 \rVert_{\VT}$ determina uma distância.

\begin{exercise}
Mostre um lema análogo ao anterior para $(\Omega, \mathcal{A})$ qualquer, desde que $\mu_1$ e $\mu_2$ sejam absolutamente contínuas com relação à uma medida fixa nesse espaço mensurável. Nesse caso utilizaremos as derivadas de Radon–Nikodym.
\end{exercise}

Como estaremos interessados em variáveis independentes, precisamos de um resultado que relacione a distância em variação total com produtos de medida. Isso é parte do seguinte

\begin{lemma}
\label{l:vt_produto}
Sejam $\mu_1, \mu_2$ distribuições em $\Omega$ e $\nu_1, \nu_2$ distribuições em $y$ ambos enumeráveis. Então
\begin{equation}
  \lVert \mu_1 \otimes \nu_1 - \mu_2 \otimes \nu_2 \rVert_{\VT} \leq \lVert \mu_1 - \mu_2 \rVert_{\VT} + \lVert \nu_1 - \nu_2 \rVert_{\VT}.
\end{equation}
\end{lemma}

\begin{proof}
Basta expandir
\begin{equation}
  \begin{split}
    \lVert \mu_1 & \otimes \nu_1 - \mu_2 \otimes \nu_2 \rVert_{\VT} = \sum_{x \in \Omega, y \in y} |\mu_1(x)\nu_1(y) - \mu_2(x)\nu_2(y)|\\
    & \leq \sum_{x \in \Omega, y \in y} |\mu_1(x)\nu_1(y) - \mu_1(x)\nu_2(y)| + |\mu_1(x)\nu_2(y) - \mu_2(x)\nu_2(y)|\\
    & \leq 2\lVert \mu_1 - \mu_2 \rVert_{\VT} + 2\lVert \nu_1 - \nu_2 \rVert_{\VT}.
  \end{split}
\end{equation}
Onde acima nós usamos que $\mu_1$ e $\nu_2$ são probabilidades. Isso termina a prova do lema.
\end{proof}

Finalmente, gostaríamos de entender como a distância de variação total se comporta com respeito à soma de variáveis independentes.
Isso estará ligado à convolução de distribuições:

\begin{definition}
Dadas, $\mu$ e $\nu$ distribuições em $\mathbb{Z}$, definimos a distribuição
\begin{equation}
  (\mu \star \nu)(x) := \sum_{y \in \mathbb{Z}} \mu(x-y) \nu(y).
\end{equation}
\end{definition}

Essa definição se relaciona com a soma de variáveis independentes graças ao seguinte
\begin{exercise}
Se $X \overset{d}\sim \mu$ e $Y \overset{d}\sim \nu$ são variáveis aleatórias inteiras e independentes, então $X + Y \overset{d}\sim \mu \star \nu$.
Dica: particione o espaço amostral nos eventos $[X = j]$, para $j \in \mathbb{Z}$, como na prova do Lema~\ref{l:soma_poisson} abaixo.
\end{exercise}

\begin{corollary}
Se $\mu$ e $\nu$ são distribuições em $\mathbb{Z}$, então $\mu \star \nu = \nu \star \mu$.
\end{corollary}

Como prometido, obtemos a seguinte relação entre a convolução e a distância de  variação total.
\begin{lemma}
\label{l:vt_conv}
Sejam $\mu_1, \mu_2, \nu_1, \nu_2$ distribuições em $\mathbb{Z}$. Então,
\begin{equation}
  \lVert \mu_1 \star \nu_1 - \mu_2 \star \nu_2 \rVert_{\VT} \leq \lVert \mu_1 \otimes \nu_1 - \mu_2 \otimes \nu_2 \rVert_{\VT}
\end{equation}
\end{lemma}

\begin{proof}
Como de costume, basta estimar
\begin{equation}
  \begin{split}
    \sum_{x \in \mathbb{Z}} \Big| & \sum_{y \in \mathbb{Z}} \mu_1(x-y) \nu_1(y) - \sum_{y \in \mathbb{Z}} \mu_2(x-y)\nu_2(y) \Big|\\
    & \leq \sum_{x, y \in \mathbb{Z}} \big| \mu_1(x-y) \nu_1(y) - \mu_2(x-y)\nu_2(y) \big|\\
    & \leq \sum_{x, z \in \mathbb{Z}} \big| \mu_1(z) \nu_2(y) - \mu_2(z)\nu_2(y) \big|\\
    & = 2\lVert \mu_1 \otimes \nu_1 - \mu_2 \otimes \nu_2 \rVert_{\VT},
  \end{split}
\end{equation}
provando o lema.
\end{proof}

Para enunciar o resultado principal dessa seção, vamos apresentar uma distribuição em $\mathbb{N}$ bastane importante, que em particular se comporta muito bem com respeito a somas de variáveis independentes, como veremos.

\begin{definition}
  Uma variável aleatória $X$ é dita ter distribuição de Poisson \index{distribuicao@distribuição!de Poisson} com parâmetro $\lambda$, se
  \begin{equation}
    P[X = k] = \frac{\lambda^k e^{-\lambda}}{k!}, \text{ para $k \geq 0$ inteiro.}
  \end{equation}
  Denotamos isso por $X \overset{d}\sim \Poisson(\lambda)$.
\end{definition}

A distribuição de Poisson se comporta bem com respeito a somas independentes, como mostra o seguinte
\begin{lemma}
\label{l:soma_poisson}
Sejam $X \overset{d}\sim \Poisson(\lambda_1)$ e $Y \overset{d}\sim \Poisson(\lambda_2)$ independentes, então $X+Y \overset{d}\sim \Poisson(\lambda_1 + \lambda_2)$.
\end{lemma}

\begin{proof}
Basta calcular
\begin{equation}
  \begin{split}
    P[X+Y = k] & = \sum_{j = 0}^k P[X = j, Y = k-j] = \sum_{j = 0}^k \frac{\lambda_1^j e^{-\lambda_1} \lambda_2^{k-j} e^{-\lambda_2}}{j! (k-j)!}\\
    & = e^{-(\lambda_1 + \lambda_2)} \frac{1}{k!} \sum_{j = 0}^k \frac{k!}{j! (k-j)!} \lambda_1^j \lambda_2^{k-j} = \frac{e^{(\lambda_1 + \lambda_2)} (\lambda_1 + \lambda_2)^k}{k!},
  \end{split}
\end{equation}
mostrando o resultado.
\end{proof}

Nossa próxima tarefa é estimar a distância entre uma variável aleatória com distribuição $\Ber(p)$ e uma $\Poisson(p)$, como segue.

\begin{lemma}
\index{Lei!dos Pequenos Numeros@dos Pequenos Números}
\label{l:vt_ber_poiss}
Para $p \in [0,1]$, seja $\mu_1 = \Ber(p)$ e $\mu_2 = \Poisson(p)$, então,
\begin{equation}
  \lVert \mu_1 - \mu_2 \rVert_{\VT} \leq p^2.
\end{equation}
\end{lemma}

\begin{proof}
Sabemos que
\begin{equation}
  \begin{split}
    \lVert \mu_1 - \mu_2 \rVert_{\VT} & = \frac{1}{2} \sum_{x} |\mu_1(x) - \mu_2(x)|\\
    & = \frac{1}{2} \Big( |\mu_1(0) - \mu_2(0)| + |\mu_1(1) - \mu_2(1)| + \sum_{x \geq 2} \mu_2(x) \Big)\\
    & = \frac{1}{2} \Big( e^{-p} - (1-p) + p(1-e^{-p}) + (1 - e^{-p} - p e^{-p}) \Big)\\
    & = \frac{2}{2} p (1 - e^{-p}) \leq p^2,
  \end{split}
\end{equation}
terminando a prova.
\end{proof}

O teorema principal de convergência dessa seção concerne a soma de variáveis Bernoulli.

\begin{theorem}[Lei dos Pequenos Números]
  \label{t:lei_peq_numeros}
  Dado, $n \geq 1$ e $p \in [0,1]$, suponha que $\Omega_n$, $\mathcal{F}_n$ e $P_p$ sejam dados como em \eqref{e:Poisson_setup}.
  Então,
  \begin{equation}
    \lVert \Bin(n,p) - \Poisson(pn) \rVert_{\VT} \leq n p^2.
  \end{equation}
\end{theorem}

\begin{proof}
  Basta observar que
  \begin{equation}
    \begin{split}
      \lVert X_n \circ P_p - \Poisson(pn) \rVert_{\VT} & \overset{\text{Lema~\ref{l:soma_poisson}}}= \lVert \Ber(p)^{\star n} - \Poisson(p)^{\star n} \rVert_{\VT}\\
      \overset{\text{Lema~\ref{l:vt_conv}}}\leq & \lVert \Ber(p)^{\otimes n} - \Poisson(p)^{\otimes n} \rVert_{\VT}\\
      \overset{\text{Lema~\ref{l:vt_produto}}}\leq & n \lVert \Ber(p) - \Poisson(p) \rVert_{\VT} \overset{\text{Lema~\ref{l:vt_ber_poiss}}}\leq n p^2,
    \end{split}
  \end{equation}
  provando o teorema.
\end{proof}

\begin{corollary}
  No mesmo contexto do teorema acima, se $p = \lambda/n$, então temos
  \begin{equation}
    \lVert \Bin(n,p) - \Poisson(pn) \rVert_{\VT} \leq \lambda^2 / n,
  \end{equation}
  que converge a zero com $n$.
\end{corollary}

\vfill
\newpage

\section{Espaços produto infinito}
\label{s:Omega_produto}

Nessa seção estudaremos $\Omega$ que são dados por produtos enumeráveis de outros espaços de probabilidade.
Mas antes iremos recordar o Teorema da Extensão de Caratheodory.

\subsection{Recordar é viver...}

Vamos lembrar o enunciado do Teorema da Extensão de Caratheodory \index{Teorema!da Extensao de Caratheodory@da Extensão de Caratheodory}.
Antes, vamos relembrar uma definição definição importante.
Uma família $\mathcal{G} \subseteq \mathcal{P}(\Omega)$ é dita uma álgebra de conjuntos \index{anel de conjuntos} se valem
\begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{G}$,
  \item se $A \in \mathcal{G}$, então $A^c \in \mathcal{G}$ e
  \item para todo $n \geq 1$, se $A_1, \dots, A_n \in \mathcal{G}$, então $\cup_{i=1}^n A_i \in \mathcal{G}$.
\end{enumerate}

\begin{theorem}[Teorema da Extensão de Caratheodory]
  Seja $\mathcal{G} \subseteq \mathcal{P}(\Omega)$ uma álgebra de conjuntos em $\Omega$ e suponha que $\mu: \mathcal{G} \to \mathbb{R}_+$ satisfaça a seguinte propriedade
  \begin{display}
    \label{e:aditiva_na_algebra}
    sempre que $A_1, A_2, \dots \in \mathcal{G}$ forem disjuntos e tais que $\cup_i A_i \in \mathcal{G}$,\\temos $\mu(\cup_i A_i) = \sum_i \mu(A_i)$.
  \end{display}
  Nesse caso, existe uma medida $\bar{\mu}: \sigma(\mathcal{G}) \to \mathbb{R}_+$ tal que $\bar{\mu}(A) = \mu(A)$ para todo $A \in \mathcal{G}$.
\end{theorem}

Mostraremos agora uma pequena simplificação do teorema acima, que é muito utilizada em probabilidade.

\begin{lemma}[Extensão por continuidade no vazio]
  \label{l:extensao_vazio}
  \index{continuidade no vazio}
  Seja $\mathcal{G} \subseteq \mathcal{P}(\Omega)$ uma álgebra de conjuntos em $\Omega$ e suponha que $P: \mathcal{G} \to \mathbb{R}_+$ satisfaça as seguintes propriedades
  \begin{enumerate}[\quad a)]
  \item $P(\Omega) = 1$,
    \item $P$ é finitamente aditiva e
    \item sempre que $B_1 \supseteq B_2 \supseteq \dots \in \mathcal{G}$ forem tais que $\cap_i B_i = \varnothing$ (denotamos isso por $B_i \downarrow \varnothing$), temos que $\lim_i \mu(B_i) = 0$.
  \end{enumerate}
  Então existe uma única medida $\widebar{P}: \sigma(\mathcal{G}) \to \mathbb{R}_+$ tal que $\widebar{P}(A) = P(A)$ para $A \in \mathcal{G}$.
\end{lemma}

Observe que $P(\Omega) = 1$ somente é necessário para provar a unicidade de $\widebar{P}$, então poderíamos tentar mostrar uma versão mais geral desse lema.
Mas no contexto de medidas infinitas, não é de se esperar que $B_i \downarrow \varnothing$ implique $\lim_i \mu(B_i) = 0$, como foi assumido acima (veja também a Proposição~\ref{p:prob_continua}).
Portanto resolvemos escrever o enunciado com probabilidades.

\begin{exercise}
  Dê um exemplo de medida que não satisfaz a segunda hipótese do Lema~\ref{l:extensao_vazio}.
\end{exercise}

\begin{proof}
  Primeiro observe que a unicidade segue da Proposição~\ref{p:P12_equal_pi}, já que $\mathcal{G}$ é um $\pi$-sistema.
  Iremos agora mostrar que a propriedade \eqref{e:aditiva_na_algebra} é válida para $P$, logo tome $A_1, A_2, \dots \in \mathcal{G}$ disjuntos e tais que $A = \cup_i A_i \in \mathcal{G}$.
  Definimos o ``resto da união'' por
  \begin{equation}
    B_n = A \setminus \mcup_{i=1}^n A_i.
  \end{equation}
  Claramente
  \begin{enumerate}[\quad a)]
  \item $B_n \downarrow \varnothing$ e
  \item $B_n \in \mathcal{G}$, pois $\mathcal{G}$ é uma álgebra.
  \end{enumerate}

  Logo podemos escrever $A$ como a união disjunta $A = \bigcup_{i=1}^n A_i \cup B_n$ e já que $P$ é finitamente aditiva,
  \begin{equation}
    P(A) = \sum_{i=1}^n P(A_i) + P(B_n),
  \end{equation}
  mas como $\lim_n P(B_n) = 0$, temos $P(\cup_i A_i) = \sum_i P(A_i)$, mostrando a propriedade \eqref{e:aditiva_na_algebra} e concluindo o teorema.
\end{proof}

\subsection{Teorema da Extensão de Kolmogorov}

O objetivo desta seção é provar um resultado que nos permitirá construir probabilidades em espaços produtos infinitos.
Antes precisaremos de introduzir algumas notações.

Dada uma coleção de espaços $E_1, E_2, \dots$, definimos o espaço produto
\begin{equation}
  \Omega = \bigtimes_{i\geq 1} E_i = \big\{(\omega_1, \omega_2, \dots); \omega_i \in E_i \text{ para todo $i \geq 1$}\big\}.
\end{equation}
e os mapas $X_i:\Omega \to E_i$, definidos para $i = 1, 2, \dots$ por
\begin{equation}
  X_i(\omega_1, \omega_2, \dots) = \omega_i,
\end{equation}
que chamamos de \emph{coordenadas canônicas} \index{coordenadas canonicas@coordenadas canônicas} associadas ao produto $\Omega$.

Se cada $E_i$ é dotado de uma $\sigma$-álgebra $\mathcal{A}_i$, então definimos
\begin{equation}
  \mathcal{F} = \sigma(X_i; i \geq 1),
\end{equation}
que é claramente uma a $\sigma$-álgebra em $\Omega$.
Chamamos $\mathcal{F}$ de $\sigma$-álbegra canônica.

\begin{exercise}
  Mostre que em $(\mathbb{R}^{\mathbb{N}},\mathcal{F})$ temos que os conjuntos
  \begin{enumerate}[\quad a)]
  \item $A = \{ \liminf_n X_n \text{ existe}\}$,
  \item $B = \{ \lim_n X_n = 4\}$ e
  \item $C = \{ \lim_n \tfrac{1}{n} X_n \text{ existe}\}$
  \end{enumerate}
  são todos mensuráveis (eventos) com respeito a $\mathcal{F}$.
  Além disso $Y = \1_A \liminf_n X_n$ é uma variável aleatória em $(\Omega, \mathcal{F})$.
\end{exercise}

\begin{exercise}
  Verifique que,
  \begin{enumerate}[\quad a)]
  \item $\mathcal{F} = \sigma\big(A_1 \times \dots \times A_k \times E_{k+1} \times E_{k+2} \times \dots; k \geq 1, A_i \in \mathcal{A}_i, i \leq k\big)$, os chamados eventos retangulares e
  \item $\mathcal{F} = \sigma\big(A \times E_{k+1} \times E_{k+2} \times \dots; k \geq 1, A \in \mathcal{A}_i \otimes \dots \otimes \mathcal{A}_k\big)$, conhecidos como eventos cilíndricos.
  \end{enumerate}
\end{exercise}

\begin{definition}
  \label{d:marginal}
  Seja $\Omega = \times E_i$ um espaço produto (infinito ou finito) dotado de uma probabilidade $P$.
  Se $X_i$ é uma coordenada canônica, então chamamos a probabilidade $X_i \circ P$ de \emph{distribuição marginal} \index{distribuicao@distribuição!marginal} de $P$ na coordenada $i$.
\end{definition}

\begin{theorem}[Extensão de Kolmogorov]
  \index{Teorema!da Extensao de Kolmogorov@da Extensão}
  \label{t:extens_kolmog}
  Seja para cada $n \geq 1$ uma medida de probabilidade $P_n$ em $\mathbb{R}^n$ tal que seja satisfeita a seguinte condição de compatibilidade \index{condicao de compatibilidade@condição de compatibilidade}
  \begin{equation}
    \label{e:consist_kolmog}
    P_{n+1} (A \times \mathbb{R}) = P_n (A), \text{ para todo $A \in \mathcal{B}(\mathbb{R}^n)$}.
  \end{equation}
  Então existe uma única probabilidade $P$ no espaço produto infinito $(\Omega, \mathcal{F})$ tal que $P(A \times \mathbb{R} \times \dots) = P_n (A)$ para todo $n$ e todo boreliano $A$ de $\mathbb{R}^n$.
\end{theorem}

\begin{proof}
  Considere a classe de conjuntos
  \begin{equation*}
    \mathcal{S}_l = \Big\{ \mcup_{i=1}^k [a_1, b_1) \times \dots \times [a_l, b_l) \subseteq \mathbb{R}^l; \text{ onde $a_i \in \mathbb{R} \cup \{-\infty\}, b_i \in \mathbb{R} \cup \{\infty\}$} \Big\}.
  \end{equation*}
  Que é obviamente uma álgebra em $\mathbb{R}^l$ e seja também
  \begin{equation}
    \mathcal{S} = \big\{ A \times \mathbb{R} \times \dots; \text{ onde } l \geq 1 \text{ e } A \in \mathcal{S}_l \big\}.
  \end{equation}
  Claramente, $\mathcal{S}$ também é uma álgebra.

  Se $B = A \times \mathbb{R} \times \dots \in \mathcal{S}$ com $A \in \mathcal{S}_l$ como acima, definimos
  \begin{equation}
    P(B) = P_l(A).
  \end{equation}
  Note que por \eqref{e:consist_kolmog} essa definição independe da escolha da escolha de $l$ que usamos na definição de $B$.

  Gostaríamos agora de utilizar o Lemma~\ref{l:extensao_vazio}.
  Para tanto, tome uma sequência encaixada $B_1 \supseteq B_2 \supseteq \dots \in \mathcal{S}$ e, supondo que $P(B_n) \geq \delta > 0$ para todo $n \geq 1$, temos de mostrar que sua interseção não pode ser vazia.

  Como $B_n \in \mathcal{S}$, podemos escrever
  \begin{equation}
    B_n = A_n \times \mathbb{R} \times \dots, \text{ onde $A_n \in \mathcal{S}_{l_n}$ e $n \geq 1$.}
  \end{equation}
  Podemos obviamente supor que
  \begin{equation}
    \label{e:l_n_monotona}
    \text{$l_n$ são estritamente crescentes.}
  \end{equation}

  A fim de obter um ponto na interseção de $B_n$, gostaríamos de aproximá-lo usando conjuntos compactos encaixados.
  Para tanto definimos os conjuntos
  \begin{equation}
    C_n = C_n^* \times \mathbb{R} \times \dots, \text{ com $C_n^* \in \mathcal{S}_{l_n}$}
  \end{equation}
  de forma que $C_n^*$ seja pré-compacto, $\widebar{C}_n^* \subseteq A_n$ e
  \begin{equation}
    P(B_n \setminus C_n) \leq \frac{\delta}{2^{l_n + 1}},
  \end{equation}
  o que pode ser feito graças à continuidade de $P_{l_n}$, que é uma probabilidade.

  Temos ainda um problema, pois os conjuntos $C_n$ não são encaixados, e isso nos impede de utilizar resultados sobre interseções de compactos.
  Introduzimos pois $D_n = \bigcap_{i=1}^n C_i$, que obviamente pertence à álgebra $\mathcal{S}$, e estimamos
  \begin{equation}
    P(B_n \setminus D_n) = P \big( \mcup\nolimits_{i=1}^n (B_n \setminus C_i) \big) \leq \sum_{i=1}^n P(B_n \setminus C_i) \leq \frac{\delta}2,
  \end{equation}
  donde $P(D_n) = P(B_n) - P(B_n \setminus D_n) \geq \delta/2$.
  De forma que os $D_n$ são encaixados e não vazios.

  Nosso próximo obstáculo vem do fato de que os conjuntos $D_n$ estão definidos em $\mathbb{R}^\mathbb{N}$, e gostaríamos de ter conjuntos em espaços de dimensão finita.
  Isso pode ser feito observando que podemos escrever $D_n = D_n^* \times \mathbb{R} \times \mathbb{R} \times \dots$, onde $D_n^* \in \mathcal{S}_{l_n}$ e
  \begin{equation}
    D_n^* = \underbrace{C_n^*}_{\mathclap{\text{pré-compacto}}} \mcap \Big( \mcap_{i=1}^{n-1} C_i^* \times \mathbb{R}^{l_n - l_i} \Big),
  \end{equation}
  de forma que os $D_n^* \subseteq \mathbb{R}^{l_n}$ são pré-compactos e não vazios.

  Para cada $n \geq 1$ considere um $\omega^n \in D_n^* \subseteq \mathbb{R}^{l_n}$.
  Usando um argumento de diagonal de Cantor, podemos obter um $\omega \in \Omega$ e uma sub-sequência de $\omega^{n_j}$ que convirja para $\omega \in \Omega$ coordenada a coordenada (observe que $\omega^{n_j} \in \mathbb{R}^{\smash{l_{n_j}}}$).
  % Tomando subsequências se necessário, podemos supor que $\omega^n$ converge coordenada a coordenada a um certo $\omega \in \Omega$.

  Para concluir a prova, veremos que $\omega \in \bigcap_m B_m$.
  Mais ainda, veremos que
  \begin{equation*}
    \text{para todo $m \geq 1$, temos $\omega = (\omega_1, \omega_2, \dots) \in \widebar{C}_m = \widebar{C}_m^* \times \mathbb{R} \times \dots \subseteq B_m$.}
  \end{equation*}
  Mas como os pontos $(\omega_1, \dots, \omega_{l_m})$ são o limite de $(\omega^{n_j}_1, \dots, \omega^{n_j}_{l_m}) \in C_m^*$ (com $n_j \geq m$), então é óbvio que $\omega \in \widebar{C}_m$, terminando a prova do teorema.
\end{proof}

Observe que usamos muito poucos atributos de $\mathbb{R}$ na prova.
Poderíamos na verdade substituir $\mathbb{R}$ por um espaço métrico que satisfaça certas propriedades, como por exemplo a existência de uma álgebra cujos conjuntos possam ser aproximados por pré-compactos.
Contudo, decidimos não apresentar essa versão mais geral aqui porque muito em breve obteremos uma versão bem mais geral do Teorema de Kolmogorov usando apenas o resultado para $\mathbb{R}$.

\begin{exercise}
  Mostre que a hipótese \eqref{e:consist_kolmog} pode ser substituida por
  \begin{equation}
    P_{n+1} (I_1 \times \dots, \times I_n \times \mathbb{R}) = P_n (I_1 \times \dots \times I_n),
  \end{equation}
  para todo $n \geq 1$ e $I_i = (-\infty, b_i]$, onde $b_i \in \mathbb{R}$, $i \leq n$.
\end{exercise}

Um importante exemplo do uso deste teorema é o seguinte.

\begin{example}
  Se $P_i$ são probabilidades em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, podemos definir $\mathbb{P}_n = \bigotimes_{i=1}^n P_i$ (relembrando, $\mathbb{P}_n$ é a única distribuição em $\mathbb{R}^n$ tal que $\mathbb{P}_n(A_1 \times \dots \times A_n) = \prod_{i=1}^n P_i(A_i)$).
  Não é difícil verificar que essa lei satisfaz as equações de consistência \eqref{e:consist_kolmog}.
  Desta forma, podemos construir uma única $\mathbb{P}$ em $\mathbb{R}^\mathbb{N}$ para os quais as coordenadas canônicas $X_i$ são independentes e possuem distribuições marginais $P_i$.
  Denotamos nesse caso $\mathbb{P} = \bigotimes_{i \geq 1} P_i$.
\end{example}

Mais adiante no texto daremos outros exemplos bastante interessantes do uso do Teorema~\ref{t:extens_kolmog}.

\begin{exercise}
  Mostre que se $p > 0$ e $\mathbb{P} = \bigotimes_{i \geq 1} \Ber(p)$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n = 1$ quase certamente.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $\mathbb{P} = \bigotimes_{i \geq 1} U_{[0,1]}$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n = 1$ quase certamente.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $\mathbb{P} = \bigotimes_{i \geq 1} \Exp(i)$ em $\mathbb{R}^\mathbb{N}$, então
  \begin{equation}
    \text{$\limsup_n X_n < \infty$ quase certamente.}
  \end{equation}
\end{exercise}

\vfill
\pagebreak

\subsection{Tópico: Percolação}

Imagine que gostaríamos de modelar o movimento de um líquido em um meio poroso, como uma rocha ou uma esponja.
A primeira tarefa nesse estudo seria modelar esse meio poroso de maneira matematicamente rigorosa, que é o que faremos a seguir.

Fixamos uma dimensão $d \geq 1$ e consideramos o seguinte grafo $G = (\mathbb{Z}^d, E)$, onde a rede quadrada $\mathbb{Z}^d$ é o conjunto de vértices de $G$ e o conjunto de elos é dado por
\begin{equation*}
  E = \big\{ \{x, y\} \subset \mathbb{Z}^d; |x - y| = 1 \},
\end{equation*}
onde $|\cdot|$ representa a distância euclideana em $\mathbb{R}^d$.

No nosso modelo, esse grafo pode ser entendido como um cristal periódico onde cada vértice representa uma cavidade do material poroso e os elos são potenciais conexões entre poros vizinhos.

Até agora nosso grafo $G$ é apenas uma rede periódica, mas as coisas começam a ficar interessantes à partir de agora.
Imaginamos que nosso material poroso está sujeito a variações durante sua formação.
Isso se reflete no fato que alguns elos de $E$ podem estar abertos ou não aleatoriamente.

Para o nosso modelos, fixamos um $p \in [0,1]$ e definimos uma coleção de variáveis aleatórias $X_e$, para $e \in E$, que sejam \iid e com distribuição $\Ber(p)$.
Essas variáveis aleatórias induzem um novo subgrafo $(\mathbb{Z}^d, \mathcal{E})$ de $G$ que corresponde a abrir apenas os elos $e$ com $X_e = 1$.
Mais precisamente
\begin{equation}
  \mathcal{E} = \big\{ e \in E; X_e = 1 \big\}.
\end{equation}
Podemos ver na Figura~\ref{f:percola} algumas simulações desse grafo aleatório.

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=.1]
    \ifdraft{\def\side{5}}{\def\side{30}}
    \draw[step=1, color=gray!50!white] (1,1) grid (\side + 1, \side + 1)
                                       (41, 1) grid (41 + \side, \side + 1) (81, 1) grid (81 + \side, \side + 1);
    \foreach \x in {1,...,\side}
    { \foreach \y in {1,...,\side}
      { \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>60}{\draw[thick] (\x, \y) -- (\x, \y + 1);}{}
        \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>60}{\draw[thick] (\x, \y) -- (\x + 1, \y);}{} } }
    \foreach \x in {1,...,\side}
    { \foreach \y in {1,...,\side}
      { \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>50}{\draw[thick] (40 + \x, \y) -- (40 + \x, \y + 1);}{}
        \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>50}{\draw[thick] (40 + \x, \y) -- (40 + \x + 1, \y);}{} } }
    \foreach \x in {1,...,\side}
    { \foreach \y in {1,...,\side}
      { \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>40}{\draw[thick] (80 + \x, \y) -- (80 + \x, \y + 1);}{}
        \pgfmathrandominteger{\a}{0}{100} \ifthenelse{\a>40}{\draw[thick] (80 + \x, \y) -- (80 + \x + 1, \y);}{} } }
  \end{tikzpicture}
  \caption{Três simulações do grafo aleatório $(\mathbb{Z}^d, \mathcal{E})$, para valores de $p = 0,4$ (esquerda), $p = 0,5$ (centro) e $p = 0,6$ (direita). Tente imaginar como seria caminhar nesse grafo como se ele fosse um labirinto.}
  \label{f:percola}
\end{figure}

Agora que temos um modelo de meio poroso bem definido, precisamos pensar em quais perguntas nos interessam sobre $\mathcal{G} = (\mathbb{Z}^d, \mathcal{E})$.
Sendo esse um modelo poara passagem de fluido, as primeiras perguntas que faremos concerne a conectividade de $\mathcal{G}$.

\begin{exercise}
  Mostre que quase certamente $\mathcal{G}$ é desconexo.
  Mais precisamente, mostre que existem quase certamente infinitos vércices isolados em $\mathcal{G}$.
\end{exercise}

Como não podemos esperar que $\mathcal{G}$ seja conexo, podemos nos perguntar algo mais fraco, como por exemplo se a componente conexa da origem $0 \in \mathbb{Z}^d$ em $\mathcal{G}$ é infinita.

Voltando à Figura~\ref{f:percola} vemos que, dependendo do valor de $p \in [0,1]$, pode ser bem difícil ou bem fácil encontrar um caminho longo à partir da origem.
Isso é uo que estudaremos em mais detalhes no que segue.

Mais precisamente estamos interessados em:
\begin{equation}
  A = \big\{\omega \in \Omega; \text{ a componente conexa de $0 \in \mathbb{Z}^d$ em $\mathcal{G}$ é infinita} \big\}.
\end{equation}

Para estudar $A$, vamos fazer uma aproximação de $A$ por eventos mais simples
\begin{equation}
  A_n = \big\{ \omega \in \Omega; \text{ a componente conexa de $0$ sai da caixa $[-n, n]^d$}\},
\end{equation}
para $n \geq 1$.

\begin{exercise}
  Mostre que $A = \cap \cap_n A_n$ e consequentemente que $A$ é de fato um evento (mensurável) e $P(A) = \lim_n P(A_n)$.
\end{exercise}

Definimos portanto a função $\theta:[0,1] \to [0,1]$ por
\begin{equation}
  \theta(p) = P_p(A),
\end{equation}
onde $P_p$ denota a probabilidade correspondente ao valor escolhido de $p \in [0,1]$.

\begin{exercise}
  Mostre que $\theta(p) \leq (1-p)^{2d}$.
\end{exercise}

Nosso objetivo é entender algumas das propriedades de $\theta$.
A nossa intuição diz que quanto maior o valor de $p$, mais elos serão abertos em $\mathcal{G}$ e portanto maior será o valor de $\theta$, ou em outras palavras, $\theta$ deve ser monótona não decrescente.

\begin{exercise}
  Construiremos nosso modelo de uma maneira alternativa num espaço de probabilidade $\mathbb{P}$.
  Sejam $Y_e$, para $e \in E$, variáveis aleatórias \iid com distribuição $U[0,1]$ e definimos para cada $p \in [0,1]$
  \begin{equation}
    X^p_e = \1_{[Y_e \leq p]}.
  \end{equation}
  Mostre que para todo $p \in [0,1]$ a distribuição conjunta de $(X_e)_{e \in E}$ sob a lei $P_p$ é a mesma que a de $(X^p_e)_{e \in E}$ sob $\mathbb{P}$.
  Use isso para concluir que $\theta$ é monótona não decrescente.
\end{exercise}

Iremos agora mostrar a existência de um regime para o qual a componente conexa da origem não é infinita.

\begin{theorem}
  Para $p < 1/(2d)$, temos que $\theta(p) = 0$.
\end{theorem}

Antes da prova, alguns exercícios.

\begin{exercise}
  Definimos um caminho como sendo uma sequência $x_1$, $\dots$, $x_k$ ($k \in \mathbb{N}$), tal que $\{x_i, x_{i+1}\} \in E$ para todo $i = 1, \dots, k-1$.
  Tal caminho é dito aberto se $X_{\{x_i, x_{i+1}\}} = 1$ para todo $i \leq k-1$.
  E dizemos que ele é auto-evitante se $x_i \neq x_j$ para todo $1 \leq i < j < k$.
  Mostre que
  \begin{equation*}
    \begin{split}
      & A_n = \Big\{ \omega \in \Omega; \text{ existe um caminho aberto $(x_i)_{i=1}^{k}$ com $x_1 = 0$ e $x_k \not \in [-n, n]^d$} \Big\}\\
      & A_n = \big\{ \omega \in \Omega; \text{ existe um caminho auto-evitante como acima} \big\}.
    \end{split}
  \end{equation*}
\end{exercise}

\begin{proof}
  Dado $p < 1/(2d)$ e $n \in \mathbb{N}$, lembramos que
  \begin{equation*}
    \begin{split}
      \theta(p) & \leq P_p(A_n) = P_p \Big[
      \begin{array}{c}
      \text{existe $k \in \mathbb{N}$ e um caminho auto-evitante $(x_i)_{i=1}^k$ }\\
      \text{aberto e com $x_1 = 0$ e $x_k \not \in [-n, n]^d$}
    \end{array} \Big]\\[2mm]
    & \leq \sum_{k \geq n} \; \; \sum_{(x_i)_{i=1}^k \text{ auto-evit.}} P_p [(x_i)_{i=1}^k \text{ aberto}] = \sum_{k \geq n} \; \; \sum_{(x_i)_{i=1}^k \text{ auto-evit.}} p^k\\
    & \leq \sum_{k \geq n} \; \; \sum_{(x_i)_{i=1}^k \text{ caminho}} P_p [(x_i)_{i=1}^k \text{ aberto}] = \sum_{k \geq n} (2d)^k p^k.
    \end{split}
  \end{equation*}
  Como $p < 1/(2d)$, a soma acima é finita e converge a zero quando $n$ diverge, provando o teorema.
\end{proof}

{\bf Notas} - O teorema acima ajuda a compreender o comportamento que observamos no lado esquerdo da Figura~\ref{f:percola}.
Mais precisamente, ele nos diz que para valores de $p$ baixos (na verdade $0,4$ não é baixo o suficiente para podermos aplicar esse teorema) é difícil encontrar um caminho aberto do centro à borda da caixa.

Na verdade, é possível mostrar que para $d = 2$,
\begin{equation}
  \begin{split}
    & \text{$\theta(p) = 0$ para todo $p < 1/2$ e}\\
    & \text{$\theta(p) > 0$ para todo $p > 1/2$,}
  \end{split}
\end{equation}
como foi mostrado por Harris e Kesten, veja por exemplo \cite{Gri99} e \cite{bollobas2006percolation}.
De fato, algo bastante interessante está acontecendo nesse modelo para $p = 1/2$, como nos mostrou o trabalho de grandes matemáticos, como: Oded Schramm, Wendelin Werner, Stanislav Smirnov, entre outros.

\todosec{Tópico: Teorema de Uma Série}{fazer...}

\vfill
\newpage

\section{Distribuições conjuntas}

Um caso bastante importante de distribuição de um elemento aleatório é o caso de vetores.
Digamos por exemplo que temos dois elementos aleatórios $X:\Omega \to E$ e $Y:\Omega \to E'$.
Já sabemos a definição de $P_X$ e $P_{Y}$ que nada mais são que as distribuições de $X$ e $Y$ respectivamente.

Mas podemos considerar o vetor $(X, Y)$ que será um elemento aleatório tomando valores em $E \times E'$ e possui também sua própria distribuição dada por $(X, Y) \circ P$ (também denotada por $P_{(X, Y)}$).
A essa probabilidade em $E \times E'$ damos o nome de distribução conjunta deste par. \index{distribuicao@distribuição!conjunta}.

Vejamos as relações que existem entre $P_X$, $P_Y$ e $P_{(X,Y)}$.
Primeiramente, é fácil ver que a distribução conjunta nos fornece as demais, pois para todo $A \subseteq E$ mensurável
\begin{equation}
  P_{(X,Y)}(A \times E') = P[(X, Y) \in A \times E'] = P[X \in A] = P_X(A)
\end{equation}
e analogamente para $P_Y$.
De acordo com a Definição~\ref{d:marginal}, as distribuições $P_X$ e $P_Y$ nada mais são do que as marginais da distribuição conjunta.

Apesar de podermos extrair as marginais $P_X$ e $P_Y$ de $P_{(X,Y)}$, o contrário não é sempre possível como mostra o seguinte exemplo.
\begin{example}
  Sejam $X, Y$ \iid com distribuição $\Ber(1/2)$.
  Então $(X, Y)$ não tem a mesma distribuição de $(X, X)$, apesar de que esses vetores possuem as mesmas marginais.
\end{example}

\begin{exercise}
  Mostre que se $X$ e $Y$ são independentes, então $P_{(X,Y)} = P_X \otimes P_Y$.
\end{exercise}

\begin{exercise}
  Sejam $X, Y$ \iid com distribuição $U_{[0,1]}$ e calcule $P_{(X, X + Y)}$.
\end{exercise}

Note que a discussão acima se extende naturalmente para coleções maiores de elementos aleatórios.
Mais precisamente, considere um conjunto $I$ qualquer (finito, enumerável ou não enumerável) de índices e seja $(X_i)_{i \in I}$ uma coleção de elementos aleatórios tomando valores em $(E_i)_{i \in I}$.
Então a distribuição conjunta destes elementos aleatórios é $P_{(X_i)_{i \in I}}$.

\begin{exercise}
  Mostre que no caso acima, se $P_{(X_i)_{i \in J}} = P_{(X'_i)_{i \in J}}$ para todo $J \subseteq I$ finito, então $P_{(X_i)_{i \in I}} = P_{(X'_i)_{i \in I}}$.
\end{exercise}

\vfill
\newpage

\section{Probabilidades condicionais}

Uma outra maneira de se construir espaços de probabilidade é atravéz de condicionamento, como mostra a seguinte definição.
\begin{definition}
  Se $(\Omega, \mathcal{F}, P)$ é espaço de probabilidade e $B \in \mathcal{F}$ é tal que $P(B) > 0$, então definimos a probabilidade \index{probabilidade!condicional} $P(\cdot | B): \mathcal{F} \to [0,1]$ por
  \begin{equation}
    \label{e:P_condicional}
    P(A | B) = \frac{P(A \cap B)}{P(B)},
  \end{equation}
  chamada probabilidade condicional dado o evento $B$.
\end{definition}

Obviamente $P(\cdot | B)$ é uma probabilidade em $(\Omega, \mathcal{F})$ e podemos entendê-la de duas formas: como uma normalização ou como uma tentativa de sucesso.
Explicaremos abaixo cada uma dessas interpretações.

Quando restringimos o espaço amostral $\Omega$ ao conjunto $B$ (e associamos a $A \in \mathcal{F}$ o valor $P(A \cap B)$), temos uma sub-probabilidade, isto é possivelmente $P(\Omega \cap B) < 1$.
Logo podemos entender o denominador de \eqref{e:P_condicional} como uma normalização para obtermos novamente uma probabilidade.

Mas a interpretação mais natural de \eqref{e:P_condicional} é dada pela seguinte proposição.
Para enunciá-la, considere $(\Omega, \mathcal{F}, P)$ um espaço de probabilidade e defina o produto
\begin{equation}
  \widebar{\Omega} = \bigtimes_{i=1}^\infty \Omega, \qquad \widebar{\mathcal{F}} = \bigotimes_{i=1}^\infty \mathcal{F} \quad \text{e} \quad \widebar P = \bigotimes_{i=1}^\infty P.
\end{equation}
Na verdade somente definimos esse produto para $\Omega = \mathbb{R}$, mas como mencionamos abaixo do Teorema da Extensão de Kolmogorov, isso pode ser fácilmente generalizado e o faremos posteriormente.

\begin{proposition}
  Na situação acima, seja $B \in \mathcal{F}$ com $P(B) > 0$ e defina $T:\widebar{\Omega} \to \mathbb{N}$ por $T(\omega) = \inf \{n \geq 1; X_n(\omega) \in B\}$, onde os $X_n$ são as coordenadas canônicas. Então $T < \infty$ quase certamente e
  \begin{equation}
    \text{$X_{T(\omega)}(\omega)$ é um elemento aleatório em $\Omega$ com distribuição $P(\cdot | B)$.}
  \end{equation}
\end{proposition}

A intuição desta proposição é que se repetimos o experimento $(\Omega, \mathcal{F}, P)$ independentemente até obter uma amostra em $B$, essa terá a distribuição condicional.

\begin{proof}
  Sejam os eventos $A_n = [X_n \in B]$, $n \geq 1$ que são claramente independentes segundo $\widebar{P}$.
  Logo, como $\sum_n \widebar{P}(A_n) = \sum_n P(B) = \infty$, temos pelo Lema de Borel-Cantelli (segunda parte) que $\widebar{P}(\text{$A_n$ infinitas vezes}) = 1$, logo $T < \infty$ quase certamente.

  Para ver que $X_{T(\omega)}(\omega)$ é um elemento aletório, basta escrever
  \begin{equation}
    [X_{T} \in A] = \mcup_{t=1}^\infty [X_t \in A, T = t],
  \end{equation}
  e observar que tanto $[X_t \in A]$ quanto $[T = t] = [X_1 \not \in B, \dots, X_{t-1} \not \in B, X_t \in B]$ são mensuráveis.

  Finalmente podemos usar a decomposição (disjunta) acima para calcular
  \begin{equation}
    \begin{split}
      \widebar{P}[X_T \in A] & = \sum_{t=1}^\infty \widebar{P} [X_t \in A, T = t]\\
      & = \sum_{t=1}^\infty \widebar{P} [X_t \in A, X_t \in B, X_s \not \in B \text{ for $s < t$}]\\
      & = \sum_{t=1}^\infty P(A \cap B) P(B^c)^{t-1} = \frac{P(A \cap B)}{1-P(B^c)} = P(A | B),
    \end{split}
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{exercise}
  Seja $\lambda > 0$ e $X \distr \Exp(\lambda)$ (lembrando a definição da distribuição exponencial: $\d (X \circ P) = \lambda \exp\{- \lambda x\} \d x$).
  Mostre que as variáveis com distribuição exponencial não possuem memória, ou seja:
  \begin{equation}
    \label{e:sem_memoria}
    P[X > t + s | X > t] = P [X > s], \text{ para todo $s, t > 0$}.
  \end{equation}
  Ou em outras palavras, sabendo que $X$ é maior que $t$, a distribuição condicional de $X - t$ ainda é $\Exp(\lambda)$.
\end{exercise}

Definimos a distribuição geométrica \index{distribuicao@distribuição!geometrica@geométrica} de parâmetro $p \in (0,1]$ por
\begin{equation}
  \Geo(p) = \sum_{i = 1}^\infty \delta_i (1-p)^i p.
\end{equation}

\begin{exercise}
  Inspirado no exercício anterior, mostre que a distribuição geométrica $\Geo(p)$ também satisfaz \eqref{e:sem_memoria} para todos $t, s \in \mathbb{N}$.
  Mostre que essas são as únicas distribuições com suporte em $\mathbb{N}$ satisfazendo tal propriedade
\end{exercise}

\begin{exercise}
  \label{x:geo_time}
  Sejam $Y_i$, para $i \geq 1$ \iid com distribuição $\Ber(p)$ e defina
  \begin{equation}
    T = \inf\{i; Y_i = 1\}.
  \end{equation}
  Mostre que $T \overset{d}\sim \Geo(p)$.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 2-5, Ex: 5, 10, 21, 22 (a) e (b).
\end{exercise}

\begin{exercise}[Porta dos desesperados]
  Nas tardes da década de 80, as crianças tinham poucas opções de entretenimento além de assistir Sérgio Malandro, que todos os dias apresentava o seguinte jogo.
  O participante era apresentado a três portas ($\Omega = \{1,2,3\}$) e apenas uma delas (chamada de $X$) continha um prêmio $X \distr U_{\Omega}$ e o jogo seguia três fases:
  \begin{enumerate}[\quad a)]
  \item O participante escolhia uma porta arbitrariamente (digamos $y \in \Omega$),
  \item o Sérgio Malandro abria uma porta $X'$ que não fosse a escolhida nem a premiada ($X' \distr U_{\Omega \setminus \{y, X\}}$)
  \item ao participante era dada a oportunidade de trocar sua porta $X$ pela porta restante em $\Omega \setminus \{X, X'\}$.
  \end{enumerate}
  Mostre que o participante sempre aumenta suas chances ao trocar sua escolha.
  Tente interpretar esse aparente paradoxo tomando o número de portas para infinito.
\end{exercise}

\begin{exercise}
  Emílio e Cristina tiveram dois filhos cujos sexos $X, X'$ são \iid e distribuidos como $U_{\{\male, \female\}}$.
  Calcule
  \begin{enumerate}[\quad a)]
  \item $P[X, X' = \male | \text{ pelo menos um é $\male$}]$ e
  \item $P[X, X' = \male | \text{ pelo menos um é $\male$ e nasceu em uma segunda-feira}]$.
  \end{enumerate}
  Interprete esses resultados trocando ``segunda-feira'' por ``primeiro de abril''.
  \footnote{Gratos ao Ricardo Misturini por sugerir esse problema}
\end{exercise}

\begin{exercise}
  Mostre que $P(\cdot|A|B) = P(\cdot|B|A)$.
\end{exercise}

\begin{exercise}
  Sejam $X, Y$ vari\'aveis aleat\'orias em um espaço $(\Omega, \mathcal{F}, P)$, independentes e com distribuição $U_{[0,1]}$.
  \begin{enumerate}[\quad a)]
  \item Calcule $(X+Y) \circ P$.
  \item Considere $P'(\cdot) = P\big(\cdot | X + Y \leq 1 \big)$ e calcule $X \circ P'$.
  \end{enumerate}
\end{exercise}

\subsection{Regra de Bayes}

Frequentemente definimos um espaço de probabilidade atravéz de probabilidades condicionais.
Consideramos por exemplo um exame médico para detectar uma doença, nesse caso temos
\begin{equation}
  \Omega = \{(\text{doente}, +), (\text{doente}, -), (\text{saudável}, +), (\text{saudável}, -)\},
\end{equation}
com obviamente a $\sigma$-álgebra das partes.

Contudo, ao contrário do que fizemos anteriormente, não daremos probabilidades $p_\omega \in [0,1]$ para cada $\omega \in \Omega$.
Poderíamos por exemplo fornecer
\begin{equation}
  \label{e:exame_medico}
  P(\text{doente}) = 0.005, \quad P( + | \text{saudável}) = 0.01, \quad P( - | \text{doente}) = 0.05.
\end{equation}
Obviamente podemos obter as probabilidades dos complementos dos eventos acima.
As probabilidades acima podem ser facilmente estimadas num laboratório e as duas últimas são chamadas respectivamente de probabilidades de \emph{falso positivo} e \emph{falso negativo}.
Outra vantagem da representação em \eqref{e:exame_medico} é que as probabilidades descritas são mais ``compartimentadas'' no seguinte sentido.
Note que $P(\text{doente})$ somente depende da população em questão, enquanto as outras duas dependem apenas do exame e não da população.
Isso não pode ser dito das probabilidades de pontos individuais em $\Omega$.

Agora fica fácil construir nosso espaço de probabilidade escrevendo, para $r \in \{+, -\}$ e $e \in \{\text{saudável}, \text{doente}\}$,
\begin{equation}
  P(r \cap e) = P(r | e) P(e).
\end{equation}
E as probabilidades do lado direito da equação acima estão todas determinadas em \eqref{e:exame_medico} (possivelmente tomando complementos).

Contudo, o que estamos interessado muitas vezes é em como interpretar resultados de um exame.
Por exemplo, quanto vele $P(\text{doente} | +)$?
Isso nos é fornecido em geral pela regra de Bayes enunciada na seguinte

\begin{proposition}
  Se $A_1, A_2, \dots$ formam uma partição (finita ou não) de $\Omega$ e $B \in \mathcal{F}$ tem probabilidade positiva, então
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{\sum_j P(A_j) P(B | A_j)}.
  \end{equation}
\end{proposition}

\begin{proof}
  Basta notar que
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{P(B)} = \frac{P(A_i) P(B | A_i)}{\sum_j P(B \cap A_j)} = \frac{P(A_i) P(B | A_i)}{\sum_j P(A_j) P(B | A_j)}.
  \end{equation}
\end{proof}

\begin{exercise}
  Utilize a fórmula acima para calcular $P(\text{doente} | +)$ com os dados em \eqref{e:exame_medico}.
  Comente o resultado.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 1, Ex: 18 e 19.
\end{exercise}

\todosec{Tópico: Distribuições de Extremos}{fazer...}

\todosec{Acoplamentos}{Talvez valha a pena escrever sobre acoplamentos de maneira geral. Talvez pegando algo do Pascal Massart. Vale a pena tentar escrever algo sobre: composiçao de acoplamentos, quando um acoplamento ``dá errado''...}

\section{Núcleos de transição}

Já focamos bastante energia em variáveis aleatórias independentes.
Por exemplo, estudamos em detalhes o que acontece com a soma de tais variáveis.
Agora passaremos a estudar elementos aleatórios dependentes e o primeiro passo para isso é obter um método geral de construí-los.

Definiremos agora um núcleo de transição.
Intuitivamente, ele nos dá um meio de usar um elemento aleatório em um espaço para induzir uma probabilidade em outro espaço.
Um exemplo em que poderíamos utilizar essa construção seria o seguinte.

Digamos que estamos preocupados com a possibilidade de um deslizamento de terra em uma determinada região.
A ocorrência desse deslizamento é algo aleatório, mas que certamente depende da quantidade de chuva no período, que também podemos modelar como sendo aleatória.

Após estudarmos alguns trabalhos anteriores, descobrimos uma função $F:\mathbb{R}_+ \to [0,1]$ que nos dá a probabilidade de um deslizamento como função da quantidade de chuva em milímetros.

Lendo o histórico pluvial na região, podemos estimar a distribuição $Q$ em $\mathbb{R}_+$ da quantidade de chuva que esperamos naquele período.
A lei $F \circ Q$ (também chamada de $Q_F$) é uma lei em $[0,1]$ que nos dá a distribuição da probabilidade de deslizamento, mas como seguimos em frente para obter a probabilidade de deslizamento (um número entre zero e um)?
Saberemos como fazer isso ao terminar essa seção.

Sejam $(E_1, \mathcal{A}_1)$ e $(E_2, \mathcal{A}_2)$ espaços mensuráveis.
\begin{definition}
  Um núcleo de transição entre $E_1$ e $E_2$ é uma função \index{nucleo de transicao@núcleo de transição}
  \begin{equation}
    K: E_1 \times \mathcal{A}_2 \to [0,1],
  \end{equation}
  tal que
  \begin{enumerate}[\quad a)]
  \item para todo $y \in E_1$, $K(y,\cdot)$ é uma probabilidade em $(E_2, \mathcal{A}_2)$ e
  \item para todo $A \in \mathcal{A}_2$, a função $K(\cdot, A): E_1 \to [0,1]$ é $\mathcal{A}_1$-mensurável.
  \end{enumerate}
\end{definition}

\begin{example}
  \label{x:chance_deslizamento}
  Daremos agora o exemplo da probabilidade de deslizamento como função de $F$ (que será possivelmente uma variável aleatória).
  Nesse caso, seja $E_1 = [0,1]$ e $E_2 = \{0,1\}$ com as $\sigma$-álgebras naturais e defina
  \begin{equation}
    K(p, A) = \big( (1-p)\delta_0 + p \delta_1 \big) (A).
  \end{equation}
\end{example}

Vamos verificar que $K$ definido acima é um núcleo.
De fato,
\begin{enumerate}[\quad i)]
\item $K(p, \cdot)$ é a distribuição Bernoulli com parâmetro $p$, que obviamente é uma probabilidade,
\item além disso, $K(\cdot, \{0\}) = 1-p = 1 - K(\cdot,\{1\})$, que obviamente é mensurável.
Isso prova que esse $K$ específico é um núcleo
\end{enumerate}

\begin{example}[Discreto]
  \label{x:nucleo_discreto}
  Seja $E_1 = \{y_i\}_{i \geq 1}$ e $E_2 = \{z_j\}_{j \geq 1}$.
  Se $p: E_1 \times E_2 \to [0,1]$ é tal que para todo $y \in E_1$ temos $\sum_{j} p(y, z_j) = 1$, então
  \begin{equation}
    K(y, A) := \sum_{j \in A} p(y, z_j) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Nesse caso $p(y,z)$ representa a probabilidade que a segunda coordenada seja $z$, se a primeira é $y$.
\end{example}

\begin{exercise}
  Mostre que se $E_1$ e $E_2$ são enumeráveis então todo núcleo entre $E_1$ e $E_2$ pode ser escrito na forma do exemplo acima.
\end{exercise}

\begin{example}[Absolutamente contínuo]
  Digamos que $E_1$ e $E_2$ sejam dotados de medidas $\mu_1$ e $\mu_2$ $\sigma$-finitas.
  Seja $\rho: E_1 \times E_2 \to \mathbb{R}_+$ mensurável e tal que para $\mu_1$-quase todo $y \in E_1$, tenhamos que $\int_{E_2} \rho(y, z) \mu_2(\d z) = 1$.
  Então
  \begin{equation}
    K(y, A) := \int_A \rho(y, z) \mu_2(\d z) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Note que $K(\cdot, A)$ está bem definido para $\mu_2$-quase todo ponto por Fubini.
\end{example}

\begin{exercise}
  Prove que os dois exemplos acima de fato definem um núcleo.
\end{exercise}

Tipicamente, definimos os núcleos de transição introduzindo $K(y, \cdot)$ como sendo uma medida que depende de $y$.
Nesse caso, uma das condições para que $K$ seja um núcleo está automaticamente satisfeita, restando apenas mostrar que $K(\cdot, A)$ é mensurável para quaisquer $A \in \mathcal{A}_2$.
Mas obviamente o conjunto $\mathcal{A}_2$ pode ser muito complexo, então gostaríamos de apenas verificar que $K(\cdot, A)$ é mensurável para os conjuntos $A$ em uma classe rica o suficiente.

\begin{proposition}
  \label{p:K_nucleo_na_classe}
  Seja $K:E_1 \times \mathcal{A}_2 \to [0,1]$, tal que $K(y, \cdot)$ é uma medida para todo $y \in E_1$.
  Se $K(\cdot, A)$ é mensurável para dodo $A \in \mathcal{G}$, onde $\mathcal{G}$ é um $\pi$-sistema que gera $\mathcal{A}_2$, então $K$ é um núcleo de transição.
\end{proposition}

\begin{proof}
  Como de costume, vamos definir
  \begin{equation}
    \mathcal{B} = \{B \in \mathcal{A}_2; K(\cdot, B) \text{ é $\mathcal{A}_1$-mensurável}\}.
  \end{equation}
  Obviamente, como $K(y, \cdot)$ é uma probabilidade, vale que
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{B}$, pois a função constante igual a um é mensurável.
  \item Se $B \in \mathcal{B}$, então $B^c \in \mathcal{B}$, pois $1 - f$ é mensurável se $f$ o é.
  \item E se $B_1, B_2, \dots \in \mathcal{B}$ são disjuntos, então $\cup_i B_i \in \mathcal{B}$, pois a soma de funções mensuráveis também é mensurável.
  \end{enumerate}

  A discussão acima mostra que $\mathcal{B}$ é um $\lambda$-sistema que contém o $\pi$-sistema $\mathcal{G}$.
  Daí, vemos que $\mathcal{A}_2 = \sigma(\mathcal{G}) \subseteq \mathcal{B}$, provando a proposição.
\end{proof}

\begin{exercise}
  Seja $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por $K(y, \cdot) = U_{[y - 1,y + 1]}$.
  Mostre que $K$ define um núcleo de transição.
\end{exercise}

Apesar de interessante, a definição acima ainda não nos permitiu definir espaços de probabilidade novos.
Isso será possibilitado pelo próximo resultado, que pode ser visto como uma generalização do Teorema de Fubini.

\chooseoptpar{
\begin{theorem}[Fubini para Núcleos de Transição]
  \index{Teorema!de Fubini para Nucleos@de Fubini para Núcleos}
  \label{t:fubini}
  Dado um núcleo \opt{}{de transição} $K$ de $(E_1, \mathcal{A}_1)$ para $(E_2, \mathcal{A}_2)$ e uma probabilidade $P_1$ em $E_1$, existe uma única probabilidade $P$ em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$ tal que
  \begin{equation}
    \label{e:fubini}
    \int_{E_1 \times E_2} f dP = \int_{E_1} \int_{E_2} f(y,z) K(y, \d z) P_1 (\d y),
  \end{equation}
  para toda $f:E_1 \times E_2 \to \mathbb{R}_+$.
  Em particular, $P(A_1 \times A_2) = \int_{A_1} K(y, A_2) P_1 (\d y)$.
  Nesse caso escrevemos $P = P_1 \star K$.
\end{theorem}
}

Antes de iniciar a prova do teorema, vamos ver que as integrais do lado direito de \eqref{e:fubini} estão bem definidas.
Para isso, definimos para $y \in E_1$ a função fatiadora $\phi_y: E_2 \to E_1 \times E_2$ dada por $\phi_y(z) = (y, z)$.
Obviamente essa função é mensurável, pois
\begin{equation}
  \phi^{-1}(A_1 \times A_2) =
  \begin{cases}
    \varnothing, \quad & \text{ se $y \not \in A_1$ e}\\
    A_2, & \text{ se $y \in A_1$}.
  \end{cases}
\end{equation}
Dessa forma, para definirmos $\int f(y,z) K(y, \d z)$, introduzimos $f_y: A_2 \to \mathbb{R}_+$ dada por $f(z) = f(y,z)$, que é mensurável pois $f_y = f \circ \phi_y$.

Assim, a integral que gostaríamos de definir se torna $\int f_y(z) K(y, \d z)$, que está obviamente bem definida.
Porém resta a pergunta, será que essa expressão define uma função mensurável de $y$?

\begin{lemma}
  Se $K$ é um núcleo de transição, então para toda $f: E_1 \times E_2 \to \mathbb{R}_+$ que seja $\mathcal{A}_1 \otimes \mathcal{A}_2$ mensurável, temos que $g^f:A_1 \to \mathbb{R}_+$ dada por
  \begin{equation}
    g^f(y) = \int f_y(z) K(y, \d z)
  \end{equation}
  é $\mathcal{A}_1$-mensurável.
\end{lemma}

\begin{proof}
  Se $f = \1_{A_1 \times A_2}$ para $A_i \in \mathcal{A}_i$, $i = 1,2$, então temos que $g^f(y) = K(y, A_2) \1_{A_1}$, que obviamente é mensurável pois $K$ é um núcleo.

  Definimos $\mathcal{D} = \{B \in \mathcal{A}_1 \otimes \mathcal{A}_2; g^{\1_B} \text{ é $\mathcal{A}_1$-mensurável}\}$.
  É fácil ver que $\mathcal{D}$ é um $\lambda$-sistema que contém o $\pi$-sistema dos retângulos, logo $\mathcal{D} = \mathcal{A}_1 \otimes \mathcal{A}_2$.

  Acabamos de ver que $g^f$ é mensurável para toda $f$ indicadora, donde o mesmo vale para $f$ simples por linearidade e para toda $f$ positiva pelo Teorema da Convergência Monótona (lembre que limite de funções mensuráveis é mensurável).
\end{proof}

Estamos prontos agora para fornecer a
\begin{proof}[Demonstração do Teorema~\ref{t:fubini}]
  Já sabemos que a integral do lado direito de \eqref{e:fubini} está bem definida (assumindo possivelmente o valor infinito).
  A unicidade vale obviamente pois a probabilidade de conjuntos do tipo $A_1 \times A_2$ definem $P$ de maneira inequívoca.


  Só nos resta mostrar que
  Isto é
  \begin{equation}
    P(B) = \int_{E_1} \int_{E_2} \1_{B} K(y, \d z) P_1 (\d y),
  \end{equation}
  nos define uma probabilidade em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$.

  De fato,
  \begin{enumerate}[\quad a)]
  \item $P(\Omega) = \int_{E_1} \int_{E_2} 1 K(y, \d z) = 1$ obviamente e
  \item se $B_1, B_2, \dots \in \mathcal{A}_1 \otimes \mathcal{A}_2$ são disjuntos, então definimos $f^i = \1_{B_i}$ e $f = \sum_i f^i$ e observamos o seguinte.
    A função fatiadora $f_y$ é igual a $\sum_i f^i_y$, donde
    \begin{equation}
      \begin{split}
        P(B) & = \int_{E_1} \int_{E_2} f_y(z) K(y, \d z) P_1(\d y)\\
        & = \int_{E_1} \sum_i \int_{E_2} f^i_y(z) K(y, \d z) P_1(\d y) = \sum_i P(B).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que demonstra o teorema.
\end{proof}

\begin{exercise}
  Considere duas probabilidades $P_i$ em $(E_i, \mathcal{A}_i)$ para $i = 1,2$ e $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dado por $K(y,A) = P_2(A)$.
  Mostre que $K$ é núcleo e que $P_1 \star K = P_1 \otimes P_2$.
  Relacione esse resultado ao Teorema de Fubini clássico para produtos de medidas.
\end{exercise}

\begin{exercise}
  Considere o núcleo do Exemplo~\ref{x:chance_deslizamento} e calcule:
  \begin{enumerate}[\quad a)]
  \item $U_{[0,1]} \star K [X_2 = 1]$,
  \item $P_1 \star K [X_2 = 1]$, onde $\d P_1 = 2x \d x$ e
  \item encontre a distribuição de $X_1 \circ \big( U_{[0,1]} \star K [\; \cdot \; | X_2 = 1] \big)$. Interprete o resultado.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Seja $P = P_1 \star K$ como acima e $Q(\cdot) = P[\cdot | X_2 = 1]$.
  Calcule
  \begin{equation}
    \int_{[0,1] \times \{0,1\}} X_1 \d Q
  \end{equation}
\end{exercise}

\begin{exercise}
  Considere $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dada por $K(p, \cdot) = \Exp(p)$.
  Mostre que $K$ é núcleo de transição e calcule $U_{[0,1]}[X_2 > 1] \star K$.
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $E_2$ e $\{y\} \in \mathcal{A}_1$ satisfaz $P_1(\{y\}) > 0$, mostre que
  \begin{equation}
    P_1 \star K [X_2 \in \cdot | X_1 = y] = K(y, \cdot).
  \end{equation}
  Ou em outras palavras, $K$ nos dá a distribuição condicional de $X_2$ dado $X_1 = y$.
\end{exercise}

Posteriormente extenderemos o resultado acima para o caso $P_1(\{y\}) = 0$, mas isso demandará algum esforço.

Vamos introduzir uma última notação com respeito a núcleos de transição.
Muitas vezes, não estamos interessados na distribuição conjunta de $P_1 \star K$ em $E_1 \times E_2$, mas apenas na distribuição marginal da segunda coordenada.
No nosso problema da chuva por exemplo, talvez poderíamos estar interessados apenas na probabilidade final de ocorrer um desmoronamento.
Nesse caso, é conveniente escrever
\begin{equation}
  \label{e:P1_K}
  P_1 K := X_2 \circ (P_1 \star K).
\end{equation}

\begin{exercise}
  Seja $K:\mathbb{R}_+ \times \mathbb{B}(\mathbb{R}_+) \to [0,1]$ dada pela equação $K(x,A) = \int_A x \exp\{-x t\} \d t$.
  \begin{enumerate}[\quad a)]
  \item Prove que $K$ \'e um n\'ucleo de transi\c{c}\~ao.
  \item Seja $P$ dada por $P = K \star \textnormal{Exp}(1)$.
    Obtenha $P[X_2 > x_2]$ para todo $x_2 \geq 0$ (lembrando que $X_2$ denota a segunda coordenada no espa\c{c}o produto onde est\'a definida $P$).
    Compare a probabilidade acima com $K(1,[x_2, \infty))$.
  \item Mostre que $P[X_1 + X_2 \geq z] = \int_0^z \exp \{-x(z-x+1)\} \d x + \exp\{-z\}$.
  \end{enumerate}
\end{exercise}

\section{Espaços canônicos}

Em várias áreas da matemática, existe um importante conceito de equivalência entre duas estruturas, como por exemplo: homeomorfismos, isometrias e isomorfismos.
Nessa seção estudaremos o caso análogo para espaços mensuráveis, que nos trará uma grande surpresa.

\begin{definition}
  Uma função $\phi:E \to E'$ entre dois espaços mensuráveis é dita bi-mensurável \index{bi-mensuravel@bi-mensurável} quando $\phi$ é mensurável e injetiva, $\phi(E)$ for mensurável e a sua inversa $\phi^{-1}:f(E) \to E$ também for mensurável.
\end{definition}

Ao tentar classificar espaços mensuráveis à partir da possibilidade de que possam ser imersos bi-mensuravelmente em outros, descobrimos que uma classe apenas inclui praticamente todos os espaços que podemos estar interessados.

\begin{definition}
  Dizemos que o espaço mensurável $(E, \mathcal{A})$ é canônico \index{espaco@espaço!canonico@canônico} se existe uma função $\phi: E \to \mathbb{R}$ bi-mensurável.
\end{definition}

Antes de mostrar que essa classe de espaços canônicos inclui muitíssimos exemplos, vamos motivar a definição acima atravéz do seguinte.

\begin{theorem}[Extensão de Kolmogorov Extendida]
  \index{Teorema!da Extensao de Kolmogorov@da Extensão}
  Se $E_1, E_2, \dots$ espaços mensuráveis canônicos, então o Teorema~\ref{t:extens_kolmog} (da extensão de Kolmogorov) também é válido no espaço produto $\Omega = E_1 \times E_2 \times \dots$ se a condição de consistência \eqref{e:consist_kolmog} for válida com $I_j$ substituídos por eventos quaiquer em $E_j$.
\end{theorem}

\begin{proof}
  Sejam $\phi_i: E_i \to \mathbb{R}$ bijeções bi-mensuráveis e defina $\psi_n: E_1 \times \dots \times E_n \to \mathbb{R}^n$ por $\psi_n(\omega_1, \dots, \omega_n) = \big(\phi_1(\omega_1), \dots, \phi_n(\omega_n)\big)$.
  Assim podemos introduzir as medidas de probabilidade
  \begin{equation}
    \bar{P_n} = \psi_n \circ P_n, \text{ em $\mathbb{R}^n$}.
  \end{equation}
  É fácil verificar que as $\bar P_n$ são consistentes como em \eqref{e:consist_kolmog}.
  Logo, existe $\widebar{P}$ em $(\mathbb{R}^\mathbb{N}, \mathcal{F})$ extendendo $\bar{P_n}$.

  Finalmente, consideramos o mapa $\Phi: \times_{i=1}^\infty \phi_i(E_i) \to \Omega$ dado por
  \begin{equation}
    \Phi(\phi_1(\omega_1), \phi_2(\omega_2), \dots) = (\omega_1, \omega_2, \dots).
  \end{equation}
  Resta mostrar que a medida $P = \Phi \circ \widebar{P}$ extende as probabilidades $P_n$:
  \begin{equation}
    \begin{split}
      P\big(A_1 \times \dots & \times A_n \times E_{n+1} \times \dots\big) = \widebar{P} \big(\Phi^{-1}(A_1 \times \dots \times A_n \times E_{n+1} \times \dots)\big)\\
      & = \widebar{P} \big( \phi_1(A_1) \times \dots \times \phi_n(A_n) \times \phi_{n+1}(E_{n+1}) \times \dots \big)\\
      & = \widebar{P}_n (\phi_1(A_1) \times \dots \times \phi_n(A_n))\\
      & = P_n \big(\psi_n^{-1}\big(\phi_1(A_1) \times \dots \times \phi_n(A_n)\big)\big) = P_n(A_1 \times \dots \times A_n),
    \end{split}
  \end{equation}
  concluindo a prova do teorema.
\end{proof}

A seguir daremos um exemplo de espaço canônico que é importante para a seção seguinte.

\begin{lemma}
  \label{l:NN_canonico}
  O espaço produto $E = \mathbb{N} \times \mathbb{N} \times \dots$, dotado da $\sigma$-álgebra produto é canônico.
\end{lemma}

\begin{proof}
  Primeiramente definimos em $E$ a métrica de Hamming:
  \begin{equation}
    \label{e:hamming_distance}
    d(x,y) = \sum_{i \geq 1} \frac{1}{2^{i + 1}} \1_{x_i \neq y_i}.
  \end{equation}
  Fica como exercício mostrar que a $\sigma$-álgebra dos borelianos induzida por essa métrica coincide com a $\sigma$-álgebra produto em $E$.
  Definimos agora o mapa $\phi:E \to \mathbb{R}$ dado por
  \begin{equation}
    \phi(n_1, n_2, \dots) = 2^{-n_1} + 2^{-1 - n_1 - n_2} + \dots + 2^{-n - \sum_{i=1}^n n_i} + \dots
  \end{equation}
  Também deixamos a cargo do leitor mostrar que $\phi$ define um homeomorfismo entre $(E,d)$ e um boreliano de $\mathbb{R}$.
\end{proof}

\subsection{Espaços poloneses}

Nessa seção mostraremos que uma grande coleção de espaços conhecidos são canônicos.

\begin{definition}
  Um espaço métrico $(E,d)$ é dito polonês \index{espaco@espaço!polones@polonês} se é separável e completo.
\end{definition}

\begin{example} \mbox{}
  \begin{enumerate}[\quad a)]
  \item Todo espaço enumerável $\Omega$ pode ser feito em um espaço métrico polonês de forma que a $\sigma$-álgebra de Borel seja $\mathcal{P}(\Omega)$.
  \item $\mathbb{R}^n$ e $C([0,1])$ são notoriamente poloneses.
  \end{enumerate}
\end{example}

\begin{exercise}
  Se $(E_i, d_i)$ são espaços métricos poloneses para $i = 1, 2, \dots$, mostre que $E = \bigtimes_i E_i$ com a métrica
  \begin{equation}
    \label{e:metrica_produto}
    d(x,y) = \sum_i \frac{1}{2^{i+1}} \frac{d_i(x_i, y_i)}{1 + d_i(x_i, y_i)}
  \end{equation}
  também é polonês.
  Mostre também que a topologia induzida por essa métrica é equivalente à topologia produto em $E$.
\end{exercise}

Outros exemplos de espaços poloneses são dados pelo seguinte lema, que também será útil para provar o resultado principal desta seção.

\begin{lemma}
  \label{l:sub_polones}
  Seja $(E,d)$ um espaço polonês e $G, F \subseteq E$ um aberto e um fechado de $E$ respectivamente.
  Então, existe uma métrica $d'$ em $F \cap G$ tal que
  \begin{enumerate}[\quad a)]
  \item $d$ e $d'$ são equivalentes (induzem a mesma noção de convergência),
  \item $d(x,y) \leq d'(x,y)$ para todo $x, y \in F \cap G$ e
  \item $(F \cap G, d')$ é polonês.
  \end{enumerate}
\end{lemma}

\begin{proof}
  A primeira observação simple é que $F \cap G$ é separável com respeito a $d$.
  Isso segue do fato de separabilidade ser equivalente à existência de uma base enumerável.

  Vamos definir em $G \times G$
  \begin{equation}
    d'(x,y) = d(x,y) + \Big| \frac{1}{d(x,G^c)} - \frac{1}{d(y,G^c)} \Big|,
  \end{equation}
  onde $d(x,A) = \inf\{d(x,x'); x' \in A\}$.

  Não é difícil ver que com a definição acima (e deixamos como exercício) que
  \begin{enumerate}[\quad a)]
  \item as métricas $d$ e $d'$ são equivalentes em $G$,
  \item $F \cap G$ é separável quando dotado da métrica $d'$,
  \item $(F \cap G, d')$ é completo.
  \end{enumerate}
  Isso termina a prova do lema.
\end{proof}

\begin{example}
  Um importante exemplo é dado por espaços produto.
  Sejam $(E_i, d_i)$ espaços poloneses para $i \geq 1$ e introduza em $E = \times_i E_i$ a métrica $d$ definida em \eqref{e:metrica_produto}.
  Então, se $A_1 \subseteq E_1$, $\dots$, $A_k \subseteq E_k$ forem abertos, o retângulo $R = A_1 \times \dots \times A_k \times E_{k+1} \times \dots$ é aberto.
  Dessa forma vemos que tanto $R$ como $R^c$ podem ser dotados de métricas com as quais se tornam espaços poloneses.
  Além disso tais métricas podem ser escolhidas satisfazendo as hipóteses do Lema~\ref{l:sub_polones}
\end{example}

\begin{lemma}
  \label{l:particao_polones}
  Seja $(E, d)$ um espaço polonês e $r > 0$.
  Então existe uma partição $A_0, A_1, \dots$ de $A$ e métricas $d_0, d_1, \dots$ nesses respectivos subconjuntos de forma que para todo $i \geq 0$,
  \begin{enumerate}[\quad a)]
  \item $(A_i, d_i)$ são espaços poloneses disjuntos,
  \item $d_i$ e $d$ são equivalentes em $A_i$ e $d_i \geq d$ e finalmente
  \item o diâmetro de $A_i$ (com respeito a $d$) é menor ou igual a $r$.
  \end{enumerate}
  Observe que alguns (possivelmente infinitos) $A_i$ podem ser vazios.
\end{lemma}

\begin{proof}
  Obtemos atravéz da separabilidade de $E$, uma coleção de bolas $(B_i)_{i \geq 0}$ com diâmetros limitados por $r$ e cobrindo $E$.
  Então definimos
  \begin{equation}
    A_0 = B_0, \quad \text{e} \quad A_n = B_n \setminus \mcup_{i=0}^{n-1} B_i \quad \text{para $n \geq 1$.}
  \end{equation}

  Agora podemos dotar cada um dos $A_i$ com a métrica $d_i$ obtida atravéz do Lema~\ref{l:sub_polones} (observe para tanto que os $A_i$ são dados por interseções de um aberto com um fechado).
  As propriedades enunciadas no lema são trivialmente satisfeitas.
\end{proof}

\begin{theorem}
  Todo espaço polonês $(E, d)$ é canônico.
\end{theorem}

\begin{proof}
  Pelo Lema~\ref{l:NN_canonico}, basta construir uma função bi-mensurável $\phi:E \to \mathbb{N}^\mathbb{N}$ e depois compô-la com uma função bi-mensurável $\phi':\mathbb{N}^\mathbb{N}$.

  Para começar, construiremos uma partição encaixada de $E$.
  Mais precisamente, defina os conjuntos de índice
  \begin{equation}
    M_n = \mathbb{N}^n \quad \text{para $n \geq 1$ e} \quad M = \cup_n M_n.
  \end{equation}

  Vamos definir borelianos $A_m$ de $E$ e métricas $d_m$ em $A_m$ para cada $m \in M$.
  Faremos isso da seguinte forma:
  \begin{enumerate}[\quad a)]
  \item se $m = i \in M_1$, então definimos $A_1, A_2, A_3, \dots$ e $d_1, d_2, d_3, \dots$ como no Lema~\ref{l:particao_polones} com $r = 1$,
  \item se $(A_m, d_m)$ já foi definido para algum $m \in I_n$, então utilizamos também o Lema~\ref{l:particao_polones} com $r = 1/n$ para particionar o conjunto $A_m$ (com a métrica $d_m$) em $A_{(m,1)}, A_{(m,2)}, \dots$ com suas respectivas métricas $d_{(m,1)}, d_{(m,2)}, \dots$
  \end{enumerate}
  Obviamente suporemos que são válidas as propriedades de tais métricas garantidas pelo Lema~\ref{l:particao_polones}.

  Podemos desde já definir $\phi:E \to \mathbb{N}^\mathbb{N}$ e para tanto, considere $x \in E$.
  Indutivamente
  \begin{enumerate}[\quad a)]
  \item como $\{A_m\}_{m \in M_1}$ formam uma partição de $E$, definimos $\phi_1(x)$ como o único índice tal que $x \in A_{\phi_1(x)}$,
  \item se já encontramos $\phi_1(x), \dots, \phi_n(x)$ tal que $x \in A_{(\phi_1(x), \dots \phi_n(x))}$, então o fato que particionamos o último conjunto na definição de $A_m$, $m \in M_{n+1}$ nos garante que podemos definir unicamente $\phi_{n+1}(x)$ de forma a continuar a indução.
  \end{enumerate}
  Da maneira acima já obtivemos $\phi(x) = (\phi_1(x), \phi_2(x), \dots)$.

  Para terminar, devemos mostrar que $\phi$ é bi-mensurável.

  Isso começa com a prova de que $\phi$ é injetiva.
  Se $\phi(x) = \phi(y)$, então existe uma sequência $m_n \in M_n$ tal que $x, y \in A_{m_n}$ para todo $n$.
  Mas isso não é possível dado que o diâmetro de $A_{m_{n+1}}$ é menor ou igual a $1/n$ na métrica $d_{m_n} \geq d$.
  Isso mostra que $x = y$.

  Vejamos agora que $\phi$ é mensurável.
  %Lembramos que em $\mathbb{N}^\mathbb{N}$ colocamos a métrica de Hamming definida em \eqref{e:hamming_distance}).
  Seja $w \in \mathbb{N}^\mathbb{N}$ tal que $\phi(x) = w$ e tome $G \subseteq \mathbb{N}^\mathbb{N}$ com $G = \{(w_1, \dots, w_l)\} \times \mathbb{N}^\mathbb{N}$ (esses conjuntos geram a $\sigma$-álgebra canônica em $\mathbb{N}^\mathbb{N}$).
  Claramente, $\phi^{-1}(G) = A_{(\phi_1(x), \dots, \phi_l(x))}$, de forma que mostramos que $\phi$ é mensurável.

  Para mostrar que $\phi^{-1}:\phi(E) \to E$ é mensurável, veremos que ela é de fato contínua.
  Dado $n \geq 1$, tomamos $\delta < 2^{-n}$.
  Se $w, w' \in \phi(E)$ são tais que $d(w, w') < \delta$ em $\mathbb{N}^\mathbb{N}$, então $w_i = w'_i$ para todo $i \leq n$, de forma que $\phi^{-1}(w)$ e $\phi^{-1}(w')$ pertencem a $A_{(w_1, \dots, w_n)}$.
  A continuidade de $\phi^{-1}$ segue do fato que o diâmetro de $A_{(w_1, \dots, w_n)}$ é no máximo $1/n$ (com respeito a $d_{(w_1, \dots, w_n)}$ e portanto com respeito a $d$).

  Vale lembrar que precisamos mostrar que $\phi(E)$ é mensurável.
  Para tanto, afirmamos que
  \begin{equation}
    \label{e:phiE_mensur}
    \phi(E) = \mathbb{N}^\mathbb{N} \setminus \mcup_{w_1, \dots, w_k} \{w_1\} \times \{w_k\} \times \mathbb{N} \times \dots,
  \end{equation}
  onde a união acima é tomada sobre todos $k \geq 1$ e $w_1, \dots, w_k$ tais que $A_{w_1, \dots, w_k}$ é vazio.
  A igualdade acima implica a mensurabilidade de $\phi$ instantaneamente.

  Dado $w \in \phi(E)$ existe $x \in E$ tal que $\phi(x) = w$.
  Como $x \in A_{w_1, \dots, w_n}$ para todo $n \geq 1$, esses conjuntos não são vazios.
  Logo $w$ não pertence à união em \eqref{e:phiE_mensur}, mostrando o lado ($\subseteq$) da inclusão.
  Finalmente, suponha que $w = (w_1, w_2, \dots)$ é tal que para todo $k \geq 1$, $A_{w_1, \dots, w_k} \neq \varnothing$.
  Tomamos portanto $x_k \in A_{w_1, \dots, w_k}$, com $k \geq 1$ e vamos mostrar que
  \begin{equation}
    \text{$(x_k)_{k \geq n}$ é Cauchy em $A_{w_1, \dots, w_n}$ para todo $n$.}
  \end{equation}
  De fato, dado $n \geq 1$, temos que, para todo $k \geq n + 1$, $x_k \in A_{w_1, \dots, w_{n+1}}$ (cujo $d_{w_1, \dots, w_{n}}$-diâmetro é menor que $1/n$), logo $x_k$ é uma sequência de Cauchy em $A_{w_1, \dots, w_n}$ com sua respectiva distância.
  Tomamos $x = \lim_n x_k$ com respeito à distância $d$ e para terminar a prova do teorema, basta motrar que $\phi(x) = w$, ou em outras palavras,
  \begin{equation}
    \label{e:x_in_Aw}
    x \in \mcap_n A_{w_1, \dots, w_n}, \text{ para todo $n \geq 1$.}
  \end{equation}
  Mas claramente
  \begin{enumerate}[\quad a)]
  \item $x \in A_\varnothing = E$ e
  \item se $x \in A_{w_1, \dots, w_n}$, então como $x_k$ é Cauchy em $A_{w_1, \dots, w_{n+1}}$, temos que $x_k$ converge a um certo $x' \in A_{w_1, \dots, w_{n+1}}$ na métrica $d_{w_1, \dots, w_{n+1}}$.
    Como essa métrica é equivalente a tanto $d_{w_1, \dots, w_n}$ quanto $d$ em $A_{w_1, \dots, w_n}$, temos que $x = x' \in A_{w_1, \dots, w_n}$.
  \end{enumerate}
  Isso conclui por indução a prova de \eqref{e:x_in_Aw} e consequentemente do teorema.
\end{proof}

Terminamos essa seção com esse importante corolário, que confirma nossa afirmação de que quase todos os espaços mensuráveis que podemos nos interessar são canônicos.
\begin{corollary}
  \label{c:borel_de_polones}
  Se $(E, d)$ é um espaço polonês e $B \in \mathcal{B}(E)$, então $(B, d)$ é canônico.
\end{corollary}

\begin{proof}
  Seja $\phi: E \to \mathbb{R}$ a função bi-mensurável que mostra que $E$ é polonês.
  Consideramos $\phi': B \to \mathbb{R}$ dada pela restrição de $\phi$ a $B$ e precisamos mostrar as seguintes afirmativas:
  \begin{enumerate}[\quad a)]
  \item $\phi'$ é injetiva
  \item $\phi'$ é mensurável
  \item $\phi'(B)$ é mensurável e
  \item a inversa $\psi': \phi'(B) \to B$ é mensurável.
  \end{enumerate}
  Vejamos,
  \begin{enumerate}[\quad a)]
  \item $\phi$ ser injetiva implica que $\phi'$ também o é.
  \item dado $A \in \mathcal{B}(R)$, $\phi'^{-1}(A) = B \cap \phi^{-1}(A) \in \mathcal{B}(B)$.
  \item denotando por $\psi: \phi(E) \to E$ a inversa de $\phi$ em sua imagem, temos que $\phi(B) = \psi^{-1}(B) \in \mathcal{B}(\mathbb{R})$ pois $\psi$ é mensurável e
  \item finalmente, se $D \in \mathcal{B}(B)$, então $\psi'^{-1}(D) = \psi^{-1}(D) \in \mathcal{B}(\mathbb{R})$, novamente pela mensurabilidade de $\psi$.
  \end{enumerate}
  Concluindo portanto a bi-mensurabilidade de $\phi'$.
\end{proof}

\vfill
\newpage

\subsection{Tópico: Cadeias de Markov}

Um exemplo de como usar núcleos de transição é a construção de Cadeias de Markov.
Esse tipo de processo é bastante útil em diversas aplicações, desde a biologia até a computação.

Considere um espaço mensurável canônico fixo $(E, \mathcal{A})$ e seja $K$ um núcleo de $E$ nele mesmo.
Seria bastante intuitivo agora iterar $K$ (já que ele está no mesmo espaço) e obter uma medida em $\Omega = \times_{i=1}^\infty E$ com a $\sigma$-álgebra canônica.

Para começar esse procedimento, seja $\mu_0$ uma medida inicial em $(E, \mathcal{A})$.
Podemos então definir $\mu_1 = \mu_0 \star K$ o que é o primeiro passo da nossa construção, porém observe que não podemos escrever ``$\mu_2 = \mu_1 \star K$'', pois $\mu_1 \star K$ é uma medida em $(E^2, \mathcal{A}^{\otimes 2})$.
Vamos com calma então.

Observe que
\begin{equation}
  \mu_1(A_0 \times A_1) = \int_{A_0} \int_{A_1} K(x_0, \d x_1) \mu_0(\d x_0),
\end{equation}
ou em outras palavras o valor de $x_0$ determina a distribuição de $x_1$.
Gostaríamos agora que $x_1$ determinasse a distribuição de $x_2$ via $K$, como por exemplo assim
\begin{equation}
  \mu_2(A_0 \times A_1 \times A_2) = \int_{A_0} \int_{A_1} \int_{A_2} K(x_1, \d x_2) K(x_0, \d x_1) \mu_0 (\d x_0).
\end{equation}
Mas essa notação é bastante carregada à medida que iteramos.

Para tornar essa notação mais simples, definimos a projeção $\phi_n:E^n \to E$ por $\phi_n(x_0, \dots, x_{n-1}) = x_{n-1}$.
Também precisamos de $K_n: E^n \times \mathcal{A} \to [0,1]$ dado por
\begin{equation}
  K_n(\vec{x},A) = K\big(\phi_n(\vec{x}), A\big) \quad \big(= K(x_{n-1}),A) \big).
\end{equation}
O fato de $K_n$ ser um núcleo de transição segue imediatamente dessa propriedade para $K$.

Note que, nessa notação, estamos dizendo que para irmos de $E^n$ para $E^{n+1}$ iremos olhar apenas para a última coordenada, na qual aplicaremos o núcleo $K$.
Isso é o ponto mais importante que caracteriza uma Cadeia de Markov: a distribuição do estado futuro da cadeia depende apenas do estado atual e não do passado.
Em alguns contextos essa propriedade é chamada de ausência de memória.

Podemos finalmente definir
\begin{equation}
  \label{e:Pn_Markov}
  \mu_{n+1} = \mu_n \star K^n, \text{ para todo $n \geq 1$}.
\end{equation}
Mas resta a questão sobre a existência de uma $\mu^\infty$ que será respondida com ajuda do próximo

\begin{lemma}
  As probabilidades $\mu_n$ definidas em \eqref{e:Pn_Markov} são compatíveis, mais precisamente $\mu_{n+1}(A \times E) = \mu_n(A)$ para todo $A \in \mathcal{A}^{\otimes n}$.
\end{lemma}

\begin{proof}
  Basta observar que
  \begin{equation}
    \mu_{n+1}(A \times E) = \mu_n \star K (A \times E) = \int_{A} \underbrace{K_n (\vec{x}, E)}_1 \mu_n(\d \vec{x}) = \mu_n(A).
  \end{equation}
  Provando o lema.
\end{proof}

Logo, o Teorema da Extensão de Kolmogorov (lembre que $(E, \mathcal{A})$ foi suposto canônico) nos fornece uma única $P$ em $(\Omega, \mathcal{F})$ tal que
\begin{equation}
  (X_0, \dots, X_n) \circ P = \mu_n, \text{ para todo $n \geq 0$}.
\end{equation}
Lembramos que $X_i$ denotam as projeções canônicas em $\Omega = \times_{i=1}^\infty E$.

Chamamos o processo $X_1, X_2, \dots$ sob a lei $P$ de Cadeia de Markov \index{Cadia de Markov} com distribuição inicial $\mu_0$ e núcleo de transição $K$.

\begin{example}
  Suponha que $E$ seja enumerável.
  Nesse caso recordamos do Exemplo~\ref{x:nucleo_discreto} que o núcleo pode ser representado por uma matriz $\big(p(x,y)\big)_{x,y \in E}$ que nos retorna a probabilidade de saltar de $x$ a $y$.
  Além disso, a distribuição inicial $\mu_0$ é determinada por $P(\{x\}) = p_0(x)$, para alguma sequência $\big(p_0(x)\big)_{x \in E}$.
\end{example}

\begin{exercise}
  Mostre que no exemplo acima temos
  \begin{equation}
    P(X_0 = x_0, \dots, X_n = x_n) = p_0(x_0) p(x_0, x_1) \dots p(x_{n-1}, x_n).
  \end{equation}
\end{exercise}

\begin{exercise}
  Defina $K:\mathbb{R}^2 \times \mathcal{B}(\mathbb{R}^2) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) = U_{S^1}(A - x).
  \end{equation}
  Nesse contexto,
  \begin{enumerate}[\quad a)]
  \item mostre que $K$ é um núcleo de transição e,
  \item considerando a cadeia com distribuição inicial $\mu_0 = \delta_0$ em $\mathbb{R}^2$ e núcleo $K$, mostre que $X_2$ tem distribuição absolutamente contínua com respeito a Lebesgue e calcule sua densidade.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Mostre que para qualquer núcleo de transição $K$ entre $E$ e $E$, existe um núcleo de transição $\bar K$ entre $E$ e $\Omega = \prod_{i=1}^\infty$, tal que para toda medida inicial $\mu_0$, temos que $\mu_0 \star K$ é a distribuição de uma Cadeia de Markov começando de $\mu_0$ e com transição dada por $K$.
  Esse núcleo é útil se quisermos mudar a distribuição inicial $\mu_0$ e uma notação bastante comum para esse núcleo é $P_{x}(\cdot) = \bar K(x, \cdot)$.
\end{exercise}

Vamos terminar essa seção dando uma interpretação bastante interessante para os núcleos de transição em analogia à álgebra linear.
Fixe um núcleo de transição $K$ entre $E$ e $E$, uma medida inicial $\mu$ e uma função limitada $f: E \to \mathbb{R}$.
Relembre a notação em \eqref{e:P1_K} e defina $K f: E \to \mathbb{R}$ dada por
\begin{equation}
  K f(x):= \int f(y) K(x, \d y),
\end{equation}
que é obviamente limitada e já vimos ser mensurável no Teorema de Fubini.

Então temos dois operadores definidos para núcleos, a multiplicação à esquerda por uma medida em $E$ ($\mu K$ que também é uma medida em $E$) e a multiplicação à direita por uma função limitada e mensurável ($K f$ que também é uma função limitada e mensurável).
Podemos pensar em $f$ como um vetor coluna e $\mu$ como um vetor linha, nesse caso $K$ faria o papel de uma matriz.
Essa analogia é real se $E$ for um espaço enumerável.

\begin{exercise}
  No contexto de cadeias de Markov,
  \begin{enumerate}[\quad a)]
  \item mostre a relação de associatividade $\mu (K f) = (\mu K) f$,
  \item defina para todo $n$ o núcleo $K^{(n)}$ iterado (de $E$ em $E$), de forma que $\mu K^{(n)} f$ ainda seja associativa.
  \item Mostre que a medida $\mu K^{(n)}$ é a distribuição de $X_n$ se começamos de $\mu$,
  \item que a função $K^{(n)} f (\cdot)$ é o valor esperado de $f$ no tempo $n$ se começamos no zero do ponto $\cdot$ e finalmente que
  \item o número real $\mu K^{(n)} f$ é a esperança de $f$ no tempo $n$ se começamos de $\mu$.
  \end{enumerate}
\end{exercise}

\todosec{Tópico: Urna de Pólya}{fazer...}

\todosec{Tópico: Recorrência e transiência}{markov recorrência/transiência + periodicidade...}

\chapter{Somas de variáveis independentes}

Nesse capítulo introduziremos várias técnicas e resultados que serão úteis em geral, mas que aparecem naturalmente no estudo de somas de variáveis aleatórias independentes, que por sua vez é um assunto de extrema importância em teoria e aplicações de probabilidade.

\section{Esperança}

\begin{definition}
  Se $X$ é uma variável aleatória com $\int_\Omega |X| \d \omega < \infty$, dizemos que $X$ é integrável \index{variavel aleatoria@variável aleatória!integravel@integrável} e definimos
  \begin{equation}
    E(X) = \int_\Omega X(\omega) P(\d \omega),
  \end{equation}
  a chamada esperança de $X$. \index{esperanca@esperança}
  Nesse caso também dizemos que $X \in \mathcal{L}^1$.
\end{definition}

Quando $X \geq 0$, também podemos supor que $E(X)$ está bem definida, mesmo que possivelmente tomando valor infinito.

Não demonstraremos algumas propriedades conhecidas da integração de Lebesgue, tais como
\begin{enumerate}[\quad a)]
\item $E(X + \alpha Y) = E(X) + \alpha E(Y)$ (se estiverem bem definidas),
\item Valem os Teoremas de Convergência (Monótona e Limitada).
\end{enumerate}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^1$ e $P[X > x] = 0$, então $E(X) \leq x$.
\end{exercise}

\begin{lemma}
  A esperança de uma variável aleatória $X \in \mathcal{L}^1$ depende somente de sua distribuição.
  Mais precisamente
  \begin{equation}
    E(X) = \int x \; P_X (\d x).
  \end{equation}
\end{lemma}

\begin{proof}
  Vamos mostrar que
  \begin{equation}
    E\big(f(X)\big) = \int f(x) (X \circ P) (\d x),
  \end{equation}
  para toda $f: \mathbb{R} \to \mathbb{R}$ mensurável tal que $f(X) \in \mathcal{L}^1$.

  Para $f = \1_A$, temos
  \begin{equation}
    E\big(f(X)\big) = P[X \in A] = (X \circ P) (A),
  \end{equation}
  por definição de $X \circ P$.

  Agora podemos extender o teorema para funções $f$ simples por linearidade, depois para funções positivas usando o Teorema da Convergência Monótona e finalmente escrevemos $x = x \1_{[0, \infty)} - (-x) \1_{(-\infty,0)}$.
\end{proof}

Vamos mostrar uma fórmula bastante simples de integração de variáveis tomando valores em um conjunto enumerável.
Se $X \in \{x_1, x_2, \dots\}$ $P$-quase certamente, então
\begin{equation}
  \begin{split}
    E(X) & = \int_\Omega X P(\d \omega) = \int \sum_i \1_{[X = x_i]} X P(\d \omega) + \int_{\{x_1, x_2, \dots\}^c} X P(\d \omega)\\
    & = \sum_i \int_{[X = x_i]} x_i P(\d \omega) + 0 = \sum_i x_i P[X = x_i].
  \end{split}
\end{equation}

Para nos acostumar à notação de probabilidade, vamos agora mostrar o mesmo resultado da seguinte forma
\begin{equation}
  \begin{split}
    E(X) & = E\Big(\sum_i X \1_{[X = x_i]}\Big) + E(X \1_{\{x_1, x_2, \dots\}^c})\\
    & = \sum_i E[X; X = x_i] + 0 = \sum_i x_i P[X = x_i].
  \end{split}
\end{equation}
Que é certamente muito útil quando nos habituamos a ela.

Observe que acima usamos a notação $E[X; \mathcal{Q}] = E(X \1_{[\mathcal{Q}]})$.
Também utilizaremos $E[X; \mathcal{Q}_1, \mathcal{Q}_2, \dots] = E(X \1_{[\mathcal{Q}_1, \mathcal{Q}_2, \dots]})$

\begin{example}
  Se $X \overset{d}\sim \Ber(p)$, então $E(X) = 0 \cdot P[X = 0] + 1 P[X = 1] = 0 + p = p$.
\end{example}

\begin{example}
  Seja $X \overset{d}\sim \Bin(n,p)$, então, para calcular $E(X)$, basta calcular $E(Y)$ onde $X \overset{d}\sim Y$.
  Como vimos anteriormente, se $Z_1, Z_2, \dots, Z_n$ são variáveis \iid (relembrando: independentes e identicamente distribuídos) com $Z_1 \overset{d}\sim \Ber(p)$, então $Y = \sum_i Z_i \overset{d}\sim \Bin(n,p)$.
  Logo
  \begin{equation}
    E(X) = E(Y) = \sum_i E(Z_i) = n p.
  \end{equation}
\end{example}

Se $d(X \circ P) = \rho(x) \d x$ (com $\rho \geq 0$ e $\int \rho(x) \d x = 1$), então
\begin{equation}
  E(X) = \int x (X \circ P)(\d x) = \int x \rho(x) \d x.
\end{equation}

\begin{example}
  Se $X \overset{d}\sim U_{[0,1]}$, então sua densidade com respeito a Lebesgue é dada por $d(X \circ P) = \1_{[0,1]} \d x$, donde $E(X) = \int_0^1 x \d x = 1/2$.
\end{example}

\begin{proposition}
  \label{p:espera_acumulada}
  Se $X \geq 0$ $P$-q.c., então
  \begin{equation}
    E(X) = \int_0^\infty P[X > x] \d x) = \int_0^\infty 1 - F(x) \d x.
  \end{equation}
\end{proposition}

\begin{proof}
  \begin{equation}
    \begin{split}
      E(X) & = E \Big( \int_0^X 1 \d x \Big) = E \Big( \int_0^\infty \1_{[x < X]} \d x \Big)\\
      & \overset{\text{Fubini}}= \int_0^\infty E(\1_{[x < X]}) \d x = \int_0^\infty P[x < X] \d x.
    \end{split}
  \end{equation}
\end{proof}

\begin{example}
  Se $X \overset{d}\sim \Exp(\lambda)$, então
  \begin{equation}
    P[X \geq x] = \int_x^\infty \lambda e^{-\lambda t} \d t = e^{-\lambda x},
  \end{equation}
  donde
  \begin{equation}
    E(X) = \int_0^\infty e^{-\lambda x} \d x = \frac{1}{\lambda}.
  \end{equation}
\end{example}

\begin{exercise}
  Se $X \in \mathcal{L}^1$ e $P[X \geq x] = P[X \leq -x]$ para todo $x \geq 0$, então $E(X) = 0$.
\end{exercise}

\begin{exercise}
  Marcelo coleciona figurinhas de futebol.
  O álbum completo conter\'a $N$ figurinhas. No $i$-ésimo dia, ele compra uma nova carta $X_i \in \{1, \dots, N\}$.
  A cole\c{c}\~ao $(X_i)_{i \geq 0}$ é distribuida de maneira \iid e uniforme nas figurinhas.
  \begin{enumerate}[\quad a)]
  \item Para $j = 1, \dots, N$, seja $T_j$ o tempo passado até a aquisi\c{c}\~ao da $j$-ésima nova figurinha, i.e.
    \begin{equation}
      T_1 = 1 \quad \text{ e } \quad T_j = \inf\{i, X_i \not \in \{X_{T_{j'}}; j' < j\}\}.
    \end{equation}
    Mostre que $T_j$ é finito quase certamente, para todo $j \leq N$.
  \item Calcule a distribuição conjunta de $(T_1, T_2 - T_1, \dots, T_N - T_{N-1})$.
  \item Calcule a esperança de $T_N$ (o dia em que Marcelo completa seu álbum).
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Sejam $X_1, X_2, \dots$ variáveis aleatórias \iid e defina o primeiro tempo de récorde como
  \begin{equation}
    R = \inf\{i \geq 2; X_i \geq X_1\}.
  \end{equation}
  Supondo que $X_1$ é absolutamente contínua com respeito à medida de Lebesgue, encontre $E(R)$.
\end{exercise}

\subsection{Desigualdade de Markov}

\begin{theorem}
  \label{t:markov}
  \index{Desigualdade de Markov}
  Se $X \geq 0$ $P$-q.c., então para todo $x > 0$,
  \begin{equation}
    P[X \geq x] \leq \frac{E(X)}{x}.
  \end{equation}
\end{theorem}

\begin{proof}
  Sabemos que $X \geq x \1_{[X \geq x]}$, logo
  \begin{equation}
    E(X) \geq x E(\1_{[X \geq x]}) = x P[X \geq x],
  \end{equation}
  que termina a prova.
\end{proof}

O próximo exemplo serve muito bem para mostrar porque estamos interessados em desigualdades como a do Teorema~\ref{t:markov} acima.

Em vários exemplos importantes, podemos ter dificuldade de calcular probabilidades explicitamente.
Nesses casos, poderíamos gastar nossas energias tentando calculá-las a qualquer custo, ou podemos nos contentar em obter cotas superiores e inferiores para as probabilidades nas quais estamos interessados.

Em vários casos, a segunda estratégia tem uma grande vantagem sobre a primeira, por possibilitar que estudemos problemas mais complexos (e consequentemente mais importantes/interessantes) e muitas vezes sem nos afastarmos da realidade (em vários exemplos as cotas superiores e inferiores são próximas o suficiente para que não nos preocupemos).

\begin{example}
  Sejam $n$ patos e $m$ caçadores.
  Cada caçador escolhe um pato aleatorea e uniformemente e atira (abatendo-o com probabilidade $p$).
  Seja $X = \# \{\text{patos vivos}\}$, que pode ter uma distribuição complicada de calcular, mas
  \begin{equation}
    \begin{split}
      E(X) &= E \Big( \sum_{i=1}^n \1_{[\text{pato $i$ vive}]} \Big) = \sum_{i=1}^n P[\text{pato $i$ vive}]\\
      &= n P[\text{pato $1$ vive}] = P\Big( \mcap_{j=1}^m [\text{caçador $j$ não mata pato $1$}] \Big)\\
      &= n P[\text{caçador $j$ não mata pato $1$}]^m = n \Big(1 - \frac{p}{n}\Big).
    \end{split}
  \end{equation}
  Observe que
  \begin{enumerate}[\quad a)]
  \item acima obtivemos uma igualdade e
  \item $[\text{pato $i$ vive}]$, $i = 1, \dots, n$ não são independentes.
  \end{enumerate}

  Finalmente estimamos (digamos para $n$ par)
  \begin{equation}
    \begin{split}
      & P[\text{patos para o jantar} \leq n/2] = P[X \geq n/2] \leq \frac{E(X)}{n/2}\\
      & \qquad = 2 \frac{n}{n} \Big( 1 - \frac{p}{n}\Big)^m \leq 2 \exp \{- \frac{pm}{n}\}.
    \end{split}
  \end{equation}
\end{example}

\todosec{Tópico: Grafos Aleatórios}{fazer erdos renyi...}

\todosec{Tópico: Currie Weiss}{fazer...}

\subsection{Esperança e independência}

\begin{proposition}
  Sejam $X$ e $Y$ variáveis aleatórias independentes e em $\mathcal{L}^2$, então
  \begin{equation}
    E(XY) = E(X) E(Y).
  \end{equation}
\end{proposition}

\begin{proof}
  Obviamente o resultado acima é válido para funções indicadoras, pois $\1_A \1_B = \1_{A \cap B}$.
  Por linearidade, o resultado também vale para funções simples e usando o Teorema da Convergência Monótona podemos extendê-lo para funções positivas.
  Finalmente, decompomos $X = X_+ - X_-$ e $Y = Y_+ - Y_-$ e lembramos que ambas estão em $\mathcal{L}^2$ para concluir a prova.
\end{proof}

\begin{exercise}
  Mostre que $E(XY)$, $E(X/Y)$, $E(X + Y)$... dependem apenas da distribuição de $(X,Y) \in \mathbb{R}^2$.
\end{exercise}

\begin{exercise}
  Mostre que se $X, Y \in \mathcal{L}^1$, então também vale $E(XY) = E(X) E(Y)$.
\end{exercise}

\section{Variância}

Na seção anterior, limitamos $P[X > a]$ usando $E(X)$ (se $X \geq 0$).
Esse método é chamado de \emph{método do primeiro momento}, \index{momento!primeiro} de acordo com a seguinte
\begin{definition}
  Dada uma variável aleatória $X$, definimos o seu $k$-ésimo momento como $E(X^k)$, para $k = 1, 2, \dots$
\end{definition}

Então, por exemplo, se $X \in \mathcal{L}^k$ e $X \geq 0$, podemos estimar
\begin{equation}
  P[X \geq x] = P [X^k \geq x^k] \leq \frac{E(X^k)}{x^k}, \text{ para quaisquer $k \geq 1$.}
\end{equation}
Observe que quando o $k$-ésimo momento de $X$ é finito, a razão acima decai mais rápido quando $x$ diverge.

\begin{exercise}
  Mostre uma fórmula análoga à da Proposição~\ref{p:espera_acumulada}.
\end{exercise}

\begin{exercise}
  Mostre que se a distribuição de $X \in \mathcal{L}^2$ tem densidade $\rho$, então
  \begin{equation}
    E(f(X)) = \int f(x) \rho(x) \d x.
  \end{equation}
\end{exercise}

Um caso bastante importante ocorre quando $k = 2$, por várias razões que descreveremos abaixo.

Digamos que estamos interessados em aproximar uma variável aleatória por uma constante de forma a minimizar o erro da aproximação.
Uma possível formulação desse problema é encontrar $a$ de forma a minimizar
\begin{equation}
  E\Big( (X - a)^2 \Big) = E(X^2) - 2 a E(X) + a^2.
\end{equation}
Essa equação obviamente possui um único mínimo em $a = E(X)$.
Ao erro da aproximação acima damos o nome de variância

\begin{definition}
  Dada uma variável aleatória $X \in \mathcal{L}^2$, definimos sua variância \index{variancia@variância} como
  \begin{equation}
    \Var(X) = E \Big( \big(X - E(X)\big)^2 \Big) = E(X^2) - E(X)^2.
  \end{equation}
\end{definition}

Observe pelas definições alternativas dadas acima que
\begin{enumerate}[\quad a)]
\item $\Var(X) \geq 0$ e
\item $E(X^2) \geq E(X)^2$.
\end{enumerate}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^2$, então $\Var(X) = 0$ se e somente se $X = a$ quase certamente.
\end{exercise}

Obviamente
\begin{equation}
  \Var(a X) = E(a^2 X^2) - E(aX)^2 = a^2 \Var(X).
\end{equation}

Podemos alternativamente entender a variância da seguinte meneira.
Sejam $X$ e $Y$ variáveis aleatórias independentes em $\mathcal{L}^2$ de mesma distribuição.
Então,
\begin{equation}
  E\big( (X - Y)^2 \big) = E(X^2) - 2 E(XY) + E(X^2) = E(X^2) - E(X)^2 = \Var(X).
\end{equation}

\begin{exercise}
  Mostre que se $X \in \mathcal{L}^2$, então $\Var(X + b) = \Var(X)$.
\end{exercise}

\begin{exercise}
  Calcule $Var(X)$ quando $X$ tem distribuições $\Ber(p)$, $U[0,1]$ ou $\Exp(\lambda)$.
\end{exercise}

A seguinte proposição mostra que a variância é uma maneira de estimar o quanto uma variável aleatória se desvia de sua média.
\begin{proposition}
  Se $X \in \mathcal{L}^2$ e $a > 0$, então
  \begin{equation}
    P [ |X - E(X)| > a] \leq \frac{\Var(X)}{a^2}.
  \end{equation}
\end{proposition}

\begin{proof}
  A desigualdade segue trivialmente da cota de Markov, ao observarmos que
  \begin{enumerate}[\quad a)]
  \item $|X - E(X)| \geq 0$,
  \item $|X - E(X)| > a$ se e somente se $|X - E(X)|^2 > a^2$ e
  \item $E\big(|X - E(X)|^2\big) = E\big((X - E(X))^2\big) = \Var(X)$,
  \end{enumerate}
  mostrando a proposição.
\end{proof}

Para variáveis aleatórias de média zero, a variância nada mais é que $E(X^2)$, ou em outras palavras $\lVert X \rVert^2_2$, o quadrado de sua norma em $\mathcal{L}^2$.
Isso nos motiva a olhar mais de perto para o produto interno em $\mathcal{L}^2$, que se traduz a $E(XY)$.
Mas para não nos restringirmos a variáveis de média zero, introduzimos a seguinte

\begin{definition}
  Se $X, Y$ são variáveis em $\mathcal{L}^2$, definimos
  \begin{equation}
    \Cov(X,Y) = E\Big( \big(X - E(X)\big) \big(Y - E(Y)\big) \Big) = E(XY) - E(X)E(Y).
  \end{equation}
\end{definition}

Uma observação importante é que
\begin{equation}
  \text{se $X$ e $Y$ em $\mathcal{L}^2$ são independentes, então $\Cov(X,Y) = 0$.}
\end{equation}

\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $\mathbb{R}^2$.
  Já vimos que elas não são independentes sob a distribuição $U_{S^1}$.
  Mostre que mesmo assim temos $\Cov(X_1, X_2) = 0$.
\end{exercise}

Uma outra propriedade bastante importante da variância é que ela se comporta bem com somas, no seguinte sentido
\begin{proposition}
  Se $X_1, \dots, X_n$ são variáveis em $\mathcal{L}^2$, então
  \begin{equation}
    \Var(X_1 + \dots + X_n) = \sum_{i=1}^n \Var(X_i) + \sum_{i \neq j} \Cov(X_i, X_j).
  \end{equation}
  Em particular, se as variáveis $X_i$ forem independentes duas a duas, então
  \begin{equation}
    \label{e:var_linear}
    \Var(X_1 + \dots + X_n) = \sum_{i=1}^n \Var(X_i).
  \end{equation}
\end{proposition}

\begin{proof}
  Basta fazer o tedioso desenvolvimento
  \begin{equation}
    \begin{split}
      \Var\Big(\sum_i X_i\Big) & = E \Big( \Big(\sum_i X_i - E\Big(\sum_i X_i\Big)\Big)^2\Big)\\
      & = E \Big( \Big(\sum_i X_i - E(X_i)\Big)^2\Big)\\
      & = \sum_{i, j = 1}^n E \big(X_i - E(X_i)\big) E\big(X_j - E(X_j)\big),
    \end{split}
  \end{equation}
  o que termina a prova ao separarmos $i = j$ de $i \neq j$.
\end{proof}

\begin{exercise}
  Calcule $\Var(X)$ quando $X \overset{d}\sim \Bin(n, p)$.
\end{exercise}

\begin{exercise}
  Calcule $E(X)$ quando $X \overset{d}\sim \Geo(p)$.
\end{exercise}

Um dito popular muito comum no Brasil é que não devemos deixar todos os ``ovos no mesmo cesto'', o que nos remete à possibilidade de perdermos todos eles caso o cesto caia.
Uma outra maneira de pensar nas vantagens de se dividir nossos riscos entre várias fontes independentes de incerteza, vem da equação \eqref{e:var_linear}, melhor explicada no exercício abaixo.

\begin{exercise}
  Imagine que $X_1, \dots, X_n$ são variáveis \iid, tomando valores em $[0,1]$ e que temos um certo valor $s \in \mathbb{R}_+$ que temos que guardar em $n$ caixas (dividindo como quisermos em $s_1, \dots, s_n$).
  Ao fim da semana, obteremos $S = \sum_i s_i X_i$.

  Calcule $E(S)$ e $\Var(S)$,
  \begin{enumerate}[\quad a)]
  \item se $s_1 = s$ e $s_i = 0$ para todo $i \geq 2$ e
  \item se $s_i = s/n$ para todo $i$.
  \end{enumerate}
  Compare os resultados.
\end{exercise}

\begin{exercise}
  Calcule $\lim_{p \to 0} F_p(x)$ onde $F_p$ é a função de distribuição acumulada de $p X_p$ com $X_p \overset{d}\sim \Geo(p)$.
  Você reconhece esse limite?
\end{exercise}

\section{Lei fraca dos grandes números}

Nessa seção iremos mostrar um dos resultados mais importantes da Teoria da Probabilidade.
O que nossa intuição tem a nos dizer sobre a probabilidade de obtermos um resultado em um dado é $1/6$?
Uma possível explicação seria por simetria, mas e o que podemos dizer no caso de um dado viciado?

Se dizemos a alguém que a probabilidade de obter $6$ em um certo dado é $1/10$, naturalmente a pessoa pode se perguntar como descobrimos isso.
Um bom jeito de obter tal medida seria jogar o dado várias vezes independentemente e calcular em qual proporção dos ensaios ele retornou um seis.

O objetivo desta seção é confirmar a validade desse experimento de maneira quantitativa.

\begin{theorem}
  \index{Lei!Fraca dos Grandes Numeros@Fraca dos Grandes Números}
  \label{t:lei_fraca}
  Se $X_1, X_2, \dots$ são i.i.d.s em $\mathcal{L}^2$ e definimos
  \begin{equation}
    S_n = \sum_{i=1}^n X_i,
  \end{equation}
  então para todo $\varepsilon > 0$
  \begin{equation}
    \lim_{n \to \infty} P \Big[\Big| \frac{S_n}{n} - E(X_1)\Big| > \varepsilon \Big] = 0.
  \end{equation}
  Ou seja, $\tfrac{S_n}{n} \to E(X_1)$ em medida (que também chamamos de ``em probabilidade'').
\end{theorem}

\begin{proof}
  Sabemos que
  \begin{equation}
    P \Big[\Big| \frac{S_n}{n} - E(X_1)\Big| > \varepsilon \Big] \leq \frac{\Var(\tfrac{S_n}{n})}{\varepsilon^2},
  \end{equation}
  pois $E(S_n/n) = 1/n E(X_1 + \dots + X_n) = E(X_1)$.

  Mas como $\Var(S_n/n) = 1/n^2 \Var (X_1 + \dots + X_n) = (n/n^2) \Var(X_1)$, temos o resultado.
\end{proof}

Observe que nós apenas utilizamos que as variáveis $X_i$ eram independentes duas a duas.

Além disso, obtivemos o seguinte resultado quantitativo que vale mesmo para valores finitos de $n$:

\begin{scholia}
  Se $X_1, X_2, \dots$ são i.i.d.s em $\mathcal{L}^2$ e definimos $S_n = \sum_{i=1}^n X_i$ como acima, então, para todo $\varepsilon > 0$ e $n \geq 1$, temos
  \begin{equation}
    P \Big[\Big| \frac{S_n}{n} - E(X_1)\Big| > \varepsilon \Big] \leq \frac{\Var(X_1)}{\varepsilon^2 n}.
  \end{equation}
\end{scholia}





\begin{corollary}
  Se $A_1, A_2, \dots$ são eventos independentes dois a dois com $P(A_i) = p \in [0,1]$ para todo $i$, então
  \begin{equation}
    \lim_{n \to \infty} P \Big[ \Big| \frac{\#\{i \leq n; \omega \in A_i\}}{n} - p \Big| > \varepsilon \Big] = 0,
  \end{equation}
  ou em outras palavras a proporção de ensaios onde o evento $A_i$ ocorre converge em probabilidade para $p$.
\end{corollary}

\begin{proof}
  Basta tomar $X_i = \1_{A_i}$ no Teorema~\ref{t:lei_fraca}.
\end{proof}

\begin{exercise}
  Sejam $(X_i)_{i \geq 1}$ variáveis \iid com distribui\c{c}\~ao Ber$(p)$, $p \in [0,1]$. Mostre que
  \begin{equation}
    \lim_{N \to \infty} \frac 1N \sum_{i = 1}^N X_i X_{i+1} = p^2, \text{ em probabilidade.}
  \end{equation}
\end{exercise}

\section{Método do segundo momento}

Vimos como a Lei Fraca dos Grandes Números seguiu de uma estimativa de segundo momento \index{momento!segundo} (mais precisamente usando a variância).

Nessa seção iremos mostrar como esse método é mais geral, se aplicando mesmo em situações onde as variáveis não são necessariamente independentes duas a duas.

\subsection{Aplicação em grafos aleatórios}

Seja $V_n = \{1, \dots, n\}$ com $n \geq 3$ e $\mathcal{E}_n = \big\{ \{x,y\} \subseteq V_n; x \neq y \big\}$.
Chamamos o par $(V_n, \mathcal{E}_n)$ de grafo completo em $n$ vértices.

Definimos em um certo espaço de probabilidade $P_n$, as variáveis aleatórias $(X_e)_{e \in \mathcal{E}_n}$ de maneira \iid com distribuição $\Ber(p)$, onde $p \in [0,1]$.
Essas variáveis induzem um subgrafo aleatório $(V_n, \mathcal{E}_n')$, onde
\begin{equation}
  \mathcal{E}_n' = \big\{ e \in \mathcal{E}_n; X_e = 1 \big\}.
\end{equation}
Dizemos que os elos $e$, tais que $X_e = 1$ são abertos.

Definimos nesse espaço a variável aleatória
\begin{equation}
  T_n = \#\big\{\text{triângulos em $(V_n, \mathcal{E}_n')$}\big\}.
\end{equation}
Essa variável claramente pode ser escrita como
\begin{equation}
  T_n = \sum_{x,y,z \in V_n \text{ distintos}} \1_{A_{\{x,y,z\}}},
\end{equation}
onde $A_{\{x,y,z\}} = \big[\text{\{x,y,z\} formam um triângulo em $(V_n, \mathcal{E}_n')$}\big]$.

Gostaríamos de entender algo sobre a distribuição de $T_n$ e começamos calculando
\begin{equation}
  \begin{split}
    E^n(T_n) & = \sum_{\{x,y,z\} \text{ distintos}} P^n(A_{\{x,y,z\}})\\
    & = \binom{n}{3} p^3 = \frac{n(n-1)(n-2)}{6}p^3.
  \end{split}
\end{equation}
Logo, $P[T_n > a] \leq n(n-1)(n-2)p^3/6a$.
Mais ainda,
\begin{equation}
  \begin{split}
    E^n(T_n^2) & = \sum_{\{x,y,z\} \text{ distintos}} \quad \sum_{\{x',y',z'\} \text{ distintos}} P^n(A_{\{x,y,z\}} \cap A_{\{x',y',z'\}})\\
    & = \underbrace{\binom{n}{6} \binom{6}{3} p^6}_{\text{todos distintos}} + \underbrace{\binom{n}{5} \binom{5}{3} \binom{3}{1} p^6}_{\text{$1$-comum}} + \underbrace{\binom{n}{4} \binom{3}{2} \binom{4}{3} p^5}_{\text{$2$ em comum}} + \underbrace{\binom{n}{3}p^3}_{\text{iguais}}
  \end{split}
\end{equation}
Donde
\begin{equation}
  \Var^n(T_n) = \frac{1}{36} n^6 p^6 - \frac{1}{36} n^6 p^6 + c n^5 p^5 + ... \leq c (n^5 p^5 + n^3 p^3),
\end{equation}
para todos $p \in [0,1]$ e $n \geq 1$ se escolhemos bem a constante $c > 0$.

Isso nos permite por exemplo estimar o que acontece em alguns regimes, como por exemplo, se $p = 1/2$, então
\begin{equation}
  E^n(T_n) = \frac{n(n-1)(n-2)}{48},
\end{equation}
que cresce como $n^3$, e $\Var^n(T_n) \leq c n^5$, logo
\begin{equation}
  P^n\Big[ \Big|T_n - E^n(T_n)\Big| > \varepsilon n^3 \Big] \leq \frac{\Var^n(T_n)}{\varepsilon^2 n^6} \leq \frac{c}{\varepsilon^2 n}.
\end{equation}

\begin{exercise}
  Sejam $X_1, \dots, X_n$ e $Y_1, \dots, Y_n$ variáveis independentes com distribuição $\Ber(p)$.
  Defina agora $Z_{i,j} = X_i Y_j$, para $i, j \in \{1, \dots, n\}$ e
  \begin{enumerate}[\quad a)]
  \item calcule a esperança de $S_n = \tfrac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n Z_{i,j}$ e
  \item estime $P[|S_n - E(S_n)| > a]$ usando o método do segundo momento. Como esse resultado se compara com o caso em que os $Z_{i,j}$ são i.i.d.?
  \end{enumerate}
\end{exercise}

\begin{exercise}
  \label{x:casas_tempestade}
  Considere uma rua infinita com casas $i \in \mathbb{Z}$.
  Para todo $i \in \mathbb{Z}$, existia uma rua entre as casas $i$ e $i+1$, mas após uma grande tempestade essas ruas foram danificadas.
  Mais precisamente, para cada $i \in \mathbb{Z}$, temos variáveis aleatórias $X_i$ que são i.i.d. com distribuição $\text{Ber}(p)$, onde $X_i = 1$ indica que o trecho da rua entre as casas $i$ e $i + 1$ foi danificado e não pode ser utilizado.
  Defina, para $i \in \mathbb{Z}$, $R_i$ como sendo o número de casas que continuaram acessíveis à casa $i$ após a tempestade.
  Por exemplo, se $X_{-2}$ e $X_0 = 1$ e $X_{-1} = 0$, temos que a casa $0$ somente pode acessar a casa $-1$, logo $R_0 = 1$.
  Nesse contexto,
  \begin{enumerate}[\quad a)]
  \item Calcule a distribuição e a esperança de $R_0$,
  \item Use o método do segundo momento para estimar a probabilidade
    \begin{equation}
      P \Big[ \Big| \frac{1}{n} \sum_{i=1}^n R_i - E(R_0) \Big| > a \Big].
    \end{equation}
  \end{enumerate}
\end{exercise}

\todosec{Tópico: Análise de DNA}{fazer "computational molecular biology" - Pevzner seção 5.5...}

\todosec{Tópico: Método Probabilístico Revisitado}{usando segundo momento agora}

\section{Lei forte dos grandes números}

\begin{theorem}[Lei Forte dos Grandes Números]
  \index{Lei!Forte dos Grandes Numeros@Forte dos Grandes Números}
  \label{t:LFGN}
  Sejam $X_1, X_2, \dots$ \iid em $\mathcal{L}^1$, com $m = E(X_1)$.
  Então,
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n X_n = m, \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

Antes de começar a prova, buscando inspiração no Teorema das Três Séries, mostraremos que basta considerar versões truncadas das variáveis $X_i$.
Isso é feito no próximo

\begin{lemma}
  \label{l:LFGN}
  Sejam $Y_i = X_i \1_{[|X_i| \leq i]}$.
  Então, para demonstrar o Teorema~\ref{t:LFGN}, basta provar que
  \begin{equation}
    \lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n Y_i = m, \text{ $P$-quase certamente.}
  \end{equation}
\end{lemma}

\begin{proof}[Prova do Lema~\ref{l:LFGN}]
  Consideramos os eventos $A_i = [X_i \neq Y_i]$.
  Obviamente,
  \begin{equation}
    \sum_i P(A_i) = \sum_i P[|X_i| \geq i] \leq \int_0^\infty P[|X_i| \geq t] \d t = E\big(|X_i|) < \infty.
  \end{equation}
  Logo, pelo Lema de Borel-Cantelli, temos que $P$-quase certamente $A_i$ acontece apenas finitas vezes.
  Digamos que $A_i$ não acontece para $i > N(\omega)$.
  Dessa forma, para qualquer $n \geq 1$,
  \begin{equation}
    \Big|\frac{1}{n}\sum_{i=1}^n (X_i - Y_i)\Big| \leq \frac{1}{n}\sum_{i=1}^n |X_i - Y_i| \leq \frac{1}{n} \sum_{i \leq N(\omega)} |X_i|,
  \end{equation}
  que converge para zero $P$-quase certamente, mostrando o resultado.
\end{proof}

O próximo passo para a prova da Lei Forte dos Grandes Números é cuidar da esperança das novas variáveis $Y_i$.
\begin{lemma}
  \label{l:lim_Z_n_LFGN}
  Sejam $Z_i = Y_i - E(Y_i)$, para $i \geq 1$ como acima.
  Então, para demosntrar o Teorema~\ref{t:LFGN}, basta mostrar que
  \begin{equation}
    \label{e:lim_Z_n_LFGN}
    \lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n Z_i = 0, \text{ $P$-quase certamente.}
  \end{equation}
\end{lemma}

\begin{proof}
  Supondo a convergência em \eqref{e:lim_Z_n_LFGN}, sabemos que
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n Y_i - E(Y_i) = 0, \text{ $P$-quase certamente.}
  \end{equation}
  Mas $E(Y_i) = E(X_i \1_{[|X_i| \leq i]})$ que converge a $E(X_i) = m$, pelo Teorema da Convergência Dominada, donde concluímos que
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n E(Y_i) = m.
  \end{equation}
  Dessa forma, obtemos que $\tfrac 1n \sum_{i=1}^n Y_i$ converge quase certamente a $m$, donde concluímos a prova do Teorema~\ref{t:LFGN} por meio do Lema~\ref{l:LFGN}.
\end{proof}

Gostaríamos de utilizar os teoremas das séries para mostrar a convergência de $\tfrac 1n \sum_{n} Z_n$, mas obviamente, o fator $\tfrac 1n$ que precede a soma nos impede de fazê-lo.
O próximo resultado é um simples exercício de análise real, que nos permite reduzir a prova de \eqref{e:lim_Z_n_LFGN} para uma simples convergência de uma série sem pré-fatores.

\begin{lemma}[Lema de Kronecker]
  Suponha que $x_n \in \mathbb{R}$ e $b_n > 0$ sejam tais que $b_n \uparrow \infty$ e $\sum_{i=1}^\infty \frac{x_i}{b_i}$ convirja a $s \in \mathbb{R}$.
  Então
  \begin{equation}
    \lim_{n \to \infty} \frac{1}{b_n} \sum_{i=1}^n x_i = 0.
  \end{equation}
\end{lemma}

\begin{proof}
  Definindo $s_0 = 0$ e $s_n = \tfrac{x_1}{b_1} + \dots + \tfrac{x_n}{b_n}$, temos, por integração por partes,
  \begin{equation}
    \sum_{i=1}^n x_i = \sum_{i=1}^n b_i \frac{x_i}{b_i} = \sum_{i=1}^n b_i s_{i} - \sum_{i=1}^n b_i s_{i-1} = b_n s_n + \sum_{i=1}^{n-1} (b_{i} - b_{i+1}) s_{i}.
  \end{equation}
  Escolhemos agora, para qualquer $\varepsilon > 0$, um $n_0 \geq 1$ tal que $|s_n - s| < \varepsilon$ para todo $n \geq n_0$.
  Dessa forma,
  \begin{equation*}
    \begin{split}
      \frac{1}{b_n} \sum_{i=1}^n x_i & = s_n - \frac{1}{b_n}\sum_{i=1}^{n-1} (b_{i+1} - b_{i}) s_{i}\\
      & = s_n - \frac{1}{b_n}\underbrace{\sum_{i=1}^{n_0-1} (b_{i+1} - b_{i})}_{\Delta_{n_0}} s_{i} - \frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_{i}) s_{i}\\
      & = \underbrace{s_n}_{\to s} - \underbrace{\frac{1}{b_n}\Delta_{n_0}}_{\to 0} - \underbrace{\frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_i) s}_{= \tfrac{(b_n - b_{n_0})s}{b_n} \to s} - \underbrace{\frac{1}{b_n}\sum_{i=n_0}^{n-1} (b_{i+1} - b_{i}) (s_{i} - s)}_{\leq \varepsilon\tfrac{(b_n - b_{n_0})}{b_n} \leq \varepsilon},
    \end{split}
  \end{equation*}
  onde os limites indicados acima representam o que acontece quando $n \to \infty$.
  A prova segue do fato de $\varepsilon$ ter sido escolhido arbitrariamente.
\end{proof}

Estamos agora em posição de finalizar a
\begin{proof}[Prova do Teorema~\ref{t:LFGN}]
  De acordo com o Lema de Kronecker e o Lema~\ref{l:lim_Z_n_LFGN}, é suficiente mostrar que
  \begin{equation}
    \sum_{i=1}^n \frac{Z_i}{i}, \text{ converge quase certamente}.
  \end{equation}
  Por outro lado, como os $Z_i$'s tem média zero, o Teorema de Uma Série diz que é suficiente mostrar que
  \begin{equation}
    \sum_{i=1}^n \Var\Big(\frac{Z_i}{i}\Big) = \sum_{i=1}^n \frac{1}{i^2} \Var(Z_i) < \infty.
  \end{equation}
  Isso segue da seguinte estimativa
  \begin{equation}
    \begin{split}
      \sum_{i=1}^n \frac{1}{i^2} \Var(Z_i) & = \sum_{i=1}^n \frac{1}{i^2} \Var(Y_i) \leq \sum_{i=1}^n \frac{1}{i^2} E\big( X_i^2 \1_{[|X_i| \leq i]}\big)\\
      & = \sum_{i=1}^n \frac{1}{i^2} \sum_{k=1}^{i} E\big( X_i^2 \1_{[k-1 < |X_i| \leq k]}\big)\\
      & = \sum_{k=1}^n E\big( X_1^2 \1_{[k-1 < |X_i| \leq k]}\big) \sum_{i=k}^{n} \frac{1}{i^2}\\
      & \leq 2 \sum_{k=1}^n \frac{1}{k} E\big( X_1^2 \1_{[k-1 < |X_i| \leq k]}\big)\\
      & \leq 2 \sum_{k=1}^n E\big( X_1 \1_{[k-1 < |X_i| \leq k]}\big) \leq 2E(X_1) < \infty.
    \end{split}
  \end{equation}
  Isso nos permite concluir a prova de \eqref{e:lim_Z_n_LFGN} via o Lema de Kronecker.
  Consequentemente, obtemos o Teorema~\ref{t:LFGN} via o Lema~\ref{l:lim_Z_n_LFGN}.
\end{proof}

\todosec{Tópico: Teorema de Weierstrass}{provar o teorema de Weierstrass de aproximação de funções contínuas por polinômios (prova probabilística). Ele é usado em convergência fraca em $\mathbb{R}$}

\todosec{Tópico: Entropia de Shannon}{fazer...}

\todosec{Tópico: Processos de renovação}{fazer...}

\section{Lei \texorpdfstring{$\{0, 1\}$}{\{0,1\}} de Kolmogorov}

Ao estudarmos o Lema de Borel-Cantelli, vimos que, se os eventos $(A_i)_{i \geq 1}$ são independentes, então a probabilidade de $[A_i \text{ infinitas vezes}]$ somente pode assumir os valores zero ou um (dependendo da somabilidade de $P(A_i)$).
Nessa seção iremos estudar outros tipos de evento que assumem apenas esses dois valores.
Esperamos que esse fenômeno se torne intuitivo ao final dessa discussão.

No que se segue, consideraremos um espaço mensurável $\Omega = \times_{i=1}^\infty E$, com a $\sigma$-álgebra canônica $\mathcal{F}$, isto é a $\sigma$-álgebra gerada pelas coordenadas canõnicas $(X_i)_{i=1}^\infty$.
\begin{definition}
  Dizemos que um evento $A \in \mathcal{F}$ é caudal se
  \begin{equation}
    A \in \sigma\big( X_i; i \geq n\big), \text{ para todo $n \geq 1$}.
  \end{equation}
  Também introduzimos a classe $\mathcal{F}_\infty$ de tais eventos, que claramente é uma $\sigma$-álgebra, pois pode ser escrita como
  \begin{equation}
    \mathcal{F}_\infty = \mcap_{n \geq 1} \sigma\big( X_i; i \geq n\big).
  \end{equation}
  Chamamos $\mathcal{F}_\infty$ de $\sigma$-álgebra caudal. \index{sigma-algebra@$\sigma$-álgebra!caudal}
\end{definition}

Vejamos que, dados $A_i \in \sigma(X_i)$, $i \geq 1$, temos que $[A_i \text{ infinitas vezes}]$ é caudal.
Para tanto, basta observar que para todo $n \geq 1$, temos que
\begin{equation*}
  [A_i \text{ infinitas vezes}] = \big[\#\{i \geq 1; \omega \in A_i\} = \infty\big] = \big[\#\{i \geq n; \omega \in A_i\} = \infty\big],
\end{equation*}
que obviamente pertence a $\sigma(X_i; i \geq n)$.

\begin{exercise}
  Mostre que em $\Omega = \mathbb{R}^{\infty}$, são caudais os seguintes eventos
  \begin{enumerate}[\quad a)]
  \item $[X_i \text{ converge}]$,
  \item $\big[\tfrac{1}{n} \sum_{i=1}^n X_i \text{ converge}\big]$ e
  \item $[\#\{i \geq 1; X_i > 0\} < \infty]$.
  \end{enumerate}
\end{exercise}

Podemos agora enunciar o pricipal teorema dessa seção

\begin{theorem}[Lei $\{0,1\}$ de Kolmogorov]
  \index{Lei!0,1 de Kolmogorov@$\{0,1\}$ de Kolmogorov}
  Se $\Omega = E^{\infty}$, onde $E$ é um espaço canônico, for provido de uma lei produto $P = \otimes_{i=1}^\infty P_i$, então todo evento caudal tem probabilidade $0$ ou $1$ sob $P$.
\end{theorem}

Quando uma $\sigma$-álgebra $\mathcal{F}$ satisfaz $P(A) \in \{0,1\}$ para todo $A \in \mathcal{F}$, dizemos que $\mathcal{F}$ é trivial. \index{sigma-algebra@$\sigma$-álgebra!trivial}
Uma outra maneira de enunciar a conclusão do teorema acima é dizer que a $\sigma$-álgebra caudal $\mathcal{F}_\infty$ é trivial.

\begin{proof}
  A idéia da prova, apesar de soar um pouco estranha, é mostrar que se $A \in \mathcal{F}_\infty$, então $A$ é independente de si mesmo.
  Em outras palavras, $P(A) = P(A \cap A) = P(A)^2$, donde $P(A) \in \{0,1\}$.
  Mas vamos com calma.

  Fixe $k \geq 1$, $A \in \mathcal{F}_\infty$ e $B \in \sigma(X_1, \dots, X_k)$.
  Nesse caso, como o evento $A$ pertence a $\sigma(X_{k+1}, X_{k+2}, \dots)$, temos que $A$ e $B$ são independentes.
  Fixe agora $A \in \mathcal{F}_\infty$ e considere a classe
  \begin{equation}
    \mathcal{B}_A = \{B \in \mathcal{F}; \text{ $B$ é independente de $A$}\}.
  \end{equation}
  Já sabemos que $\sigma(X_1, \dots, X_k) \subseteq \mathcal{B}_A$ para todo $k \geq 1$.

  Obviamente $\Omega$ é independente de $A$, assim como $B^c \in \mathcal{B}_A$ sempre que $B \in \mathcal{B}_A$.
  Além disso, suponha que $B_1, B_2, \dots$ in $\mathcal{B}_A$ são disjuntos, então,
  \begin{equation*}
    P\big( (\mcup_i B_i) \cap A \big) = P\big( \mcup_i (B_i \mcap A) \big) \overset{\text{disj.}}= \sum_i P(B_i \mcap A) \overset{\text{indep.}}= P(A) P(\mcup_i B_i).
  \end{equation*}
  Logo $\mathcal{B}_A$ é um $\lambda$-sistema.

  Lembrando que $\mathcal{B}_A$ contém o $\pi$-sistema $\bigcup_k \sigma(X_1, \dots, X_k)$, isto é dos eventos cilíndricos, temos que todos eventos são indepentes de $A$, inclusive o próprio $A$.
  Isso termina a prova do teorema.
\end{proof}

\begin{exercise}
  Dizemos que uma probabilidade $P$ no espaço produto $\Omega = \times_{n \geq 1} E$ (com a $\sigma$-álgebra canônica) é fortemente misturadora se, para todo $k \geq 1$, temos
  \begin{equation}
    \lim_{n \to \infty} \sup \big| P(A \cap B) - P(A) P(B) \big| = 0,
  \end{equation}
  onde o supremo acima é tomado sobre $A \in \sigma(X_1, \dots, X_k)$ e $B \in \sigma(X_n, X_{n+1}, \dots)$.
  Mostre que nesse caso, a $\sigma$-álgebra dos eventos caudais é trivial.
\end{exercise}

\section{Momentos exponenciais}

Nessa seção desenvolveremos uma outra técnica para estimar a probabilidade de uma variável aleatória se desviar de sua esperança.

Já vimos o método do primeiro, segundo e quarto momento para controlar uma soma de variáveis independentes.
Um exemplo disso foi visto na estimativa
\begin{equation}
  P\Big[ \sum_{i=1}^n (X_i - E(X_i)) \geq a \Big] \leq \frac{\sum_i \Var (X_i)}{a^2}.
\end{equation}

Em geral, quanto maior o momento, melhor a estimativa do decaimento para a probabilidade de que uma variável se desvie de sua esperança.
Nessa seção iremos para momentos exponenciais, que em um certo sentido produzem estimativas ótimas para o comportamento assintótico da probabilidade de desvio.

Note que se quisermos um erro pequeno mas considerável (como por exemplo $\sim 0.01$), o método do segundo momento é muito bom, como veremos posteriormente.
Mas se quisermos um erro realmente muito pequeno (em situações concretas, algo como $10^{-12}$ por exemplo), certamente teremos que aumentar bastante o valor de $n$, mas quanto?
As cotas de segundo momento são muito ruins para esse tipo de estimativa, nos levando a escolher um $n$ maior que o necessário.
Abaixo, desenvolveremos um método mais eficiente para responder a essa pergunta, obviamente sob certas hipóteses na distribuição das variáveis aleatórias.

\begin{definition}
  Dada uma variável aleatória $X$, definimos sua transformada de Laplace \index{trasformada!de Laplace} como
  \begin{equation}
    \phi_X(s) = E(\ex{s X}) \in (0, \infty],
  \end{equation}
  para todos $s \in \mathbb{R}$.
  Essa transformada também é chamada \emph{função geradora de momentos} de $X$. \index{funcao@função!geradora de momentos}
\end{definition}

\begin{exercise}
  Calcule a função geradora de momentos das distribuições $\Ber(p)$, $\Exp(\lambda)$ e $U_{[0,1]}$.
\end{exercise}

\begin{proposition}
  \label{p:propried_phi}
  Se $E(\ex{\delta |X|}) < \infty$, então
  \begin{enumerate}[\quad a)]
  \item $X \in \mathcal{L}^p$ para todo $1 \leq p < \infty$,
  \item $\phi_X(s) < \infty$ para todo $s \in (-\delta, \delta)$,
  \item $\phi_X(s)$ é $C^\infty$ em $(-\delta, \delta)$ e
  \item $\phi_X^{(n)}(s) = E(X^n \ex{sX})$.
  \end{enumerate}
\end{proposition}

A última conclusão da proposição acima justifica a nomenclatura função geradora de momentos.

\begin{proof}
  Obviamente, para todo $p \geq 1$ existe $c > 0$ tal que $\ex{\delta |x|} \geq c |x|^p$, donde $X \in \mathcal{L}^p$.
  Além disso, para todo $s \in (-\delta, \delta)$, temos $\phi_X(s) = E(\ex{s X}) \leq E(\ex{\delta |X|}) < \infty$, donde \textit{2.} segue imediatamente.

  Fixando $s \in \mathbb{R}$, vamos agora calcular
  \begin{equation}
    \begin{split}
      \frac{\phi_X(s + h) - \phi_X(s)}{h} & = \frac{E\big(\ex{(s+h)X} - \ex{sX}\big)}{h}\\
      & = E\Big(\ex{sX} \frac{\ex{hX} - 1}{h}\Big).
    \end{split}
  \end{equation}
  Lembrando que $|\tfrac{1}{y}(e^y - 1)| \leq c e^{|y|}$, para todo $y \in \mathbb{R}$, temos que para $h < (\delta - |s|)/2$, o integrando acima é dominado por $c |X| \ex{\smash{\tfrac{\delta + |s|}{2} |X|}} \in \mathcal{L}^1$, logo podemos usar o Teorema da Convergência Dominada para trocar o limite $h \to 0$ com a esperança, obtendo
  \begin{equation}
    \phi_X'(s) = E(X \ex{sX}).
  \end{equation}

  Note que para todo $\varepsilon > 0$ e $k \geq 1$, $|x|^k \leq c(k) \ex{\varepsilon |x|}$, isso nos permite repetir o argumento acima indutivamente para obter \textit{3.} e \textit{4.}
\end{proof}

Lembramos que ao usarmos o método do segundo momento, nos foi bastante útil o fato que a variância se comporta bem com relação a somas independentes.
Mais precisamente, $\Var(X_1 + \dots + X_k) = \Var(X_1) + \dots + \Var(X_k)$.

Uma outra propriedade importante da função geradora de momentos é que ela também se comporta bem com respeito à somas independentes.
\begin{proposition}
  Se $X_1, \dots, X_n$ são variáveis independentes com $\phi_{X_i}(s) < \infty$ para todo $i \leq k$ e $|s| < \delta$, então
  \begin{equation}
    \phi_{X_1 + \dots + X_k}(s) = \phi_{X_1}(s) \dotsm \phi_{X_k}(s), \text{ para todos $|s| < \delta$.}
  \end{equation}
\end{proposition}

\begin{proof}
  Basta observar que
  \begin{equation}
    \begin{split}
      E(\exp & \{s(X_1 + \dots + X_k)\}) = E(\ex{sX_1} \dotsm \ex{sX_k}))\\
      & = E\big(\ex{sX_1}) \dotsm E(\ex{sX_k}\big) = \phi_{X_1}(s) \dotsm \phi_{X_k}(s),
    \end{split}
  \end{equation}
  usando Fubini.
\end{proof}

Consideraremos agora uma sequência $X_1, X_2, \dots$ de variáveis \iid com $\phi_{X_1}(s) < \infty$ para $|s| < \delta$.
Então podemos tentar estimar, para $a > 0$ e $|s| < \delta$,
\begin{equation*}
  \begin{split}
    P \Big[ & \frac{X_1 + \dots + X_n}{n} - E(X_1) \geq a \Big] = P \Big[ X_1 + \dots + X_n \geq (a + E(X_1)) n \Big]\\
    & \quad = P \Big[ \ex{s(X_1 + \dots + X_n)} \geq \ex{s (a + E(X_1)) n}\Big]\\
    & \quad \leq \phi_{X_1 + \dots + X_n}(s) \ex{-s (a + E(X_1))n } = \phi_{X_1}^n(s) \ex{-s (a + E(X_1))n }.
  \end{split}
\end{equation*}
O primeiro fator na estimativa acima pode crescer exponencialmente com $n$, enquanto o segundo decresce.
Gostaríamos que o comportamento do segundo predominasse, o que podemos concluir do seguinte argumento.

Sabemos que $\phi_{X_1}(s)$ é diferenciável em zero e que $\phi'_{X_1}(0) = E(X_1)$.
Logo, existe $s > 0$ tal que $\phi_{X_1}(s) < 1 + (E(X_1) + \tfrac{a}{2}) s$, donde
\begin{equation*}
  \begin{split}
    P \Big[ & \frac{X_1 + \dots + X_n}{n} - E(X_1) \geq a \Big] = P \Big[ X_1 + \dots + X_n \geq (E(X_1) + a) n \Big]\\
    & \quad \leq \big(1 + (E(X_1) + \frac{a}{2})s \big)^n \ex{-s (E(X_1) + a)n }\\
    & \quad \leq \exp\Big\{ s \Big( E(X_1 + \frac{a}{2} - E(X_1) - a) n \Big) \Big\} = \ex{-san/2}.
  \end{split}
\end{equation*}
Isso nos garante um decaimento exponencial da probabilidade da média dos $X_i$ se desviar da esperança.

\begin{exercise}
  Aplique o método acima para variáveis $X_i$ \iid com distribuição $\Ber(1/2)$ e encontre $s(a)$ que otimize o decaimento da probabilidade $P\big[\sum_{i=1}^n X_i > (1/2 + a) n \big]$.
\end{exercise}

Poderíamos nos perguntar se a cota acima é suficientemente boa.
Talvez pudéssemos esperar um decaimento ainda melhor que exponencial.
Para responder a essa pergunta, vamos considerar o seguinte exemplo.
Sejam $(X_i)_{i \geq 1}$ variáveis \iid com $X_1 \distr \Ber(1/2)$.
Nesse caso temos por exemplo
\begin{equation}
  P\Big[ \big| \frac{X_1 + \dots + X_n}{n} - \frac 12 \big| \geq \frac 14\Big] \geq P[X_i = 1, \forall i \leq n] = 2^{-n}.
\end{equation}
Dessa forma, sabemos que não podemos esperar um decaimento melhor que exponencial, mesmo para variáveis bem simples (como Bernoulli) que satisfazem $\phi_X(s) < \infty$ para todo $s \in \mathbb{R}$.

Note que para variáveis com distribuição $\Ber(1/2)$, temos cotas exponenciais em $n$ (superior e inferior), mas elas possuem expoentes diferentes.
Resta agora tentar entender qual é o expoente correto para o decaimento da probabilidade $P[X_1 + \dots + X_n \geq n(E(X_1) + a)]$, o que será feito na próxima seção.

\begin{exercise}
  Na Nova Caledônia, temos $k$ habitantes.
  Seja $f:\{1, \dots, k\} \to \{0,1\}$ uma função que indica a intenção de voto de cada cidadão.
  Mais precisamente, para cada habitante $i \in \{1, \dots, k\}$, se $f(i) = 0$, então $i$ vota no candidato $0$, enquanto se $f(i) = 1$, o cidadão $i$ vota no candidato $1$.
  Para estimar o número $k_1 = \# f^{-1}(\{1\})$ de pessoas que votam em $1$, nós escolhemos variáveis aleatórias $Y_i$ i.i.d. com distribuição uniforme em $\{1, \dots, k\}$ e queremos estimar
  \begin{equation}
    \text{Err}_n(\epsilon) = P \Big[ \Big| \frac{1}{n} \sum_{i=1}^n f(Y_i) - \frac{k_1}{k} \Big| > \epsilon \Big].
  \end{equation}
  Sabendo que $k$ é par e $k_1 = k/2$, então
  \begin{enumerate}[\quad a)]
  \item use o método do segundo momento para obter um $n$ tal que $\text{Err}_{n}(0.01) < 0.02$ e um $n$ tal que $\text{Err}_{n}(0.01) < 10^{-12}$,
  \item use o método do momento exponencial para obter resolver o ítem acima.
  \end{enumerate}
  Compare os quatro resultados obtidos acima.
\end{exercise}

\todosec{Tópico: Processos de ramificação}{fazer...}

\section{Princípio de Grandes Desvios}
\label{s:PGD}

\todo{lim vira liminf ou limsup}

A primeira tarefa nossa será otimizar a estimativa grosseira feita na seção anterior.
Essas estimativas são chamadas de \emph{estimativas de grandes desvios}, pois se referem a probabilidades que a média empírica de $X_i$ se desvie de sua esperança por um valor constante $a$.
Futuramente no curso estudaremos as probabilidades de que esse desvio seja de ordem $a_n \to 0$ que são chamados de \emph{desvios moderados} ou \emph{flutuações}, dependendo se a probabilidade de desvio converge a zero ou não.

\todo{o limite dos grandes desvios existe}

\begin{theorem}[Princípio de Grandes Desvios - cota superior]
  \index{Principio@Princípio!de Grandes Desvios@de Grandes Desvios}
  \label{t:PGDleq}
  Consideramos variáveis aleatórias \iid $X_1, X_2, \dots$ tais que $\phi_{X_1}(s) < \infty$, para todo $s \in (-\delta, \delta)$.
  Então, para $a > 0$,
  \begin{equation}
    P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \leq \ex{-\psi_{X_1}(m + a) n},
  \end{equation}
  onde $m = E(X_1)$ e
  \begin{equation}
    \psi_{X_1}(b) = \sup_{s \geq 0} \big\{ bs - \log \big( \phi_{X_1}(s) \big) \big\}
  \end{equation}
  é chamada função taxa. \index{funcao@função!taxa}
\end{theorem}

É importante observar que para estimar $P\big(X_1 + \dots + X_n \leq (m - a)n\big)$, basta considerarmos $X'_i = -X_i$ ao utilizar o teorema acima.

%Antes de provar o teorema, vamos fazer uma breve observação sobre como a função geradora de momentos se comporta com respeito a soma de constantes.
%Isso nos permitirá centrar as variáveis para nossas estimativas.
%
%\begin{lemma}
%  \label{l:phi_Xmaisb}
%  Seja $X$ uma variável aleatória tal que para algum $s_0 > 0$ tenhamos $\phi_{X}(s) < \infty$ para todo $s \in (-\delta, \delta)$.
%  Então
%  \begin{equation}
%    \log\big(\phi_{X - b}(s)\big) = \log\big(\phi_{X}(s)\big) -bs < \infty, \text{ para todo $s \leq s_0$.}
%  \end{equation}
%\end{lemma}

%\begin{proof}
%  Basta observar que
%  \begin{equation}
%    \phi_{X - b}(s) = E\big( \ex{s(X-b)} \big) = \ex{-sb} E\Big( \ex{sX}\Big) = \ex{-sb} \phi_X(s),
%  \end{equation}
%  e tomar logarítmos de ambos os lados para obter o resultado.
%\end{proof}

\begin{proof}
  Já sabemos que, para todo $s \geq 0$,
  \begin{equation}
    \begin{split}
      P\big[ X_1 & + \dots + X_n \geq \big(m + a \big) n \big] \leq \phi_{X_1}^n (s) \ex{-s (m + a) n}\\[1mm]
      & = \ex{ \log \big( \phi_{X_1}(s)\big) n - s(m + a) n}\\
      & = \ex{ - \big( (m + a)s - \log \big( \phi_{X_1}(s)\big) \big) n}\\
%      & \overset{\text{Lema}~\ref{l:phi_Xmaisb}\;\;}= & \ex{ \log \big( \phi_{X_1 - m}(s) \big) n - s a n}\\
%      & = & \ex{ - \big(as -\log \big( \phi_{X_1 - m}(s) \big) \big) n}
    \end{split}
  \end{equation}
  O que termina a prova do teorema se tomamos o ínfimo em $s \geq 0$.
\end{proof}

\begin{exercise}
  Calcule $\psi_X(a)$ quando $X$ é distribuída como $U_{[0,1]}$ e $\Exp(\lambda)$.
\end{exercise}

Vamos agora tomar um exemplo concreto para análise.
Sejam $X_1, X_2, \dots$ variáveis aleatórias \iid com distribuição $\Ber(1/2)$, donde
\begin{equation}
  \phi_{X_1}(s) = \frac{1}{2} (1 + e^s) \quad \text{e} \quad \psi_{X_1}(b) = \sup_{s \geq 0} \{bs - \log(1 + e^s) + \log(2) \}.
\end{equation}
Um cálculo simples nos mostra que, se $b < 1$, o mínimo acima é atingido no único ponto $s_{\text{max}} = \log(\tfrac{b}{1-b})$.
Portanto, podemos concluir do Teorema~\ref{t:PGDleq} que
\begin{equation}
  \begin{split}
    P[X_1 + \dots & + X_n > 1/2 + a] \leq \ex{- \psi_{X_1}(s_{\text{max}})n}\\
    & = \exp\Big\{-n \Big(b \log(b) + (1-b)\log(1-b) + \log(2) \Big)\Big\}
  \end{split}
\end{equation}
Note que $P[X_1 + \dots + X_n = n] = 2^{-n} = \ex{-\log(2)n} = \ex{-\psi_{X_1}(1-)n}$.
Isso nos dá um forte indício de que talvez nossas cotas superiores não estejam tão longe de ser precisas.
Para confirmar essa hipótese, precisamos obter cotas inferiores parecidas.

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=3]
    \draw[->] (-0.2,0) -- (1.2,0) node[right] {$b$};
    \draw[-] (1,0.02) -- (1,-0.02) node[below] {$1$};
    \draw[-] (0.02,{ln(2)}) -- (-0.02,{ln(2)}) node[left] {$\log(2)$};
    \node[below left] at (0,0) {$0$};
    \draw[->] (0,-0.2) -- (0,1.1) node[above] {$\psi_{X}(b)$};
    \draw[domain=0.0001:0.9999,smooth,variable=\x,blue] plot ({\x},{\x*ln(\x) + (1 - \x)*ln(1 - \x) + ln(2)});
    \draw[->] (1.8,0) -- (3.2,0) node[right] {$b$};
    \draw[-] (3,0.02) -- (3,-0.02) node[below] {$1$};
    \node[below left] at (2,0) {$0$};
    \draw[->] (2,-0.2) -- (2,1.6) node[above] {$\psi_{X'}(b)$};
    \draw[domain=2.0001:2.9999,smooth,variable=\x,blue] plot ({\x},{(\x-2)*ln((\x - 2)/0.75) + (1 - \x + 2)*ln((1 - \x + 2)/(0.25))});
    \draw[-,dotted] (3,{ln(4/3)}) -- (1.98,{ln(4/3)}) node[left] {$\log(4/3)$};
    \draw[-] (2.02,{ln(4)}) -- (1.98,{ln(4)}) node[left] {$\log(4)$};
  \end{tikzpicture}
  \caption{Funções taxa $\psi_{X}(b)$ de uma variável $X$ com distribuição $\Ber(1/2)$, e $\psi_{X'}(b)$ de uma variável com distribuição $\Ber(3/4)$, para $b \in (0,1)$.}
\end{figure}

Antes de buscar cotas inferiores para as probabilidades de desvio, vamos estabelecer algumas propriedades da função $\psi_X(b)$.
Primeiramente, quando podemos dizer que o supremo na definição de $\psi_X$ é atingido em algum $s_{\text{max}}$?
Certamente, esse nem sempre é o caso, por exemplo se $X = m$ quase certamente, então $\phi_X(s) = e^{sm}$ e o supremo definindo $\psi_X(b)$ não é atingido se $b \neq m$.

\begin{lemma}
  \label{l:smax_PGD}
  Seja $X$ uma variável aleatória tal que $\phi_X(s) < \infty$ para todo $s \in (-\delta, \delta)$.
  Supondo $a \geq 0$ é tal que $P[X > m + a] > 0$, então existe $s_{\text{max}} \geq 0$ tal que $\psi_X(m + a) = (m + a)s_{\text{max}} - \log\big(\phi_X(s_\text{max})\big)$.
\end{lemma}

\begin{proof}
  Por hipótese, existe $b > m + a$ tal que $p = P[X \geq b] > 0$, donde $\phi_X(s) \geq p e^{s(m+a)}$.
  Dessa forma, $(m + a)s - \log\big( \phi_X(s) \big) \leq (m + a - b)s - \log(p)$, que converge a menos infinito quando $s$ diverge.
  Isso, junto com a continuidade de $\phi_X$ implica a existência do $s_{\text{max}}$ desejado.
\end{proof}

\todo{provar que a função taxa é convexa, portanto contínua (está como exercício mas é usado)}

\begin{exercise}
  Suponha que se $\phi_{X}(s)$ é finita para todo $s \in (-\delta, \delta)$ e mostre que
  \begin{enumerate}[\quad a)]
  \item na definição de $\psi_{X}(a)$, poderíamos tomar o ínfimo em todos $s \in \mathbb{R}$ (ao invéz de $s \geq 0$) sem mudar o valor de $\psi_X(a)$,
  \item a função $\psi_{X}(s)$ é não negativa, semi-contínua inferior e convexa em seu domínio e
  \item $\psi_X(a)$ se anula somente em $a = 0$ e $\psi_X$ é crescente no seu domínio.
  \end{enumerate}
\end{exercise}

Buscaremos agora cotas inferiores para a probabilidade de obter um grande desvio.
Gostaríamos que essas estimativas fossem o mais próximas possíveis das estimativas superiores obtidas acima.
Certamente não podemos obter algo como
\begin{equation}
  \label{e:PGDgeq_falso}
  `` P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \geq \exp\{-\psi_{X_1}(a) n\} ",
\end{equation}
pois senão isso nos daria uma igualdade o que é impossível, pois perdemos um pouco de precisão ao utilizar a desigualdade de Markov na cota superior.

Contudo, gostaríamos de entender se ao menos o expoente $\psi_{X_1}(a)$ na cota superior também desempenha algum papel na cota inferior.
Isso é confirmado no seguinte resultado

\begin{theorem}[Princípio de Grandes Desvios - cota inferior]
  \index{Principio de Grandes Desvios@Princípio de Grandes Desvios}
  \label{t:PGDgeq}
  Sejam $X_1, X_2, \dots$ variáveis aleatórias \iid com $\phi_{X_1}(s) < \infty$, para todo $s \in \mathbb{R}$.
  Então, para todo $a > 0$,
  \begin{equation}
    \liminf_{n \to \infty} \frac{1}{n} \log P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] \geq -\psi_{X_1}(m + a),
  \end{equation}
  onde novamente $m = E(X_1)$ e $\psi_{X_1}(b)$ é definida como no Teorema~\ref{t:PGDleq}.
\end{theorem}

Note que o resultado do teorema acima é mais fraco que o que vemos na equação \eqref{e:PGDgeq_falso}, mas mostra que $\psi_{X_1}(a)$ é realmente o expoente correto no decaimento da probabilidade de grandes desvios.

A idéia da prova é transformar a distribuição de $X_i$, usando uma exponencial como derivada de Radon-Nikodim.
Essa nova distribuição possuirá esperança maior que $m + a$, de forma que se tomamos a média de variáveis \iid $X'_1, \dots, X'_n$ distribuídas dessa forma, obteremos algo que se concentra acima de $m + a$.
Finalmente, o preço pago para que as variáveis $X_i$ se comportem como as $X'_i$ será aproximadamente $\ex{-\psi_{X_1}(m + a)}$, como desejado para nossa cota inferior.

\begin{proof}
  Primeiramente, consideraremos o caso $P[X_1 \leq m + a] = 1$.
  Nesse caso, temos
  \begin{equation*}
    \begin{split}
      P\big[ X_1 + \dots + X_n \geq \big(m + a \big) n \big] & = P[X_i = m + a, \text{ para todo $i \leq n$}]\\
      & = P[X_1 = m + a]^n.
    \end{split}
  \end{equation*}
  Donde o limite acima é igual a $\log(P[X_1 = m + a])$.

  Mas por outro lado,
  \begin{equation*}
    \begin{split}
      - \psi_{X_1}(m + a) & = \inf_{s \geq 0} \big\{ \log\big(E(\ex{s (X_1)})\big) - (m + a)s \big\} = \inf_{s \geq 0} \big\{ \log\big(E(\ex{s (X_1 - m - a)})\big) \big\}\\
      & \leq \liminf_{s \to \infty} \; \log\big(E(\ex{s (X_1 - m - a)})\big) = \log \big(P[X_1 = m + a]\big),
    \end{split}
  \end{equation*}
  pelo Teorema da Convergência Dominada, demonstrando o teorema nesse caso especial.

  Suponhamos agora que $P[X_1 > m + a] > 0$, o que implica que para $b > m + a$ suficientemente próximo de $m + a$, temos $P[X_1 > b] > 0$.
  Observe que basta mostrar que para tais $b$ e para todo $\delta > 0$,
  \begin{equation}
    \label{e:PGD_perto_b}
    \lim_n \frac{1}{n} \log \Big(P\Big[\frac{X_1 + \dots + X_n}{n} \in (b - \delta, b + \delta) \Big]\Big) \geq -\psi_{X_1}(b),
  \end{equation}
  pois a função $\psi_{X_1}(b)$ é convexa, portanto contínua.

  Vamos definir uma nova distribuição $\nu$ com derivada de Radon-Nikodim
  \begin{equation}
    \d \nu = \frac{1}{Z_\sigma} \ex{\sigma x} (X_1 \circ P) (\d x).
  \end{equation}
  Observamos primeiramente que o valor de $\sigma$ ainda não foi escolhido.
  Além disso após escolhido $\sigma$, teremos que calcular a constante de normalização $Z_{\sigma}$ de forma que $\nu$ seja uma probabilidade.

  Escolheremos $\sigma \geq 0$ como no Lema~\ref{l:smax_PGD}, isto é, tal que $\psi_{X_1}(b) = b\sigma - \log\big( \phi_{X_1}(\sigma) \big)$.
  Isso nos dá imediatamente que $Z_\sigma = E[\ex{\sigma X_1}] = \phi_{X_1}(\sigma)$.
  Por diferenciabilidade de $\phi_{X_1}$, o máximo deve ser assumido em um ponto de derivada zero, ou seja
  \begin{equation}
    b = \frac{\phi_{X_1}'(\sigma)}{\phi_{X_1}(\sigma)} \overset{\text{Prop.~\ref{p:propried_phi}}}= \frac{E(X \ex{\sigma X})}{E(\ex{\sigma X})} = \frac{E(X \ex{\sigma X})}{Z_\sigma} = \int x \nu(\d x).
  \end{equation}
  Isso implica que se uma variável aleatória tem distribuição $\nu$, sua esperança é $b$.
  Obviamente uma tal variável aleatória $X'$ satisfaz obrigatoriamente $\phi_{X'}(s) < \infty$ para todo $s \geq 0$, donde $X' \in \mathcal{L}^p$ para todo $p > 1$.

  Como prometido, consideramos variáveis $X_1', X_2', \dots$ \iid com distribuição $\nu$.
  Pela lei fraca dos grandes números, para qualquer $\delta > 0$,
  \begin{equation}
    \lim_n P\Big[ \frac{X_1' + \dots + X_n'}{n} \in (b-\delta,b+\delta) \Big] = 1.
  \end{equation}

  Finalmente vamos relacionar essa probabilidade à probabilidade definida em termos de $X_i$, na qual estamos interessados.
  \begin{equation*}
    \begin{split}
      P\Big[ & \frac{X_1 + \dots + X_n}{n} \in (b-\delta, b+\delta) \Big] = \int_{x_i; \big| \tfrac{1}{n} \sum_{i \leq n} x_i - b\big| < \delta} \;\; \bigotimes_{i=1}^n (X_1 \circ P)(\d x_i)\\
      & = Z_\sigma^n \int_{x_i; \big| \tfrac{1}{n} \sum_{i \leq n} x_i - b \big| < \delta} \;\; \ex{-\sigma \textstyle{\sum_{i=1}^n x_i}} \bigotimes_{i=1}^n (X_1' \circ P)(\d x_i)\\[2mm]
      & \geq Z_\sigma^n \exp\{-(b + \delta) \sigma n\} P\Big[ \frac{X_1' + \dots + X_n'}{n} \in (b-\delta,b+\delta) \Big].
    \end{split}
  \end{equation*}
  Tomando o logarítmo, dividindo por $n$ e tomando o liminf quando $n$ vai a infinito, recuperamos
  \begin{equation}
    \begin{split}
      \lim_n \frac{1}{n} \log \Big(P\Big[ & \frac{X_1 + \dots + X_n}{n} \in (b - \delta,b +  \delta) \Big] \Big) \geq \log(Z_\sigma) - (b + \delta) \sigma\\
      & = \log(\phi_{X_1}(\sigma)) - (b + \delta) \sigma = -\psi_{X_1}(\sigma) - \delta \sigma.
    \end{split}
  \end{equation}
  Como isso vale para todo $\delta > 0$, provamos \eqref{e:PGD_perto_b} o que conclui a prova do teorema.
\end{proof}


\begin{exercise}
  Mostre o Teorema~\ref{t:PGDgeq} no caso em que $\phi_{X_1}(s) < \infty$, para todo $s \in (-\delta, \delta)$.
\end{exercise}

\section{O Teorema Central do Limite}

Até esse momento, já estudamos bastante somas de variáveis aleatórias independentes.
Agora estudaremos esse tópico pela última vez, mas atravéz de uma técnica bastante elegante, que certamente inspira vários trabalhos em probabilidade.

\subsection{A distribuição normal}

Começaremos estudando de maneira sistemática o que acontece quando somamos duas variáveis aleatórias \iid em termos de distribuição.
Isso pode ser visto como um operador no espaço de distribuições em $\mathbb{R}$ que definiremos a seguir.
Estaremos interessados nos pontos fixos de tal operador, mas antes, vamos fazer uma observação simples que evitará trivialidades.

\begin{lemma}
  Sejam $X$ e $Y$ variáveis aleatórias em $\mathcal{L}^2$, \iid com distribuição $\mu$.
  Nesse caso, se $X + Y$ também tem distribuição $\mu$, então $\mu = \delta_0$.
\end{lemma}

\begin{proof}
  Sabemos que
  \begin{equation}
    \begin{split}
      E(X + Y) & = E(X) + E(Y) = 2 E(X) \text{ e}\\
      \Var(X + Y) & = \Var(X) + \Var(Y) = 2 \Var(X).
    \end{split}
  \end{equation}
  Mas como $X + Y$ tem a mesma distribuição de $X$, então $E(X) = 2 E(X)$ e $\Var(X) = 2 \Var(X)$, donde ambas são zero.
  Usando o método dos segundo momento, para todo $a > 0$,
  \begin{equation}
    P[|X| \geq a] \leq \frac{\Var(X)}{a^2} = 0,
  \end{equation}
  terminando a prova de que $X = 0$ quase certamente.
\end{proof}

A intuição dessa prova é que quando somamos duas variáveis não determinísticas, a incerteza da soma (medida atravéz da variância) tende a aumentar.
Dessa forma não podemos continuar com a mesma distribuição.

Mas existe uma maneira simples de tornar esse problema bastante interessante novamente.
Digamos que $X$ e $Y$ pertencem a $\mathcal{L}^2$ e são i.i.d.
Então
\begin{equation}
  \Var(X + Y) = 2 \Var(X) = \Var(\sqrt{2} X).
\end{equation}
Então podemos nos perguntar se

\begin{question}
  \label{q:ponto_fixo_soma}
  Existe alguma distribuição não trivial $\mu$ em $\mathcal{L}^2$ tal que, se $X$ e $Y$ são independentes e distribuídas de acordo com $\mu$, temos
  \begin{equation}
    \frac{X + Y}{\sqrt{2}} \distr \mu \; ?
  \end{equation}
\end{question}

Para tentar responder essa questão, vamos estudar mais a fundo qual é a distribuição da soma de duas variáveis aleatórias independentes.
Para isso, considere a distribuição $(X,Y) \circ P$ do par, que coincide com $\mu \otimes \mu$, nos dando
\begin{equation}
  P\Big[ \frac{X + Y}{\sqrt{2}} \leq z \Big] = \mu \otimes \mu \big( \big\{(x, y); \tfrac{x + y}{\sqrt{2}} \leq z \big\} \big).
\end{equation}

Note também que a transformação linear $(x,y) \mapsto \tfrac{1}{\sqrt{2}}\big(x + y, x - y\big)$ é uma rotação rígida em $\mathbb{R}^2$, o que nos motiva a propor a pergunta mais simples.

\begin{question}
  Existe alguma distribuição não trivial $\mu$ em $\mathcal{L}^2$ tal que, se $X$ e $Y$ são independentes e distribuídas de acordo com $\mu$, temos que a distribuição do par $(X,Y)$ é invariante por rotações?
\end{question}

Ainda estamos numa busca não rigorosa de tal distribuição, então vamos supor algumas outras propriedades, como por exemplo que $\mu$ seja absolutamente contínua com respeito a Lebesgue, isto é $\d \mu = f(x) \d x$.
Nesse caso, já vimos que $(X, Y) \circ f(x) f(y) \d x \d y$ e no fundo estamos procurando uma função $f$ tal que
\begin{equation}
  f(x) f(y) = h(x^2 + y^2), \text{ para todo $x, y \in \mathbb{R}$ e alguma $h: \mathbb{R}_+ \to \mathbb{R}_+$.}
\end{equation}
Se $g = \log f$ e $k = \log h$, no fundo buscamos $g(x) + g(y) = k(x^2 + y^2)$.
Como ainda não estamos preocupados com unicidade de $\mu$ por enquanto, apenas existência, podemos simplesmente tomar $g(x) = \alpha x^2 - \beta$.

Como gostaríamos que $f(x) = \ex{\alpha x^2 - \beta}$ fosse uma densidade, ou seja $\int f \d x = 1$.
Para isso, precisamos que $\alpha$ seja negativo e, fixado $\alpha$, o valor de $\beta$ já estará determinado por normalização.
Tudo isso motiva finalmente a seguinte

\begin{definition}
  Dizemos que $X$ tem distibuição normal canônica, se \index{distribuicao@distribuição!normal}
  \begin{equation}
    \label{e:normal_canonica}
    X \distr \frac{1}{\sqrt{2 \pi}} \exp \big\{-x^2/2\big\} \d x.
  \end{equation}
  Além disso, para $m \in \mathbb{R}$ e $\sigma \geq 0$, dizemos que $Y \distr \mathcal{N}(m, \sigma^2)$ se $Y$ tem a mesma distribuição de $\sigma X + m$, onde $X$ tem distribuição normal canônica ($\mathcal{N}(0, 1)$).
\end{definition}

Muitas vezes chamamos essa distribuição de gaussiana, obviamente em homenagem a Gauss.
Note que $\mathcal{N}(m, 0) = \delta_m$.

Vamos rapidamente observar que a definição acima realmente descreve uma distribuição de probabilidade, ou seja que a integral da densidade acima é um.
Para tanto, vamos usar um truque conhecido, que consiste em retornar ao plano.
Obviamente,
\begin{equation}
  \begin{split}
    \Big(\int \exp \big\{-x^2/2\big\} \d x\Big)^2 & = \int \int \exp \big\{-(x^2 + y^2)/2\big\} \d x \d y\\
    & = \int_0^{2 \pi} \int_0^\infty \exp \{ - r^2 / 2 \} r \d r \d \theta \overset{2 s \; = \; r^2}= 2 \pi.
  \end{split}
\end{equation}
Donde a constante em \eqref{e:normal_canonica} está de fato correta.

\begin{exercise}
  Mostre que a distribuição $\mathcal{N}(m, \sigma^2)$, tem densidade
  \begin{equation}
    \frac{1}{\sigma \sqrt{2 \pi}} \ex{-(x - m)^2/(2 \sigma^2)}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Mostre que se $Y \distr \mathcal{N}(m, \sigma^2)$, então $Y$ tem esperança $m$ e variância $\sigma^2$.
\end{exercise}

Para confirmar que de fato as distribuições normais se comportam bem com respeito a somas independentes, apresentamos o seguinte resultado.

\begin{proposition}
  \label{p:soma_normais}
  Se $X \distr \mathcal{N}(m, \sigma^2)$ e $Y \distr \mathcal{N}(\bar{m}, \bar{\sigma}^2)$ são independentes, então $X + Y$ tem distribuição $\mathcal{N}(m + \bar{m}, (\sigma + \bar{\sigma})^2)$.
\end{proposition}

\begin{proof}
  O caso em que $\sigma$ ou $\bar{\sigma}$ se anulam é trivial, portanto vamos considerar que ambas são positivas.
  Não é difícil ver que podemos também supor que $m = \bar{m} = 0$.
  Podemos então calcular
  \begin{equation}
    P[X + Y \leq a] = P[\sigma W + \bar{\sigma} Z \leq a],
  \end{equation}
  onde $W$ e $Z$ são independentes com distribuição $\mathcal{N}(0,1)$.
  Assim, a probabilidade acima pode ser escrita como
  \begin{equation}
    \label{e:soma_normal}
    \mathcal{N}(0,1) \otimes \mathcal{N}(0,1) \Big( \big\{ (w,z) \in \mathbb{R}^2; \sigma w + \bar{\sigma} z \leq a \big\} \Big).
  \end{equation}
  Agora aplicaremos a rotação rígida $A: \mathbb{R}^2 \to \mathbb{R}^2$ dada por
  \begin{equation}
    A(w,z) = \frac{1}{\sqrt{\sigma^2 + \bar{\sigma}^2}} \big( \sigma w + \bar{\sigma} z, \bar{\sigma} w - \sigma z \big).
  \end{equation}

  Como sabemos que a densidade $f$ de $(W,Z)$ é invariante por $A$, ou seja $f \circ A = f$, então podemos escrever \eqref{e:soma_normal} como
  \begin{equation*}
    \begin{split}
      \mathcal{N}(0,1) & \otimes \mathcal{N}(0,1) \Big( A \big(\big\{ (w,z) \in \mathbb{R}^2; \sigma w + \bar{\sigma} z \leq a \big\} \big) \Big)\\
      & = \mathcal{N}(0,1) \otimes \mathcal{N}(0,1) \Big( \Big\{(w,z); \frac{1}{\sqrt{\sigma^2 + \bar{\sigma}^2}}w \leq a \Big\} \Big)\\
      & = \mathcal{N}(0,1) \big( (-\infty, a \sqrt{\sigma^2 + \bar{\sigma}^2} \big] \big) = \mathcal{N}(0,\sigma^2 + \bar{\sigma}^2) \big( (-\infty, a \big] \big),
    \end{split}
  \end{equation*}
  terminando a prova da proposição.
\end{proof}

\todo{Fazer as iteradas do operador convolução, isso nos dá a normalizada com $\sqrt{2^j}$, depois trocamos $2^j$ por $n$.}

Podemos obter um corolário interessante sobre a soma de várias normais i.i.d.
\begin{corollary}
  \label{c:normaliz_normais}
  Sejam $X_1, X_2, \dots$ variáveis \iid com distribuição $\mathcal{N}(m,\sigma^2)$, então
  \begin{equation}
    X_1 + \dots + X_n \distr \mathcal{N}(nm, n \sigma^2).
  \end{equation}
  Como consequência
  \begin{equation}
    \frac{\sum_{i=1}^n X_i - n E(X_1)}{\sigma \sqrt{n}} \distr \mathcal{N}(0,1).
  \end{equation}
\end{corollary}

Lembrando da Lei dos Grandes Números, se dividimos a soma dos $X_i - E(X_i)$ por $n$, essa fração vai a zero quase certamente,
O que concluímos acima é que podemos dividir por $\sqrt{n}$ e teremos um limite não trivial (nem zero, nem infinito).

Mais uma observação curiosa: nossa motivação para a definição da distribuição normal passou por invariância por rotações e podemos extender essa invariância para $n$ normais independentes.
Note que a somar as coordenadas canônicas é equivalente a multiplicar pelo vetor $(1,1,\dots,1)$, que tem norma euclideana $\sqrt{n}$.

Uma outra maneira de entender o corolário acima é que a normal é um ponto fixo da operação seguinte
\begin{enumerate}[\quad a)]
\item tome uma distribuição $\mu \in \mathcal{L}^2$,
\item considere $X_1, \dots, X_n$ \iid com distribuição $\mu$ e
\item retorne a distribuição de
  \begin{equation}
    \frac{X_1 + \dots + X_n - n E(X_1)}{\sqrt{\Var(X_1) n}}.
  \end{equation}
\end{enumerate}

Na Questão~\ref{q:ponto_fixo_soma}, nos perguntamos quais seriam os outros possíveis pontos fixos dessa operação e será isso considerado depois.
Mas uma outra questão bastante importante é se o ponto fixo $\mathcal{N}(0,1)$ é atrator, ou seja se começando com outras distribuições poderíamos nos aproximar de $\mathcal{N}(0,1)$ à medida que $n$ cresce.

Isso é estudado no Teorema Central do Limite (TCL) que provaremos posteriormente.
Mas antes, precisamos desenvolver uma boa definição de convergência para distribuições o que será o nosso próximo tópico.

\todo{Mencionar que queremos saber se o ponto fixo $\mathcal{N}(0,1)$ é atrator.}

\subsection{Convergência fraca}

Em muitos casos é importante ter uma noção de convergência de medidas de probabilidade.
Supondo por exemplo no espaço mensurável $(E,\mathcal{A})$, tenhamos uma sequência de probabilidades $\mu_n$ e gostaríamos de saber se ela converge a uma determinada $\mu$.

Um candidato natural para dara sentido a essa convergência poderia se a distância de variação total entre duas medidas
\begin{equation}
  d_{\VT}(\mu,\nu) = \sup_{A \in \mathcal{A}} |\mu(A) - \nu(A)|.
\end{equation}
Não é difícil mostrar que a definição acima induz uma métrica, mas ela possui alguns problemas que descreveremos a seguir.

\begin{exercise}
  Mostre que $d_{\VT}$ define uma métrica.
\end{exercise}

\begin{exercise}
  Sejam $\mu$ e $\nu$ absolutamente contínuas com respeito a uma medida fixa $\eta$, tendo densidades $\rho$ e $\pi$ respectivamente.
  Encontre uma fórmula para $d_{\VT}(\mu, \nu)$ em termos das densidades.
  Essa fórmula nos remete a qual distância entre funções?
\end{exercise}

Digamos que o espaço amostral $E$ já seja provido de uma métrica $d$ e $\mathcal{A}$ seja a $\sigma$-álgebra dos borelianos em $E$.
Qualquer que seja a noção de convergência que iremos considerar, gostaríamos de dizer que $\delta_{x_n}$ converge a $\delta_x$ sempre que $x_n \to x$ em $E$.
Esse porém não é o caso para $d_{\VT}$, pois se $x_n \neq x$ para todo $n$ e $\{x\} \in \mathcal{A}$, teríamos
\begin{equation}
  d_{\VT}(\delta_{x_n}, \delta_x) \geq |\delta_{x_n}(\{x\}) - \delta_{x}(\{x\}) | = |0 - 1| = 1.
\end{equation}

Aqueles que já viram o conceito de convergência fraca acharão natural que a convergência de $\mu_n$ para $\mu$ seja definida em termos da convergência das integrais $\int f \d \mu_n$ para $\int f \d \mu$.
Porém, como mencionamos no exemplo das medidas $\delta_{x_n}$ acima, gostaríamos também de a convergência respeitasse a topologia original do espaço $E$, o que torna natural a seguinte

\begin{definition}
  Dizemos que uma sequência de medidas de probabilidade $\mu_n$ converge fracamente (ou converge em distribuição) para uma probabilidade $\mu$ se \index{convergencia@convergência!fraca}
  \begin{equation}
    \lim_{n \to \infty} \int f \d \mu_n = \int f \d \mu, \text{ para toda $f:E \to \mathbb{R}$ contínua e limitada.}
  \end{equation}
  Essa convergência muitas vezes é denotada por $\mu_n \Rightarrow \mu$.
\end{definition}

Essa definição fica ainda mais natural para aqueles que conhecem o Teorema da Representação de Riesz.
Com isso em mente, podemos relacionar a convergência em distribuição com a convergência fraca$^*$ no espaço de medidas finitas.

\begin{exercise}
  Mostre que em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, temos que $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n} \Rightarrow U_{[0,1]}$.
\end{exercise}

\begin{exercise}
  Considere a função $\phi$ do espaço de medidas em $([0,1], \mathcal{B}([0,1]))$ nele mesmo, dada pelo seguinte:
  \begin{equation}
    \phi(\mu)(A) = \tfrac{1}{2} \big( \mu(3A) + \mu(3A - 2) \big).
  \end{equation}
  Identifique o limite em distribuição de $\phi^{(n)}(\delta_0)$.
  Mostre que
  \begin{enumerate}[\quad a)]
  \item a função de distribuição acumulada associada ao limite é contínua,
  \item o limite não é absolutamente contínuo com respeito à medida de Lebesgue.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Sejam $X_1, X_2, \dots$ i.i.d. distribuidas como $\text{Exp}(1)$ e defina
  \begin{equation}
    M_n = \max_{i = 1, \dots, n} X_i.
  \end{equation}
  Mostre que $M_n - \log(n)$ converge fracamente e identifique o limite.
  Observe que não precisamos dividir $M_n - \log(n)$ por nada para obter a convergência.
\end{exercise}


O próximo resultado é bastante útil para provar convergência fraca, pois nos fornece uma coleção de equivalências muitas vezes mais fáceis de verificar.

\begin{theorem}[Teorema de Portmanteau]
  \index{Teorema!de Portmanteau}
  \label{t:portmanteau}
  Sejam $(\mu_n)_{n \geq 1}$ e $\mu$ medidas de probabilidade em $(E, \mathcal{A})$.
  São equivalentes:
  \begin{enumerate}[\quad a)]
  \item[a)] $\mu_n \Rightarrow \mu$,
  \item[a')] $\int f \d \mu_n \to \int f \d \mu$, para toda $f$ unifmormemente contínua e limitada,
  \item[b)] $\limsup_n \mu_n(F) \leq \mu(F),$ para todo $F \subseteq E$ fechado,
  \item[b')] $\liminf_n \mu_n(G) \geq \mu(G),$ para todo $F \subseteq E$ aberto,
  \item[c)] $\lim_n \mu_n(A) = \mu(A),$ para todo $A \in \mathcal{A}$ com $\mu(\partial A) = 0$.
  \end{enumerate}
\end{theorem}

Para memorizar o teorema acima, é conveniente lembrar dos dois exemplos:
\begin{enumerate}[\quad i)]
  \item se $x_n \to x$ com $x_n \neq x$, $F = \{x\}$ e $G = B(x, \delta) \setminus \{x\}$ temos, para $n$ grande,
    \begin{equation}
      \mu_n(F) = \mu(G) = 0 < 1 = \mu(F) = \mu_n(G),
    \end{equation}
  \item em $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, seja $\mu_{2n} = \delta_n$ e $\mu_{2n+1} = \mu = \delta_0$.
    Obviamente $\mu_n$ não converge fracamente a $\mu$. Contudo, para todo $A \in \mathcal{B}(\mathbb{R})$,
    \begin{equation}
      \begin{split}
        \liminf_n \mu_n (A) & \leq \liminf_n \mu_{2n}(A) = \mu(A) \text{ e}\\
        \limsup_n \mu_n (A) & \geq \limsup_n \mu_{2n}(A) = \mu(A).
      \end{split}
    \end{equation}
\end{enumerate}

\begin{proof}[Prova do Teorema~\ref{t:portmanteau}]
  Obviamente, $(a \Rightarrow a')$, pois $a')$ somente supõe a convergência das integrais para funções $f$ que sejam uniformemente contínuas, portanto é um requisito mais fraco que $a)$.

  Observamos também que $(b \Leftrightarrow b')$.
  De fato, basta tomarmos complementos e observar a mudança nos sinais das desigualdades.

  Então, para a prova do teorema, basta mostrar que $(a' \Rightarrow b)$, $(b + b' \Rightarrow c)$ e $(c \Rightarrow a)$.

  Começamos com $(a' \Rightarrow b)$ e para tanto, consideramos $F \subseteq E$ fechado.
  Seja $\delta > 0$ e defina a função $f_\delta: E \to \mathbb{R}$ dada por
  \begin{equation}
    f_\delta (x) = \max \Big\{ 1 - \frac{d(x, F)}{\delta}, 0 \Big\}.
  \end{equation}
  Claramente, $f$ é uniformemente contínua e vale $\1{F} \leq f_\delta \leq \1{B(F,\delta)}$.
  Dessa desigualdade, temos $\limsup_n \mu_n(F) \leq \limsup_n \int f_\delta \d \mu_n = \int f_\delta \d \mu \leq \mu(B(F,\delta))$.
  Tomando agora o limite com $\delta \to 0$, obtemos $b)$ por continuidade da probabilidade $\mu$.


  Para mostrar $(b + b' \Rightarrow c)$, seja $A \in \mathcal{A}$ tal que $\mu(\partial A) = 0$.
  Nesse caso, sabemos que
  \begin{equation*}
    \begin{split}
      \limsup_n \mu_n(A) & \leq \limsup_n \mu_n(\bar A) \leq \mu (\bar A) = \mu (\mathring{A})\\
      & \leq \liminf \mu_n (\mathring{A}) \leq \liminf_n \mu_n (A),
    \end{split}
  \end{equation*}
  o que mostra o limite em $c)$.

  Finalmente, resta mostrar $(c \Rightarrow a)$ e, para tanto, consideramos uma função $f: E \to \mathbb{R}$ contínua e limitada.
  Digamos, com $\lVert f \rVert_\infty = M$.

  Sabemos que os conjuntos $\{f^{-1}(\{a\})\}_{a \in \mathbb{R}}$ são disjuntos, logo os conjuntos $f^{-1}(\{a\})$ podem ter medida $\mu$ positiva apenas para uma coleção enumerável de valores $a \in \mathbb{R}$.
  Obtemos assim uma coleção finita $b_0 < b_1 < \dots < b_k$, tal que
  \begin{equation}
    \begin{array}{c}
      b_0 < -M \text{ e } b_k > M, \quad b_{i+1} - b_i \leq \delta \text{ e}\\
      \mu\big(f^{-1} (\{b_i\}) \big) = 0 \text{ para todo $i \leq k$}.
    \end{array}
  \end{equation}

  \begin{figure}[!ht]
    \centering
    \begin{tikzpicture}[scale=3]
      \draw[->,gray,very thin] (-1,0) -- (1.4,0) node[right,black] {$x$};
      \draw[->,gray,very thin] (0.08,-0.2) -- (0.08,1.3) node[above,black] {$f(x)$};
      \draw[domain=-.8:1.2,smooth,variable=\x,blue] plot ({\x},{ 1/(1 + 10 * \x * \x) });
      \foreach \x in {5,7} { \draw[-,dashed,gray,very thin] ({-sqrt(1 / \x - 0.1)},0) -- ({-sqrt(1 / \x - 0.1)},0.1*\x) -- ({sqrt(1 / \x - 0.1)}, 0.1*\x) -- ({sqrt(1 / \x - 0.1)}, 0); }
      \foreach \x in {-1,1,3,5,7,9,11} { \draw[thick] (.06,0.1*\x) -- (.1, 0.1*\x); }
      \draw[thick] ({-sqrt(1 / 5 - 0.1)},0) -- ({-sqrt(1 / 7 - 0.1)},0);
      \draw[thick] ({sqrt(1 / 5 - 0.1)},0) -- ({sqrt(1 / 7 - 0.1)},0);
    \end{tikzpicture}
    \caption{Uma função contínua e limitada $f$, os pontos $b_i$ e um conjunto $A_i$.}
  \end{figure}

  Iremos aproximar $f$ por uma função da forma $f_\delta = \sum_{i} b_i \1_{A_i}$, onde os conjuntos $A_i = f^{-1}\big( [b_i, b_{i+1}) \big)$ são disjuntos.
  Obviamente $f_\delta \leq f \leq f_\delta + \delta$, donde
  \begin{equation*}
    \liminf \int f_\delta \d \mu_n \leq \liminf \int f \d \mu_n \leq \limsup \int f \d \mu_n \leq \liminf \int f_\delta \d \mu_n + \delta.
  \end{equation*}
  Mas como $\int f_\delta \d \mu_n = \sum_i b_i \mu_n (A_i)$, a prova estará concluida se mostrarmos que $\mu_n (A_i) \to \mu(A_i)$ para todo $i \leq k$.
  Isso segue de $d)$, pois $\partial A_i \subseteq f^{-1}(\{b_i, b_{i+1}\})$, que tem medida zero.
\end{proof}

\begin{exercise}
  Lembrando que em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, temos $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n} \Rightarrow U_{[0,1]}$, use o ítem $d)$ do Teorema~\ref{t:portmanteau} para dar uma caracterização dos conjuntos Riemann-mensuráveis.
  Mais precisamente, encontre os $A \subseteq \mathbb{R}$ tais que $\tfrac{1}{n} \sum_{i=1}^n \delta_{i/n}(A)$ converge para a medida de Lebesgue de $A$.
\end{exercise}

Nós algumas vezes denotamos $X_n \Rightarrow X$ quando $X_n$ e $X$ são elementos aleatórios de $(\Omega, \mathcal{F}, P)$ para descrever a convergência fraca de suas respectivas distribuições.
Mais precisamente, $X_n \circ P \Rightarrow X \circ P$.

\subsection{Convergência fraca em \texorpdfstring{$\mathbb{R}$}{R}}

No caso especial em que $E = \mathbb{R}$, temos vários outras maneiras de caracterizar convergência em distribuição.
A primeira é dada pela seguinte

\begin{proposition}
  \label{p:conv_distr_suave}
  Se $\int g \d \mu_n$ converge para $\int g \d \mu$ para toda $g \in C^3$ limitada e com as três primeiras derivadas limitadas, então $\mu_n \Rightarrow \mu$.
\end{proposition}

\begin{proof}
  Primeiramente, vamos ver que podemos nos concentrar em um conjunto compacto da reta.

  Para isso fixe um $\varepsilon > 0$ e tome $M'$ tal que $\mu\big( [-M', M'] \big) > 1 - \varepsilon / 3$.
  Tomando uma função $g$ satisfazendo as hipóteses do teorema e tal que
  \begin{equation}
    \1{[-M',M']} \leq g \leq \1{[-M'-1,M'+1]},
  \end{equation}
  concluimos que
  \begin{equation}
    \mu_n \big( [-(M'+1), M'+1] \big) \geq 1 - \varepsilon/2,
  \end{equation}
  para todo $n$ suficientemente grande.
  Se tomamos $M \geq M'$ suficientemente grande, podemos obter a cota acima para todo $n$ (com $M$ no lugar de $M'+1$ e $\varepsilon$ no lugar de $\varepsilon/2$).

  Fixamos agora uma $f: \mathbb{R} \to \mathbb{R}$ contínua e limitada.
  Sabemos que é possível aproximar $f$ por uma função $g \in C^3$ de suporte compacto, com $\lVert g \rVert_\infty \leq 2 \lVert f \rVert_\infty$ e $|g - f| \leq \varepsilon/M$ uniformemente no intervalo $[-M,M]$.
  Essa $g$ certamente satisfaz as hipóteses do teorema.

  Portanto,
  \begin{equation*}
    \begin{split}
      \Big| \int f \d \mu_n - \int f \d \mu\Big| & \leq 2 \varepsilon \lVert f \rVert_\infty + \Big| \int_{-M}^M f \d \mu_n - \int_{-M}^M f \d \mu\Big|\\
      & \leq 2 \varepsilon \lVert f \rVert_\infty + \frac \varepsilon{M} 2 M + \Big| \int_{-M}^M g \d \mu_n - \int_{-M}^M g \d \mu\Big|\\
      & \leq 2 \varepsilon \lVert f \rVert_\infty + 2 \varepsilon + \Big| \int g \d \mu_n - \int \d \mu\Big|.
    \end{split}
  \end{equation*}
  Como o último termo converge a zero e $\varepsilon$ foi escolhido arbitrariamente, isso conclui a prova da proposição.
\end{proof}

\subsection{O TCL para uma sequência i.i.d.}

\begin{theorem}
  \index{Teorema!Central do Limite}
  \label{:tcl_iid}
  Considere num espaço $(\Omega, \mathcal{F}, P)$, uma sequência $X_1, X_2, \dots$ de variáveis aleatórias \iid em $\mathcal{L}^3$.
  Nesse caso, se definimos $m = E(X_1)$ e $\sigma^2 = \Var(X_1)$, temos
  \begin{equation}
    \frac{\sum_{i=1}^n (X_i - m)}{\sigma \sqrt{n}} \Rightarrow \mathcal{N}(0,1).
  \end{equation}
\end{theorem}

\begin{proof}
  Primeiramente, observe que podemos supor que $m = 0$, pois de qualquer forma iremos subtrair a média da distribuição na qual nos interessamos.
  Uma outra observação importante é que podemos supor $\sigma = 1$, pois no caso geral de qualquer forma estamos somando $X_i/\sigma$ no enunciado.

  Como vimos na Proposição~\ref{p:conv_distr_suave}, basta mostrar a convergência das integrais de funções $g \in C^3$, que possuam todas as três primeiras derivadas limitadas.
  Considerando a função
  \begin{equation}
    \phi^n(x_1, \dots, x_n) := g\Big(\frac{x_1 + \dots + x_n}{\sqrt{n}} \Big),
  \end{equation}
  nos basta provar a convergência de números reais
  \begin{equation}
    \label{e:tcl_limite_phi}
    \lim_n \int \phi^n(X_1, \dots, X_n) \d P = \int g(s) \mathcal{N}(0,1)(\d s).
  \end{equation}

  Vale lembrar que no Corolário~\ref{c:normaliz_normais} já estabelecemos algo mais forte para variáveis normais.
  Mais precisamente, suponha que extendemos nosso espaço de probabilidade para $(\Omega', \mathcal{F}', P')$, onde exista uma sequência $Y_1, Y_2, \dots$ de variáveis aleatórias \iid com distribuição $\mathcal{N}(0,1)$ independente de $X_1, X_2, \dots$
  Então,
  \begin{equation}
    \int \phi^n(Y_1, \dots, Y_n) \d P' = \int g(s) \mathcal{N}(0,1) (\d s),
  \end{equation}
  o que tornaria o limite em \eqref{e:tcl_limite_phi} trivial para tais variáveis.
  A nossa estratégia será aproximar $\phi^n(X_1, \dots, X_n)$ por $\phi(Y_1, \dots, Y_n)$, e faremos isso trocando uma variável de cada vez.

  Para entender o que acontece quando trocamos uma das variáveis $X_i$ por $Y_i$, temos que expandir $g$ em série de potências, isto é, escrever
  \begin{equation}
    g(s) = g(s_0) + g'(s_0)(s - s_0) + g''(s_o)(s-s_0)^2/2 + r_{s_0}(s - s_0),
  \end{equation}
  onde $r_{s_0}(h)/h^3$ é limitada por $M$, uniformemente em $h$ e $s_0$ em consequência das nossas suposições sobre $g$.

  Denotando $z_i = (y_1, \dots, y_{i-1}, x_i, \dots x_n)$, $z_i^o := (y_1, \dots, y_{n-1}, 0, x_{n+1}, \dots, x_n)$ e $s_i^o = y_1 + \dots + y_{n-1} + x_{n+1} + \dots x_n$, temos
  \begin{equation}
    \phi^n(z_i) %& = \phi^n(z_i^o) + \frac{\partial \phi^n}{\partial x_i} (z_i^o) x_i + \frac{\partial^2 \phi^n}{\partial x_i^2} (z_i^o) \frac{x_i^2}{2} + r_z(x_i)\\
    = \phi^n(z_i^o) + g' \Big( \frac{s_i^o}{\sqrt{n}} \Big) \frac{x_i}{\sqrt{n}} + g'' \Big( \frac{s_i^o}{\sqrt{n}} \Big) \frac{x_i^2}{2n} + r_{\frac{s_i^o}{\sqrt{n}}} \Big( \frac{x_i}{\sqrt{n}} \Big),
  \end{equation}
  Nós propositalmente expandimos $\phi^n$ até ordem dois, pois $X_i$ e $Y_i$ possuem os mesmos momentos de ordem um ($m=0$) e dois ($\sigma^2=1$).

  Integrando os dois lados da igualdade acima com respeito a $Z_i \circ P$ (denotamos como antes, $Z_i = (Y_1, \dots, Y_{i-1}, X_i, \dots, X_n)$ e $Z_i^o$, $S_i^o$ analogamente), teremos
  \begin{equation}
    \int \phi^n(Z_i) \d P' = \int \phi^n(Z_i^o) \d P' + \frac{1}{2n} v_i + k_i,
  \end{equation}
  onde as quantidades $v$ e $k$, se escrevem como
  \begin{equation}
    v_i = \int g'' \Big( \frac{S_i^o}{\sqrt{n}} \Big) \d P' \quad \text{ e } \quad k_i = \int r_{S_i^o/\sqrt{n}} \Big(\frac{X_i}{\sqrt{n}}\Big) \d P'.
  \end{equation}
  Note que $v_i$ não depende de $X_i$ e que
  \begin{equation}
    |k_i| \leq \Big| \int \Big(\frac{X_i^3}{n^{3/2}}\Big) \Big(\frac{n^{3/2}}{X_i^3}\Big) r_{S_i^o/\sqrt{n}} \Big(\frac{X_i}{\sqrt{n}}\Big) \d P' \Big| \leq \frac{M}{n^{3/2}} E(|X_i^3|).
  \end{equation}

  As observações acima são o ponto mais importante da prova de que essa aproximação funciona e uma outra maneira de colocá-las é a seguinte.
  Como $X_i$ e $Y_i$ possuem os dois primeiros momentos iguais, os dois primeiros termos de Taylor coincidem após a integração (o primeiro se anula e o segundo é $v_i$ tanto para $X_i$ quanto para $Y_i$).
  O resto é de ordem muito pequena para influir no limite.

  De fato, se retiramos o termo $Y_i$ de $Z_{i+1}$, fazendo a mesma expansão que para $X_i$, obtemos
  \begin{equation}
    \int \phi^n(Z_{i+1}) \d P' = \int \phi^n(Z_i^o) \d P' + \frac{1}{2n} v_i + k'_i,
  \end{equation}
  com o termo de ordem superior $k'_i$ sendo definido exatamente como $k_i$, mas com $Y_i$ no lugar de $X_i$.

  Estamos prontos agora para a computação final
  \begin{equation*}
    \begin{split}
      \Big| \int \phi^n & (X_1, \dots, X_n) \d P - \int g(s) \mathcal{N}(0,1)(\d s) \Big|\\
      & = \Big| \int \phi^n(Z_0) \d P' - \int \phi^n(Z_n) \d P' \Big|\\
      & \leq \sum_{i=0}^{n-1} \Big| \int \phi^n(Z_{i}) \d P' - \int \phi^n(Z_{i+1}) \d P' \Big| = \sum_{i=0}^{n-1} |k_i - k'_i|\\
      & \leq n \frac{M}{n^{3/2}} \big(E(|X_1|^3) + E(|Y_1|^3) \big),
    \end{split}
  \end{equation*}
  que claramente converge a zero, provando o teorema.
\end{proof}

\begin{corollary}
  A $\mathcal{N}(0,1)$ é a única distribuição $\mu$ que possui esperança zero, variância $1$ e é tal que se $X, Y$ são \iid com distribuição $\mu$, então $(X + Y)/\sqrt{2}$ possuem distribuição $\mu$.
\end{corollary}

\begin{proof}
  Usando a invariância enunciada acima, temos que
  \begin{equation}
    \frac{X_1 + \dots + X_{2^k}}{\sqrt{2^k}} \distr \mu.
  \end{equation}
  Mas pelo Teorema central do limite, a distribuição dessa combinação de $X_i$ deve convergir a $\mathcal{N}(0,1)$, logo temos $\mu = \mathcal{N}(0,1)$.
\end{proof}

\todosec{Tópico: Análise de componentes principais}{variáveis gaussianas e principal component analysis...}

\todosec{Tópico: Funções características???}{funcoes caracteristicas e tomografia...}

\chapter{Esperança condicional}

\section{Esperança condicional}

Como já foi dito anteriormente, a estrutura de $\sigma$-álgebra tem um papel muito importante na área de probabilidade.
Durante o curso de Teoria da Medida, muitas vezes o conceito de $\sigma$-álgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conteúdo realmente interessante do curso.
Em alguns momentos, chegamos a desejar que tudo fosse mensurável e não tivéssemos que nos preocupar com tais formalidades.

No estudo que iniciaremos agora, nos restringiremos a sub-$\sigma$-álgebras $\mathcal{F}'$ próprias de $\mathcal{F}$ propositalmente.
Ficará claro portanto, que o estudo de $\sigma$-álgebras e mensurabilidade não é uma mera tecnicalidade, mas sim uma ferramenta importante.

Em algum sentido (que ficará claro no decorrer do texto) essas sub-$\sigma$-ál\-ge\-bras representarão uma forma de ``informação incompleta''.
Daremos sentido a frases como ``nós temos conhecimento apenas da $\sigma$-álgebra $\mathcal{F}'$''.

Mas antes lembraremos um lema básico de Teoria da Medida.

\begin{lemma}
  \label{l:f_igual_fp}
  Se $f, f'$ são funções mensuráveis tais que
  \begin{equation}
    \int_A f \d \mu = \int_A f' \d \mu, \text{ para todo $A \in \mathcal{F}'$,}
  \end{equation}
  então $f = f'$ $\mu$-quase certamente.
\end{lemma}

\begin{proof}
  Aplicando a hipótese para $A = [f > f']$, vemos que
  \begin{equation}
    \int_A f - f' \d \mu = 0,
  \end{equation}
  mas no conjunto $A$ acima, o integrando é positivo.
  Portanto, $f = f'$, $\mu$-quase certamente em $A$.
  Aplicando o mesmo raciocínio para $[f < f']$ obtemos que $f = f'$ quase certamente.
\end{proof}

O lema acima nos diz que se soubermos integrar $f$ em todos os eventos $A$, então podemos recuperar a função $f$ propriamente dita.
O que aconteceria se soubéssemos integrar $f$ apenas para eventos $A$ em uma sub-$\sigma$-álgebra?
É isso que estudaremos à partir de agora.

\begin{definition}
  \label{d:esperanca_condicional}
  Seja uma variável aleatória $X \in \mathcal{L}^1(P)$ e uma sub-$\sigma$-álgebra $\mathcal{F}' \subseteq \mathcal{F}$.
  Dizemos que uma variável aleatória $Y$ é a esperança condicional \index{esperanca@esperança!condicional} de $X$ com respeito a $\mathcal{F}'$ (ou dada $\mathcal{F}'$) se
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $E(X \1_{A}) = E(Y \1_{A})$ para todo $A \in \mathcal{F}'$.
  \end{enumerate}
  Nesse caso, escrevemos
  \begin{equation}
    Y = E(X | \mathcal{F}').
  \end{equation}
\end{definition}

Observe que faz sentido escrever $E\big(Y|\mathcal{F}'\big)(\omega)$, pois $E(X|\mathcal{F}')$ é uma variável aleatória.

Interpretamos informalmente a definição acima como ``$Y$ é a melhor aproximação $\mathcal{F}'$-mensurável de $X$''.
Ou $Y$ é a melhor aproximação que podermos fazer de $X$ se ``conhecemos apenas $\mathcal{F}'$''.

\begin{example}
  \label{x:EXF_trivial}
  Se $\mathcal{F}' = \{\varnothing, \Omega\}$, então $Y = E(X)$ (uma variável aleatória constante) é esperança condicional de $X$ dado $\mathcal{F}'$, pois
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável (por ser constante). Além disso
  \item $E(X \1_\varnothing) = 0 = E(Y \1_\varnothing)$ e $E(X \1_\Omega) = E(X) = E(Y \1_\Omega)$.
  \end{enumerate}
\end{example}

Uma propriedade muito importante que segue da Definição~\ref{d:esperanca_condicional} é dada pela seguinte

\begin{proposition}
  \label{p:ec_em_L1}
  Se $Y$ satisfaz as $a)$ e $b)$ em Definição~\ref{d:esperanca_condicional}, então $Y \in \mathcal{L}^1(P)$.
\end{proposition}

\begin{proof}
  Tomamos $A = [Y \geq 0]$ e $A' = [Y \leq 0]$ que estão em $\mathcal{F}'$ e estimamos
  \begin{equation}
    \int |Y| \d P = \int_A Y \d P + \int_{A'} Y \d P = \int_A X \d P + \int_{A'} X \d P \leq \int |X| \d P < \infty
  \end{equation}
  O que mostra a proposição.
\end{proof}

Além do Exemplo~\ref{x:EXF_trivial} trivial acima, quando podemos esperar que existam esperanças condicionais?

\begin{theorem}
  Dada $X \in \mathcal{L}^1(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$ uma $\sigma$-álgebra, então existe a esperança condicional $E(X|\mathcal{F}')$.
  Além disso ela é única $P$-quase certamente.
\end{theorem}

\begin{proof}
  Vamos primeiro mostrar a unicidade quase certa.
  Para isso, supomos que existam $Y$ e $Y'$ satisfazendo as condições da Definição~\ref{d:esperanca_condicional} (logo em $\mathcal{L}^1$).
  Iremos proceder como no Lema~\ref{l:f_igual_fp} acima, definindo $A = [Y > Y']$, donde concluímos que
  \begin{equation}
    E\big( (Y - Y')\1_{A} \big) = E(Y \1_{A}) - E(Y' \1_{A}) = 0.
  \end{equation}
  Mas como $Y > Y'$ em $A$, vemos que $Y \leq Y'$ quase certamtente.
  A prova da unicidade pode ser completa trocando os papéis de $Y$ e $Y'$ acima.

  Vamos agora para a prova da existência.
  Como $X \in \mathcal{L}^1(P)$, podemos introduzir
  \begin{equation}
    \mu(A) = E(X \1_{A}),
  \end{equation}
  que define uma medida com sinal em $(\Omega, \mathcal{F})$, com variação total finita.

  Caso o leitor não se sinta familiarizado com o conceito de medida com sinal, poderá decompor $X$ em partes positiva e negativa e proceguir sem problemas.

  Um passo importante da prova é observar que $\mu$ também define uma medida no espaço $(\Omega, \mathcal{F}')$.
  Estamos portanto propositalmente restringindo nossa $\sigma$-álgebra.
  Como $P(A) = 0$ implica que $\mu(A) = 0$, temos que $\mu \ll P$ e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada $Y:\Omega \to \mathbb{R}$ tal que
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $\mu(A) = \int_A Y \d P$.
  \end{enumerate}
  Agora é só observar que as afirmações acima correspondem às condições da Definição~\ref{d:esperanca_condicional}.
\end{proof}


Observe que a condição de $\mathcal{F}'$-mensurabilidade é essencial para a unicidade.
De fato, $X$ obviamente satisfaz a segunda condição da Definição~\ref{d:esperanca_condicional}, mas não necessariamente a primeira.

\section{Propriedades básicas da esperança condicional}

Nessa seção justificaremos, em certa medida, a nomenclatura ``esperança condicional''.
Faremos isso mostrando que ela satisfaz várias propriedades que já conhecemos para a esperança tradicional.

Mas como podemos mostrar propriedades simples tais como a linearidade da esperança condicional?
Vamos começar com um exemplo

\begin{proposition}
  \index{esperanca@esperança!condicional!aditividade}
  Se $X, X' \in \mathcal{L}^1(P)$, então
  \begin{equation}
    E(X + X'|\mathcal{F}') = E(X|\mathcal{F}') + E(X'|\mathcal{F}'), \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

Note que a igualdade acima é uma igualdade entre variáveis aleatórias.

\begin{proof}
  Sabemos que $Y = E(X|\mathcal{F}') + E(X'|\mathcal{F}')$ é uma variável aleatória bem definida.
  Mais do que isso, sabemos que ela é uma candidata muito boa a $E(X + X'|\mathcal{F}')$.
  Logo, por unicidade da esperança condicional, basta verificar que $Y$ satisfaz as condições da Definição~\ref{d:esperanca_condicional} com respeito a $X + X'$.
  De fato
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável, por ser uma soma de duas variáveis $\mathcal{F}'$-mensuráveis e
  \item por linearidade da esperança (não da esperança condicional), temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E\big( E(X|\mathcal{F}')\1_A + E(X'|\mathcal{F}')\1_A \big)\\
        & = E\big( E(X|\mathcal{F}')\1_A\big) + E\big(E(X'|\mathcal{F}')\1_A \big)\\
        & = E(X \1_A) + E(X' \1_A) = E\big( (X + X') \1_A \big).
      \end{split}
    \end{equation}
  \end{enumerate}
  Isso termina a prova do proposição.
\end{proof}

\begin{exercise}
  Dados $X \in \mathcal{L}^1$ e $\alpha \in \mathbb{R}$, mostre que $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$.
\end{exercise}

Uma outra propriedade bem simples da esperança condicional é a monotonicidade.

\begin{lemma}
  \index{esperanca@esperança!condicional!monotonicidade}
  \label{l:ec_mono}
  Se $X \geq X'$ em $\mathcal{L}^1(P)$, então
  \begin{equation}
    E(X|\mathcal{F}') \geq E(X'|\mathcal{F}'), \text{$P$-quase certamente.}
  \end{equation}
  Em particular, se $X \geq 0$, então $E(X|\mathcal{F}') \geq 0$ quase certamente.
\end{lemma}

\begin{proof}
  Seja $A = [E(X'|\mathcal{F}') - E(X|\mathcal{F}') > 0]$, que pertence a $\mathcal{F}'$.
  Então
  \begin{equation}
    0 \leq E\big( (E(X'|\mathcal{F}') - E(X|\mathcal{F}')) \1_A \big) = E\big((X' - X) \1_A\big) \leq 0,
  \end{equation}
  o que implica que $P(A) = 0$.
\end{proof}



\begin{proposition}
  \label{p:EZX_ZEX}
  Se $X, ZX \in \mathcal{L}^1(P)$, com $Z \in \mathcal{F}'$, temos
  \begin{equation}
    E(XZ|\mathcal{F}') = Z E(X|\mathcal{F}') \text{ $P$-quase certamente}.
  \end{equation}
  Em particular, $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$, para todo $\alpha \in \mathbb{R}$.
  Uma outra consequência interessante é que $Z E(X|\mathcal{F}')$ estará automaticamente em $\mathcal{L}^1$.
\end{proposition}

De maneira bastante informal, vamos dar uma intuição para o resultado acima.
Ao considerarmos a esperança condicional dada $\mathcal{F}'$, nós já conhecemos as variáveis aleatórias $\mathcal{F}'$-mensuráveis, portanto elas se comportam como constantes.

\begin{proof}
  Mais uma vez, basta verificar que $Z E(X|\mathcal{F}')$ satisfaz as condições que definem a esperança condicional.
  A primeira é trivial, pois $Z E(X|\mathcal{F}')$ é $\mathcal{F}'$-mensurável por ser um produto de funções $\mathcal{F}'$-mensuráveis.

  Para provar a segunda condição, começamos com o caso $Z = \1_B$, implicando que $B \in \mathcal{F}'$, donde
  \begin{equation*}
    E\big(ZE(X|\mathcal{F}') \1_A \big) = E\big( E(X|\mathcal{F}') \1_{A \cap B}\big) = E(X \1_{A \cap B}) = E(ZX \1_A).
  \end{equation*}
  Por linearidade, já sabemos que o resultado vale para funções $Z$ simples e gostaríamos de extender para quaisquer $Z$ positivas via Teorema da Convergência Monótona.
  Um problema aqui é que mesmo que $Z$ seja positiva, não sabemos se $E(X|\mathcal{F}')$ também será positiva.

  Portanto, trataremos primeiramente do caso $X \geq 0$.
  Para tais $X$, sabemos pelo Lema~\ref{l:ec_mono} que $E(X|\mathcal{F}') \geq 0$ quase certamente.
  Daí, podemos concluir que $Z E(X|\mathcal{F}') = E(ZX|\mathcal{F}')$ para toda $Z \geq 0$, podemos aproximá-la por baixo por $Z_n$ simples e, pelo Teorema da Convergência Monótona,
  \begin{equation}
    \begin{array}{e}
      E\big( Z E(X|\mathcal{F}') \big) & \overset{\text{TCM}}= & \lim_n E\big( Z_n E(X|\mathcal{F}') \big)\\
      & = & \lim_n E\big( E(Z_n X|\mathcal{F}') \big) \overset{\text{TCM}}= E\big( E(ZX|\mathcal{F}') \big).
    \end{array}
  \end{equation}
  O que mostra o resultado sempre que $X \geq 0$.

  Além disso, pela Proposição~\ref{p:ec_em_L1}, sabemos que $Z E(X|\mathcal{F}') \in \mathcal{L}^1$.
  Podemos finalmente concluir a prova decompondo $X = X_+ - X_-$ e a linearidade.
\end{proof}

Para corroborar nossa afirmação que a esperança condicional é uma aproximação da variável aleatória, fornecemos o seguinte

\begin{lemma}
  Se $X \in \mathcal{L}^2(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$, então $E(X|\mathcal{F}')$ é a projeção ortogonal de $X$ no espaço vetorial $H_{\mathcal{F}'}$.
  Onde $H_{\mathcal{F}'} = \{Y \in \mathcal{L}^2; Y \text{ é $\mathcal{F}'$-mensurável}\}$.
\end{lemma}

\begin{proof}
  Temos que verificar que $X - E(X|\mathcal{F}')$ é ortogonal a $H_{\mathcal{F}'}$.
  Ou seja, mostrar que para todo $Z \in H_{\mathcal{F}'}$, temos
  \begin{equation}
    E\big( XZ - E(X|\mathcal{F}') Z \big) = 0.
  \end{equation}
  Note que não é claro que essa esperança faz sentido, pois não sabemos que $ZE(X|\mathcal{F}') \in \mathcal{L}^1$.
  Mas isso segue facilmente da Proposição~\ref{p:EZX_ZEX}.

  Agora sim, se $Z = \1_{A}$ para algum $A \in \mathcal{F}'$, essa afirmação segue da definição de $E(X|\mathcal{F}')$.
  Finalmente podemos extender esse resultado a funções simples, positivas e finalmente a todas $Z \in H_{\mathcal{F}'}$.
\end{proof}

Vimos acima uma metodologia que se repete frequentemente.
Digamos que queremos provar que uma determinada expressão nos dá a esperança condicional de algo.
Podemos começar provando esse resultado para funções indicadoras, depois para funções simples usando a linearidade provada acima.

Porém ainda falta um ingrediente bastante importante para construir ou verificar que determinadas variáveis são esperanças condicionais.

\begin{theorem}[Convergência Monótona para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.M.}
  \label{t:TCM_EC}
  Se as variáveis $X_n$ satisfazem $X_n \uparrow X$ e estão todas em $\mathcal{L}^1(P)$, então
  \begin{equation}
    \lim_n E(X_n|\mathcal{F}') = E(X|\mathcal{F}').
  \end{equation}
\end{theorem}

\begin{proof}[Demonstração do Teorema~\ref{t:TCM_EC}]
  Sabemos que $E(X_{n+1} | \mathcal{F}') \geq E(X_n|\mathcal{F}')$, donde concluímos que $E(X_n|\mathcal{F}') \uparrow Y$.
  Vamos demosntrar que $Y = E(X|\mathcal{F}')$.
  \begin{enumerate}[\quad a)]
  \item Por ser um limite de funções $\mathcal{F}'$ mensuráveis, $Y$ é $\mathcal{F}'$-mensurável.
  \item Dado $A \in \mathcal{F}'$, temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E(\lim_n E(X_n |\mathcal{F}') \1_A) \overset{\text{TCM}}= \lim_n E\big( E(X_n|\mathcal{F}') \1_A \big)\\
        & = \lim_n E(X_n \1_A) \overset{\text{TCM}}= E(X \1_A).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que termina a prova do teorema.
\end{proof}

No que segue, muitas vezes escreveremos $E(X|Z)$ para representar a esperança condicional $E(X|\sigma(Z))$.

\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $E_1 \times E_2$ e definimos a probabilidade $\d P = \rho(x,y) \d \mu_1 \d \mu_2$, onde $\rho:E_1 \times E_2 \to \mathbb{R}_+$ é uma densidade.
  Dê sentido à expressão abaixo e mostre que elá é $E(X_1|X_2)$:
  \begin{equation}
     \frac{\int x\rho(x, X_2) \mu_1(\d x)}{\int \rho(x, X_2) \mu_1(\d x)}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Seja $E$ enumerável com uma $\sigma$-álgebra $\mathcal{F}'$.
  Mostre que
  \begin{equation}
    \mathcal{F}' = \sigma(A_i, i \geq 1), \text{ com $A_i \subseteq E$ disjuntos}.
  \end{equation}
  Suponha que todos conjuntos $A_i$ tem probabilidade positiva e mostre que
  \begin{equation}
    E(X|\mathcal{F}') = \sum_i E^i(X) \1_{A_i},
  \end{equation}
  onde $E^i$ é a esperança com respeito à probabilidade $P(\cdot|A_i)$.
  Em breve extenderemos esse tipo de resultado a espaços quaisquer.
\end{exercise}

Uma outra propriedade que a esperança condicional herda da integral é a

\begin{proposition}[Desigualdade de Jensen]
  \index{esperanca@esperança!condicional!desigualdade de Jensen}
  Se $\phi:\mathbb{R} \to \mathbb{R}$ é convexa, $X, \phi(X) \in \mathcal{L}^1(P)$, então
  \begin{equation}
    \phi\big( E(X|\mathcal{F}') \big) \leq E\big( \phi(X) | \mathcal{F}' \big).
  \end{equation}
\end{proposition}

\begin{proof}
  Se $\phi$ for uma função linear, o resultado segue da linearidade que já provamos para a esperança condicional.
  Além disso, se temos uma função $\psi:\mathbb{R} \to \mathbb{R}$ linear e tal que $\psi(x) \leq \phi(x)$ para todo $x \in \mathbb{R}$, então
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq E\big( \psi(X) | \mathcal{F}' \big) = \psi \big( E(X|\mathcal{F}') \big).
  \end{equation}
  Tomamos finalmente o supremo em todas as $\psi$ lineares com $\psi \leq \phi$ dos dois lados da desigualdade acima, obtendo
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq \sup_{\substack{\psi \leq \phi\\\psi \text{ linear}}} \psi \big( E(X|\mathcal{F}') \big) = \phi \big( E(X|\mathcal{F}') \big),
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{corollary}
  Se $X \in \mathcal{L}^1(P)$, então $\big| E(X|\mathcal{F}') \big| \leq E\big(|X| \big| \mathcal{F}' \big)$.
\end{corollary}

Uma outra propriedade interessante da esperança condicional diz respeito a sua relação com independência.

\begin{proposition}
  Se $X \in \mathcal{L}^1(P)$ é independente de $\mathcal{F}'$, então
  \begin{equation}
    E(X|\mathcal{F}') = E(X) \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

\begin{proof}
  Funções constantes são sempre mensuráveis. Além disso, se $A \in \mathcal{F}'$, então
  \begin{equation}
    E(X \1_A) = E(X) P(A) = E\big( E(X) \1_A \big),
  \end{equation}
  concluindo a prova.
\end{proof}

Terminamos essa seção com o que chamamos da propriedade de torre da esperança condicional.

\begin{proposition}
  \index{esperanca@esperança!condicional!torre}
  Se $\mathcal{F}' \subseteq \mathcal{F}''$ são ambas sub-$\sigma$-álgebras de $\mathcal{F}$, então para $X \in \mathcal{L}^1(P)$, temos
  \begin{equation}
    \label{e:ec_torre}
    E\big( E(X|\mathcal{F}') \big| \mathcal{F}'' \big) = E(X|\mathcal{F}') = E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big),
  \end{equation}
  ou em outras palavras, independentemente da ordem, prevalece a condição na menor $\sigma$-álgebra.
  Consequentemente, $E\big( E(X|\mathcal{F}') \big) = E(X)$.
\end{proposition}

\begin{proof}
  Como $E(X|\mathcal{F}')$ é $\mathcal{F}''$-mensurável, a Proposição~\ref{p:EZX_ZEX}, aplicada com $X = 1$, mostra a primeira igualdade em \eqref{e:ec_torre}.

  Falta mostrar que $E\big( E(X|\mathcal{F}'') \big| \mathcal{F}'\big)$ é a esperança condicional de $X$ dada $\mathcal{F}'$.
  Obviamente ela é $\mathcal{F}'$-mensurável, e nos resta verificar a segunda condição.
  Mas para todo $A \in \mathcal{F}'$, lembrando que $A$ também pertence a $\mathcal{F}''$ e usando a definição de esperança condicional duas vezes,
  \begin{equation}
    E\Big( E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big) \1_A \Big) = E\big( E(X | \mathcal{F}'')  \1_A \big) = E(X \1_A).
  \end{equation}
  O que termina a prova da proposição.
\end{proof}

\begin{lemma}
  \label{l:f_g_circ_X}
  Se $X: \Omega \to E$ é um elemento aleatório e $f:\Omega \to \mathbb{R}$ é $\sigma(X)$-mensurável, então existe uma $g:E \to \mathbb{R}$ mensurável tal que $f = g \circ X$.
\end{lemma}

\begin{proof}
  Como de costume, consideramos primeiramente o caso $f = \1_A$
  Claramente $A$ tem que pertencer a $\sigma(X)$, ou seja $A = X^{-1}(B)$ para algum $B \in \mathcal{A}$.
  Neste caso colocamos $g = \1_B$, donde obtemos $f(\omega) = 1 \Leftrightarrow \omega \in A \Leftrightarrow X(\omega) \in B \Leftrightarrow g \circ X = 1$.

  No caso em que $f$ é simples, temos $f = \sum_i a_i (g_i \circ X) = (\sum_i a_i g_i) \circ X$.
  Se $f$ é positiva, então ela é um limite crescente de funções do tipo $g_n \circ X$, além disso podemos tomar $g_n$ crescentes, pois
  \begin{equation}
    f_{n+1} = f_{n+1} \vee f_{n} = (g_{n+1} \circ X) \vee (g_n \circ X) = (g_n \vee g_{n+1}) \circ X.
  \end{equation}

  Finalmente usamos a linearidade da composição novamente para resolver o caso geral $f = f_+ - f_-$.
\end{proof}

Se $X: \Omega \to E$ é elemento aleatório, então $E(Y|\sigma(X))$ é obviamente $\sigma(X)$-mensurável.
Pelo lema anterior, $E(Y|\sigma(X)) = g \circ X$ para alguma $g: E \to \mathbb{R}$.
Nesse caso denotamos
\begin{equation}
  E(Y|X = x) = g(x).
\end{equation}

\begin{exercise}
  Mostre que $g$ é única $X \circ P$-quase certamente.
\end{exercise}

Gostaríamos de dizer que $E(Y|X = x)$ satisfaz alguma propriedade que justifique essa notação.
Apesar de que apenas na próxima seção poderemos justificar completamente essa nomenclatura, nesse momento já podemos mostrar a seguinte relação
\begin{equation*}
  E(Y) = E\big( E(Y | X) \big) = E\big( E(Y | X = x) \circ X \big) = \int E(Y| X = x) (X \circ P) (\d x).
\end{equation*}
Em outras palavras, para integrar $Y$, basta conhecermos a distribuição de $X$ e a esperança condicional de $Y$, dado que $X = x$.

\begin{exercise}
  Sejam $X$ e $Y$ as coordenadas canônicas em $E_1 \times E_2$, com a probabilidade $P = \mu_1 \otimes \mu_2$ e seja $f:E_1 \times E_2 \to \mathbb{R}$ em $\mathcal{L}^1(P)$.
  Mostre que
  \begin{equation}
     E(f|X = x) = \int f(x, y) \mu_2(\d y).
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $\mathbb{R}$ e $P_1$ é uma probabilidade em $E_1$, mostre que em $P_1 \star K$ temos
  \begin{equation}
    E(X_2|X_1 = x_1) = \int x_2 K(x_1, \d x_2).
  \end{equation}
\end{exercise}

Um outro resultado bastante importante é o seguinte

\begin{theorem}[Teorema da Convergência Dominada para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.D.}
  Se $X_n \to X$ e existe $Y \in \mathcal{L}^1(P)$ tal que $|X_n| \leq Y$ para todo $n$, então
  \begin{equation}
    E(X_n | \mathcal{F}) \to E(X|\mathcal{F}) \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

\begin{proof}
  Seja $Z_n = \sup_{k \geq n} |X_k - X|$ o erro máximo à partir de $n$.
  Claramente, $Z_n \downarrow 0$ quase certamente e além disso
  \begin{equation}
    |Z_n| \leq \sup_{k \geq 1} |X_k| + |X| \leq 2 Y,
  \end{equation}
  donde $E(Z_n) \to E(0) = 0$, quase certamente pelo Teorema da Convergência Dominada.

  Obviamente $E(Z_n|\mathcal{F})$ é uma sequência positiva e não-crescente, logo decresce quase certamtente para algum $Z$.
  Daí,
  \begin{equation}
    \big| E(X_n | \mathcal{F}) - E(X | \mathcal{F}) \big| \leq E(Z_n | \mathcal{F}) \downarrow Z \geq 0.
  \end{equation}
  Mas $E(Z) \leq E\big( E(Z_n|\mathcal{F}) \big) = E(Z_n)$.
  Como $E(Z_n)$ vai a zero pelo Teorema da Convergência Dominada, temos que $Z = 0$ quase certamente como gostaríamos.
\end{proof}

\begin{exercise}
  Sejam $Z_1, Z_2, \dots$ variáveis aleatórias \iid em $\mathcal{L}^1(P)$ com $E(Z_1) = 0$.
  \begin{enumerate}[\quad a)]
  \item Defina $X_0 = 0$ e
    \begin{equation}
      X_n = \sum_{i = 1}^n Z_i, \text{ para $n \geq 1$.}
    \end{equation}
    Mostre que $E(X_{n + 1} | Z_1, \dots, Z_n) = X_n$.
  \item Supondo agora que $Z_1 \in \mathcal{L}^2(P)$ e $E(Z) = 0$, defina $Y_0 = 0$ e
    \begin{equation}
      Y_n = \Big( \sum_{i = 1}^n Z_i \Big)^2 - n E(Z_1^2)
    \end{equation}
    Mostre que $E(Y_{n + 1} | Z_1, \dots, Z_n) = Y_n$.
  \end{enumerate}
\end{exercise}

\todosec{Tópico: Martingais a tempo discreto}{fazer...}

\todosec{Tópico: Propriedade fraca de Markov}{mostrar que cadeias = processos...}

\section{Probabilidade Condicional Regular}

Já sabemos definir por exemplo $E(\1_A|X = x)$.
Gostaríamos porém de garantir que essa expressão definisse uma probabilidade em $A$, e chamaríamos essa probabilidade de $P(A|X = x)$.
Mas certamente gostaríamos que $P(\cdot|X = x)$ fosse uma função $\sigma$-aditiva.
Essa especulação parece promissora, por exemplo se $A$ e $B$ são disjuntos,
\begin{equation*}
  P(A \cup B |\mathcal{F}') = E(\1_{A \cup B} | \mathcal{F}') = E(\1_A|\mathcal{F}') + E(\1_{B}|\mathcal{F}') = P(A|\mathcal{F}') + P(B|\mathcal{F}').
\end{equation*}
Ótimo, mas ainda temos o seguinte problema.

Lembramos que a equação acima está bem definida apenas quase certamente.
Poderíamos portanto garantir que para uma classe enumerável de conjuntos $A \in \mathcal{F}$, essa aditividade fosse satisfeita.
Porém, a $\sigma$-álgebra $\mathcal{F}$ é frequentemente não enumerável, portanto não conseguimos a $\sigma$-aditividade plena.
Isso pode ser contornado se o espaço for canônico, como afirma o nosso próximo resultado.

\todo{Tirar o teorema \ref{t:prob_cond_reg_F} e fazer direto o \ref{t:prob_cond_reg_X} com $q \in \mathbb{Q}$... (quem precisa do \ref{t:prob_cond_reg_F} anyway???)}

\begin{theorem}
  \label{t:prob_cond_reg_F}
  Seja $X: \Omega \to E$ um elemento aleatório tomando valores em um espaço canônico $E$ e $\mathcal{F}'$ uma sub-$\sigma$-álgebra qualquer.
  Então existe um núcleo $K$ entre $\Omega$ e $E$, tal que para todo $B$
  \begin{equation}
    K(\omega, B) = E\big(\1_{[X \in B]} | \mathcal{F}'\big) (\omega) \text{ $P$-quase certamente.}
  \end{equation}
  A esse núcleo, damos o nome Probabilidade Condicional Regular \index{probabilidade!condicional!regular}(dada $\mathcal{F}'$), que é denotada por $P(X \in \cdot|\mathcal{F}')$.
\end{theorem}

\todo{melhorar a prova da existência de Prob Cond Regular. Em particular, $\hat F = F$ nos racionais?}

\begin{proof}
  Primeiramente observamos que podemos assumir sem perda de generalidade que $E = \mathbb{R}$.
  De fato, suponha que já conhecemos o resultado pra variáveis aleatórias e somos dados $X$ tomando valores em $E$ canônico.
  Como $E$ é canônico, existe uma bijeção $\phi:E \to \mathbb{R}$ bi-mensurável, com imagem mensurável logo $\phi \circ X$ é variável aletória.

  Dessa forma, existe o núcleo $K'(\omega, \cdot) = P(\phi \circ X \in \cdot | \mathcal{F}')(\omega)$ e podemos definir
  \begin{equation}
    K(\omega, \cdot) = \phi^{-1} \circ K'(\omega, \cdot),
  \end{equation}
  que será um núcleo entre $\Omega$ e $E$ pois $\phi^{-1}$ é mensurável.
  Para mostrar que $K = P(X \in \cdot|\mathcal{F}')$, tome $B \in \mathcal{A}$ e observe que
  \begin{equation}
    \begin{split}
      K(\omega, B) & = K'\big(\omega, (\phi^{-1})^{-1}(B)\big) = K'\big(\omega, \phi(B)\big)\\
      & = E \big( \1_{[\phi \circ X \in \phi(B)]} | \mathcal{F} \big) = E \big( \1_{[X \in B]} | \mathcal{F} \big),
    \end{split}
  \end{equation}
  terminando a prova de que é suficiente considerar o caso $E = \mathbb{R}$.

  Vamos agora considerar $X$ uma variável aleatória e definimos para cada $q \in \mathbb{Q}$,
  \begin{equation}
    F(\omega, q) = E(\1_{[X \leq q]} | \mathcal{F}')(\omega),
  \end{equation}
  que é mensurável e bem definida quase certamente.

  Observamos que
  \begin{enumerate}[\quad a)]
  \item $F(\omega, q) \in [0,1]$, $P$-quase certamente para todo $q \in \mathbb{Q}$, pois $\1_{[X \leq q]} \in [0,1]$.
  \item Se $q \leq q'$, então $F(\omega, q) \leq F(\omega, q')$, $P$-quase certamente, pois $\1_{[X \leq q]} \leq \1_{[X \leq q']}$.
  \item Se escolhemos $q_n = n$ (analogamente $q_n = -n$), então $F(\omega, n) \to 1$ (analogamente $F(\omega, -n) \to 0$), $P$-quase certamente, pois $[X \leq n] \uparrow \Omega$ e pelo Teorema da Convergência Monótona para esperanças condicionais.
  \end{enumerate}
  Tomando a interseção de todos $q \in \mathbb{Q}$ para o ítem $a)$, todos $q, q' \in \mathbb{Q}$ no ítem $b)$ e os dois casos do ítem $c)$, encontramos um evento quase certo $\Omega'$ onde valem os três ítens acima.
  Para os pontos de medida nula $\omega \in \Omega \setminus \Omega'$, podemos redefinir $F(\omega, p)$ como uma função de distribuição acumulada fixa $F_0$.
  Dessa forma valem os ítens $a)$, $b)$ e $c)$ para todos pontos de $\Omega$.
  Note também que após essa redefinição, ainda obtemos $F(\cdot, q)$ mensurável para todo $q \in \mathbb{Q}$, pois redefinimos $F$ como sendo uma constante em um conjunto mensurável.

  Vamos agora extender as definições acima para $\hat{F}:\Omega \times \mathbb{Q}$
  \begin{equation}
    \hat{F}(\omega, x) = \lim_{q \downarrow x} F(\omega, q),
  \end{equation}
  que existe pois $F$ é monótona e limitada.
  Assim obtivemos que $\hat{F}(\omega, x)$ satisfaz as três condicões acima para todo ponto, o que caracteriza uma função acumulada de distribuição.
  Existe portanto para todo $\omega \in \Omega$ uma medida $\mu_\omega$ na reta tal que
  \begin{equation}
    \mu_\omega\big((-\infty, x]\big) = \hat{F}(\omega,x),
  \end{equation}
  e definimos $K(\omega, A) = \mu_\omega(A)$.

  Exercício: mostre que $\hat{F}$ é contínua à direita.

  Pela Proposição~\ref{p:K_nucleo_na_classe}, já sabemos que $K$ é um núcleo de transição, pois $K\big(\cdot, (-\infty, q]\big)$ é mensurável para todo $q$ e esses conjuntos formam um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$.

  Finalmente, precisamos verificar que $K$ é a prometida esperança condicional.
  Para tanto, fixado $B \in \mathcal{B}(\mathbb{R})$, gostaríamos de ver que
  \begin{equation}
    K(\omega, B) = E(\1_{[X \in B]} | \mathcal{F}')(\omega), \text{ $P$-quase certamente.}
  \end{equation}
  Definindo como $\mathcal{G} \subseteq \mathcal{B}(\mathbb{R})$ a classe onde isso vale, já vimos que $\mathcal{G}$ contém $(-\infty, q]$ para $q \in \mathbb{Q}$ pois $K(\omega, B) = \hat{F}(\omega, q)$ quase certamtente.
  Mas $\mathcal{G}$ é um $\lambda$-sistema pelo Teorema da Convergência Monótona para esperanças condicionais.
  Já que $\mathcal{G}$ contém um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$, terminamos a prova do teorema.
\end{proof}

Interpretamos $P(X \in \cdot| \mathcal{F}')$ da seguinte forma.
Se alguém tiver acesso à $\sigma$-álgebra $\mathcal{F}'$ (por exemplo se $\mathcal{F}' = \sigma(Y)$ e o pessoa for capaz de observar o valor de $Y(\omega)$), ela pode não saber o valor de $X(\omega)$, mas já sabe a nova distribuição condicional de $X$: $P(X \in \cdot|\mathcal{F}')(\omega)$.

\begin{exercise}
  Se $X$ é variável aleatória então
  \begin{equation}
    E(X|\mathcal{F}') = \int x P(X \in \d x|\mathcal{F}'), \text{ $P$-q.c.}
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $\Omega = E_1 \times E_2$ com $E_2$ canônico é dotado da probabilidade $\d P = \rho(x_1, x_2) \mu_1 \otimes \mu_2 (\d x_1 \d x_2)$, então
  \begin{equation}
    P(X_2 \in A|X_1) = \frac{\int_A \rho(X_1, x_2) \mu_2(\d x_2)}{\int \rho(X_1, x_2) \mu_2(\d x_2)},
  \end{equation}
  $P$-quase certamtente.
\end{exercise}

Uma das grandes vantagens de ter um núcleo de transição a determinar uma distribuição conjunta, como é o caso quando obtemos uma probabilidade condicional regular, é que podemos usar a versão generalizada de Fubini.
Antes, nós somente podiamos usar Fubini para espaços produto.

Vamos introduzir nosso último conceito de condicionais.

\begin{definition}
  Dado $X:\Omega \to E$ um elemento aleatório, dizemos que um núcleo $K: E \times \mathcal{F} \to [0,1]$ é uma \emph{probabilidade condicional regular dado $X$} se
  \begin{equation}
    \label{e:K_prob_cond_reg_X}
    K\big( X(\omega), A\big) = E(\1_A|\sigma(X)), \text{ $P$-quase certamente.}
  \end{equation}
  Nesse caso escrevemos $K(x, A) = P(A|X = x)$.
\end{definition}

A existência de tais condicionais não decorre somente do Teorema~\ref{t:prob_cond_reg_F}, já que o Lema~\ref{l:f_g_circ_X} não se aplica para núcleos de transição.
A principal dificuldade de adaptarmos esse lema para núcleos vem do fato de que a imagem de uma função mensurável não é necessariamente mensurável.

Contudo, não estamos muito longe de obter a existência das condicionais definidas acima.

\begin{theorem}
  \label{t:prob_cond_reg_X}
  Sejam $\Omega$ e $E$ espaços mensuráveis e $X: \Omega \to E$ um elemento aleatório.
  Então se $\Omega$ é canônico, existe $P(A|X = x)$, a probabilidade condicional regular dada $X$.
\end{theorem}

Observe que a hipótese de ser canônico é sobre $\Omega$!

\begin{proof}
  Definimos o elemento aleatório $X^\star: \Omega \to \Omega \times E'$ dado por $X^\star (\omega) = (\omega, X(\omega))$.
  Como $X^\star$ é claramente mensurável, ele induz uma probabilidade natural em $\Omega \times E$, mais precisamente $P^\star = X^\star \circ P$.

  Introduzimos também em $\Omega \times E$ as projeções canônicas $\pi_\Omega$ e $\pi_E$.
  Utilizamos agora o Teorema~\ref{t:prob_cond_reg_F} para obter um núcleo $K^\star$ de $\Omega \times E$ em $\Omega$ que dá a probabilidade condicional regular de $\pi_\Omega$ (com respeito a $P^\star$) dada $\sigma(\pi_E)$, ou seja
  \begin{equation}
    K^\star(\cdot, A) = E^\star \big(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E) \big) \text{ $P^\star$-q.c.}
  \end{equation}
  Mas como $K^\star(\cdot, A)$ é $\sigma(\pi_E)$-mensurável, podemos usar o Lema~\ref{l:f_g_circ_X} para obter uma $g_A: E \to \Omega \times E$ tal que
  \begin{equation}
    K^\star\big( (\omega, x), A \big) = g_A (\pi_E(\omega, x)) = g_A(x).
  \end{equation}
  Em particular, o lado esquerdo da equação acima não depende de $\omega$.
  Podemos finalmente definir $K(x, A) = g_A(x)$.

  Vemos facilmente que $K$ é um núcleo, pois toda $g_A$ é mensurável e $K(x, \cdot) = K^\star\big( (\omega, x), \cdot \big)$, que é uma medida.
  Finalmente, temos que verificar \eqref{e:K_prob_cond_reg_X}.
  \begin{equation}
    \begin{split}
      K(X(\omega), A) & = g_A(X(\omega)) = K^\star \big( (\omega, X(\omega)), A \big) = K^\star (X^\star(x), A)\\
      & \overset{\text{$P^\star$-q.c.}}= E^\star \big(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E) \big) \circ X^\star.
    \end{split}
  \end{equation}
  Agora somente resta nos ver que essa é uma versão de $E(\1_A|\sigma(X))$, que segue da conta
  \begin{equation}
    \begin{split}
      E\big( E^\star(& \1_{[\pi_\Omega \in A]} | \sigma(\pi_E)) \circ X^\star \1_{[X \in B]}\big)\\
      & = E^\star \big( E^\star(\1_{[\pi_\Omega \in A]} | \sigma(\pi_E)) \1_{[\pi_E \in B]}\big)\\
      & = E^\star ( \1_{[\pi_\Omega \in A, pi_E \in B]} ) = E(\1_A \1_{[X \in B]}),
    \end{split}
  \end{equation}
  como gostaríamos.
\end{proof}

\begin{exercise}
  Considere em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ as projeções canônicas $X_1$ e $X_2$.
  Calcule, em cada um dos exemplos abaixo, a probabilidade condicional regular $P[X_1 \in \cdot|X_2 = x_2]$, justificando sua resposta,
  \begin{enumerate}[\quad a)]
  \item Quando $P$ é a medida uniforme em $T = \{(x,y) \in [0,1]^2; x \leq y\}$ (ou seja, a medida de Lebesgue em $\mathbb{R}^2$ restrita a $T$ e normalizada para ser uma probabilidade).
  \item Quando $P$ é a medida $U_{S^1}$ (uniforme em $S^1$).
  \end{enumerate}
\end{exercise}

\section{Princípio da substituição}

No próximo resultado, veremos como o conceito abstrato de probabilidade condicional regular pode nos ajudar a fazer cálculos envolvendo variáveis dependentes.

\begin{theorem}
  \index{Principio@Princípio!da Substituicao@da Substituição}
  Dado $X: \Omega \to E$ um elemento aleatório, se existe $P(\cdot | X = x)$ (em particular se $\Omega$ é canônico), então a medida $P(\cdot | X = x)$ tem suporte no conjunto $[X = x] \subseteq \Omega$, $X \circ P$-quase certamente.
\end{theorem}

\begin{proof}
  Seja $G \in \Omega \times E$ dado por $G = \{(\omega, x); X(\omega) \neq x\}$.
  Como $G = [\pi_\Omega \neq X \circ \pi_E]$, sabemos que $G$ é mensurável.
  Para $x \in E$, denotamos por $G'_x$ as fatias $\{\omega \in \Omega; (\omega, x) \in G\}$ (que coincidem com $[X = x]^c$) e que são $\mathcal{F}$-mensuráveis para quase todo $x \in E$, como foi visto no Teorema de Fubini.

  Com essa notação, vemos que
  \begin{equation}
    \begin{split}
      0 = E^\star (\1_G) & = \int P^\star(G | \pi_E = x) (\pi_E \circ P^\star) (\d x)\\
      & = \int K(x, G'_x) (X \circ P) (\d x)\\
      & = \int P\big( [X = x]^c | X = x \big) (X \circ P) (\d x).
    \end{split}
  \end{equation}
  Mas como o integrando acima é não-negativo, ele deve ser zero $(X \circ P)$-quase certamente, finalizando a prova do teorema.
\end{proof}


\begin{exercise}
  Considere as medidas
  \begin{equation}
    \mu_a = \frac{\delta_{-1} + \delta_1}{2}, \qquad \text{e} \qquad \mu_b = \mathcal{N}(0, 1).
  \end{equation}
  e $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) =
    \begin{cases}
      \mu_a (A - x), & \text{ se $x < 0$,}\\
      \mu_b (A - x), & \text{ se $x \geq 0$,}
    \end{cases}
  \end{equation}
  Mostre que
  \begin{enumerate}[\quad a)]
  \item $K$ define um núcleo de transição entre $\mathbb{R}$ em $\mathbb{R}$.
  \item Se $X_1, X_2, \dots$ for uma cadeia de Markov em $\mathbb{R}$ com núcleo de transição $K$, então calcule
    \begin{enumerate}[\qquad i)]
    \item $E(X_i)$, para todo $i \geq 1$ e
    \item $\text{Var}(X_i)$, para todo $i \geq 1$.
    \item Mostre que
      \begin{equation}
        \frac{\sum_{i = 1}^n X_i}{\sqrt{n}} \Rightarrow \mathcal{N}(0,1).
      \end{equation}
    \end{enumerate}
  \end{enumerate}
\end{exercise}

\todosec{Tópico: Processos de Poisson em \texorpdfstring{$\mathbb{R}$}{R}}{fazer...}

\todosec{Tópico: Processos de Markov em tempo contínuo}{fazer...}

\todosec{Tópico: Sistemas de partículas}{fazer...}

\chapter{Soluções de exercícios}

\emph{Solução de \ref{x:casas_tempestade}}
Primeiramente, vamos ver qual é a distribuição de $R_0$.
Vamos escrever $R_0 = E_0 + D_0$, onde $E_0$ é o número de casas acessíveis à esquerda e $D_0$ à direita.
Note que $E_0$ e $D_0$ são independentes e identicamente distribuídas, com
\begin{equation}
  P[D_0 = l] = P[X_l = 1, X_i = 0 \text{ para $i = 0, \dots, l-1$}] = p (1-p)^l.
\end{equation}
Podemos agora calcular
\begin{equation}
  P[R_0 = k] = \sum_{l=0}^k P[D_0 = l, E_0 = k-l] = \sum_{l=0}^k p^2 (1-p)^{k} = p^2 k (1-p)^k.
\end{equation}
Além disso,
\begin{equation}
  E(R_0) = 2 E(D_0) = \sum_{l=0}^\infty l P[D_0 = l] = 2 p \sum_{l=0}^\infty l (1-p)^l = \frac{2(1-p)}{p} =: m.
\end{equation}
O que resolve o primeiro ítem.

O grande problema do segundo ítem é que as variáveis $R_i$ não são independentes, veja por exemplo que $P[R_0=0,R_1=2,R_2=0] = 0$.
Nesse caso, o método do segundo momento deve ser feito com atenção.
Chamando de $S_n = \sum_{i=1}^n R_i$, temos
\begin{equation}
  P \Big[ \Big| \frac{1}{n} S_n - E(R_0) \Big| > a \Big] \leq \frac{\text{Var}(S_n)}{a^2 n^2},
\end{equation}
mas a variância da soma não se torna a soma das variâncias.
De fato
\begin{equation}
  \begin{split}
    \text{Var}(S_n) & = E \Big( \big(\sum_{i=1}^n (R_i - E(R_i)) \big)^2\Big) = \sum_{i=1}^n \sum_{j=1}^n E \Big(\big(R_i - E(R_i)\big) \big(R_j - E(R_j) \big)\Big)\\
    & = \sum_{i=1}^n \sum_{j=1}^n \text{Cov}(R_i, R_j) = n \text{Var}(R_0) + 2 \sum_{k=1}^{n-1} (n-k) \text{Cov}(R_0, R_k).
  \end{split}
\end{equation}
Aqui já temos metade da estimativa resolvida, mas ainda falta obter uma estimativa explícita.

Então precisamos estimar superiormente $\text{Cov}(R_i, R_j) = \text{Cov}(R_0, R_{j-1})$.
Podemos calcular essa quantidade explicitamente, mas vamos evitar contas chatas fazendo uma estimativa do tipo
\begin{equation}
  \text{Cov}(R_0, R_k) \leq c \exp\{-c' k\}, \text{ para todo $k \geq 1$}.
\end{equation}
O que nos daria que
\begin{equation}
  \text{Var}(S_n) \leq n \text{Var}(R_0) + 2 \sum_{k=1}^{n-1} (n-k) c \exp\{-c' k\} \leq c'' n.
\end{equation}
Donde a probabilidade que queríamos estimar é no máximo ${c}/{a^2 n}$, como no caso independente.

Para obter a prometida cota para a covariância, observe que podemos truncar $D_0$ e $E_k$ para obter independência.
Definindo
\begin{equation}
  \tilde{R_0} = E_0 + ( D_0 \wedge \lfloor k/2 \rfloor ) \text{ e } \tilde{R}_k = D_k + ( E_k \wedge \lfloor k/2 \rfloor ),
\end{equation}
temos que $\tilde{R}_0$ e $\tilde{R}_k$ são independentes (pois dependem de elos disjuntos).
Daí
\begin{equation}
  \begin{split}
    \text{Cov}(R_0, R_k) & = E(R_0 R_k) - m^2\\
    & = E(\tilde{R}_0 \tilde{R_k}) + E(R_0 R_k \1{[R_0 \neq \tilde{R}_0] \cup [R_k \neq \tilde{R}_k]}) - m^2\\
    & \leq E(\tilde{R}_0)^2 - m^2 + E\big( (E_0 + D_0) (E_k + D_k) \1{[R_0 \neq \tilde{R}_0] \cup [R_k \neq \tilde{R}_k]}\big)\\
    & \leq E\big( (E_0 + k + D_k)^2 \1{[R_0 \neq \tilde{R}_0] \cup [R_k \neq \tilde{R}_k]}\big)\\
    & = E\big( (E_0 + k + D_k)^2 \big) P\big([R_0 \neq \tilde{R}_0] \cup[R_k \neq \tilde{R}_k]\big)\\
    & \leq \big( 2 E(E_0^2) + k^2 + 2k E(E_0) + E(E_0)^2 \big) \cdot 2 \cdot P[R_0 \neq \tilde{R}_0]\\
    & \leq c k^2 (1-p)^{\lfloor k/2 \rfloor} \leq c \exp \{-c' k\}.
  \end{split}
\end{equation}
Finalizando a cota para a covariância.

\clearpage

\nocite{}
\bibliographystyle{jcamsalpha}
\bibliography{bibliography}

\addcontentsline{toc}{chapter}{Index}
\printindex



\end{document}
