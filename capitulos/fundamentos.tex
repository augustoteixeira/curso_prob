% !TEX encoding = UTF-8 Unicode


\chapter{Fundamentos}

A probabilidade moderna se baseia fortemente na Teoria da Medida e supomos durante esse curso que o leitor esteja bem familiarizado com conceitos tais como: Medida de Lebesgue, extensões de medida e teoremas de convergência.
Iremos agora justificar brevemente a escolha da Teoria da Medida para o estudo de probabilidade.

No início da Teoria da Probabilidade, a maioria dos fenômenos estudados apresentava apenas um número finito de resultados possíveis, como por exemplo ao se jogar um dado de seis lados ou sortear uma carta em um baralho.
Em tais casos é desnecessário o uso de ferramentas sofisticadas pra modelar tais situações.
Por exemplo, podemos simplesmente dizer que a probabilidade de se obter cada um dos lados do dado é igual a $1/6$.

Mas digamos, por exemplo, que queremos um modelo para estudar o volume de chuva em uma cidade durante um ano.
Obviamente, esse volume poderia ser qualquer número real positivo e não podemos simplesmente atribuir valores positivos de probabilidade a cada número real (lembramos que somas não enumeráveis de termos positivos são sempre infinitas).
Mas como podemos continuar nossa modelagem se nem ao menos podemos dizer qual é a probabilidade de chover um determinado volume esse ano, por exemplo $(\pi/19)mm$?

A solução para tal dilema, se baseia no fato de que na verdade nunca estamos interessados no exato resultado do nosso experimento.
Gostaríamos sim de responder perguntas do tipo: qual é a probabilidade de que chova entre zero e $37mm$?
Estamos portanto interessados em atribuir probabilidades não a valores exatos do experimento, mas a certos conjuntos de possíveis valores.
Chamamos tais conjuntos de \emph{eventos}. \index{evento}

Voltando ao caso do dado de seis lados, poderíamos nos interessar por exemplo pela probabilidade dos seguintes eventos: o lado sorteado foi ímpar ($P(\{1,3,5\}) = 1/2$) ou o lado sorteado foi dois ($P(\{2\}) = 1/6$).
E percebemos rapidamente que para eventos disjuntos a probabilidade de sua união é a soma de suas probabilidades (no caso acima, $P(\{1,2,3,5\}) = 1/2 + 1/6 = 2/3$).
Esse caráter aditivo da probabilidade certamente nos remete aos conceitos básicos de Teoria da Medida.
Vamos agora formalizar a discussão acima com mais calma, sob a ótica dessa teoria.

\section{Espaços mensuráveis}

Denotaremos sempre por $\Omega$ o nosso \emph{espaço amostral} \index{espaco@espaço!amostral} (a princípio qualquer conjunto).
Um ponto nesse espaço corresponde por exemplo a um possível resultado do nosso experimento aleatório.

\begin{example} Possíveis exemplos de espaço amostral
  \label{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $\Omega_1 = \{1, 2, \dots, 6\}$,
  \item $\Omega_2 = \mathbb{R}_+$,
  \item $\Omega_3 = \{f:[0,1] \to \mathbb{R}; \text{$f$ é contínua}\}$.
  \end{enumerate}
\end{example}
Os exemplos acima poderiam ser usados em modelar por exemplo: o resultado de um dado, o volume anual de chuva em uma cidade e o comportamento ao longo do dia do preço de uma ação na bolsa de valores.

Consideraremos sempre $\Omega$'s equipados com uma \emph{$\sigma$-álgebra} \index{sigma-algebra@$\sigma$-álgebra} denotada por $\mathcal{F}$.
Mais precisamente
\begin{definition}
  Dizemos que $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ é uma $\sigma$-álgebra se
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{F}$,
  \item $A \in \mathcal{F}$ implica que $A^\cc \in \mathcal{F}$ e
  \item se $(A_n)_{n\ge 1} \in \mathcal{F}^{\bbN}$, então $\cup_{n\ge 1} A_n \in \mathcal{F}$.
  \end{enumerate}
\end{definition}
Nesse caso, dizemos que $(\Omega, \mathcal{F})$ é um \emph{espaço mensurável}
\index{epaco@espaço!mensuravel@mensurável} e os elementos $A \in \mathcal{F}$ são chamados de \emph{eventos}.
Usaremos a notação $A^{\cc}:=\gO\setminus A$ para denotar o evento \emph{complementar} a $A$ \index{evento}

Se $\mathcal{G} \subseteq \mathcal{P}(\Omega)$ (que chamamos de uma classe ou família), denotamos por $\sigma(\mathcal{G})$ a
\emph{$\sigma$-álgebra gerada por $\mathcal{G}$} \index{sigma-algebra@$\sigma$-álgebra!gerada por G@gerada por $\mathcal{G}$}, que é a menor $\sigma$-álgebra
contendo $\mathcal{G}$ (e a interseção de todas $\sigma$-álgebras que contem $\mathcal{G}$).
Um exemplo importante é dado pela \emph{$\sigma$-álgebra de Borel} \index{sigma-algebra@$\sigma$-álgebra!de borel}, gerada pelos abertos de uma topologia em $\Omega$.

\medskip

Dado $\cF$ and $\cF'$ duas $\sigma$-álgebras, usaremos a notação $\cF\vee\cF'$ para denotar
a $\sigma$-álgebras gerada pela união $\cF\cup\cF'$.


\begin{example} Típicos exemplos de $\sigma$-álgebra correspondentes aos espaços amostrais do Exemplo~\ref{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $\mathcal{F}_1 = \mathcal{P}(\Omega_1)$,
  \item $\mathcal{F}_2 = \mathcal{B}([0,1])$,
  \item $\mathcal{F}_3 = \mathcal{B}(C[0,1])$ e
  \end{enumerate}
\end{example}

\begin{example} Alguns eventos de $\mathcal{F}_1, \mathcal{F}_2$ e $\mathcal{F}_3$ acima
  \begin{enumerate}[\quad a)]
  \item $\{\text{$x$ é ímpar}\}, \{1\} \subset \Omega_1$,
  \item $[0,1/2], \{0\}, (\mathbb{Q} \cap [0,1]) \subset \Omega_2$,
  \item $\{f:[0,1] \to \mathbb{R}; f(1) > 0\} \subset \Omega_3$, e
  \todo{$\{a_3=4\}, \{ \text{ a soma dos $4$ primeiros dados vale $13$} \}$}
  \end{enumerate}
\end{example}

\begin{exercise}
  Mostre que $\{f:[0,1] \to \mathbb{R}; f(t) \geq 0 \text{ para todo $t \in [0,1]$}\} \subset \Omega_3$ é um evento (ou seja, pertence a $\mathcal{F}_3$).
\end{exercise}

\begin{notation}
  Se $Q$ for uma condição qualquer sobre elementos $\omega \in \Omega$, escreveremos $[\text{$\omega$ satisfaz $Q$}]$ \index{[omega satisfaz Q]@$[\text{$\omega$ satisfaz $Q$}]$} para denotar $\{\omega \in \Omega; \text{ $\omega$ satisfaz $Q$}\}$.
\end{notation}

Por exemplo, $\{f:[0,1] \to \mathbb{R}; f(1) > 0\}$ pode ser escrita simplesmente como $[f(1) > 0]$.

\section{Espaços de probabilidade}

Agora estamos prontos para introduzir o conceito moderno do que é uma probabilidade.

\begin{definition}
  Dado $(\Omega, \mathcal{F})$ espaço mensurável, dizemos que $P:\mathcal{F} \to [0,1]$ é uma \emph{probabilidade} \index{probabilidade} se
  \begin{enumerate}[\quad a)]
  \item $P(\Omega) = 1$ e
  \item Seja uma sequencia $(A_i)_{i\in I}$ finita o enumerável de eventos disjuntos ($A_i \cap A_j = \varnothing$ se $i \neq j$), temos
    \begin{equation}
      P\big({\mcup\nolimits_{i\in I}} A_i\big) = \sum_{i\in I} P(A_i).
    \end{equation}
  \end{enumerate}
\end{definition}

Obviamente, isso nada mais é que uma medida que associa massa um ao espaço todo.

Ofereceremos agora alguns exempos de espaços de probabilidade bastante utilizados.
\begin{example}[Bernoulli]
  \label{x:bernoulli}
  Com $\Omega = \{0, 1\}$, $\mathcal{F} = \mathcal{P}(\Omega)$ e $p \in [0, 1]$, definimos $\Ber(p)$ \index{distribuicao@distribuição!de Bernoulli} como sendo uma probabilidade em $(\Omega, \mathcal{F})$ dada por
  \begin{equation}
    \Ber(p) = p \delta_1 + (1 - p) \delta_0,
  \end{equation}
  onde $\delta_\cdot$ acima denotam as deltas de Dirac.
\end{example}

\begin{example} Probabilidades nos espaços do Exemplo~\ref{x:espacos_amostrais}
  \begin{enumerate}[\quad a)]
  \item $P_1(A) = (\#A)/6$ em $(\Omega_1, \mathcal{F}_1)$.
    Ou mais geralmente $P_1'(A) = \sum_{i \in A} p_i$, onde $p_i \geq 0$ e $\sum_i p_i = 1$.
  \item $P_2$ pode ser a medida de Lebesgue em $([0,1], \mathcal{B}([0,1]))$.
    Mais geralmente também podemos ter $P_2'(A) = \int_A \rho(x) \d x$, onde $\rho:[0,1] \to \mathbb{R}_+$ é uma função mensuravel chamada densidade, satisfazendo $\int_{[0,1]} \rho (x) \d x = 1$.
  \item $P_3 = \delta_{0}$, que atribui o valor um se o evento contém a função identicamente nula ($f \equiv 0$) e zero caso contrário.
  \end{enumerate}
\end{example}
Obviamente o terceiro exemplo é bastante artificial (e inútil).
Mas, futuramente, estaremos prontos para introduzir medidas bem interessantes no espaço $(\Omega_3, \mathcal{F}_3)$.

\begin{proposition}
  Valem as afirmativas seguintes
  \begin{enumerate}[\quad a)]
  \item $P(A^{\cc}) = 1 - P(A)$.
  \item Se $A \subseteq B$ são mensuráveis, então $P(A) \leq P(B)$.
  \item A cota da união: para $I$ finito ou enumerável
    \begin{equation}
      P\big(\mcup\nolimits_{i\in I} A_i\big) \leq \smash{\sum\limits_{i\in I}} P(A_i).
    \end{equation}
  \item O que chamamos de princípio da \emph{inclusão e exclusão} \index{inclusao e exclusao@inclusão e exclusão}
    \begin{equation}
      P\big(\mcup\nolimits_{i=1}^{n} A_i\big) = \smash{\sum\limits_{k = 1}^n} (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}).
    \end{equation}
  \end{enumerate}
\end{proposition}

\begin{proof}

$a)$ By disjoint union, temos $P(A)+P(A^{\cc})=P(A\cup A^{\cc})=1.$


  $b)$ Como $A \cap (B \setminus A) = \varnothing$, então
    \begin{equation}
        P(B) = P(A \cup (B \setminus A)) = P(A) + P(B \setminus A) \geq P(A).
  \end{equation}

  $c)$ $P(A \cup B) = P (A \cup (B \setminus A)) = P(A) + P(B \setminus
    A) \leq P(A) + P(B)$.\\
    Deixamos o caso enumerável como exercício abaixo.

  $d)$ Chamamos $A$ a união dos $A_i$. Basta mostrar a validade da equação abaixo e depois integrar com
    respeito a $P$.
    \begin{equation}
      \label{e:indicadora_como_produto}
      \1_A(\omega) = \sum_{k=1}^n (-1)^{k - 1} \sum_{\substack{I \subseteq \{1, \dots, n\}\\|I| = k}} \prod_{i \in I} \1_{A_i}(\omega).
    \end{equation}
    Para tanto, observe que para todo $\omega \in \Omega$,
    \begin{equation}
      (\1_A - \1_{A_1}) \cdot \dots \cdot (\1_A - \1_{A_n})(\omega) = 0.
    \end{equation}
    Logo, expandindo o produto acima obtemos
    \begin{equation}
      \1_A + \sum_{k = 1}^n \sum_{\substack{I \subseteq \{1, \dots, n\}\\|I| = k}} (-1)^k \prod_{i \in I} \1_{A_i}(\omega) = 0,
    \end{equation}
    que equivale a \eqref{e:indicadora_como_produto}.
\end{proof}

\begin{exercise}
  Mostre que $P\big(\mcup\nolimits_i A_i\big) \leq \sum_i P(A_i)$ no caso enumerável.
\end{exercise}

\begin{exercise}
  Mostre que
  \begin{equation*}
    \begin{split}
      P\big( \mcup\nolimits_{i=1}^n A_i \big) & \leq \sum\limits_{k = 1}^m (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}) \text{ se $m$ é ímpar e}\\
      P\big( \mcup\nolimits_{i=1}^n A_i \big) & \geq \sum\limits_{k = 1}^m (-1)^{k-1} \sum\limits_{1 \leq i_1 < \dots < i_k \leq n} P(A_{i_1} \cap \dots \cap A_{i_k}) \text{ se $m$ é par.}
    \end{split}
  \end{equation*}
\end{exercise}



\begin{exercise}
  Seja $n \geq 1$ um número inteiro e considere $\Omega = \{0, 1\}^n$, o hipercubo de dimensão $n$ (cada $\omega \in \Omega$ pode ser visto como uma função $\omega:\{1, \dots, n\} \to \{0,1\}$).
  Para cada $i \in \{1, \dots, n\}$, definimos o evento $A_i = \{ \omega \in \Omega : \omega(i) = 1 \}$.
  Dadas duas probabilidades $P$ e $P'$ em $(\Omega, \mathcal{P}(\Omega))$, mostre que se $P(B) = P'(B)$ para todos conjuntos $B$ dados por interseções de $A_i$'s, então $P = P'$.
\end{exercise}

\begin{proposition}
  \label{p:prob_continua}
  Toda probabilidade $P$ é contínua, isto é:
  \begin{enumerate}[\quad a)]
  \item Se $A_1 \subseteq A_2 \subseteq \dots \in \mathcal{F}$ for uma sequência crescente de eventos, então \\
  $\lim_{n\to \infty} P(A_n) = P(\mcup\nolimits_{n=1}^{\infty} A_n)$.
  \item Também, se $A_1 \supseteq A_2 \supseteq \dots \in \mathcal{F}$, temos $\lim\limits _{n\to \infty} P(A_n) = P(\mcap\nolimits_{n=1}^{\infty} A_n)$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  $a)$ Observe que
  \begin{equation}
    \mcup_{n = 1}^\infty A_n = \mcup_{n = 1}^\infty \Big( A_n \setminus \big( \mcup_{i=1}^{n-1} A_i \big) \Big),
  \end{equation}
  que são disjuntos.
  Logo
  \begin{equation}
    \begin{split}
      P\big(\mcup\nolimits_{n = 1}^\infty A_n\big) & = \sum_{n = 1}^\infty P\Big( A_n \setminus \big(\mcup\nolimits_{i=1}^{n-1} A_i \big) \Big)\\
      & = \lim_{n\to \infty} P({\mcup\nolimits_{i = 1}^n} A_i) = \lim_{n\to \infty} P(A_n).
    \end{split}
  \end{equation}

  $b)$ A prova é análoga à de $(a)$.
\end{proof}

\begin{lemma}[Borel-Cantelli - primeira parte]
  Sejam $A_1, A_2, \dots \in \mathcal{F}$ satisfazendo $\sum_{i = 1}^\infty P(A_i) < \infty$.
  Então
  \begin{equation}
    P[\text{$A_i$ para infinitos $i$}] := P\big({\mcap\nolimits_{n = 1}^\infty} ({\mcup\nolimits_{i \geq n}} A_i)\big) = 0.
  \end{equation}
\end{lemma}

\begin{proof}
  Estimamos
  \begin{equation}
    P \Big( {\mcap_{n = 1}^\infty} \big({\mcup\nolimits_{i \geq n}} A_i \big) \Big) = \lim_{n\to \infty} P \big( {\mcup\nolimits_{i \geq n}} A_i \big) \leq \lim_{n\to \infty} {\textstyle\sum\limits_{i \geq n}} P(A_i) = 0.
  \end{equation}
  O que termina a prova do lemma.
\end{proof}

Imagine que jogamos todos os dias em uma loteria e que nossa probabilidade de ganhar no dia $i$ é $p_i$.
Então se $\sum_i p_i < \infty$, sabemos que certamente não ganharemos infinitas vezes.

\section{Sistemas \texorpdfstring{$\lambda$-$\pi$}{lambda-pi}}

Uma importante ferramenta para provar fatos teóricos sobre probabilidades é o Teorema de Dynkin que apresentaremos nessa seção.
Ele trata de classes de eventos que não são necessariamente $\sigma$-álgebras, mas sistemas $\lambda$ ou $\pi$ como definidos abaixo.

\begin{definition}
  Dizemos que uma classe $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\pi$-sistema \index{pi sistema@$\pi$-sistema} se for fechado por interseções finitas, isto é: para todos $A, B \in \mathcal{A}$ temos $A \cap B \in \mathcal{A}$.
\end{definition}

\begin{definition}
  Dizemos que $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ é um $\lambda$-sistema, \index{lambda sistema@$\lambda$-sistema} se
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{A}$,
  \item Sempre que $A \in \mathcal{A}$ temos $A^\cc \in \mathcal{A}$.
  \item Para $A_1, A_2, \dots \in \mathcal{A}$ disjuntos dois a dois, temos $\cup_i A_i \in \mathcal{A}$.
  \end{enumerate}
\end{definition}

\begin{exercise}
  \label{x:lambda_nao_sigma}
  Dê um exemplo de $\lambda$-sistema que não seja uma $\sigma$-álgebra.
\end{exercise}
Podemos observar que de um certo sentido, $\pi$-sistema e $\gl$-sistema contem metade complementar dos requerimentos
para ser uma $\sigma$-álgebra.

Definimos para $\mathcal{A} \subseteq \mathcal{P}(\Omega)$, o menor $\lambda$-sistema contendo $\mathcal{A}$, ou seja,
\begin{definition}
Definimos para $\mathcal{A} \subseteq \mathcal{P}(~W)$, o menor $\lambda$-sistema contendo $\mathcal{A}$, ou seja
\begin{equation}
  \lambda(\mathcal{A}) = \bigcap_{\substack{\text{$\mathcal{B}$ $\lambda$-sistema}\\\mathcal{A} \subseteq \mathcal{B}}} \mathcal{B}.
\end{equation}
\end{definition}

\begin{lemma}\label{l:pilamb}
Se $\cA\subseteq  \mathcal{P}(\Omega) $ é um $\pi$-sistema e um $\gl$-sistema, então $\cA$ é uma $\sigma$-álgebra.
\end{lemma}

\begin{proof}
Temos que $\cA$ é estável por complementar e contem $\gO$, por ser um $\lambda$-sistema.
Só precisamos que $\cA$ seja estável por união enumerável (ou finita).
Seja $(A_n)_{n\ge 1}$ uma sequência de elementos de $\cA$.
Por estabilidade por complementar e intersecção finita, $B_n$ definido por
\begin{equation*}
B_n = \bigcup_{i=1}^n A_i = (\cap_{i=1}^n A_i^\cc)^\cc
 \end{equation*}
 pertence a $\cA$.
 Pelas mesmas razões e também o caso de $C_n=B_n\setminus B_{n-1}=B_n \cap B_{n-1}^{\cc}$ ($B_0=\emptyset$).
Para concluir observamos que
\begin{equation*}
\bigcup_{n=1}^\infty A_n = \bigcup_{n=1}^{\infty} B_n=  \bigcup_{n=1}^{\infty}C_n.
 \end{equation*}
Os $C_n$ sendo disjuntos, a união deles pertencia a $\cA$ por propriedades das $\gl$-álgebras.
\end{proof}

Vamos ver agora uma versão mais puxada do resultado acima que vai ficar muito utíl para provar unicidade ou igualdade entre probabilidades.

Deixamos de Exercício de verificar que  $\lambda(\mathcal{A})$ é sempre um $\lambda$-sistema.


\begin{theorem}[Dynkin]
  \index{Teorema!de Dynkin}
  \label{t:dynkin}
  Se $\mathcal{A}$ é um $\pi$-sistema, então $\lambda(\mathcal{A}) = \sigma(\mathcal{A})$.
\end{theorem}

Note pelo Exercício~\ref{x:lambda_nao_sigma} que a hipótese de que $\mathcal{A}$ é um $\pi$-sistema é necessária em geral.

\begin{proof}
  Obviamente, basta mostrar é que $\lambda(\mathcal{A})$ é fechado por uniões não necessariamente disjuntas.
Pelo Lemma \ref{l:pilamb}é suficiente provar que
  \begin{equation}
    \label{e:lambda_is_pi}
    \lambda(\mathcal{A}) \text{ é um $\pi$-sistema}.
  \end{equation}
Para isso é suficiente de verificar a propriedade seguinte
  \begin{equation}\label{interestavel}
   \forall A_1,A_2 \in \gl(\cA),\quad  A_1\cap A_2 \in \gl(\cA),
  \end{equation}
pois o caso de interseções de mais conjuntos pode ser deduzido por indução.

  \medskip


  Vamos primeiramente mostrar que $\lambda(\mathcal{A})$ é fechado por interseções com $\mathcal{A}$.
  Para tanto, definimos $\mathcal{B} = \big\{B \in \lambda(\mathcal{A}); \text{$B \cap A \in \lambda(\mathcal{A})$ para todo $A \in \mathcal{A}$})\big\}$ e provamos que
  \begin{equation}
    \label{e:B_igual_lambda}
    \cB = \lambda(\mathcal{A}).
  \end{equation}
  Obviamente, $\mathcal{A} \subseteq \mathcal{B}$, pois $\mathcal{A}$ é um $\pi$-sistema.
  Então basta mostrar que $\mathcal{B}$ é um $\lambda$-sistema.
  \begin{enumerate}[\quad a)]
  \item $\Omega$ obviamente pertence a $\mathcal{B}$.
  \item \textit{Estabilidade por complementar}: Consideramos $B \in \mathcal{B}$. Para  $A \in \mathcal{A}$ arbitrário,
  $$B^\cc \cap A =(A^\cc \cup (B \cap A))^\cc\in \cA $$
  e portanto, como $B \cap A\in \gl(\cA)$ por definição, por estabilidade de $\gl(\cA)$ por complementar e união disjunta temos
  $B^\cc \cap A \in \gl(\cA)$, o que implica que $B^\cc\in \cB$.
  \item \textit{Estabilidade por união disjunta}: Se $B_1, B_2, \dots \in \mathcal{B}$ são disjuntos e $A \in \mathcal{A}$ arbitrário, definindo $B:=\mcup_{n=1}^{\infty} B_n$
  temos
    \begin{equation}
   B\cap A=   \big(\mcup_{n=1}^{\infty} B_n \big) \cap A = \mcup_{n=1}^{\infty} \big(B_n \cap A\big) \in \lambda(\mathcal{A}),
    \end{equation}
   A união acima sendo disjunta, temos  $B \cap A \in \gl(\cA)$ e
    logo $\mcup_{n=1}^{\infty} B_n \in \mathcal{B}$.
  \end{enumerate}
  Isso termina a prova de \eqref{e:B_igual_lambda}.

  \medskip

 Agora, para concluir,  definimos
 \begin{equation}
   \bar{\mathcal{B}} := \{B \in \lambda(\mathcal{A});
   B \cap A \in \lambda(\mathcal{A}),
   \; \forall A \in \lambda(\mathcal{A})\}
 \end{equation}
 e mostraremos que
  \begin{equation}
    \label{e:Bbar_igual_lambda}
    \bar{\mathcal{B}} = \lambda(\mathcal{A}),
  \end{equation}
  que e equivalente a \eqref{interestavel}.

  \medskip

 \noindent Observe que $\mathcal{A} \subseteq \bar{\mathcal{B}}$ pois $\mathcal{B} = \lambda(\mathcal{A})$ (veja a definição de $\mathcal{B}$),
então para mostrar   \eqref{e:Bbar_igual_lambda} sò precisamos mostrar que
  \begin{equation}
    \label{e:B_barra_lambda}
    \text{$\bar{\mathcal{B}}$ é um $\lambda$-sistema}.
  \end{equation}
  Para tanto, verificaremos
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \bar{\mathcal{B}}$, que é claro.
  \item \textit{Estabilidade por complementar}:
  Considerando $B \in  \bar{\mathcal{B}}$.
  Tomando $A \in \gl(\cA)$ arbitrário temos
  $$B^\cc \cap A = \big(A^\cc \cup (A \cap B)\big)^\cc$$
e como $A \cap B\in \gl(A)$ por definição de $\bar \cB$,  $B^\cc \cap A \in \lambda(\mathcal{A})$ por propriedades de $\gl$-sistema,
o que permite de concluir que $B^\cc \in \bar{\mathcal{B}}$.
  \item \textit{União disjunta} Também o caso de uniões disjuntas é bastante análogo ao feito para $\mathcal{B}$.
  \end{enumerate}


  Finalmente mostraremos que $\lambda(\mathcal{A})$ é um $\pi$-sistema.
  De fato, dado $A \in \lambda(\mathcal{A})$, segue da igualdade $\bar{\mathcal{B}} = \lambda(\mathcal{A})$ que $A \cap B \in \lambda(\mathcal{A})$, para todo $B \in \lambda(\mathcal{A})$.
  Logo estabelecemos \eqref{e:lambda_is_pi}, terminando a prova do teorema.
\end{proof}

\subsection{Igualdade de probabilidades}

\begin{proposition}
  \label{p:P12_equal_pi}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega, \mathcal{F})$, tais que $P_1(A) = P_2(A)$ para todo $A \in \mathcal{A}$ e $\mathcal{A}$ é
  um $\pi$-sistema, então $P_1(B) = P_2(B)$ para todo $B \in \sigma(\mathcal{A})$.
\end{proposition}

\begin{proof}
  Seja $\mathcal{B} = \{A \in \mathcal{F}; P_1(A) = P_2(A)\}$.
  É fácil ver que $\mathcal{B}$ é um $\lambda$-sistema.
  Logo $\mathcal{B}$ contém $\lambda(\mathcal{A})$ que é igual a $\sigma(\mathcal{A})$ por Dynkin.
\end{proof}

\begin{corollary}
  \label{c:produto_e_unico}
  Se $P_1$ e $P_2$ são probabilidades em $(\Omega_1 \times \Omega_2, \mathcal{F}_1 \otimes \mathcal{F}_2)$, tais que
  \begin{equation}
    P_1(A_1 \times A_2) = P_2(A_1 \times A_2), \text{ para todos $A_1 \in \mathcal{F}_1$, $A_2 \in \mathcal{F}_2$,}
  \end{equation}
  então $P_1 = P_2$.
\end{corollary}

\begin{proof}
  Obviamente as caixas do tipo $A_1 \times A_2$ formam um $\pi$-sistema que gera $\mathcal{F}_1 \otimes \mathcal{F}_2$ (por definição).
\end{proof}

\begin{example}
  Observe que é importante que $\mathcal{A}$ seja um $\pi$-sistema na Proposição~\ref{p:P12_equal_pi}.
  Imagine por exemplo que $\Omega = \{0,1\}^2$ e $P_1 = \tfrac 14 \sum_{x \in \Omega} \delta_x$ e $P_2 = \tfrac 12 (\delta_{(0,0)} + \delta_{(1,1)})$.
  Nesse caso
  \begin{equation}
    P_1(A) = P_2(A) = 1/2 = P_1(B) = P_2(B),
  \end{equation}
  com $A = \{(0,0), (0,1)\}$ e $B = \{(0,0), (1,0)\}$.
  Contudo, $P_1 \neq P_2$, mesmo tendo $\mathcal{P}(\Omega) = \sigma(\{A,B\})$.
\end{example}


\section{Elementos aleatórios}

Muitas vezes não estamos interessados no resultado exato do nosso experimento aleatório, mas sim em uma determinada medição ou função de $\omega \in \Omega$.
Por exemplo, no caso do Exemplo~\ref{x:espacos_amostrais} $c)$, talvez não nos interesse toda a função $f$, mas apenas o seu valor no fim do dia $f(1)$.
Essas medições são ditas elementos aleatórios que definimos à seguir.

Seja $(E,\mathcal{A})$ um espaço mensurável.
Nesse caso, se $X: \Omega \to E$ é uma função $(\mathcal{F}, \mathcal{A})$-mensurável, dizemos que $X$ é um \emph{elemento aleatório} \index{elemento aleatorio@elemento aleatório} em $(\Omega, \mathcal{F})$ tomando valores em $E$, ou um $E$-elemento aleatório.

\begin{example} Consideramos os casos
  \begin{enumerate}[\quad a)]
  \item $X:\Omega \to \mathbb{R}$ mensurável é dita variável aleatória. \index{variavel aleatoria@variável aleatória}
  \item $X:\Omega \to \mathbb{R}^d$ mensurável é dito vetor aleatório ($d$-dimensional).
  \item $X:\Omega \to C[0,1]$ mensurável é dita função aleatória.
  \end{enumerate}
\end{example}
Seguindo a motivação do Exemplo~\ref{x:espacos_amostrais} $c)$, poderia ser que, por exemplo, estivéssemos interessados apenas na variável aleatória $X:\Omega_3 \to \mathbb{R}$ dada por $X(f) = f(1)$.

\begin{exercise}
  Mostre que $X:\Omega_3 \to \mathbb{R}$ dada por $X(f) = f(1)$ é uma variável aleatória.
\end{exercise}

Citando Kingman em seu livro Poisson Processes: ``\emph{a random elephant is a function from $\Omega$ into a suitable space of elephants.}''

Relembrando a nossa notação: $P[X \in A] = P(\{\omega \in \Omega; X(\omega) \in A\})$.

\begin{proposition}
  Seja $X:\Omega \to E$ onde $(E, \mathcal{A})$ é um espaço mensurável com $\mathcal{A} = \sigma(\mathcal{G})$.
  Então para verificar que $X$ é um elemento aleatório, basta provar que $X^{-1}(G) \in \mathcal{F}$ para todo $G \in \mathcal{G}$.
\end{proposition}

\begin{proof}
  Teoria da Medida.
\end{proof}

\begin{example}
  Se $\Omega$ e $E$ são espaços topológicos dotados das correspondentes $\sigma$-álgebras de Borel, então toda função contínua é um $E$-elemento aleatório.
\end{example}

Como vamos ver ao longo deste curso, a noção de $\sigma$-algebra na teoria da probabilidade pode ter outro papel, além de apenas o de definir os eventos mensúraveis.
Um primeiro exemple e a introdução de $\sigma$-álgebra associada a um elemeno aleatorio que contem todos eventos que podem ``ser descritos em termo de $X$''.

\begin{definition}
Seja $X \ : \ (\gO,\cF)\to (E,\cA)$ um elemento aleatorio.
A $\sigma$-álgebra associada a $X$ (o gerada por $X$) e definida por

$$\sigma(X):=\{ X^{-1}(A) \ : \ A\in E \}.$$

For definição $\sigma(X)\subset \mathcal G$.
 \end{definition}


 \begin{exercise}
Consideramos $\gO=\bbR^2$ com a $\sigma$-álgebra de Borel, e definimos a varíável aleatoria $X(\go_1,\go_2)=\max(\go_1,\go_2)$.
Descrever $\sigma(X)$.
\end{exercise}


\subsection{Distribuição de elementos aleatórios}

\begin{definition}
  Se $X:\Omega \to E$ é um elemento aleatório (com respeito a $\mathcal{F}$ em $\Omega$ e $\mathcal{A}$ em $E$) e $\Omega$ é dotado de uma probabilidade $P$, então denotamos por $X_{*}P$,
  a chamada \emph{distribuição de $X$} \index{distribuicao@distribuição}, a medida de probabilidade
  \begin{equation}
    X_* P(A) := P\big( \{\omega \in \Omega \, : \,  X(\omega) \in A\} \big) = P[X \in A].
  \end{equation}
  no espaço mensurável $(E,\mathcal{A})$.
\end{definition}

\begin{remark}
 Essa definição corresponde com a de \textit{medida imagem} vista no curso de integração que tem um papel ainda mais importante em probabilidade.
\end{remark}

Fica como exercício verificar que $X_*P$ é de fato uma probabilidade em $E$.

\begin{exercise}
  Seja $X:[0,1] \to \{0,1\}$ dada por $X(\omega) = \1_A (\omega)$.
  Nesse caso, mostre que $X_*P = \Ber(p)$ para algum $p \in [0,1]$.
  Calcule o valor de $p$.
\end{exercise}

Duas notações importantes nesse contexto são:
\begin{enumerate}[\quad a)]
\item Sejam $(\Omega, \mathcal{F}, P)$ e $(\Omega',\mathcal{F}',P')$ dois espaços de probabilidade e $X$ e $Y$ dois elementos aleatórios.
Dizemos que $X \stackrel{d}{=} Y$, \index{X d Y@$X \distr Y$} quando $X_*P = Y_*P'$.
Note que $X$ e $Y$ nem ao menos precisam pertencer ao mesmo espaço de probabilidade para dizermos que são \emph{igualmente distribuídos}, mas precisam ser elementos aleatórios de mesmo tipo (ou seja, possuir o mesmo contradomínio).
\item Escrevemos $X \distr \mu$, \index{X d mu@$X \distr \mu$} que lê-se \emph{$X$ é distribuída como $\mu$}, onde $\mu$ é uma probabilidade em $E$, caso $X_*P = \mu$.
\end{enumerate}

\begin{exercise}
  Sejam $X$ e $Y$ variáveis aleatórias tais que $X$ é nula quase certamente.
  Mostre que $X + Y$ tem a mesma distribuição de $Y$.
\end{exercise}

O exercício acima é bastante simples, mas o usaremos para fazer uma importante observação sobre como são enunciados tipicamente os resultados de probabilidade.

Raramente encontramos teoremas que explicitam qual é o espaço de probabilidades $\Omega$ em questão.
Como no exercício acima, o contexto de um teorema frequentemente é dado apenas em termos de elementos aleatórios em $\Omega$ e de suas distribuições.
Dessa forma, podemos utilizar o resultado em vários contextos diferentes, desde que possamos encontrar elementos aleatórios que satisfaçam as hipóteses.
Com o tempo, passamos até mesmo a considerar menos relevante a escolha específica do espaço amostral, focando cada vez mais na distribuição de seus elementos aleatórios.

\begin{topics}

\section{Tópico: O paradoxo de Bertrand}

Vamos estudar um problema que realça a importância do jeito em que escolhemos o espaço amostral.
Queremos calcular a probabilidade que uma corda ``uniformemente distribuida'' em um círculo seja maior do que o lado do triângulo equilátero inscrito nesse  círculo (no caso do círculo unitário, o comprimento desse lado vale $\sqrt{3}$).
Bertrand propôs dois métodos para realizar esse cálculo. \index{Paradoxo de Bertrand@Paradoxo de Bertrand} \footnote{Somos gratos a Hubert Lacoin por sugerir e redigir esse tópico.}

\begin{enumerate}[\quad a)]
 \item Escolher as duas extremidades da corda uniformemente no círculo.
 \item Escolher o centro da corda uniformemente no interior do disco.
\end{enumerate}

No caso $a)$, uma vez que uma extremidade é fixada, o comprimento da corda fica maior do que $\sqrt{3}$ somente se o segundo ponto ficar num setor angular de comprimento $2 \pi / 3$.
Logo, essa probabilidade vale $(2\pi/3) / (2\pi) = 1/3$.

\medskip

No caso $b)$, pra que a corda fique maior do que $\sqrt{3}$, o centro dela deve ficar no circulo inscrito dentro do triângulo equilátero, cujo raio é $1/2$.
Então a probabilidade vale a razão dessas áreas, que é $1/4$.

\medskip

Obtemos então duas respostas diferentes para essa pergunta simples, o que não é nada surpreendente: $a)$ e $b)$ correspondem a dois experimentos
diferentes com espaços amostrais diferentes.

\end{topics}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Notas_de_aula"
%%% End:
