\chapter{Probabilidades condicionais}

Uma outra maneira de se construir espaços de probabilidade é através de condicionamento, como mostra a seguinte definição.
\begin{definition}
  Se $(\Omega, \mathcal{F}, P)$ é espaço de probabilidade e $B \in \mathcal{F}$ é tal que $P(B) > 0$, então definimos a probabilidade \index{probabilidade!condicional} $P(\cdot | B): \mathcal{F} \to [0,1]$ por
  \begin{equation}
    \label{e:P_condicional}
    P(A | B) = \frac{P(A \cap B)}{P(B)},
  \end{equation}
  chamada probabilidade condicional dado o evento $B$.
\end{definition}

Obviamente $P(\cdot | B)$ é uma probabilidade em $(\Omega, \mathcal{F})$ e podemos entendê-la de duas formas: como uma normalização ou como uma tentativa de sucesso.
Explicaremos abaixo cada uma dessas interpretações.

Quando restringimos o espaço amostral $\Omega$ ao conjunto $B$ (e associamos a $A \in \mathcal{F}$ o valor $P(A \cap B)$), temos uma sub-probabilidade, isto é, possivelmente $P(\Omega \cap B) < 1$.
Logo podemos entender o denominador de \eqref{e:P_condicional} como uma normalização para obtermos novamente uma probabilidade.

Mas a interpretação mais natural de \eqref{e:P_condicional} é dada pela seguinte proposição.
Para enunciá-la, considere $(\Omega, \mathcal{F}, P)$ um espaço de probabilidade e defina o produto infinito
\begin{equation}
  \widebar{\Omega} =\Omega^{\mathbb{N}}, \qquad \widebar{\mathcal{F}} = \mathcal{F}^{\otimes \mathbb{N}} \quad \text{e} \quad \widebar P =  P^{\otimes \mathbb{N}}.
\end{equation}
Na verdade somente definimos esse produto para $\Omega = \mathbb{R}$, mas como mencionamos abaixo do Teorema da Extensão de Kolmogorov, isso pode ser facilmente generalizado e o faremos posteriormente.

\begin{proposition}
  Na situação acima, seja $B \in \mathcal{F}$ com $P(B) > 0$ e defina $T:\widebar{\Omega} \to \mathbb{N}$ por $T(\omega) = \inf \{n \geq 1\, : \, X_n(\omega) \in B\}$, onde os $X_n$ são as coordenadas canônicas. Então $T < \infty$ quase certamente e
  \begin{equation}
    \text{$X_{T(\omega)}(\omega)$ é um elemento aleatório em $\Omega$ com distribuição $P(\cdot | B)$.}
  \end{equation}
\end{proposition}

A intuição desta proposição é que se repetimos o experimento $(\Omega, \mathcal{F}, P)$ independentemente até obter uma amostra em $B$, essa terá a distribuição condicional.

\begin{proof}
  Sejam os eventos $A_n = [X_n \in B]$, $n \geq 1$ que são claramente independentes segundo $\widebar{P}$.
  Logo, como $\sum_n \widebar{P}(A_n) = \sum_n P(B) = \infty$, temos pelo Lema de Borel-Cantelli (segunda parte) que $\widebar{P}(\text{$A_n$ infinitas vezes}) = 1$, logo $T < \infty$ quase certamente.

  Para ver que $X_{T(\omega)}(\omega)$ é um elemento aletório, basta escrever
  \begin{equation}
    [X_{T} \in A] = \mcup_{t=1}^\infty [X_t \in A, T = t],
  \end{equation}
  e observar que tanto $[X_t \in A]$ quanto $[T = t] = [X_1 \not \in B, \dots, X_{t-1} \not \in B, X_t \in B]$ são mensuráveis.

  Finalmente podemos usar a decomposição (disjunta) acima para calcular
  \begin{equation}
    \begin{split}
      \widebar{P}[X_T \in A] & = \sum_{t=1}^\infty \widebar{P} [X_t \in A, T = t]\\
      & = \sum_{t=1}^\infty \widebar{P} [X_t \in A, X_t \in B, X_s \not \in B \text{ for $s < t$}]\\
      & = \sum_{t=1}^\infty P(A \cap B) P(B^c)^{t-1} = \frac{P(A \cap B)}{1-P(B^c)} = P(A | B),
    \end{split}
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{exercise}
  Sejam $\lambda > 0$ e $X \distr \Exp(\lambda)$ (lembrando a definição da distribuição exponencial: $\Exp(\lambda)(\d x) = \lambda \exp\{- \lambda x\} \d x$).
  Mostre que as variáveis com distribuição exponencial não possuem memória, ou seja:
  \begin{equation}
    \label{e:sem_memoria}
    P[X > t + s\, |\, X > t] = P [X > s], \text{ para todo $s, t > 0$}.
  \end{equation}
  Ou em outras palavras, sabendo que $X$ é maior que $t$, a distribuição condicional de $X - t$ ainda é $\Exp(\lambda)$.
\end{exercise}

Definimos a distribuição geométrica \index{distribuicao@distribuição!geometrica@geométrica} de parâmetro $p \in (0,1]$ por
\begin{equation}
  \Geo(p) = \sum_{i = 1}^\infty (1-p)^{i-1} p \delta_i.
\end{equation}

\begin{exercise}
  Inspirado no exercício anterior, mostre que a distribuição geométrica $\Geo(p)$ também satisfaz \eqref{e:sem_memoria} para todos $t, s \in \mathbb{N}$.
  Mostre que essas são as únicas distribuições com suporte em $\mathbb{N}$ satisfazendo tal propriedade
\end{exercise}

\begin{exercise}
  \label{x:geo_time}
  Sejam $Y_i$, para $i \geq 1$, \iid com distribuição $\Ber(p)$ e defina
  \begin{equation}
    T = \inf\{i\, : \, Y_i = 1\}.
  \end{equation}
  Mostre que $T \overset{d}\sim \Geo(p)$.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 2-5, Ex: 5, 10, 21, 22 (a) e (b).
\end{exercise}

\begin{exercise}[Porta dos desesperados]
  Nas tardes da década de 80, as crianças tinham poucas opções de entretenimento além de assistir Sérgio Malandro, que todos os dias apresentava o seguinte jogo.
  O participante era apresentado a três portas ($\Omega = \{1,2,3\}$) e apenas uma delas (chamada de $X$) continha um prêmio $X \distr U_{\Omega}$ e o jogo seguia três fases:
  \begin{enumerate}[\quad a)]
  \item O participante escolhia uma porta arbitrariamente (digamos $y \in \Omega$),
  \item o Sérgio Malandro abria uma porta $X'$ que não fosse a escolhida nem a premiada ($X' \distr U_{\Omega \setminus \{y, X\}}$)
  \item ao participante era dada a oportunidade de trocar sua porta $X$ pela porta restante em $\Omega \setminus \{X, X'\}$.
  \end{enumerate}
  Mostre que o participante sempre aumenta suas chances ao trocar sua escolha.
  Tente interpretar esse aparente paradoxo tomando o número de portas para infinito.
\end{exercise}

\begin{exercise}
  Emílio e Cristina tiveram dois filhos cujos sexos $X, X'$ são \iid e distribuidos como $U_{\{\male, \female\}}$.
Enunciando hipóteses adequadas se for necessario,  calcule
  \begin{enumerate}[\quad a)]
  \item $P[X, X' = \male | \text{ pelo menos um é $\male$}]$ e
  \item $P[X, X' = \male | \text{ pelo menos um é $\male$ e nasceu em uma segunda-feira}]$.
  \end{enumerate}
  Interprete esses resultados trocando ``segunda-feira'' por ``primeiro de abril''.
  \footnote{Gratos ao Ricardo Misturini por sugerir esse problema}
\end{exercise}

\begin{exercise}
  Supondo que $P(A \cap B) > 0$, mostre que ``$P(\cdot|A|B) = P(\cdot|B|A)$''.
  Mais precisamente, podemos condicionar $P$ em $B$ e depois a probabilidade resultante em $A$ ou vice-versa.
\end{exercise}

\begin{exercise}
  Sejam $X, Y$ vari\'aveis aleat\'orias em um espaço $(\Omega, \mathcal{F}, P)$, independentes e com distribuição $U_{[0,1]}$.
  \begin{enumerate}[\quad a)]
  \item Calcule $ P_{X+Y}$.
  \item Considere $P'(\cdot) = P\big(\cdot \, | \, X + Y \leq 1 \big)$ e calcule $X_* P'$.
  \end{enumerate}
\end{exercise}

\todo{Falar de Lei da Probabilidade Total, com exemplos.}

\subsection{Regra de Bayes}

Frequentemente definimos um espaço de probabilidade através de probabilidades condicionais.
Consideramos por exemplo um exame médico para detectar uma doença, caso em que temos
\begin{equation}
  \Omega = \{(\text{doente}, +), (\text{doente}, -), (\text{saudável}, +), (\text{saudável}, -)\},
\end{equation}
com obviamente a $\sigma$-álgebra das partes.

Contudo, ao contrário do que fizemos anteriormente, não daremos probabilidades $p_\omega \in [0,1]$ para cada $\omega \in \Omega$.
Poderíamos por exemplo fornecer
\begin{equation}
  \label{e:exame_medico}
  P(\text{doente}) = 0.005, \quad P( + | \text{saudável}) = 0.01, \quad P( - | \text{doente}) = 0.05.
\end{equation}
Obviamente podemos obter as probabilidades dos complementos dos eventos acima.
As probabilidades acima podem ser facilmente estimadas num laboratório e as duas últimas são chamadas respectivamente de probabilidades de \emph{falso positivo} e \emph{falso negativo}.
Outra vantagem da representação em \eqref{e:exame_medico} é que as probabilidades descritas são mais ``compartimentadas'' no seguinte sentido.
Note que $P(\text{doente})$ somente depende da população em questão, enquanto as outras duas dependem apenas do exame e não da população.
Isso não pode ser dito das probabilidades de pontos individuais em $\Omega$.

Agora fica fácil construir nosso espaço de probabilidade escrevendo, para $r \in \{+, -\}$ e $e \in \{\text{saudável}, \text{doente}\}$,
\begin{equation}
  P(r \cap e) = P(r | e) P(e).
\end{equation}
E as probabilidades do lado direito da equação acima estão todas determinadas em \eqref{e:exame_medico} (possivelmente tomando complementos).

Contudo, o que estamos interessado muitas vezes é em como interpretar resultados de um exame.
Por exemplo, quanto vele $P(\text{doente} | +)$?
Isso nos é fornecido em geral pela regra de Bayes enunciada na seguinte proposição.

\begin{proposition}
  Se $(A_j)_{j\in I}$ formam uma partição (finita o enumeável) de $\Omega$ e $B \in \mathcal{F}$ tem probabilidade positiva, então
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{\sum_{j\in I} P(A_j) P(B | A_j)}.
  \end{equation}
\end{proposition}

\begin{proof}
  Basta notar que
  \begin{equation}
    P(A_i | B) = \frac{P(A_i) P(B | A_i)}{P(B)} = \frac{P(A_i) P(B | A_i)}{\sum_{j\in I} P(B \cap A_j)} = \frac{P(A_i) P(B | A_i)}{\sum_{j\in I} P(A_j) P(B | A_j)}.
  \end{equation}
\end{proof}

\begin{exercise}
  Utilize a fórmula acima para calcular $P(\text{doente} | +)$ com os dados em \eqref{e:exame_medico}.
  Comente o resultado.
\end{exercise}

\begin{exercise}
  Barry James: Cap. 1, Ex: 18 e 19.
\end{exercise}

\todosec{Tópico: Distribuições de Extremos}{fazer...}

\todosec{Acoplamentos}{Talvez valha a pena escrever sobre acoplamentos de maneira geral. Talvez pegando algo do Pascal Massart. Vale a pena tentar escrever algo sobre: composiçao de acoplamentos, quando um acoplamento ``dá errado''...}


\chapter{Esperança condicional}

\section{Esperança condicional}

Como já foi dito anteriormente, a estrutura de $\sigma$-álgebra tem um papel muito importante em probabilidade.
Durante o curso de Teoria da Medida, muitas vezes o conceito de $\sigma$-álgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conteúdo realmente interessante do curso.
Em alguns momentos, chegamos a desejar que tudo fosse mensurável e não tivéssemos que nos preocupar com tais formalidades.

Contudo, no estudo que iniciaremos agora, nos restringiremos a $\sigma$-álgebras menores de maneira proposital.
Ficará claro em particular, que o estudo de mensurabilidade não é uma mera tecnicalidade, mas sim uma ferramenta importante.

Esse interesse, vem da necessidade de representar situações de ``informação incompleta'', onde podemos apenas observar uma parte da realidade.
Isso certamente é de suma importância em diversas aplicações, desde a estatística, física e computação até a teoria de jogos.
Vamos começar com um exemplo simples.

Suponha que $\Omega = \mathbb{R}^2$ é dotado da $\sigma$-álgebra de Borel e denotamos por $X_1, X_2$ as coordenadas canônicas.
Como podemos representar matematicamente a afirmação ``uma pessoa somente conhece o valor de $X_1$ e não de $X_2$''?
Digamos por exemplo que essa pessoa deverá tomar uma decisão (por exemplo escolher um elemento de $E$) baseando-se apenas nessa informação incompleta.
A maneira que modelamos isso matemáticamente é dizendo que a decisão da pessoa deve ser uma função $f: \Omega \to E$ mensurável com respeito a $\sigma(X_1)$.

Nossa primeira utilização desse conceito será feita agora ao introduzirmos a noção de esperaça condicional, que generaliza o conceito de esperança.
Relembrando o cálculo \eqref{e:EX_aproxima}, nós podemos pensar em $E(X)$ como uma boa maneira de aproximar $X$ por um número real.
Isso por exemplo poderia ser útil se não temos nenhuma informação sobre o que ocorreu, mas ainda sim temos que tentar adivinhar o valor de $X$.
Mas vamos agora imaginar uma outra situação, onde temos um pouco de informação sobre o que ocorreu.

Voltando ao exemplo em que $\Omega = \mathbb{R}^2$, digamos que nós podemos observar o valor de $X_1$, mas gostaríamos de estimar o valor de $X_2$.
De acordo com o que discutimos acima, nossa estimativa agora não precisa mais ser apenas um número real, podendo ser qualquer função mensurável com respeito a $\sigma(X_1)$.

Vamos no que segue tornar esse discussão rigorosa, mas antes lembramos um lema básico de Teoria da Medida.

\begin{lemma}
  \label{l:f_igual_fp}
  Se $f, f'$ são funções mensuráveis tais que
  \begin{equation}
    \int_A f \d \mu = \int_A f' \d \mu, \text{ para todo $A \in \mathcal{F}'$,}
  \end{equation}
  então $f = f'$ $\mu$-quase certamente.
\end{lemma}

\begin{proof}
  Aplicando a hipótese para $A = [f > f']$, vemos que
  \begin{equation}
    \int_A f - f' \d \mu = 0,
  \end{equation}
  mas no conjunto $A$ acima, o integrando é positivo.
  Portanto, $f = f'$, $\mu$-quase certamente em $A$.
  Aplicando o mesmo raciocínio para $[f < f']$ obtemos que $f = f'$ quase certamente.
\end{proof}

O lema acima nos diz que se soubermos integrar $f$ em todos os eventos $A$, então podemos recuperar a função $f$ propriamente dita.
O que aconteceria se soubéssemos integrar $f$ apenas para eventos $A$ em uma sub-$\sigma$-álgebra?
É isso que estudaremos à partir de agora.

\begin{definition}
  \label{d:esperanca_condicional}
  Seja uma variável aleatória $X \in \mathcal{L}^1(P)$ e uma sub-$\sigma$-álgebra $\mathcal{F}' \subseteq \mathcal{F}$.
  Dizemos que uma variável aleatória $Y$ é a esperança condicional \index{esperanca@esperança!condicional} de $X$ com respeito a $\mathcal{F}'$ (ou a esperança condicional de $X$ dada $\mathcal{F}'$) se
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $E(X \1_{A}) = E(Y \1_{A})$ para todo $A \in \mathcal{F}'$.
  \end{enumerate}
  Nesse caso, escrevemos
  \begin{equation}
    Y = E(X | \mathcal{F}').
  \end{equation}
\end{definition}

Observe que faz sentido escrever $E\big(Y|\mathcal{F}'\big)(\omega)$, pois $E(X|\mathcal{F}')$ é uma variável aleatória.

Interpretamos informalmente a definição acima como ``$Y$ é a melhor aproximação $\mathcal{F}'$-mensurável de $X$''.
Ou $Y$ é a melhor aproximação que podermos fazer de $X$ se ``conhecemos apenas $\mathcal{F}'$''.

\begin{example}
  \label{x:EXF_trivial}
  Se $\mathcal{F}' = \{\varnothing, \Omega\}$, então $Y = E(X)$ (uma variável aleatória constante) é esperança condicional de $X$ dado $\mathcal{F}'$, pois
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável (por ser constante). Além disso
  \item $E(X \1_\varnothing) = 0 = E(Y \1_\varnothing)$ e $E(X \1_\Omega) = E(X) = E(Y \1_\Omega)$.
  \end{enumerate}
\end{example}

Uma propriedade muito importante que segue da Definição~\ref{d:esperanca_condicional} é dada pela seguinte

\begin{proposition}
  \label{p:ec_em_L1}
  Se $Y$ satisfaz as $a)$ e $b)$ em Definição~\ref{d:esperanca_condicional}, então $Y \in \mathcal{L}^1(P)$.
\end{proposition}

\begin{proof}
  Tomamos $A = [Y \geq 0]$ e $A' = [Y < 0]$ que estão em $\mathcal{F}'$ e estimamos
  \begin{equation}
    \int |Y| \d P = \int_A Y \d P + \int_{A'} Y \d P = \int_A X \d P + \int_{A'} X \d P \leq \int |X| \d P < \infty
  \end{equation}
  O que mostra a proposição.
\end{proof}

Além caso trivial dado acima pelo Exemplo~\ref{x:EXF_trivial}, quando podemos esperar que existam esperanças condicionais?

\begin{theorem}
  Dada $X \in \mathcal{L}^1(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$ uma $\sigma$-álgebra, então existe a esperança condicional $E(X|\mathcal{F}')$.
  Além disso ela é única $P$-quase certamente.
\end{theorem}

\begin{proof}
  Vamos primeiro mostrar a unicidade quase certa.
  Para isso, supomos que existam $Y$ e $Y'$ satisfazendo as condições da Definição~\ref{d:esperanca_condicional} (logo em $\mathcal{L}^1$).
  Iremos proceder como no Lema~\ref{l:f_igual_fp} acima, definindo $A = [Y > Y']$, donde concluímos que
  \begin{equation}
    E\big( (Y - Y')\1_{A} \big) = E(Y \1_{A}) - E(Y' \1_{A}) = 0.
  \end{equation}
  Mas como $Y > Y'$ em $A$, vemos que $Y \leq Y'$ quase certamtente.
  A prova da unicidade pode ser completa trocando os papéis de $Y$ e $Y'$ acima.

  Vamos agora para a prova da existência.
  Como $X \in \mathcal{L}^1(P)$, podemos introduzir
  \begin{equation}
    \mu(A) = E(X \1_{A}),
  \end{equation}
  que define uma medida com sinal em $(\Omega, \mathcal{F})$, com variação total finita.

  Caso o leitor não se sinta familiarizado com o conceito de medida com sinal, poderá decompor $X$ em partes positiva e negativa e proceguir sem problemas.

  Um passo importante da prova é observar que $\mu$ também define uma medida no espaço $(\Omega, \mathcal{F}')$.
  Estamos portanto propositalmente restringindo nossa $\sigma$-álgebra.
  Como $P(A) = 0$ implica que $\mu(A) = 0$, temos que $\mu \ll P$ e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada $Y:\Omega \to \mathbb{R}$ tal que
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $\mu(A) = \int_A Y \d P$.
  \end{enumerate}
  Agora é só observar que as afirmações acima correspondem às condições da Definição~\ref{d:esperanca_condicional}.
\end{proof}

Observe que a condição de $\mathcal{F}'$-mensurabilidade é essencial para a unicidade.
De fato, $X$ obviamente satisfaz a segunda condição da Definição~\ref{d:esperanca_condicional}, mas não necessariamente a primeira.

\begin{exercise}
  Mostre que se $X \in \mathcal{F}'$, então $E(X|\mathcal{F}') = X$ quase certamente.
\end{exercise}

\begin{exercise}
  Seja $P$ a probabilidade uniforme em $\{(x_1, x_2) \in [0,1]^2; x_1 \geq x_2\}$.
  Calcule $E(X_2|X_1)$.
\end{exercise}

\begin{exercise}
  Seja $E$ enumerável com uma $\sigma$-álgebra $\mathcal{F}'$.
  Mostre que
  \begin{equation}
    \mathcal{F}' = \sigma(A_i, i \geq 1), \text{ com $A_i \subseteq E$ disjuntos}.
  \end{equation}
  Suponha que todos conjuntos $A_i$ tem probabilidade positiva e mostre que
  \begin{equation}
    E(X|\mathcal{F}') = \sum_i E^i(X) \1_{A_i},
  \end{equation}
  onde $E^i$ é a esperança com respeito à probabilidade $P(\cdot|A_i)$.

\end{exercise}


\section{Propriedades básicas da esperança condicional}

Nessa seção justificaremos, em certa medida, a nomenclatura ``esperança condicional''.
Faremos isso mostrando que ela satisfaz várias propriedades que já conhecemos para a esperança tradicional.

Mas como podemos mostrar propriedades simples tais como a linearidade da esperança condicional?
Vamos começar com um exemplo

\begin{proposition}
  \index{esperanca@esperança!condicional!aditividade}
  Se $X, X' \in \mathcal{L}^1(P)$, então
  \begin{equation}
    E(X + X'|\mathcal{F}') = E(X|\mathcal{F}') + E(X'|\mathcal{F}'), \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

Note que a igualdade acima é uma igualdade entre variáveis aleatórias.

\begin{proof}
  Sabemos que $Y = E(X|\mathcal{F}') + E(X'|\mathcal{F}')$ é uma variável aleatória bem definida.
  Mais do que isso, sabemos que ela é uma candidata muito boa a $E(X + X'|\mathcal{F}')$.
  Logo, por unicidade da esperança condicional, basta verificar que $Y$ satisfaz as condições da Definição~\ref{d:esperanca_condicional} com respeito a $X + X'$.
  De fato
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável, por ser uma soma de duas variáveis $\mathcal{F}'$-mensuráveis e
  \item por linearidade da esperança (não da esperança condicional), temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E\big( E(X|\mathcal{F}')\1_A + E(X'|\mathcal{F}')\1_A \big)\\
        & = E\big( E(X|\mathcal{F}')\1_A\big) + E\big(E(X'|\mathcal{F}')\1_A \big)\\
        & = E(X \1_A) + E(X' \1_A) = E\big( (X + X') \1_A \big).
      \end{split}
    \end{equation}
  \end{enumerate}
  Isso termina a prova do proposição.
\end{proof}

\begin{exercise}
  Dados $X \in \mathcal{L}^1$ e $\alpha \in \mathbb{R}$, mostre que $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$.
\end{exercise}

Uma outra propriedade bem simples da esperança condicional é a monotonicidade.

\begin{lemma}
  \index{esperanca@esperança!condicional!monotonicidade}
  \label{l:ec_mono}
  Se $X \geq X'$ em $\mathcal{L}^1(P)$, então
  \begin{equation}
    E(X|\mathcal{F}') \geq E(X'|\mathcal{F}'), \text{$P$-quase certamente.}
  \end{equation}
  Em particular, se $X \geq 0$, então $E(X|\mathcal{F}') \geq 0$ quase certamente.
\end{lemma}

\begin{proof}
  Seja $A = [E(X'|\mathcal{F}') - E(X|\mathcal{F}') > 0]$, que pertence a $\mathcal{F}'$.
  Então
  \begin{equation}
    0 \leq E\big( (E(X'|\mathcal{F}') - E(X|\mathcal{F}')) \1_A \big) = E\big((X' - X) \1_A\big) \leq 0,
  \end{equation}
  o que implica que $P(A) = 0$.
\end{proof}

\begin{proposition}
  \label{p:EZX_ZEX}
  Se $X, ZX \in \mathcal{L}^1(P)$, com $Z \in \mathcal{F}'$, temos
  \begin{equation}
    E(XZ|\mathcal{F}') = Z E(X|\mathcal{F}') \text{ $P$-quase certamente}.
  \end{equation}
  Em particular, $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$, para todo $\alpha \in \mathbb{R}$.
  Uma outra consequência interessante é que $Z E(X|\mathcal{F}')$ estará automaticamente em $\mathcal{L}^1$.
\end{proposition}

De maneira bastante informal, vamos dar uma intuição para o resultado acima.
Ao considerarmos a esperança condicional dada $\mathcal{F}'$, nós já conhecemos as variáveis aleatórias $\mathcal{F}'$-mensuráveis, portanto elas se comportam como constantes.

\begin{proof}
  Mais uma vez, basta verificar que $Z E(X|\mathcal{F}')$ satisfaz as condições que definem a esperança condicional.
  A primeira é trivial, pois $Z E(X|\mathcal{F}')$ é $\mathcal{F}'$-mensurável por ser um produto de funções $\mathcal{F}'$-mensuráveis.

  Para provar a segunda condição, começamos com o caso $Z = \1_B$, implicando que $B \in \mathcal{F}'$, donde
  \begin{equation*}
    E\big(ZE(X|\mathcal{F}') \1_A \big) = E\big( E(X|\mathcal{F}') \1_{A \cap B}\big) = E(X \1_{A \cap B}) = E(ZX \1_A).
  \end{equation*}
  Por linearidade, já sabemos que o resultado vale para funções $Z$ simples e gostaríamos de extender para quaisquer $Z$ positivas via Teorema da Convergência Monótona.
  Um problema aqui é que mesmo que $Z$ seja positiva, não sabemos se $E(X|\mathcal{F}')$ também será positiva.

  Portanto, trataremos primeiramente do caso $X \geq 0$.
  Para tais $X$, sabemos pelo Lema~\ref{l:ec_mono} que $E(X|\mathcal{F}') \geq 0$ quase certamente.
  Daí, podemos concluir que $Z E(X|\mathcal{F}') = E(ZX|\mathcal{F}')$ para toda $Z \geq 0$, podemos aproximá-la por baixo por $Z_n$ simples e, pelo Teorema da Convergência Monótona,
  \begin{equation}
    \begin{array}{e}
      E\big( Z E(X|\mathcal{F}') \big) & \overset{\text{TCM}}= & \lim_n E\big( Z_n E(X|\mathcal{F}') \big)\\
      & = & \lim_n E\big( E(Z_n X|\mathcal{F}') \big) \overset{\text{TCM}}= E\big( E(ZX|\mathcal{F}') \big).
    \end{array}
  \end{equation}
  O que mostra o resultado sempre que $X \geq 0$.

  Além disso, pela Proposição~\ref{p:ec_em_L1}, sabemos que $Z E(X|\mathcal{F}') \in \mathcal{L}^1$.
  Podemos finalmente concluir a prova por linearidade decompondo $X = X_+ - X_-$.
\end{proof}

O próximo resultado tenta corroborar nossa afirmação que a esperança condicional é uma boa maneira de aproximar uma variável aleatória.

\begin{lemma}
  Se $X \in \mathcal{L}^2(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$, então $E(X|\mathcal{F}')$ é a projeção ortogonal de $X$ no espaço vetorial $H_{\mathcal{F}'}$.
  Onde $H_{\mathcal{F}'} = \{Y \in \mathcal{L}^2; Y \text{ é $\mathcal{F}'$-mensurável}\}$.
\end{lemma}

\begin{proof}
  Temos que verificar que $X - E(X|\mathcal{F}')$ é ortogonal a $H_{\mathcal{F}'}$.
  Ou seja, mostrar que para todo $Z \in H_{\mathcal{F}'}$, temos
  \begin{equation}
    E\big( XZ - E(X|\mathcal{F}') Z \big) = 0.
  \end{equation}
  Note que não é claro que essa esperança faz sentido, pois não sabemos que $ZE(X|\mathcal{F}') \in \mathcal{L}^1$.
  Mas isso segue facilmente da Proposição~\ref{p:EZX_ZEX}.

  Mas $E\big( E(X|\mathcal{F}') Z \big) = Z E\big( E(X | \mathcal{F}') \1_\Omega \big) = Z E\big( X \1_\Omega \big)$, provando o resultado.
  \todo{Adicionar footnote.}
\end{proof}

Uma outra propriedade que a esperança condicional herda da integral é a

\begin{proposition}[Desigualdade de Jensen]
  \index{esperanca@esperança!condicional!desigualdade de Jensen}
  Se $\phi:\mathbb{R} \to \mathbb{R}$ é convexa, $X, \phi(X) \in \mathcal{L}^1(P)$, então
  \begin{equation}
    \phi\big( E(X|\mathcal{F}') \big) \leq E\big( \phi(X) | \mathcal{F}' \big).
  \end{equation}
\end{proposition}

\begin{proof}
  Se $\phi$ for uma função linear, o resultado segue da linearidade que já provamos para a esperança condicional.
  Além disso, se temos uma função $\psi:\mathbb{R} \to \mathbb{R}$ linear e tal que $\psi(x) \leq \phi(x)$ para todo $x \in \mathbb{R}$, então
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq E\big( \psi(X) | \mathcal{F}' \big) = \psi \big( E(X|\mathcal{F}') \big).
  \end{equation}
  Tomamos finalmente o supremo em todas as $\psi$ lineares com $\psi \leq \phi$ dos dois lados da desigualdade acima, obtendo
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq \sup_{\substack{\psi \leq \phi\\\psi \text{ linear}}} \psi \big( E(X|\mathcal{F}') \big) = \phi \big( E(X|\mathcal{F}') \big),
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{corollary}
  Se $X \in \mathcal{L}^1(P)$, então $\big| E(X|\mathcal{F}') \big| \leq E\big(|X| \big| \mathcal{F}' \big)$.
\end{corollary}

Uma outra propriedade interessante da esperança condicional diz respeito a sua relação com independência.

\begin{proposition}
  Se $X \in \mathcal{L}^1(P)$ é independente de $\mathcal{F}'$, então
  \begin{equation}
    E(X|\mathcal{F}') = E(X) \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

\begin{proof}
  Funções constantes são sempre mensuráveis. Além disso, se $A \in \mathcal{F}'$, então
  \begin{equation}
    E(X \1_A) = E(X) P(A) = E\big( E(X) \1_A \big),
  \end{equation}
  concluindo a prova.
\end{proof}

Terminamos essa seção com o que chamamos da propriedade de torre da esperança condicional.

\begin{proposition}
  \index{esperanca@esperança!condicional!torre}
  Se $\mathcal{F}' \subseteq \mathcal{F}''$ são ambas sub-$\sigma$-álgebras de $\mathcal{F}$, então para $X \in \mathcal{L}^1(P)$, temos
  \begin{equation}
    \label{e:ec_torre}
    E\big( E(X|\mathcal{F}') \big| \mathcal{F}'' \big) = E(X|\mathcal{F}') = E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big),
  \end{equation}
  ou em outras palavras, independentemente da ordem, prevalece a condição na menor $\sigma$-álgebra.
  Consequentemente, $E\big( E(X|\mathcal{F}') \big) = E(X)$.
\end{proposition}

\begin{proof}
  Como $E(X|\mathcal{F}')$ é $\mathcal{F}''$-mensurável, a Proposição~\ref{p:EZX_ZEX}, aplicada com $X = 1$, mostra a primeira igualdade em \eqref{e:ec_torre}.

  Falta mostrar que $E\big( E(X|\mathcal{F}'') \big| \mathcal{F}'\big)$ é a esperança condicional de $X$ dada $\mathcal{F}'$.
  Obviamente ela é $\mathcal{F}'$-mensurável, e nos resta verificar a segunda condição.
  Mas para todo $A \in \mathcal{F}'$, lembrando que $A$ também pertence a $\mathcal{F}''$ e usando a definição de esperança condicional duas vezes,
  \begin{equation}
    E\Big( E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big) \1_A \Big) = E\big( E(X | \mathcal{F}'')  \1_A \big) = E(X \1_A).
  \end{equation}
  O que termina a prova da proposição.
\end{proof}


\section{Teoremas classicos de convergência para esperança condicional}
Vimos acima uma metodologia que se repete frequentemente.
Digamos que queremos provar que uma determinada expressão nos dá a esperança condicional de algo.
Podemos começar provando esse resultado para funções indicadoras, depois para funções simples usando a linearidade provada acima.
Porém ainda falta um ingrediente bastante importante para construir ou verificar que determinadas variáveis são esperanças condicionais.

\begin{theorem}[Convergência Monótona para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.M.}
  \label{t:TCM_EC}
  Se as variáveis $X_n$ satisfazem $X_n \uparrow X$ e estão todas em $\mathcal{L}^1(P)$, então
  \begin{equation}
    \lim_{n\to \infty} E(X_n|\mathcal{F}') = E(X|\mathcal{F}').
  \end{equation}
\end{theorem}

\begin{proof}[Demonstração do Teorema~\ref{t:TCM_EC}]
  Sabemos que $E(X_{n+1} | \mathcal{F}') \geq E(X_n|\mathcal{F}')$, donde concluímos que $E(X_n|\mathcal{F}') \uparrow Y$.
  Vamos demosntrar que $Y = E(X|\mathcal{F}')$.
  \begin{enumerate}[\quad a)]
  \item Por ser um limite de funções $\mathcal{F}'$ mensuráveis, $Y$ é $\mathcal{F}'$-mensurável.
  \item Dado $A \in \mathcal{F}'$, temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E(\lim_n E(X_n |\mathcal{F}') \1_A) \overset{\text{TCM}}= \lim_n E\big( E(X_n|\mathcal{F}') \1_A \big)\\
        & = \lim_n E(X_n \1_A) \overset{\text{TCM}}= E(X \1_A).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que termina a prova do teorema.
\end{proof}









Um outro resultado bastante importante é o seguinte

\begin{theorem}[Teorema da Convergência Dominada para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.D.}
  Se $X_n \to X$ e existe $Y \in \mathcal{L}^1(P)$ tal que $|X_n| \leq Y$ para todo $n$, então
  \begin{equation}
    E(X_n | \mathcal{F}) \to E(X|\mathcal{F}) \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

\begin{proof}
Primeiro, observamos que pelo Teorema de Convergência dominada (usual), o limite $X$ e integrável.\\


  Seja $Z_n = \sup_{k \geq n} |X_k - X|$ o erro máximo à partir de $n$.
  Claramente, $Z_n \downarrow 0$ quase certamente e além disso
  \begin{equation}
    |Z_n| \leq \sup_{k \geq 1} |X_k| + |X| \leq 2 Y,
  \end{equation}
  donde $E(Z_n) \to E(0) = 0$, quase certamente pelo Teorema da Convergência Dominada.
Obviamente $E(Z_n|\mathcal{F})$ é uma sequência positiva e não-crescente, logo decresce quase certamente para algum $Z$.
  Daí,
  \begin{equation}
    \big| E(X_n | \mathcal{F}) - E(X | \mathcal{F}) \big| \leq E(Z_n | \mathcal{F}) \downarrow Z \geq 0.
  \end{equation}
  Mas $E(Z) \leq E\big( E(Z_n|\mathcal{F}) \big) = E(Z_n)$.
  Como $E(Z_n)$ vai a zero pelo Teorema da Convergência Dominada, temos que $Z = 0$ quase certamente como gostaríamos.
\end{proof}

\section{Núcleos de transição}

Já focamos bastante energia em variáveis aleatórias independentes.
Por exemplo, estudamos em detalhes o que acontece com a soma de tais variáveis.
Agora passaremos a estudar elementos aleatórios dependentes e o primeiro passo para isso é obter um método geral de construí-los.

Definiremos agora um núcleo de transição.
Intuitivamente, ele nos dá uma maneira de usar um elemento aleatório em um espaço para induzir uma probabilidade em outro espaço.
Um exemplo em que poderíamos utilizar essa construção seria o seguinte.

Digamos que estamos preocupados com a possibilidade de um deslizamento de terra em uma determinada região.
A ocorrência desse deslizamento é algo aleatório, mas que certamente depende da quantidade de chuva no período, que também podemos modelar como sendo aleatória.

Após estudarmos alguns trabalhos anteriores, descobrimos uma função $F:\mathbb{R}_+ \to [0,1]$ que nos dá a probabilidade de um deslizamento ocorrer, como função da quantidade de chuva em milímetros.

Lendo o histórico pluvial da região, podemos estimar a distribuição $Q$ em $\mathbb{R}_+$ correspondente à quantidade de chuva naquele período.
A lei $F_* Q$ (também chamada de $Q_F$) é uma lei em $[0,1]$ que nos dá a distribuição da probabilidade de deslizamento, mas como seguimos em frente para obter a probabilidade de deslizamento (um número entre zero e um)?
Saberemos como fazer isso ao terminar essa seção.

Sejam $(E_1, \mathcal{A}_1)$ e $(E_2, \mathcal{A}_2)$ espaços mensuráveis.
\begin{definition}
  Um núcleo de transição entre $E_1$ e $E_2$ é uma função \index{nucleo de transicao@núcleo de transição}
  \begin{equation}
    K: E_1 \times \mathcal{A}_2 \to [0,1],
  \end{equation}
  tal que
  \begin{enumerate}[\quad a)]
  \item para todo $y \in E_1$, $K(y,\cdot)$ é uma probabilidade em $(E_2, \mathcal{A}_2)$ e
  \item para todo $A \in \mathcal{A}_2$, a função $K(\cdot, A): E_1 \to [0,1]$ é $\mathcal{A}_1$-mensurável.
  \end{enumerate}
\end{definition}

\begin{example}
  \label{x:chance_deslizamento}
  Daremos agora o exemplo da probabilidade de deslizamento como função de $F$ (que será possivelmente uma variável aleatória).
  Nesse caso, seja $E_1 = [0,1]$ e $E_2 = \{0,1\}$ com as $\sigma$-álgebras naturais e defina
  \begin{equation}
    K(p, A) = \big( (1-p)\delta_0 + p \delta_1 \big) (A).
  \end{equation}
\end{example}

Vamos verificar que $K$ definido acima é um núcleo de transição.
De fato,
\begin{enumerate}[\quad i)]
\item $K(p, \cdot)$ é a distribuição Bernoulli com parâmetro $p$, que obviamente é uma probabilidade,
\item além disso, $K(\cdot, \Omega) = 1$, $K(\cdot, \varnothing) = 1$ e $K(\cdot, \{0\}) = 1-p = 1 - K(\cdot,\{1\})$, que obviamente são mensuráveis.
\end{enumerate}

Isso prova que esse $K$ específico é um núcleo de transição

\begin{example}[Caso discreto]
  \label{x:nucleo_discreto}
  Sejam $E_1$ e $E_2$ espaços finitos ou enumeráveis.
  Se $p: E_1 \times E_2 \to [0,1]$ é tal que para todo $y \in E_1$ temos $\sum_{z\in E_2} p(y, z) = 1$, então
  \begin{equation}
    K(y, A) := \sum_{z \in A} p(y, z) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Nesse caso $p(y,z)$ representa a probabilidade que a segunda coordenada seja $z$, se a primeira é $y$.
\end{example}

\begin{exercise}
  Mostre que se $E_1$ e $E_2$ são enumeráveis então todo núcleo entre $E_1$ e $E_2$ pode ser escrito na forma do exemplo acima.
\end{exercise}

\begin{example}[Caso absolutamente contínuo]
  Digamos que $E_1$ e $E_2$ sejam dotados de medidas $\mu_1$ e $\mu_2$ $\sigma$-finitas.
  Seja $\rho: E_1 \times E_2 \to \mathbb{R}_+$ mensurável e tal que para $\mu_1$-quase todo $y \in E_1$, tenhamos $\int_{E_2} \rho(y, z) \mu_2(\d z) = 1$.
  Então
  \begin{equation}
    K(y, A) := \int_A \rho(y, z) \mu_2(\d z) \text{ é um núcleo de transição entre $E_1$ e $E_2$.}
  \end{equation}
  Note que $K(\cdot, A)$ está bem definido para $\mu_2$-quase todo ponto pelo Teorema de Fubini.
\end{example}

\begin{exercise}
  Prove que os dois exemplos acima de fato definem um núcleo.
\end{exercise}

Tipicamente, definimos os núcleos de transição introduzindo $K(y, \cdot)$ como sendo uma medida que depende de $y$.
Nesse caso, uma das condições para que $K$ seja um núcleo está automaticamente satisfeita, restando apenas mostrar que $K(\cdot, A)$ é mensurável para quaisquer $A \in \mathcal{A}_2$.
Mas obviamente o conjunto $\mathcal{A}_2$ pode ser muito complexo, então gostaríamos de apenas verificar que $K(\cdot, A)$ é mensurável para os conjuntos $A$ em uma classe rica o suficiente.

\begin{proposition}
  \label{p:K_nucleo_na_classe}
  Seja $K:E_1 \times \mathcal{A}_2 \to [0,1]$, tal que $K(y, \cdot)$ é uma medida para todo $y \in E_1$.
  Se $K(\cdot, A)$ é mensurável para todo $A \in \mathcal{G}$, onde $\mathcal{G}$ é um $\pi$-sistema que gera $\mathcal{A}_2$, então $K$ é um núcleo de transição.
\end{proposition}

\begin{proof}
  Como de costume, vamos definir
  \begin{equation}
    \mathcal{B} = \{B \in \mathcal{A}_2\, : \, K(\cdot, B) \text{ é $\mathcal{A}_1$-mensurável}\}.
  \end{equation}
  Obviamente, como $K(y, \cdot)$ é uma probabilidade, vale que
  \begin{enumerate}[\quad a)]
  \item $\Omega \in \mathcal{B}$, pois a função constante igual a um é mensurável.
  \item Se $B \in \mathcal{B}$, então $B^c \in \mathcal{B}$, pois $1 - f$ é mensurável se $f$ o é.
  \item E se $B_1, B_2,\dots, B_n \in \mathcal{B}$ são disjuntos, então $\mcup_{i=1}^n B_i \in \mathcal{B}$, pois a soma de funções mensuráveis também é mensurável.
  \end{enumerate}

  A discussão acima mostra que $\mathcal{B}$ é um $\lambda$-sistema que contém o $\pi$-sistema $\mathcal{G}$.
  Daí, vemos pelo Teorema~\ref{t:dynkin} que $\mathcal{A}_2 = \sigma(\mathcal{G}) \subseteq \mathcal{B}$, provando a proposição.
\end{proof}

\begin{exercise}
  Seja $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por $K(y, \cdot) = U_{[y - 1,y + 1]}$.
  Mostre que $K$ define um núcleo de transição.
\end{exercise}

Apesar de interessante, a definição acima ainda não nos permitiu definir espaços de probabilidade novos.
Isso será possibilitado pelo próximo resultado, que pode ser visto como uma generalização do Teorema de Fubini.

\chooseoptpar{
\begin{theorem}[Fubini para Núcleos de Transição]
  \index{Teorema!de Fubini para Nucleos@de Fubini para Núcleos}
  \label{t:fubini}
  Dado um núcleo \opt{}{de transição} $K$ de $(E_1, \mathcal{A}_1)$ para $(E_2, \mathcal{A}_2)$ e uma probabilidade $P_1$ em $E_1$, existe uma única probabilidade $P$ em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$ tal que
  \begin{equation}
    \label{e:fubini}
    \int_{E_1 \times E_2} f dP = \int_{E_1} \int_{E_2} f(y,z) K(y, \d z) P_1 (\d y),
  \end{equation}
  para toda $f:E_1 \times E_2 \to \mathbb{R}_+$.
  Em particular, $P(A_1 \times A_2) = \int_{A_1} K(y, A_2) P_1 (\d y)$.
  Nesse caso escrevemos $P = P_1 \star K$.
\end{theorem}
}

\todo{Trocar $y, z$ por $x, y$.}

Antes de iniciar a prova do teorema, vamos ver que as integrais do lado direito de \eqref{e:fubini} estão bem definidas.
Para isso, definimos para $y \in E_1$ a função fatiadora $\phi_y: E_2 \to E_1 \times E_2$ dada por $\phi_y(z) = (y, z)$.
Obviamente essa função é mensurável, pois
\begin{equation}
  \phi_y^{-1}(A_1 \times A_2) =
  \begin{cases}
    \varnothing, \quad & \text{ se $y \not \in A_1$ e}\\
    A_2, & \text{ se $y \in A_1$}.
  \end{cases}
\end{equation}
Dessa forma, para definirmos $\int f(y,z) K(y, \d z)$, introduzimos $f_y: A_2 \to \mathbb{R}_+$ dada por $f_y(z) = f(y,z)$, que é mensurável pois $f_y = f \circ \phi_y$.

Assim, gostaríamos de integrar a função $y \mapsto \int f_y(z) K(y, \d z)$, que está obviamente bem definida.
Porém resta a pergunta, será que essa expressão define uma função mensurável de $y$?

\begin{lemma}
  Se $K$ é um núcleo de transição, então para toda $f: E_1 \times E_2 \to \mathbb{R}_+$ que seja $\mathcal{A}_1 \otimes \mathcal{A}_2$ mensurável, temos que $g^f:A_1 \to \mathbb{R}_+$ dada por
  \begin{equation}
    g^f(y) = \int f_y(z) K(y, \d z)
  \end{equation}
  é $\mathcal{A}_1$-mensurável.
\end{lemma}

\begin{proof}
  Se $f = \1_{A_1 \times A_2}$ para $A_i \in \mathcal{A}_i$, $i = 1,2$, então temos que $g^f(y) = K(y, A_2) \1_{A_1}$, que obviamente é mensurável pois $K$ é um núcleo.

  Definimos $\mathcal{D} = \{B \in \mathcal{A}_1 \otimes \mathcal{A}_2\, : \, g^{\1_B} \text{ é $\mathcal{A}_1$-mensurável}\}$.
  É fácil ver que $\mathcal{D}$ é um $\lambda$-sistema que contém o $\pi$-sistema dos retângulos, logo $\mathcal{D} = \mathcal{A}_1 \otimes \mathcal{A}_2$.

  Acabamos de ver que $g^f$ é mensurável para toda $f$ indicadora, donde o mesmo vale para $f$ simples por linearidade e para toda $f$ positiva pelo Teorema da Convergência Monótona (lembre que limite de funções mensuráveis é mensurável).
\end{proof}

Estamos prontos agora para fornecer a
\begin{proof}[Demonstração do Teorema~\ref{t:fubini}]
  Já sabemos que a integral do lado direito de \eqref{e:fubini} está bem definida (assumindo possivelmente o valor infinito).
  A unicidade vale obviamente pois \eqref{e:fubini} aplicado a funções indicadoras temos necessariamente para todos $B$
\begin{equation}
    P(B) = \int_{E_1} \int_{E_2} \1_{B} K(y, \d z) P_1 (\d y).
  \end{equation}
  Só temos que verificar a fórmula acima nos define uma probabilidade em $(E_1 \times E_2, \mathcal{A}_1 \otimes \mathcal{A}_2)$.

  De fato,
  \begin{enumerate}[\quad a)]
  \item obviamente $P(E_1 \times E_2) = \int_{E_1} \int_{E_2}  K(y, \d z) P_1(\d y) = 1$ e
  \item se $(B_i)_{i\in I}$ e uma família finita ou enumerável de eventos disjuntos (em $\mathcal{A}_1 \otimes \mathcal{A}_2$) então
  $\1_{\bigcup_{i\in I} B_i}=\sum_{i\in I} \1_{B_i}$ a $\sigma$-aditividade de $P$ segue das propriedades básicas
  (linearidade e Teorema de convergência monótona) da integração.
  \end{enumerate}
  Isto demonstra o teorema.
\end{proof}

\begin{exercise}
  \label{x:nucleo_constante}
  Considere duas probabilidades $P_i$ em $(E_i, \mathcal{A}_i)$ para $i = 1,2$ e $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dado por $K(y,A) = P_2(A)$.
  Mostre que $K$ é núcleo e que $P_1 \star K = P_1 \otimes P_2$.
  Relacione esse resultado ao Teorema de Fubini clássico para produtos de medidas.
\end{exercise}

\begin{exercise}
  Considere o núcleo do Exemplo~\ref{x:chance_deslizamento} e calcule:
  \begin{enumerate}[\quad a)]
  \item $U_{[0,1]} \star K [X_2 = 1]$,
  \item $P_1 \star K [X_2 = 1]$, onde $\d P_1 = 2x \d x$ e
  \item encontre a distribuição de $(X_1)_* \big( U_{[0,1]} \star K [\; \cdot \; | X_2 = 1] \big)$. Interprete o resultado.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Seja $P = P_1 \star K$ como acima e $Q(\cdot) = P[\cdot | X_2 = 1]$.
  Calcule
  \begin{equation}
    \int_{[0,1] \times \{0,1\}} X_1 \d Q
  \end{equation}
\end{exercise}

\begin{exercise}
  Para $0 \leq a < b \leq 1$, definimos a probabilidade $U_{[a,b]}$ em $([0,1], \mathcal{B}([0,1]))$ através da seguinte fórmula $U_{[a,b]}(B) = \mathcal{L}(B \cap [a,b])/(b-a)$.
  Consideramos também a função $K:[0,1] \times \mathcal{B}([0,1]) \to [0,1]$ dada por $K(x, \cdot) = U_{[0,x]} (\cdot)$, se $x > 0$ e $K(0, \cdot) = \delta_0(\cdot)$.
  \begin{enumerate}[\quad a)]
  \item Mostre que $K$ é um núcleo de transição.
  \item Calcule $U_{[0,1]} \star K [X_1 < 1/2]$ e $U_{[0,1]} \star K [X_2 < 1/2]$, onde $X_1$ e $X_2$ são as projeções canônicas em $[0,1]^2$.
  \item Mostre que $U_{[0,1]} \star K$ é absolutamente contínua com respeito à medida de Lebesgue em $[0,1]^2$ e calcule sua densidade.
\end{enumerate}

\end{exercise}

\begin{exercise}
  Considere $K:E_1 \times \mathcal{A}_2 \to [0,1]$ dada por $K(p, \cdot) = \Exp(p)$.
  Mostre que $K$ é núcleo de transição e calcule $U_{[0,1]} \star K [X_2 > 1]$.
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $E_2$ e $\{y\} \in \mathcal{A}_1$ satisfaz $P_1(\{y\}) > 0$, mostre que
  \begin{equation}
    P_1 \star K [X_2 \in \cdot | X_1 = y] = K(y, \cdot).
  \end{equation}
  Ou em outras palavras, $K$ nos dá a distribuição condicional de $X_2$ dado $X_1 = y$.
\end{exercise}

Posteriormente extenderemos o resultado acima para o caso $P_1(\{y\}) = 0$, mas isso demandará algum esforço.

Vamos introduzir uma última notação com respeito a núcleos de transição.
Muitas vezes, não estamos interessados na distribuição conjunta de $P_1 \star K$ em $E_1 \times E_2$, mas apenas na distribuição marginal da segunda coordenada.
No nosso problema da chuva por exemplo, talvez poderíamos estar interessados apenas na probabilidade final de ocorrer um deslizamento.
Nesse caso, é conveniente escrever
\begin{equation}
  \label{e:P1_K}
  P_1 K := (X_2)_*(P_1 \star K) = (P_1 \star K)_{X_2}.
\end{equation}

\begin{exercise}
  Seja $K:\mathbb{R}_+ \times \mathcal{B}(\mathbb{R}_+) \to [0,1]$ dada pela equação $K(x,A) = \int_A x \exp\{-x t\} \d t$.
  \begin{enumerate}[\quad a)]
  \item Prove que $K$ \'e um n\'ucleo de transi\c{c}\~ao.
  \item Seja $P$ dada por $P = \textnormal{Exp}(1) \star K$.
    Obtenha $P[X_2 > x_2]$ para todo $x_2 \geq 0$ (lembrando que $X_2$ denota a segunda coordenada no espa\c{c}o produto onde est\'a definida $P$).
    Compare a probabilidade acima com $K(1,[x_2, \infty))$.
  \item Mostre que $P[X_1 + X_2 \geq z] = \int_0^z \exp \{-x(z-x+1)\} \d x + \exp\{-z\}$.
  \end{enumerate}
\end{exercise}

\vfill
\pagebreak


\subsection{Condicionamento com respeito a um elemento aleatorio.}

No caso onde $\cF'$ e a $\sigma$-algebrà gerada por uma variavel (o elemento) aleatoria(o) $Z$, 
muitas vezes escreveremos $E(X|Z)$ para representar a esperança condicional $E(X|\sigma(Z))$.


\begin{lemma}
  \label{l:f_g_circ_X}
  Se $X: \Omega \to E$ é um elemento aleatório e $Y:\Omega \to \mathbb{R}$ é uma variável aleatoria $\sigma(X)$-mensurável, 
  então existe uma $g:E \to \mathbb{R}$ mensurável tal que $Y = g(X)$.
\end{lemma}

\begin{proof}
  Como de costume, consideramos primeiramente o caso $Y = \1_A$
  Claramente $A$ tem que pertencer a $\sigma(X)$, ou seja $A = X^{-1}(B)$ para algum $B \in \mathcal{A}$.
  Neste caso colocamos $g = \1_B$, donde obtemos $Y(\omega) = 1 \Leftrightarrow \omega \in A \Leftrightarrow X(\omega) \in B \Leftrightarrow g \circ X = 1$.

  No caso em que $Y$ é simples, temos $Y = \sum_i a_i (g_i (X)) = (\sum_i a_i g_i)(X)$.
  Se $Y$ é positiva, então ela é um limite crescente de funções simples $Y_n$ que podem se ser exprimidas como $g_n(X)$. 
  Além disso podemos escolher $g_n$ crescentes, pois se não for o caso definindo $\tilde g_n= \max_{k\le n}g_k$ temos
  tambem $Y_n=\tilde g_n(X)$, pois por indução
  \begin{equation}
    Y_{n+1} = \max(Y_{n+1}, Y_{n}) = \max(g_{n+1}(X) , \tilde g_n(X)) = \tilde g_{n+1}(X).
  \end{equation}
Se $g$ for o limite de $\tilde g_n$, temos $Y=g(X)$.

\medskip

  Finalmente usamos a linearidade da composição novamente para resolver o caso geral $f = f_+ - f_-$.
\end{proof}







Se $X: \Omega \to E$ é elemento aleatório, então $E(Y|\sigma(X))$ é $\sigma(X)$-mensurável e mensurável por definição e temos
$E[Y| X] = g(X)$ para alguma $g: E \to \mathbb{R}$.
Nesse caso ``calcular'' a esperança de $Y$ conditionada a $\sigma(X)$ corresponde a achar uma expressão para essa função. 

\begin{exercise}
  Mostre que $g$ é única modulo modificações em conjuntos de probabilidade zero para $P_X$. 
\end{exercise}

No caso onde a distribuição $X$ tem supporte discreto, a função $g$ tem que ser definida por 
$$g(x)=E[Y \, | \, X = x]= \frac{E[Y\1_{\{X=x\}}]}{P[X=x]}$$


% 
% Gostaríamos de extender essa noção $E(Y|X = x)$ satisfaz alguma propriedade que justifique essa notação.
% Apesar de que apenas na próxima seção poderemos justificar completamente essa nomenclatura, nesse momento já podemos mostrar a seguinte relação
% \begin{equation*}
%   E(Y) = E\big( E(Y | X) \big) = E\big( E(Y | X = x) \circ X \big) = \int E(Y| X = x) (X \circ P) (\d x).
% \end{equation*}
% Em outras palavras, para integrar $Y$, basta conhecermos a distribuição de $X$ e a esperança condicional de $Y$, dado que $X = x$.

\begin{exercise}
  Sejam $X$ e $Y$ as coordenadas canônicas em $E_1 \times E_2$, com a probabilidade $P = \mu_1 \otimes \mu_2$ e seja $f:E_1 \times E_2 \to \mathbb{R}$
  em $\mathcal{L}^1(P)$.
  Mostre que
  \begin{equation}
     E[ f(X,Y) \,| \, X] = \int f(X, y) \mu_2(\d y).
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $\mathbb{R}$ e $P_1$ é uma probabilidade em $E_1$, mostre que se $P=P_1 \star K$ temos
  \begin{equation}
    E[ X_2 \, | \, X_1] = \int x_2 K(X_1, \d x_2).
  \end{equation}
\end{exercise}


\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $\mathbb{R} \times E$ e definimos a probabilidade $\d P = \rho(x,y) \d \mu_1 \d \mu_2$, onde $\rho:\mathbb{R} \times E \to \mathbb{R}_+$ é uma densidade.
  Dê sentido à expressão abaixo e mostre que elá é $E(X_1|X_2)$:
  \begin{equation}
     \frac{\int x\rho(x, X_2) \mu_1(\d x)}{\int \rho(x, X_2) \mu_1(\d x)}.
  \end{equation}
\end{exercise}




\begin{exercise}
  Sejam $Z_1, Z_2, \dots$ variáveis aleatórias \iid em $\mathcal{L}^1(P)$ com $E(Z_1) = 0$.
  \begin{enumerate}[\quad a)]
  \item Defina $X_0 = 0$ e
    \begin{equation}
      X_n = \sum_{i = 1}^n Z_i, \text{ para $n \geq 1$.}
    \end{equation}
    Mostre que $E(X_{n + 1} | Z_1, \dots, Z_n) = X_n$.
  \item Supondo agora que $Z_1 \in \mathcal{L}^2(P)$ e $E(Z) = 0$, defina $Y_0 = 0$ e
    \begin{equation}
      Y_n = \Big( \sum_{i = 1}^n Z_i \Big)^2 - n E(Z_1^2)
    \end{equation}
    Mostre que $E(Y_{n + 1} | Z_1, \dots, Z_n) = Y_n$.
  \end{enumerate}
\end{exercise}


\todosec{Tópico: Martingais a tempo discreto}{fazer...}

\todosec{Tópico: Propriedade fraca de Markov}{mostrar que cadeias = processos...}

\todosec{Tópico: Recorrência e transiência}{markov recorrência/transiência + periodicidade...}

\begin{topics}
\section{Tópico: Cadeias de Markov}
\label{s:cadeias_Markov}

Um exemplo de como usar núcleos de transição é a construção de Cadeias de Markov.
Esse tipo de processo é bastante útil em diversas aplicações, desde a biologia até a computação.

Considere um espaço mensurável canônico fixo $(E, \mathcal{A})$ e seja $K$ um núcleo de $E$ nele mesmo.
Seria bastante intuitivo agora iterar $K$ (já que ele está no mesmo espaço) 
e obter uma medida em $\Omega =E^{\bbN}$ com a $\sigma$-álgebra canônica.

Para começar esse procedimento, seja $\mu_0$ uma medida inicial em $(E, \mathcal{A})$.
Podemos então definir $\mu_1 = \mu_0 \star K$ o que é 
o primeiro passo da nossa construção, porém observe que não podemos escrever 
``$\mu_2 = \mu_1 \star K$'', pois $\mu_1 \star K$ é uma medida em $(E^2, \mathcal{A}^{\otimes 2})$.
Vamos com calma então.

Observe que
\begin{equation}
  \mu_1(A_0 \times A_1) = \int_{A_0} \int_{A_1} K(x_0, \d x_1) \mu_0(\d x_0),
\end{equation}
ou em outras palavras o valor de $x_0$ determina a distribuição de $x_1$.
Gostaríamos agora que $x_1$ determinasse a distribuição de $x_2$ via $K$, como por exemplo assim
\begin{equation}
  \mu_2(A_0 \times A_1 \times A_2) = \int_{A_0} \int_{A_1} \int_{A_2} K(x_1, \d x_2) K(x_0, \d x_1) \mu_0 (\d x_0).
\end{equation}
Mas essa notação fica bastante carregada à medida que iteramos.

Para tornar essa notação mais simples, definimos a projeção $\phi_n:E^n \to E$ por $\phi_n(x_0, \dots, x_{n-1}) = x_{n-1}$.
Também precisamos de $K_n: E^n \times \mathcal{A} \to [0,1]$ dado por
\begin{equation}
  K_n(\vec{x},A) = K\big(\phi_n(\vec{x}), A\big) \quad \big(= K(x_{n-1}),A) \big).
\end{equation}
O fato de $K_n$ ser um núcleo de transição segue imediatamente dessa propriedade para $K$.

Note que, nessa notação, estamos dizendo que para irmos de $E^n$ para $E^{n+1}$ iremos olhar apenas para a última coordenada, na qual aplicaremos o núcleo $K$.
Isso é o ponto mais importante que caracteriza uma Cadeia de Markov: a distribuição do estado futuro da cadeia depende apenas do estado atual e não do passado.
Em alguns contextos essa propriedade é chamada de ausência de memória.

Podemos finalmente definir
\begin{equation}
  \label{e:Pn_Markov}
  \mu_{n+1} = \mu_n \star K_n, \text{ para todo $n \geq 1$}.
\end{equation}
Mas resta a questão sobre a existência de uma $\mu^\infty$ que será respondida com ajuda do próximo resultado.

\begin{lemma}
  As probabilidades $\mu_n$ definidas em \eqref{e:Pn_Markov} são compatíveis, mais precisamente $\mu_{n+1}(A \times E) = \mu_n(A)$ para todo $A \in \mathcal{A}^{\otimes n}$.
\end{lemma}

\begin{proof}
  Basta observar que
  \begin{equation}
    \mu_{n+1}(A \times E) = \mu_n \star K (A \times E) = \int_{A} \underbrace{K_n (\vec{x}, E)}_1 \mu_n(\d \vec{x}) = \mu_n(A).
  \end{equation}
  Provando o lema.
\end{proof}

Logo, o Teorema da Extensão de Kolmogorov (lembre que $(E, \mathcal{A})$ foi suposto canônico) nos fornece uma única $P$ em $(\Omega, \mathcal{F})$ tal que
\begin{equation}
   P_{(X_0, \dots, X_n)} = \mu_n, \text{ para todo $n \geq 0$}.
\end{equation}
Lembramos que $X_i$ denotam as projeções canônicas em $\Omega = \mtimes_{i=1}^\infty E$.

Chamamos o processo $X_1, X_2, \dots$ sob a lei $P$ da Cadeia de Markov \index{Cadia de Markov} com distribuição inicial $\mu_0$ e núcleo de transição $K$.

\begin{example}
  \label{x:Markov_p_xy}
  Suponha que $E$ seja enumerável.
  Nesse caso recordamos do Exemplo~\ref{x:nucleo_discreto} que o núcleo pode ser representado por uma matriz $\big(p(x,y)\big)_{x,y \in E}$ que nos retorna a probabilidade de saltar de $x$ a $y$.
  Além disso, a distribuição inicial $\mu_0$ é determinada por $P(\{x\}) = p_0(x)$, para alguma sequência $\big(p_0(x)\big)_{x \in E}$.
\end{example}

\begin{exercise}
  Mostre que no exemplo acima temos
  \begin{equation}
    P(X_0 = x_0, \dots, X_n = x_n) = p_0(x_0) p(x_0, x_1) \dots p(x_{n-1}, x_n).
  \end{equation}
\end{exercise}

\begin{exercise}
  Defina $K:\mathbb{R}^2 \times \mathcal{B}(\mathbb{R}^2) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) = U_{S^1}(A - x).
  \end{equation}
  Nesse contexto,
  \begin{enumerate}[\quad a)]
  \item mostre que $K$ é um núcleo de transição e,
  \item considerando a cadeia com distribuição inicial $\mu_0 = \delta_0$ em $\mathbb{R}^2$ e núcleo $K$, mostre que $X_2$ tem distribuição absolutamente contínua com respeito a Lebesgue e calcule sua densidade.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Mostre que para qualquer núcleo de transição $K$ entre $E$ e $E$, existe um núcleo de transição 
  $\widebar{K}$ entre $E$ e $\Omega = E^{\bbN}$, tal que para toda medida inicial $\mu_0$, temos que $\mu_0 \star K$ é a distribuição de uma Cadeia de Markov começando de $\mu_0$ e com transição dada por $K$.
  Esse núcleo é útil se quisermos mudar a distribuição inicial $\mu_0$ e uma notação bastante comum para esse núcleo é $P_{x}(\cdot) = \widebar{K}(x, \cdot)$.
\end{exercise}

Vamos terminar essa seção dando uma interpretação bastante interessante para os núcleos de transição em analogia à álgebra linear.
Fixe um núcleo de transição $K$ entre $E$ e $E$, uma medida inicial $\mu$ e uma função limitada $f: E \to \mathbb{R}$.
Relembre a notação em \eqref{e:P1_K} e defina $K f: E \to \mathbb{R}$ dada por
\begin{equation}
  K f(x):= \int f(y) K(x, \d y),
\end{equation}
que é obviamente limitada e já vimos ser mensurável no Teorema de Fubini.

Então temos dois operadores definidos para núcleos, a multiplicação 
à esquerda por uma medida em $E$ ($\mu K$ que também é uma medida em $E$)
e a multiplicação à direita por uma função limitada e mensurável 
($K f$ que também é uma função limitada e mensurável).
Podemos pensar em $f$ como um vetor coluna e $\mu$ como um vetor linha, 
nesse caso $K$ faria o papel de uma matriz.
Essa analogia é real se $E$ for um espaço enumerável.

\begin{exercise}
  No contexto de cadeias de Markov,
  \begin{enumerate}[\quad a)]
  \item mostre a relação de associatividade $\mu (K f) = (\mu K) f$,
  \item defina para todo $n$ o núcleo $K^{(n)}$ iterado (de $E$ em $E$), de forma que $\mu K^{(n)} f$ ainda seja associativa.
  \item Mostre que a medida $\mu K^{(n)}$ é a distribuição de $X_n$ se começamos de $\mu$,
  \item que a função $K^{(n)} f (\cdot)$ é o valor esperado de $f$ no tempo $n$ se começamos no zero do ponto $\cdot$ e finalmente que
  \item o número real $\mu K^{(n)} f$ é a esperança de $f$ no tempo $n$ se começamos de $\mu$.
  \end{enumerate}
\end{exercise}

Vamos agora dar um exemplo simples de Cadeia de Markov que poderemos analisar em detalhes.

Seja $E = \mathbb{Z}$ e considere $K: \mathbb{Z} \times \mathcal{P}(\mathbb{Z}) \to [0,1]$ dado por
\begin{equation}
  K(x, \cdot) = \frac{\delta_{x-1} + \delta_{x+1}}{2},
\end{equation}
que obviamente define um núcleo pois toda função em $\mathbb{Z}$ é mensurável na $\sigma$-álgebra das partes.

Podemos portanto construir $P$ em $\mathbb{Z}^{\mathbb{N}}$ que nos fornece a lei de uma Cadeia de Markov em $\mathbb{Z}$ com distribuição inicial $\delta_0$ e núcleo de transição $K$.
Chamamos esse processo de passeio aleatório simples simétrico. \index{passeio aleatorio simples@passeio aleatório simples}

Poderíamos estar interessados em várias perguntas sobre esse processo, como por exemplo quão longe esperamos que o passeio aleatório pode ir depois de um determinado tempo?
Para responder essa e várias outras questões, iremos mostrar outra construção do passeio simples simétrico atravéz de uma soma de variáveis aleatórias.

Introduzimos um espaço de probabilidade $\tilde P$, variáveis $Y_1, Y_2, \dots$ \iid com distribuição $(\delta_{-1} + \delta_{1})/2$ e definimos $S_0 = 0$ e $S_n = Y_1 + \dots + Y_n$.

\begin{lemma}
  A distribuição da sequência infinita $(X_0, X_1, \dots)$ sob a lei $P$ do passeio aleatório simples e simétrico é igual à distribuição de $(S_0, S_1, \dots)$ sob $\tilde P$.
\end{lemma}

\begin{proof}
  Observamos primeiramente que basta mostrar a igualdade de distribuições para cilindros do tipo $\{x_1\} \times \dots \times \{x_n\} \times \mathbb{Z}^\mathbb{N}$, pois tais eventos compõem um $\pi$-sistema que gera a $\sigma$-álgebra produto em $\mathbb{Z}^\mathbb{N}$.
  Calculamos portanto
  \begin{equation*}
    \begin{split}
      \qquad P & [X_1 = x_1, \dots, X_n = x_n]
      \intertext{pela definição de Cadeia de Markov (via extensão de Kolmogorov),}
      & = \mu_n [X_1 = x_1, \dots, X_n = x_n]\\
      & = \mu_{n-1} \star K_n [X_1 = x_1, \dots, X_n = x_n]
      \intertext{por Fubini para núcleos (Teorema~\ref{t:fubini}),}
      & = \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] K_n\big( (x_1, \dots, x_{n-1}), \{x_n\} \big)\\
      & = \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] K\big( x_{n-1}, \{x_n\} \big)\\
      & = \frac 12 \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] \1_{\{|x_{n-1} - x_n| = 1\}}\\
      & = \dots = 2^{-n} \prod_{i=1}^n \1_{\{|x_{i-1} - x_i| = 1\}}.
    \end{split}
  \end{equation*}
  Faremos agora esse cálculo para a distribuição de $S_i$'s:
  \begin{equation*}
    \begin{split}
      \qquad \tilde P & [S_1 = x_1, \dots, S_n = x_n]\\
      & = \mu_n [Y_1 = x_1 - x_0, Y_2 = x_2 - x_1 \dots, Y_n = x_n - x_{n-1}]\\
      & = \prod_{i = 1}^n \tilde P [Y_i = x_i - x_{i-1}] = 2^{-n} \prod_{i=1}^n \1_{\{|x_{i-1} - x_i| = 1\}}.
    \end{split}
  \end{equation*}
  Isso mostra o enunciado do lemma.
\end{proof}

Podemos agora por exemplo estimar
\begin{equation}
  P[|X_n| \geq \varepsilon n] = \tilde P [|S_n| \geq \varepsilon n] \leq 2 \exp \{- \psi_{(\delta_{-1} + \delta_1)/2}(\varepsilon) n\},
\end{equation}
que responde nossa pergunta sobre a probabilidade de um passeio aleatório se distanciar muito da origem.

\end{topics}

\begin{topics}

\section{Tópico: Urna de Pólya}
\label{s:urna_polya}

Um excelente exemplo de como Cadeias de Markov podem gerar interessantes modelos de situações reais são as chamadas Urnas de Pólya.
Esse processo modela sistemas de física, biologia, computação e economia que apresentam o que chamamos de reforço.

Tome por exemplo duas empresas que competem pelo mercado de aviões.
Inicialmente, não temos nenhuma razão para escolher uma em detrimento da outra, portanto compramos nosso primeiro avião de cada empresa com probabilidade meio.
Porém, depois que já compramos diversos aviões de uma determinada empresa, ela já recebeu bastante dinheiro que pode ser reinvestido para gerar melhor tecnologia e aumentar as chances que ela seja escolhida novamente no futuro.
Isso é o que chamamos de reforço.

Vamos agora apresentar rigorosamente um modelo para situações desse tipo.
O nosso modelo começa com uma urna contendo duas bolas, uma vermelha e uma azul.
No cada passo do processo, escolheremos uma bola da urna ao acaso, olharemos sua cor e retornaremos essa bola para dentro urna junto com mais uma bola da mesma cor.
Isso pode será formalizado à seguir.

Vamos construir uma medida em $\{0, 1\}^\mathbb{N}$, dotado da $\sigma$-álgebra produto.
Fixada uma sequência finita $w_1, \dots, w_n$ em $\{0,1\}$, definimos
\begin{equation}
  N_x (w_1, \dots, w_n) = \# \big\{ j \in \{1, \dots, n\}\, : \, w_j = x \big\} + 1,
\end{equation}
que nada mais é que o número de bolas do tipo $x$ que se encontram na urna no tempo $n$.
Quando tivermos uma sequência infinita de $w_i$'s, escreveremos $N^n_x$ para denotar $N_x(w_1, \dots, w_n)$.

Para cada $n \geq 1$, definimos $K_n:\{0,1\}^n \times \mathcal{P}(\{0,1\})$ por
\begin{equation}
  K_n(w_1, \dots, w_n) = \Ber\big( \tfrac{N_1}{n} \big).
\end{equation}
Ou seja, dadas cores $w_1, \dots, w_n$, escolheremos uma bola de cor $1$ proporcionalmente ao número $N_1$ de bolas de cor $1$ que já foram sorteadas.

\begin{exercise}
  \label{x:constr_Polya}
  Mostre que todos $K_n$ acima definem núcleos de transição.
  Além disso a seguinte sequência de medidas é compatível no sentido de Kolmogorov:
  \begin{itemize}
  \item $P_1 = \Ber(1/2)$,
  \item $P_2 = P_1 \star K_1$,
  \item $P_3 = P_2 \star K_2, \dots$
  \end{itemize}
  Conclua que existe a medida $P$ em $\{0,1\}^\mathbb{N}$ que define o modelo de Pólya.
\end{exercise}

Podemos agora fazer perguntas como por exemplo: será que escolheremos bolas de ambas as cores para sempre, ou a partir de um certo momento escolheremos bolas de apenas uma cor com certa probabilidade.
Mais precisamente, qual é a probabilidade de $[X_i = 1, \text{ infinitas vezes}]$?


Para responder perguntas desse tipo, iremos mostrar algo muito curioso, que pode ser entendido como uma outra maneira de representar o modelo descrito acima.
Mas antes, vamos colecionar alguns fatos sobre o modelo da Urna de Pólya.

Primeiramente vamos olhar para os seguintes eventos.
Fixamos $n \geq 1$ e uma sequência $w_1, \dots, w_n \in \{0,1\}$ e seja $A$ o evento $\{w_1\} \times \dots \times \{w_n\} \times \{0,1\} \times \dots$
Note que os eventos desse tipo (junto com o evento $\varnothing$) formam um $\pi$-sistema que gera a $\sigma$-álgebra canônica de $\{0,1\}^\mathbb{N}$, portanto essa coleção é bastante completa para identificar a distribuição da Urna de Pólya.

Podemos calcular a probabilidade do evento $A$ acima
\begin{equation}
  \begin{split}
    P(A) & = \frac{N^1_{w_1}}2 \frac{N^2_{w_1}}3 \dots \frac{N^n_{w_n}}{n+1} = \frac{1}{(n+1)!} \prod_{i=1}^n N^i_{w_i}\\
    & = \frac{N^n_1! (n - N^n_1)!}{(n+1)!} = \frac{1}{(n+1)} \binom{n}{N^n_1}^{-1}.
  \end{split}
\end{equation}
O que é muito interessante sobre a equação acima é que ela nos remete a problemas combinatórios ao notarmos o fator binomial acima.

Vamos portanto construir um processo completamente diferente que apresenta as mesmas probabilidades que o anterior.
Seja $\cS_N$ o conjunto de todas as permutações $\sigma$ de $\{1,\dots,N\}$.
É fácil ver que
\begin{equation*}
  \frac{1}{(n+1)} \binom{n}{j}^{-1} = U_{\cS_{n+1}} \Big[ \sigma(n+1) =j+1, \sigma(i) \leq j \text{ se e só se } \; i \leq j \Big].
\end{equation*}

Um método muito interessante de se produzir uma permutação uniforme é dado pelos seguintes exercícios.

\begin{exercise}
  Seja $n \geq 1$ um inteiro, $P$ uma probabilidade em $(E, \mathcal{A})$, $\sigma$ uma permutação fixa em $\cS_n$.
  Então
  \begin{equation}
    \label{e:intercambiavel}
    (X_1, \dots, X_n) \distr (X_{\sigma(1)}, \dots, X_{\sigma(n)}),
  \end{equation}
  onde $X_i$ como sempre representam as coordenadas canônicas em $(E^{n}, \mathcal{A}^{\otimes n}, P^{\otimes n})$.
\end{exercise}

Ou em outras palavras, aplicar uma permutação fixa a uma sequência \iid não altera sua distribuição.
Sequências de elementos aleatórios (não necessariamente \iid's) que satisfazem \eqref{e:intercambiavel} são ditas intercambiáveis. \index{sequencias@sequências!intercambiaveis@intercambiáveis}

Um outro exercício interessante nesse tópico é o seguinte
\begin{exercise}
  Seja $n \geq 1$ e $F:[0,1]^n \to \cS_n$ dada por
  \begin{equation*}
    F(x_1, \dots, x_n) =
    \begin{cases}
      (1, 2, \dots, n), \quad & \text{se existe $i \neq j$ tal que $x_i = x_j$, }\\
      \text{o único $\sigma$ tal que $x_{\sigma(1)} < \dots < x_{\sigma(n)}$,} & \text{caso contrário.}
    \end{cases}
  \end{equation*}
  Mostre que $F_*(U_{[0,1]}^{\otimes n}) = U_{\cS_n}$.
\end{exercise}

Ou seja, ordenar uma sequência de uniformes independentes nos fornece uma permutação uniforme.
Como prometido, isso nos dá uma maneira de construir uma permutação uniforme de $\{1, \dots, n\}$ à partir de uma sequência \iid (que é algo que já estamos começando a entender melhor).

Podemos agora escrever nossa probabilidade de observar uma sequência no modelo da 
Urna de Pólya em termos de uma sequência \iid de variáveis aleatórias.
\begin{equation*}
  \begin{split}
    \frac{1}{(n+1)} \binom{n}{N^n_1}^{\mathclap{\;-1}} & =
    F_{*} U_{[0,1]}^{\otimes n+1} \Big[ \sigma(n+1) = N^n_1 + 1, \sigma(i) \leq N^n_1 \text{ se e só se } i \leq N^n_1 \Big]\\
    & =  U^{\otimes n+1}_{[0,1]} \Big[ \text{$X_i < X_{n+1}$, para $i \leq N^n_1$ e $X_i > X_{n+1}$, para $i \ge N^n_1+1$} \Big].
  \end{split}
\end{equation*}
Agora estamos prontos para provar o resultado principal que nos ajudará a calcular probabilidades no modelo da Urna de Pólya.

Dado $u \in [0,1]$, seja $P_u = \Ber(u)^{\otimes \bbN}$, ou seja a probabilidade que nos dá uma sequência infinita de moedas independentes com probabilidade $u$ de sucesso.
Definimos agora $\widebar{K}: [0,1] \times (\mathcal{P}(\{0,1\})^{\otimes \bbN}) \to [0,1]$ dada por
\begin{equation}
  \widebar{K}(u,A) = P_u(A).
\end{equation}

\begin{lemma}
  A função $\widebar{K}$ definida acima é um núcleo entre $[0,1]$ e $\{0,1\}^{\mathbb{N}}$.
\end{lemma}

\begin{proof}
  Usando a Proposição~\ref{p:K_nucleo_na_classe}, basta ver que
  \begin{display}
    para todo $k \geq 1$ e $w_1, \dots, w_k \in \{0,1\}$, temos que $P_u(X_1 = w_1, \dots, X_k = w_k)$ é uma função mensurável de $u \in [0,1]$.
  \end{display}
  Mas é fácil ver que
  \begin{equation}
    \label{e:Polya_binomial}
    P_u(X_1 = w_1, \dots, X_k = w_k) = u^{N_1(w_1, \dots, w_k)} (1 - u)^{N_0(w_1, \dots, w_k)},
  \end{equation}
  que obviamente é mensurável, provando assim o lema.
\end{proof}

O resultado muito curioso a qual nos referimos é o seguinte.

\begin{lemma}
  A lei $P$ definida no Exercício~\ref{x:constr_Polya} é igual a $U_{[0,1]} \widebar{K}$.
\end{lemma}

Em outras palavras, digamos que realizamos os seguintes experimentos.
Primeiramente João realiza o processo da Urna de Pólya e anota a sequência das cores obtidas.
Depois Maria sorteia uma variável aleatória $X$ de distribuição uniforme em $[0,1]$ e depois joga infinitas vezes uma moeda com probabilidade $X$ de obter vermelho e $(1-X)$ de obter azul, anotando também quais cores foram obtidas.
Finalmente, não seríamos capazes de distinguir essas duas sequências (mesmo que pudéssemos repetir várias vezes esse experimento) pois elas tem a mesma distribuição em $\{0,1\}^{\mathbb{N}}$.

\begin{proof}
  Já sabemos que basta mostrar a igualdade para eventos do tipo $A = \{w_1\} \times \dots \times \{w_n\} \times \{0,1\}^\mathbb{N}$.
  Sabemos pelo Teorema de Fubini para Núcleos que
  \begin{equation}
    U_{[0,1]} \widebar{K}(A) = \int_0^1 K(u, A) \d u \overset{\eqref{e:Polya_binomial}}= \int_0^1 u^{N_1(w_1, \dots, w_k)} (1 - u)^{N_0(w_1, \dots, w_k)} \d u.
  \end{equation}

  Por outro lado , sabemos (usando simetria entre $0$ e $1$)que
  \begin{equation}
    P[A]=U^{\otimes n+1}_{[0,1]} \Big[ \text{$X_i < X_{n+1}$, para $i \leq N^n_0$ e $X_i > X_0$, para $i \ge N^n_0+1$} \Big]
  \end{equation}

  Se definirmos $\tilde{K}:[0,1] \times \mathcal{B}([0,1]^n)$, dado por $\tilde{K}(u,B) =  U^{\otimes n}_{[0,1]}$, sabemos que isso define um núcleo pelo Exercício~\ref{x:nucleo_constante}.
  Mais ainda, esse mesmo exercício nos diz que $U_{[0,1]} \star \tilde{K} = 
   U^{\otimes}_{[0,1]}$, de forma que
  \begin{equation*}
    \begin{split}
      P(A) & = U_{[0,1]} \star \tilde{K} \Big[ \text{$X_i < X_0$, para $i \leq N^n_0$ e $X_i > X_0$, para $i\ge N^n_0+1$} \Big]\\
      & = \int_0^1  U^{\otimes n}_{[0,1]} \Big[ \text{$X_i < u$, para $i \leq N^n_0$ e $X_i > u$, para $i \ge N^n_0+1$} \Big] \d u\\
      & = \int_0^1 u^{N^n_0} (1-u)^{n - N^n_0} \d u,
    \end{split}
  \end{equation*}
  que coincide com $U_{[0,1]} \widebar{K}(A)$, provando o lema.
\end{proof}

\begin{exercise}
  Mostre que a probabilidade, segundo o modelo da Urna de Pólya, de que observemos infinitas bolas de ambas as cores é um.
\end{exercise}



\end{topics}


\section{Espaços canônicos}

Em várias áreas da matemática, existe um importante conceito de equivalência entre duas estruturas, como por exemplo: homeomorfismos, isometrias e isomorfismos.
Nessa seção estudaremos o caso análogo para espaços mensuráveis, que nos trará uma grande surpresa.

\begin{definition}
  Uma função $\phi:E \to E'$ entre dois espaços mensuráveis é dita bi-mensurável \index{bi-mensuravel@bi-mensurável} quando $\phi$ é uma bijeção mensurável, com inversa mensurável.
%mensurável, injetiva, sua imagem $\phi(E)$ for mensurável e a sua inversa $\phi^{-1}:\phi(E) \to E$ também for mensurável.
\end{definition}

Vamos agora tentar classificar os espaços a menos de bi-mensurabilidade.
Descobriremos que na verdade os borelianos da reta incluem praticamente tudo em que podemos estar interessados.
Começamos com a seguinte definição.

\begin{definition}
  Dizemos que o espaço mensurável $(E, \mathcal{A})$ é canônico \index{espaco@espaço!canonico@canônico} se existe uma função $\phi: E \to B$ bi-mensurável para algum $B \in \mathcal{B}(\mathbb{R})$.
\end{definition}

Antes de mostrar que essa classe de espaços canônicos inclui muitíssimos exemplos, vamos motivar a definição acima exemplificando como esse conceito pode ser utilizado.

\begin{theorem}[Extensão de Kolmogorov Extendida]
  \index{Teorema!da Extensao de Kolmogorov@da Extensão}
  Se $(E_1,\mathcal{F}_1), (E_2,\mathcal{F}_2), \dots$ são espaços mensuráveis canônicos, então o Teorema~\ref{t:extens_kolmog} (da extensão de Kolmogorov)
  também é válido no espaço produto $\Omega = E_1 \times E_2 \times \dots$: \\
  Se a seguinte condição de consistência for válida
  \begin{equation}
   \forall n\ge 0, \forall A \in \bigotimes_{i=1}^n \mathcal{F}_i,\quad P_{n+1}(A\times E_{n+1})=P_n(A).
  \end{equation}
então existe uma probabilidade $P$ em $\Omega$ tal que
  a chamada esperança de $X$. \index{esperanca@esperança}
  Nesse caso também dizemos que $X \in \mathcal{L}^1(P)$.

  \medskip

  Dizemos que um vector aleatório ${\bf X}=(X_1,\dots,X_d)$ é integrável se todas coordenadas dele são integráveis e definimos a esperança de ${\bf X}$ por

    \begin{equation}
    E({\bf X}) = (E(X_1),\dots, E(X_d)).
  \end{equation}
\end{theorem}

\begin{proof}
  Sejam $\phi_i: E_i \to B_i \in \mathcal{B}(\mathbb{R})$ bijeções bi-mensuráveis e defina $\widebar{\phi}_n:
  E_1 \times \dots \times E_n \to \mathbb{R}^n$ por $\widebar{\phi}_n(\omega_1, \dots, \omega_n) = \big(\phi_1(\omega_1), \dots, \phi_n(\omega_n)\big)$.
  Assim podemos introduzir as medidas de probabilidade
  \begin{equation}
    \widebar{P}_n = (\widebar{\phi}_n)_* P_n, \text{ em $\mathbb{R}^n$}.
  \end{equation}
  É fácil verificar que as $\widebar{P}_n$ são consistentes como em \eqref{e:consist_kolmog}.
  Logo, existe $\widebar{P}$ em $(\mathbb{R}^\mathbb{N}, \mathcal{F})$ extendendo $\widebar{P}_n$.

  Vamos agora definir uma medida em $\prod_{i=1}^{\infty} E_i$.
  Para tanto, primeiramente fixamos para cada $i \geq 1$ um elemento arbitrário $w_i$ de $E_i$ e definimos $\psi_i :\mathbb{R} \to E_i$ por
  \begin{equation*}
    \psi_i(x) =
    \begin{cases}
      \phi_i^{-1}(x), \quad & \text{se $x \in B_i$,}\\
      w_i & \text{no caso contrário}.
    \end{cases}
  \end{equation*}
  Como $B_i \in \mathcal{B}(\mathbb{R})$, concluimos que $\psi_i$ é mensurável.

  Finalmente, consideramos o mapa $\Psi: \mathbb{R}^\mathbb{N} \to \Omega$ dado por
  \begin{equation}
    \Psi(x_1, x_2, \dots) = (\psi_1(x_1), \psi_2(x_2), \dots).
  \end{equation}
  Resta mostrar que a medida $P = \Psi_* \widebar{P}$ estende as probabilidades $P_n$.
  Observe que
  \begin{equation*}
    \begin{split}
      P\big(A_1 \times \dots \times A_n \times & E_{n+1} \times \dots\big) = \widebar{P} \big(\Psi^{-1}(A_1 \times \dots \times A_n \times E_{n+1} \times \dots)\big)\\
      & = \widebar{P} \big( \psi^{-1}_1(A_1) \times \dots \times \psi^{-1}_n(A_n) \times \mathbb{R} \times \dots \big)\\
      & = \widebar{P}_n (\psi^{-1}_1(A_1) \times \dots \times \psi^{-1}_n(A_n))\\
      & = P_n \big(\phi^{-1}_1\big(\psi^{-1}_1(A_1)) \times \dots \times \phi^{-1}_n\big(\psi_n^{-1}(A_n)\big)\big)\\
      & = P_n(A_1 \times \dots \times A_n),
    \end{split}
  \end{equation*}
  concluindo a prova do teorema.
\end{proof}

Uma ferramenta importante para construirmos espaços canônicos é a seguinte.

\begin{lemma}
  \label{l:mensur_de_canonico}
  Seja $(E, \mathcal{A})$ é um espaço canônico e $A \in \mathcal{A}$, então $A$ também é canônico quando dotado da $\sigma$-álgebra $\{A \cap C\, : \, C \in \mathcal{A}\}$ induzida por $\mathcal{A}$ em $A$.
\end{lemma}

\begin{proof}
  Seja $\phi: E \to B \in \mathcal{B}(\mathbb{R})$ uma função bi-mensurável que mostra que $E$ é canônico.
  Consideramos $\phi': A \to \mathbb{R}$ dada pela restrição de $\phi$ a $A$ e precisamos mostrar as seguintes afirmativas:
  \begin{enumerate}[\quad a)]
  \item $\phi'$ é injetiva.
  \item $\phi'$ é mensurável.
  \item $\phi(A)\in \mathcal{B}(\mathbb{R})$.
  \item A inversa de $\phi'$ (chamada $\psi'$) de $\phi'(A)$ em $A$ é mensurável.
  \end{enumerate}
  Vejamos,
  \begin{enumerate}[\quad a)]
  \item $\phi$ ser injetiva implica que $\phi'$ também o é.
  \item Dado $D \in \mathcal{B}(\mathbb{R})$, $(\phi')^{-1}(D) = A \cap \phi^{-1}(D)$ which is of the form $A\cap C$ with $C\in \mathcal{B}(\mathbb{R}^d)$.
  \item Denotando por $\psi: B \to E$ a inversa de $\phi$, temos que $\phi(A) = \psi^{-1}(A) \in \mathcal{B}(B)$ pois $\psi$ é mensurável.
  \item Finalmente, se $D \in \mathcal{B}(A)$, então $(\psi')^{-1}(D) = \psi^{-1}(D) \in \mathcal{B}(B)$, novamente pela mensurabilidade de $\psi$.
  \end{enumerate}
  Concluindo portanto a bi-mensurabilidade de $\phi'$ quando o seu contra-domínio é restrito a sua imagem.
\end{proof}

A seguir daremos um exemplo de espaço canônico que será importante na seção seguinte.

\begin{lemma}
  \label{l:NN_canonico}
  O espaço produto $E = \mathbb{N} \times \mathbb{N} \times \dots$, dotado da $\sigma$-álgebra produto é canônico.
\end{lemma}

\begin{proof}
  Primeiramente definimos em $E$ a Métrica de Hamming:
  \begin{equation}
    \label{e:hamming_distance}
    d_H(x,y) = \sum_{i \geq 1} \frac{1}{2^{i + 1}} \1_{\{x_i \neq y_i\}}.
  \end{equation}
  Fica como exercício mostrar que a $\sigma$-álgebra dos borelianos induzida por essa métrica coincide com a $\sigma$-álgebra produto em $E$.
  Definimos agora o mapa $\phi:E \to \mathbb{R}$ dado por
  \begin{equation}
    \phi(n_1, n_2, \dots) = 2^{-n_1} + 2^{-1 - n_1 - n_2} + \dots + 2^{-k - \sum_{i=1}^k n_i} + \dots
  \end{equation}
  Também deixamos a cargo do leitor mostrar que $\phi$ define um homeomorfismo entre $(E,d_H)$ e um boreliano de $\mathbb{R}$.
\end{proof}

\subsection{Espaços poloneses}

Nessa seção mostraremos que todos espaços chamados poloneses são canônicos.

\begin{definition}
  Um espaço métrico $(E,d)$ é dito polonês \index{espaco@espaço!polones@polonês} se é separável e completo.
\end{definition}


\begin{proof}
  Obtemos através da separabilidade de $E$, uma coleção de bolas $(B_i)_{i \geq 1}$ com diâmetros limitados por $r$ e cobrindo $E$.
  Então definimos
  \begin{equation}
    A_1 = B_1, \quad \text{e} \quad A_n = B_n \setminus \mcup_{i=0}^{n-1} B_i \quad \text{para $n \geq 1$.}
  \end{equation}

  Agora podemos dotar cada um dos $A_i$ com a métrica $d_i$ obtida através do Lema~\ref{l:sub_polones} (observe para tanto que os $A_i$ são dados por interseções de um aberto com um fechado).
  As propriedades enunciadas no lema são trivialmente satisfeitas.
\end{proof}


  Vamos definir borelianos $A_m$ de $E$ e métricas $d_m$ em $A_m$ para cada $m \in M$.
  Faremos isso da seguinte forma:
  \begin{enumerate}[\quad a)]
  \item se $m = i \in M_1$, então definimos $A_1, A_2, A_3, \dots$ e $d_1, d_2, d_3, \dots$ como no Lema~\ref{l:particao_polones} com $r = 1$,
  \item se $(A_m, d_m)$ já foi definido para algum $m \in M_n$, então utilizamos também o Lema~\ref{l:particao_polones} com $r = 1/n$ para particionar o conjunto $A_m$ (com a métrica $d_m$) em $A_{(m,1)}, A_{(m,2)}, \dots$ com suas respectivas métricas $d_{(m,1)}, d_{(m,2)}, \dots$
  \end{enumerate}
  Obviamente suporemos que são válidas as propriedades de tais métricas garantidas pelo Lema~\ref{l:particao_polones}.

  Podemos desde já definir $\phi:E \to \mathbb{N}^\mathbb{N}$ e para tanto, considere $x \in E$.
  Indutivamente
  \begin{enumerate}[\quad a)]
  \item como $\{A_m\}_{m \in M_1}$ formam uma partição de $E$, definimos $\phi_1(x)$ como o único índice tal que $x \in A_{\phi_1(x)}$,
  \item se já encontramos $\phi_1(x), \dots, \phi_n(x)$ tal que $x \in A_{(\phi_1(x), \dots, \phi_n(x))}$, então o fato que particionamos o último conjunto na definição de $A_m$, $m \in M_{n+1}$ nos garante que podemos definir unicamente $\phi_{n+1}(x)$ de forma a continuar a indução.
  \end{enumerate}
  Da maneira acima já obtivemos $\phi(x) = (\phi_1(x), \phi_2(x), \dots)$.
  Para terminar, devemos mostrar que $\phi$ é bi-mensurável quando seu contra-domínio é restrito à sua imagem.

  Isso começa com a prova de que $\phi$ é injetiva.
  Se $\phi(x) = \phi(y)$, então existe uma sequência $m_n \in M_n$ tal que $x, y \in A_{m_n}$ para todo $n$.
  Mas isso não é possível dado que o diâmetro de $A_{m_{n+1}}$ é menor ou igual a $1/n$ na métrica $d_{m_n} \geq d$.
  Isso mostra que $x = y$.

  Vejamos agora que $\phi$ é mensurável.
  %Lembramos que em $\mathbb{N}^\mathbb{N}$ colocamos a métrica de Hamming definida em \eqref{e:hamming_distance}).
  Seja $w \in \mathbb{N}^\mathbb{N}$ tal que $\phi(x) = w$ e tome $G \subseteq \mathbb{N}^\mathbb{N}$ com $G = \{(w_1, \dots, w_l)\} \times \mathbb{N}^\mathbb{N}$ (esses conjuntos geram a $\sigma$-álgebra canônica em $\mathbb{N}^\mathbb{N}$).
  Claramente, $\phi^{-1}(G) = A_{(\phi_1(x), \dots, \phi_l(x))}$, de forma que mostramos que $\phi$ é mensurável.

  Para mostrar que sua inversa $\psi:\phi(E) \to E$ é mensurável, veremos que ela é de fato contínua com respeito à Métrica de Hamming definida em \eqref{e:hamming_distance}.
  Dado $n \geq 1$, tomamos $\delta < 2^{-n}$.
  Se $w, w' \in \phi(E)$ são tais que $d_H(w, w') < \delta$ em $\mathbb{N}^\mathbb{N}$, então $w_i = w'_i$ para todo $i \leq n$, de forma que $\phi^{-1}(w)$ e $\phi^{-1}(w')$ pertencem a $A_{(w_1, \dots, w_n)}$.
  A continuidade de $\phi^{-1}$ segue do fato que o diâmetro de $A_{(w_1, \dots, w_n)}$ é no máximo $1/n$ (com respeito a $d_{(w_1, \dots, w_{n-1})}$ e portanto com respeito a $d$).

  Mas atenção, apesar de que parece que provamos o teorema, ainda falta mostrar que $\phi(E)$ é mensurável.
  Para tanto, afirmamos que
  \begin{equation}
    \label{e:phiE_mensur}
    \phi(E) = \mathbb{N}^\mathbb{N} \setminus \Big( \bigcup_{(w_1, \dots, w_k)\in \mathcal{E}} \{w_1\} \times \{w_k\} \times \mathbb{N} \times \dots \Big),
  \end{equation}
  onde
  \begin{equation*}
   \mathcal{E}:=\{ (w_1, \dots, w_k)\in \bigcup_{n\ge 1} \mathbb{N}^n \, : \, A_{\omega_1,\dots,\omega_k}=\emptyset \}.
  \end{equation*}

  A igualdade acima será mostrada no que segue.

  Dado $w \in \phi(E)$ existe $x \in E$ tal que $\phi(x) = w$.
  Como $x \in A_{w_1, \dots, w_n}$ para todo $n \geq 1$, esses conjuntos não são vazios.
  Logo $w$ não pertence à união em \eqref{e:phiE_mensur}, mostrando o lado ($\subseteq$) da equalidade.
  Finalmente, suponha que $w = (w_1, w_2, \dots)$ é tal que para todo $k \geq 1$, $A_{w_1, \dots, w_k} \neq \varnothing$.
  Tomamos portanto para todo $k \geq 1$ um ponto $x_k \in A_{w_1, \dots, w_k}$.

  Afirmamos que
  \begin{equation}
    \text{para todo $n$, $(x_k)_{k \geq n}$ é Cauchy em $(A_{w_1, \dots, w_n}, d_{w_1, \dots, w_n})$,}
  \end{equation}
 o que segue logo do fato que por $k \geq n+1$, $x_k \in A_{w_1, \dots, w_{k}}$ cujo $d_{w_1, \dots, w_{n}}$-diâmetro é menor que $1/k$.

 \medskip

 Consideramos $x^n$ o limite de $(x_k)_{k\ge n}$ em $(A_{w_1, \dots, w_n}, d_{w_1, \dots, w_n})$.
 É fácil de mostrar que $x^n=x^0:=x$ (o limite da sequência em $(E,d)$) para todo valor de $n$.
 É suficiente ver que  $d(x^n,x_k)\le d_{w_1, \dots, w_n}(x^n,x_k)$, para todo $k\ge n$, o que implica que $x^n$ é o limite em $(E,d)$.

 \medskip

 Como consequência podemos concluir que $x\in A_{w_1, \dots, w_n}$ para todo $n$ e então que $\phi(x)=\omega$, o que conclui a prova do teorema.
  que termina a prova.


O próximo exemplo serve muito bem para mostrar porque estamos interessados em desigualdades como a do Teorema~\ref{t:markov} acima.

Em vários exemplos importantes, podemos ter dificuldade de calcular probabilidades explicitamente.
Nesses casos, poderíamos gastar nossas energias tentando calculá-las a qualquer custo,
ou podemos nos contentar em obter cotas superiores e inferiores para as probabilidades nas quais estamos interessados.

Em vários casos, a segunda estratégia tem uma grande vantagem sobre a primeira, por possibilitar que estudemos problemas mais complexos
(e consequentemente mais importantes/interessantes) e muitas vezes sem nos afastarmos da realidade
(em vários exemplos as cotas superiores e inferiores são próximas o suficiente para que não nos preocupemos).





Um exemplo de como usar núcleos de transição é a construção de Cadeias de Markov.
Esse tipo de processo é bastante útil em diversas aplicações, desde a biologia até a computação.

Considere um espaço mensurável canônico fixo $(E, \mathcal{A})$ e seja $K$ um núcleo de $E$ nele mesmo.
Seria bastante intuitivo agora iterar $K$ (já que ele está no mesmo espaço)
e obter uma medida em $\Omega =E^{\mathbb{N}}$ com a $\sigma$-álgebra canônica.

Para começar esse procedimento, seja $\mu_0$ uma medida inicial em $(E, \mathcal{A})$.
Podemos então definir $\mu_1 = \mu_0 \star K$ o que é o primeiro passo da nossa construção, porém observe que não podemos escrever ``$\mu_2 = \mu_1 \star K$'', pois $\mu_1 \star K$ é uma medida em $(E^2, \mathcal{A}^{\otimes 2})$.
Vamos com calma então.

Observe que
\begin{equation}
  \mu_1(A_0 \times A_1) = \int_{A_0} \int_{A_1} K(x_0, \d x_1) \mu_0(\d x_0),
\end{equation}
ou em outras palavras o valor de $x_0$ determina a distribuição de $x_1$.
Gostaríamos agora que $x_1$ determinasse a distribuição de $x_2$ via $K$, como por exemplo assim
\begin{equation}
  \mu_2(A_0 \times A_1 \times A_2) = \int_{A_0} \int_{A_1} \int_{A_2} K(x_1, \d x_2) K(x_0, \d x_1) \mu_0 (\d x_0).
\end{equation}
Mas essa notação fica bastante carregada à medida que iteramos.

Para tornar essa notação mais simples, definimos a projeção $\phi_n:E^n \to E$ por $\phi_n(x_0, \dots, x_{n-1}) = x_{n-1}$.
Também precisamos de $K_n: E^n \times \mathcal{A} \to [0,1]$ dado por
\begin{equation}
  K_n(\vec{x},A) = K\big(\phi_n(\vec{x}), A\big) \quad \big(= K(x_{n-1},A) \big).
\end{equation}
O fato de $K_n$ ser um núcleo de transição segue imediatamente dessa propriedade para $K$.

Note que, nessa notação, estamos dizendo que para irmos de $E^n$ para $E^{n+1}$ iremos olhar apenas para a última coordenada, na qual aplicaremos o núcleo $K$.
Isso é o ponto mais importante que caracteriza uma Cadeia de Markov: a distribuição do estado futuro da cadeia depende apenas do estado atual e não do passado.
Em alguns contextos essa propriedade é chamada de ausência de memória.

Podemos finalmente definir
\begin{equation}
  \label{e:Pn_Markov}
  \mu_{n+1} = \mu_n \star K_n, \text{ para todo $n \geq 1$}.
\end{equation}
Mas resta a questão sobre a existência de uma $\mu^\infty$ que será respondida com ajuda do próximo resultado.

\begin{lemma}
  As probabilidades $\mu_n$ definidas em \eqref{e:Pn_Markov} são compatíveis, mais precisamente $\mu_{n+1}(A \times E) = \mu_n(A)$ para todo $A \in \mathcal{A}^{\otimes n}$.
\end{lemma}

\begin{proof}
  Basta observar que
  \begin{equation}
    \mu_{n+1}(A \times E) = \mu_n \star K (A \times E) = \int_{A} \underbrace{K_n (\vec{x}, E)}_1 \mu_n(\d \vec{x}) = \mu_n(A),
  \end{equation}
  provando o lema.
\end{proof}

Logo, o Teorema da Extensão de Kolmogorov (lembre que $(E, \mathcal{A})$ foi suposto canônico) nos fornece uma única $P$ em $(\Omega, \mathcal{F})$ tal que
\begin{equation}
   P_{(X_0, \dots, X_n)} = \mu_n, \text{ para todo $n \geq 0$}.
\end{equation}
Lembramos que $X_i$ denotam as projeções canônicas em $\Omega = \prod_{i=1}^\infty E$.

Chamamos o processo $X_1, X_2, \dots$ sob a lei $P$ da Cadeia de Markov \index{Cadia de Markov} com distribuição inicial $\mu_0$ e núcleo de transição $K$.

\begin{example}
  \label{x:Markov_p_xy}
  Suponha que $E$ seja enumerável.
  Nesse caso recordamos do Exemplo~\ref{x:nucleo_discreto} que o núcleo pode ser representado por uma matriz $\big(p(x,y)\big)_{x,y \in E}$ que nos retorna a probabilidade de saltar de $x$ a $y$.
  Além disso, a distribuição inicial $\mu_0$ é determinada por $P(\{x\}) = p_0(x)$, para alguma sequência $\big(p_0(x)\big)_{x \in E}$.
\end{example}

\begin{exercise}
  Mostre que no exemplo acima temos
  \begin{equation}
    P(X_0 = x_0, \dots, X_n = x_n) = p_0(x_0) p(x_0, x_1) \dots p(x_{n-1}, x_n).
  \end{equation}
\end{exercise}

\begin{exercise}
  Defina $K:\mathbb{R}^2 \times \mathcal{B}(\mathbb{R}^2) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) = U_{S^1}(A - x).
  \end{equation}
  Nesse contexto,
  \begin{enumerate}[\quad a)]
  \item mostre que $K$ é um núcleo de transição e,
  \item considerando a cadeia com distribuição inicial $\mu_0 = \delta_0$ em $\mathbb{R}^2$ e núcleo $K$, mostre que $X_2$ tem distribuição absolutamente contínua com respeito a Lebesgue e calcule sua densidade.
  \end{enumerate}
\end{exercise}

\begin{exercise}
  Mostre que para qualquer núcleo de transição $K$ entre $E$ e $E$, existe um núcleo de transição
  $\widebar{K}$ entre $E$ e $\Omega = E^{\mathbb{N}}$, tal que para toda medida inicial $\mu_0$, temos que $\mu_0 \star K$ é a distribuição de uma Cadeia de Markov começando de $\mu_0$ e com transição dada por $K$.
  Esse núcleo é útil se quisermos mudar a distribuição inicial $\mu_0$ e uma notação bastante comum para esse núcleo é $P_{x}(\cdot) = \widebar{K}(x, \cdot)$.
\end{exercise}

Vamos terminar essa seção dando uma interpretação bastante interessante para os núcleos de transição em analogia à álgebra linear.
Fixe um núcleo de transição $K$ entre $E$ e $E$, uma medida inicial $\mu$ e uma função limitada $f: E \to \mathbb{R}$.
Relembre a notação em \eqref{e:P1_K} e defina $K f: E \to \mathbb{R}$ dada por
\begin{equation}
  K f(x):= \int f(y) K(x, \d y),
\end{equation}
que é obviamente limitada e já vimos ser mensurável no Teorema de Fubini.

Então temos dois operadores definidos para núcleos, a multiplicação à esquerda por uma medida em $E$ ($\mu K$ que também é uma medida em $E$) e a multiplicação à direita por uma função limitada e mensurável ($K f$ que também é uma função limitada e mensurável).
Podemos pensar em $f$ como um vetor coluna e $\mu$ como um vetor linha, nesse caso $K$ faria o papel de uma matriz.
Essa analogia é real se $E$ for um espaço enumerável.

\begin{exercise}
  No contexto de cadeias de Markov,
  \begin{enumerate}[\quad a)]
  \item mostre a relação de associatividade $\mu (K f) = (\mu K) f$,
  \item defina para todo $n$ o núcleo $K^{(n)}$ iterado (de $E$ em $E$), de forma que $\mu K^{(n)} f$ ainda seja associativa.
  \item Mostre que a medida $\mu K^{(n)}$ é a distribuição de $X_n$ se começamos de $\mu$,
  \item que a função $K^{(n)} f (\cdot)$ é o valor esperado de $f$ no tempo $n$ se começamos no zero do ponto $\cdot$ e finalmente que
  \item o número real $\mu K^{(n)} f$ é a esperança de $f$ no tempo $n$ se começamos de $\mu$.
  \end{enumerate}
\end{exercise}

Vamos agora dar um exemplo simples de Cadeia de Markov que poderemos analisar em detalhes.

Seja $E = \mathbb{Z}$ e considere $K: \mathbb{Z} \times \mathcal{P}(\mathbb{Z}) \to [0,1]$ dado por
\begin{equation}
  K(x, \cdot) = \frac{\delta_{x-1} + \delta_{x+1}}{2},
\end{equation}
que obviamente define um núcleo pois toda função em $\mathbb{Z}$ é mensurável na $\sigma$-álgebra das partes.

Podemos portanto construir $P$ em $\mathbb{Z}^{\mathbb{N}}$ que nos fornece a lei de uma Cadeia de Markov em $\mathbb{Z}$ com distribuição inicial $\delta_0$ e núcleo de transição $K$.
Chamamos esse processo de passeio aleatório simples simétrico. \index{passeio aleatorio simples@passeio aleatório simples}

Poderíamos estar interessados em várias perguntas sobre esse processo, como por exemplo quão longe esperamos que o passeio aleatório pode ir depois de um determinado tempo?
Para responder essa e várias outras questões, iremos mostrar outra construção do passeio simples simétrico através de uma soma de variáveis aleatórias.

Introduzimos um espaço de probabilidade $\tilde P$, variáveis $Y_1, Y_2, \dots$ \iid com distribuição $(\delta_{-1} + \delta_{1})/2$ e definimos $S_0 = 0$ e $S_n = Y_1 + \dots + Y_n$.

\begin{lemma}
  A distribuição da sequência infinita $(X_0, X_1, \dots)$ sob a lei $P$ do passeio aleatório simples e simétrico é igual à distribuição de $(S_0, S_1, \dots)$ sob $\tilde P$.
\end{lemma}

\begin{proof}
  Observamos primeiramente que basta mostrar a igualdade de distribuições para cilindros do tipo $\{x_1\} \times \dots \times \{x_n\} \times \mathbb{Z}^\mathbb{N}$, pois tais eventos compõem um $\pi$-sistema que gera a $\sigma$-álgebra produto em $\mathbb{Z}^\mathbb{N}$.
  Calculamos portanto
  \begin{equation*}
    \begin{split}
      \qquad P & [X_1 = x_1, \dots, X_n = x_n]
      \intertext{pela definição de Cadeia de Markov (via extensão de Kolmogorov),}
      & = \mu_n [X_1 = x_1, \dots, X_n = x_n]\\
      & = \mu_{n-1} \star K_n [X_1 = x_1, \dots, X_n = x_n]
      \intertext{por Fubini para núcleos (Teorema~\ref{t:fubini}),}
      & = \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] K_n\big( (x_1, \dots, x_{n-1}), \{x_n\} \big)\\
      & = \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] K\big( x_{n-1}, \{x_n\} \big)\\
      & = \frac 12 \mu_{n-1}[X_1 = x_1, \dots, X_{n-1} = x_{n-1}] \1_{\{|x_{n-1} - x_n| = 1\}}\\
      & = \dots = 2^{-n} \prod_{i=1}^n \1_{\{|x_{i-1} - x_i| = 1\}}.
    \end{split}
  \end{equation*}
  Faremos agora esse cálculo para a distribuição de $S_i$'s:
  \begin{equation*}
    \begin{split}
      \qquad \tilde P & [S_1 = x_1, \dots, S_n = x_n]\\
      & = \mu_n [Y_1 = x_1 - x_0, Y_2 = x_2 - x_1 \dots, Y_n = x_n - x_{n-1}]\\
      & = \prod_{i = 1}^n \tilde P [Y_i = x_i - x_{i-1}] = 2^{-n} \prod_{i=1}^n \1_{\{|x_{i-1} - x_i| = 1\}}.
    \end{split}
  \end{equation*}
  Isso mostra o enunciado do lemma.
\end{proof}

Podemos agora por exemplo estimar
\begin{equation}
  P[|X_n| \geq \varepsilon n] = \tilde P [|S_n| \geq \varepsilon n] \leq 2 \exp \{- \psi_{(\delta_{-1} + \delta_1)/2}(\varepsilon) n\},
\end{equation}
que responde nossa pergunta sobre a probabilidade de um passeio aleatório se distanciar muito da origem.



\section{Probabilidade Condicional Regular}

Já sabemos definir por exemplo $E(\1_A|X = x)$.
Gostaríamos porém de garantir que essa expressão definisse uma probabilidade em $A$, e chamaríamos essa probabilidade de $P(A|X = x)$.
Mas certamente gostaríamos que $P(\cdot|X = x)$ fosse uma função $\sigma$-aditiva.
Essa especulação parece promissora, por exemplo se $A$ e $B$ são disjuntos,
\begin{equation*}
  P(A \cup B |\mathcal{F}') = E(\1_{A \cup B} | \mathcal{F}') = E(\1_A|\mathcal{F}') + E(\1_{B}|\mathcal{F}') = P(A|\mathcal{F}') + P(B|\mathcal{F}').
\end{equation*}
Ótimo, mas ainda temos o seguinte problema.

Lembramos que a equação acima está bem definida apenas quase certamente.
Poderíamos portanto garantir que para uma classe enumerável de conjuntos $A \in \mathcal{F}$, essa aditividade fosse satisfeita.
Porém, a $\sigma$-álgebra $\mathcal{F}$ é frequentemente não enumerável, portanto não conseguimos a $\sigma$-aditividade plena.
Isso pode ser contornado se o espaço for canônico, como afirma o nosso próximo resultado.

Ele nos ajudará bastante ao fazermos cálculos usando condicionais, de maneira semelhante à Lei da Probabilidade Total.
Esse é o conteúdo do seguinte resultado.

\begin{theorem}[Teorema da Desintegração] \index{Teorema!da Desintegracao@da Desintegração}
  \label{desintegracao}
  Sejam espaços mensuráveis $(\Omega, \mathcal{F})$ e $(E, \mathcal{A})$, com $E$ canônico.
  Se $P$ é uma probabilidade no espaço produto $(\Omega \times E, \mathcal{F} \otimes \mathcal{A})$ e denotamos por $P_1 = P_{X_1}$ a 
  distribuição marginal da primeira coordenada, então existe um núcleo de transição $K: \Omega \times \mathcal{A} \to [0,1]$ satisfazendo
  \begin{equation}
    P = P_1 \star K,
  \end{equation}
  Em particular,
  \begin{equation}
    \label{e:prob_cond_reg_prod}
    P(A \times B) = \int_A K(\omega, B) P_1 (\d \omega) \text{ para todo $A \in \mathcal{F}$, $B \in \mathcal{A}$}.
  \end{equation}
 Nesse caso podemos definir 
 $$P[X_2 \in B | X_1 = \omega]:=K(\omega, B)$$ 
 (como de costume $X_i$ denota a $i$-ésima coordenada canônica).
\end{theorem}

\begin{proof}
  Como de costume, basta resolver o caso $(E, \mathcal{A}) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
  De fato, se assumimos a validade do teorema para a reta, podemos usar a função bi-mensurável $\phi: E \to B \in \mathcal{B}(\mathbb{R})$ para concluir o caso geral.

  Nos restringiremos agora ao espaço $(\Omega \times \mathbb{R}, \mathcal{F} \otimes \mathcal{B}(\mathbb{R}), P)$.
  Para cada $q \in \mathbb{Q}$, definimos $P^q_\Omega : \mathcal{F} \to [0,1]$ por
  \begin{equation}
    P^q_1 (A) = P\big(  A  \times (-\infty, q]\big).
  \end{equation}
  Observando que $P^q_1$ é absolutamente contínua com respeito a $P_1$, podemos definir
  \begin{equation}
    F(\omega, q) = \frac{\d P^q_1}{\d P_1}(\omega).
  \end{equation}
  Observamos as seguintes propriedades de $F$:
  \begin{enumerate}[\quad a)]
  \item para cada $q \in \mathbb{Q}$, $F(\cdot, q) \in [0,1]$, $P_\Omega$-quase certamente, pois $P^q_1(A) \leq P_1(A)$ para todo $A \in \mathcal{F}$,
  \item para $q < q' \in \mathbb{Q}$, $F(\cdot, q) \leq F(\cdot, q')$, $P_1$-quase certamente, pois $P^q_1(A) \leq P^{q'}_\Omega(A)$ para todo $A \in \mathcal{F}$ e
  \item $F(\cdot, n) \to 1$ (analogamente $F(\cdot, -n) \to 0$) quando $n$ tende a infinito, $P_1$-quase certamente.
    Para ver isso, note que a sequência de variáveis aleatórias $F(\cdot, n)$ é quase certamente monótona não decrescente, logo converge $P_\Omega$-quase certamente.
    Sendo limitada, converge em $\mathcal{L}^1$ e como sua integral em $P_\Omega$ converge para um, $F(\cdot, n) \to 1$, quase certamente (analogamente para $F(\cdot, -n)$).
  \end{enumerate}
  Existe pois um conjunto $\Omega' \in \mathcal{F}$ com $P_\Omega(\Omega') = 1$ no qual as três hipóteses acima são satisfeitas.
  Definimos $\hat{F}(\omega, q)$ como sendo igual a $F(\omega, q)$ em $\Omega'$ e igual a $F_0(q)$ (uma função de distribuição fixa) caso contrário (que claramente será mensurável).
  Finalmente podemos definir $\tilde{F}(\omega, x) = \inf_{q \in \mathbb{Q}; q \downarrow x} \hat{F}(\omega, q)$, que satisfaz para todo $\omega$ as hipóteses do Teorema~\ref{t:existe_prob_R}.
  Logo, existe para cada $\omega \in \Omega$ uma medida $K(\omega, \cdot)$ em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ satisfazendo $K(\omega,(-\infty, q]) = F(\omega, q)$ $P_\Omega$-quase certamente.

  Precisamos mostrar que $K$ é um núcleo, e para isso basta observar que $F(\omega, q)$ são mensuráveis e a família $\{(-\infty, q]; q \in \mathbb{Q}\}$ forma um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$.

  Finalmente, vamos verificar \eqref{e:prob_cond_reg_prod}, notando que se $A \in \mathcal{F}$ e $B = (-\infty, q]$,
  \begin{equation}
    \int_A K(\omega, B) P_\Omega(\d \omega) = \int_A F(\omega, q) P_\Omega (\d \omega) = P^q_\Omega(A) = P(A \times B).
  \end{equation}
  Como a classe $B$ é um $\pi$-sistema gerando $\mathcal{B}(\mathbb{R})$ terminamos a prova.
\end{proof}

Interpretamos $P[X_2 \in B | X_1 = \omega]$ da seguinte forma.
Se alguém tiver acesso à $\sigma$-álgebra $\sigma(X_1)$, ou seja, essa pessoa é capaz de observar o valor de $\omega$, ela pode não saber o valor de $X_2$, mas já pode atualizar sua distribuição para $P(X_2 \in \cdot| X_1 = \omega)$.

Uma das grandes vantagens de ter um núcleo de transição a determinar uma distribuição conjunta, como foi feito acima, é que podemos usar a versão generalizada de Fubini.
Antes, nós somente podiamos usar Fubini para espaços construídos através de um núcleo.

\begin{exercise}
  Se $\Omega = E_1 \times E_2$ com $E_2$ canônico é dotado da probabilidade $\d P = \rho(x_1, x_2) \mu_1 \otimes \mu_2 (\d x_1 \d x_2)$, mostre que
  \begin{equation}
    P(X_2 \in A|X_1 = x_1) = \frac{\int_A \rho(x_1, x_2) \mu_2(\d x_2)}{\int \rho(x_1, x_2) \mu_2(\d x_2)},
  \end{equation}
  $(P_{X_1})$-quase certamtente.
\end{exercise}

\begin{exercise}
  \label{x:prob_cond_reg_indep}
  Sejam $X_1$ e $X_2$ as projeções canônicas em um espaço produto $\Omega \times E$, com $E$ canônico.
  Então, se $X_1$ e $X_2$ são independentes com respeito a $P$, vale
  \begin{equation}
    P[X_2 \in B | X_1 = \omega] = P[X_2 \in B] \text{ para $P_{X_1}$-quase todo $\omega$}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Considere em $(\mathbb{R}^2, \mathcal{B}(\mathbb{R}^2))$ as projeções canônicas $X_1$ e $X_2$.
  Calcule, em cada um dos exemplos abaixo, a probabilidade condicional regular $P[X_1 \in \cdot|X_2 = x_2]$, justificando sua resposta,
  \begin{enumerate}[\quad a)]
  \item Quando $P$ é a medida uniforme em $T = \{(x,y) \in [0,1]^2; x \leq y\}$ (ou seja, a medida de Lebesgue em $\mathbb{R}^2$ restrita a $T$ e normalizada para ser uma probabilidade).
  \item Quando $P$ é a medida $U_{S^1}$ (uniforme em $S^1$).
  \end{enumerate}
\end{exercise}

\section{Princípio da substituição}

O Teorema~\ref{desintegracao} é bastante poderoso e nos permite definir e calcular diversas probabilidades, como faremos à seguir.
Nessa seção construiremos nossa última versão de probabilidade condicional regular que não se restringe a espaços produtos e nos fornecerá o que chamamos de Princípio da Substituição. \index{Principio@Princípio!da Substituicao@da Substituição}

\begin{theorem}
  \label{t:princ_substit}
  Sejam $(\Omega, \mathcal{F}, P)$ e $(E, \mathcal{A})$ espaços mensuráveis canônicos.
  Considere também $X: \Omega \to E$ um elemento aleatório, então existe um núcleo de transição $K$ de $E$ a $\Omega$ tal que
  \begin{equation}
    \label{e:reg_cond_prob_givenX}
    K(X(\omega), F) = E[\1_{F} | X], \text{ para todo $F \in \mathcal{F}$}.
  \end{equation}
  Também denotamos esse núcleo como $K(x, F) = P[F | X = x]$, que é único no sentido que se $K'$ 
  também satisfaz \eqref{e:reg_cond_prob_givenX}, então $K(x, F) = K'(x, F)$ para $(P_X)$-quase todo $x \in E$.

  Além disso vale o que chamamos de Princípio da Substituição:
  \begin{equation}
    \label{e:princ_substit}
    K(x, [X = x]) = 1, \quad \text{$P_X$-quase certamente}.
  \end{equation}
  Que pode ser dito de maneira estranha: $P[X = x|X = x] = 1$, quase certamente.
\end{theorem}

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=3]
    \draw[->,gray,very thin] (0, -.8) -- (0,1.2) node[left, black] {$\Omega$};
    \draw[->,gray,very thin] (-0.2, 0.08) -- (1.3, 0.08) node[above,black] {$E$};
    \draw[domain=-.8:1.2,smooth,variable=\x,blue] plot ({ 1/(1 + 10 * \x * \x) }, {\x});
    \draw[-,dashed,gray,very thin] (0, {-sqrt(1 / 7 - 0.1)}) -- (0.7, {-sqrt(1 / 7 - 0.1)}) -- (0.7, {sqrt(1 / 7 - 0.1)}) -- (0, {sqrt(1 / 7 - 0.1)});
    \draw[thick] (0.7, .06) -- (0.7, .1);
    \node[below, right] at (.7, 0) {$x$};
    \draw[thick] (0, {-sqrt(1 / 7 - 0.1)}) circle (.01);
    \draw[thick] (0, {sqrt(1 / 7 - 0.1)}) circle (.01);
    \node[below] at (-.24, .32) {$[X = x]$};
  \end{tikzpicture}
  \caption{O gráfico do elemento aleatório $X$ representado horizontalmente.
    Os pontos marcados no eixo vertical representam o conjunto $[X = x]$ que possui medida um segundo $P[\; \cdot \; | X = x]$ de acordo com o Teorema~\ref{t:princ_substit}}
\end{figure}

\begin{proof}
  Defina o elemento aleatório $W: \Omega \to E \times \Omega$, dado por $W(\omega) = (X(\omega), \omega)$, que percorre o gráfico de $X$ (representado horizontalmente).
  Observe que a medida $P_W P$ possui marginais $(X_1)_* P_W = X_* P$ e $(X_2)_* P_W = P$.
  Como $P_W$ satisfaz as condições do Teorema~\ref{desintegracao}, existe um núcleo $K: E \times \mathcal{F} \to [0,1]$ tal que para todo $A \in \mathcal{A}$, $F \in \mathcal{F}$,
  \begin{equation}
    P_W(A \times F) = \int_A K(x, F) P_X (\d x).
  \end{equation}
  Fixado $F \in \mathcal{F}$, $K(X(\omega), F)$ é obviamente $\sigma(X)$ mensurável, por ser uma composição de uma função mensurável em $E$ com $X$.
  Logo, para provar \eqref{e:reg_cond_prob_givenX}, basta mostrar a segunda propriedade de esperanças condicionais.
  Se $B \in \sigma(X)$, podemos escrever $B = [X \in A]$ para algum $A \in \mathcal{A}$, donde
  \begin{equation}
    \begin{split}
      E\big[ K(X, F) \1_B \big] & = E\big[ K(X, F) \1_{[X \in A]} \big] = \int_A K(x, F) P_X(\d x)\\
      & = P_W (A \times F) = E[\1_{X \in A} \1_F] = E[\1_B \1_F],
    \end{split}
  \end{equation}
  concluindo a prova de \eqref{e:reg_cond_prob_givenX}.

  Para mostrarmos o Princípio da Substituição, vamos usar o seguinte lema.

  \begin{lemma}
    Se $X : \Omega \to E$ é um elemento aleatódio tomando valores em um espaço $E$ canônico, então seu gráfico $G = \{(\omega, X(\omega)); \omega \in \Omega\}$ é mensurável na $\sigma$-álgebra produto $\mathcal{F} \otimes \mathcal{A}$.
  \end{lemma}

  \begin{proof}
    Primeiramente, consideramos o caso $(E, \mathcal{A}) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
    Neste caso, vemos que
    \begin{equation}
      G = \bigcap_{n \geq 1} \bigcup_{j \in \mathbb{Z}} [X \in \big(j/2^n, (j+1)/2^n \big]] \times \big( j/2^n, (j+1)/2^n \big],
    \end{equation}
    que é mensurável.

    Caso $E$ seja outro espaço canônico qualquer, existe $\phi: E \to B \in \mathcal{B}(\mathbb{R})$ bi-mensurável e $G = \Phi^{-1}(G_{\phi(X)})$, onde 
    $G_{\phi(X)}$ é o gráfico de $\phi(X)$ e $\Phi(\omega, x) = (\omega, \phi(x))$.
    Logo $G$ também é mensurável nesse caso.
  \end{proof}

  Retornando à prova de \eqref{e:princ_substit}, já sabemos que $G' = \{(X(\omega), \omega); \omega \in \Omega\}$ é mensurável.
  Além disso, por definição $P_W(G') = P[(X(\omega), \omega) \in G'] = P(\Omega) = 1$, ou seja a medida $P_W$ tem suporte em $G'$.

  Logo podemos escrever
  \begin{equation}
    \begin{split}
      1 = P_W(G') & = \int \int \1_{G'} (x, \omega) K(x, \d \omega)  P_X (\d x)\\
      & = \int K(x, [X = x]) P_X (\d x).
    \end{split}
  \end{equation}
  Mas como o integrado acima pertence a $[0,1]$, essa integral só pode ser um se $K(x, [X = x]) = 1$, $P_X$-quase certamente, como desejado.
\end{proof}

\begin{exercise}
  Sejam $X: \Omega \to E$ e $Y: \Omega \to E'$ elementos aleatórios com $E$ canônico.
  Então existe um núcleo de transição $K$ entre $E$ e $E'$ tal que
  \begin{equation}
    \label{e:regular_cond_prob_givenX}
    K(X(\omega), B) = E[\1_{Y \in B} | X], \text{ para todo $B \in \mathcal{A}'$}.
  \end{equation}
  Poderíamos chamar esse núcleo de $K(x, B) = P[Y \in B | X = x]$.
\end{exercise}

\begin{exercise}
  Mostre que se $K(x, F) = P[F| X = x]$, então
  \begin{equation}
    \label{e:reg_cond_exp_givenX}
    \int f(\omega') K(X(\omega), \d \omega') = E(f | X)(\omega), \text{ para toda $f \in \mathcal{F}$}.
  \end{equation}
\end{exercise}

% \begin{exercise}
%   Se $Y$ é variável aleatória e $X: \Omega \to E$ é um elemento aleatório canônico, mostre que
%   \begin{equation}
%     E(Y|X) = \int y P(Y \in \d y|X = \cdot) \circ X, \text{ $P$-q.c.}
%   \end{equation}
% \end{exercise}

Vamos agora mostrar uma aplicação do que foi feito acima, tentando justificar o nome Princípio da Substituição.

\begin{proposition}
  Se $X, Y$ são variáveis aleatórias independentes, então a função de distribuição acumulada $F$ de $X + Y$ é dada por
  \begin{equation}
    F(z) = P[X + Y \leq z] = \int_{-\infty}^\infty F_Y(z - x) P_X (\d x),
  \end{equation}
  onde $F_Y(y) = P[Y \leq y]$.
\end{proposition}

Esse lema pode ser visto como uma generalização do Exercício~\ref{x:convolucao_densidade} para o caso não absolutamente contínuo.
Vale a pena tentar diferenciar (não rigorosamente) a equação acima em $z$.

\begin{proof}
  Vamos calcular
  \begin{equation}
    \begin{split}
      P[X + Y \leq z] & = E\big( E(\1_{[X + Y \leq z]} | X) \big)\\
      & = \int_{-\infty}^\infty P[X + Y \leq z \ | \ X = x\cdot) P_X(\dd x)\\
      & = \int_{-\infty}^\infty P[ Y \leq z-x  \ | \ X = x\cdot) P_X(\dd x).
     \end{split}
  \end{equation}
  Agora vamos usar a hipótese que $X$ e $Y$ são independentes.
  Isso equivale a dizer que a distribuição conjunta desse par é igual a $P_X \otimes P_Y$ e pela unicidade da probabilidade condicional regular 
  temos que $P[Y \in F | X = x] = P[Y \in F]$, $(P_X)$-quase certamente, veja Exercício~\ref{x:prob_cond_reg_indep}.
  Portanto,
  \begin{equation}
    P[X + Y \leq z] = \int_{-\infty}^\infty F_Y(z - x)  P_X (\d x),
  \end{equation}
  terminando a prova do lema.
\end{proof}


\begin{exercise}
  Considere as medidas
  \begin{equation}
    \mu_a = \frac{\delta_{-1} + \delta_1}{2}, \qquad \text{e} \qquad \mu_b = \mathcal{N}(0, 1).
  \end{equation}
  e $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) =
    \begin{cases}
      \mu_a (A - x), & \text{ se $x < 0$,}\\
      \mu_b (A - x), & \text{ se $x \geq 0$,}
    \end{cases}
  \end{equation}
  Mostre que
  \begin{enumerate}[\quad a)]
  \item $K$ define um núcleo de transição entre $\mathbb{R}$ em $\mathbb{R}$.
  \item Se $X_1, X_2, \dots$ for uma cadeia de Markov em $\mathbb{R}$ com núcleo de transição $K$, então calcule
    \begin{enumerate}[\qquad i)]
    \item $E(X_i)$, para todo $i \geq 1$ e
    \item $\text{Var}(X_i)$, para todo $i \geq 1$.
    \item Mostre que
      \begin{equation}
        \frac{\sum_{i = 1}^n X_i}{\sqrt{n}} \Rightarrow \mathcal{N}(0,1).
      \end{equation}
    \end{enumerate}
  \end{enumerate}
\end{exercise}

\begin{topics}

\section{Tópico: Processos de Poisson em \texorpdfstring{$\mathbb{R}$}{R}}

Nessa seção aplicaremos o conceito de Probabilidade Condicional Regular e do Princípio da Substituição \index{Principio@Princípio!da Substituicao@da Substituição} para estudarmos um importante processo de chegadas chamado Processo de Poisson. \index{Processo de Poisson}

O Tenente Boavista está encarregado de vigiar o Sargento Pimenta, que frequentemente dorme durante sua vigília.
Para isso, Boavista tem que decidir os momentos $t_1, t_2, \dots \in \mathbb{R}$ que ele irá verificar se Pimenta está cochilando.
Uma primeira estratégia poderia ser tomar intervalos igualmente espaçados, $t_1 = 1, \dots, t_k = k$, mas o Sargento certamente iria dormir nos intevalos $(k + \varepsilon, k + 1 - \varepsilon)$ sem se preocupar.

Dado esse problema, o Tenente decide escolher tempos aleatórios $T_1, T_2, \dots$
Mas é importante lembrar que não são todas as distribuições que funcionarão bem, por exemplo se $T_k - T_{k-1} \geq a$ quase certamente o Sargento irá se aproveitar desse intervalinho.

A primeira simplificação que o Tenente imagina para esse problema é a seguinte: dado que houve uma vistoria no instante $t_k$, então o que acontecerá à partir daí será o mesmo processo com o qual ele começou.
Isso pode ser traduzido de maneira rigorosa como
\begin{equation}
  \label{e:Poisson_incr_ind}
  P\big[ (T_{k+1} - t_k, T_{k+2} - t_k, \dots ) \in A | T_k = t_k \big] = P\big[ (T_1, T_2, \dots ) \in A \big],
\end{equation}
$T_k \circ P$-quase certamente.
Não iremos entrar muito em detalhes sobre qual é essa esperança condicional, pois no momento ainda estamos trabalhando heuristicamente, mas já podemos dizer que:
\begin{equation}
  \label{e:increm_poisson}
  \begin{split}
    P\big[ T_1 \in A_1, T_2 - T_1 \in A_2 \big] & = E\big[ \1_{T_1 \in A_1} P[T_2 - T_1 \in A_2 | T_1 = t_1] \circ T_1 \big]\\
    & \overset{\eqref{e:Poisson_incr_ind}}= E\big[ \1_{T_1 \in A_1} P[T_1 \in A_2] \big] = P[T_1 \in A_1] P[T_1 \in A_2].
  \end{split}
\end{equation}
Procedendo de maneira análoga, podemos concluir que $(T_1, T_2 - T_1, T_3 - T_2, \dots)$ são uma coleção \iid.
Agora o Tenente Boavista somente precisa escolher a distribuição de $T_1$.

Para essa escolha, ele sabe que se ele não chegar em tempo $t$, então o Sargento Pimenta sabe que sua próxima chegada terá distribuição $P[T_1 - t \in A | T_1 > t]$.
Como o Tenente Boavista gostaria que essa essa informação fosse inútil para o Sargento Pimenta, ele escolherá
\begin{equation}
  P[T_1 - t \in A | T_1 > t] = P[T_1 \in A].
\end{equation}
E sabemos que as distribuições $\Exp(\lambda)$, para $\lambda > 0$ satisfazem isso, portanto já temos um candidato ao nosso processo de vistorias, mas antes vamos introduzir algumas notações.

Já podemos perceber por \eqref{e:increm_poisson} que mais importante que os tempos $T_k$, serão os intervalos entre visitas $X_k = T_k - T_{k-1}$.

Seja $\mathcal{D}\big( [0, \infty) \big)$ o espaço de todas as funções càdlàg em $\mathbb{N}$, ou seja
\begin{equation*}
  \mathcal{D}\big( [0, \infty) \big) = \big\{ f:\mathbb{R}_+ \to \mathbb{N}: f \text{ é contínua à direita e com limite à esquerda} \big\}.
\end{equation*}
Definiremos $\Gamma: \mathbb{R}^\mathbb{N} \to \mathcal{D}\big( [0, \infty) \big)$ da seguinte forma: dados $(x_1, x_2, \dots) \in \mathbb{R}^\mathbb{N}$, seja $\Gamma(x_1, \dots) = N$, tal que
\begin{equation}
  N_t = \max\{n; \sum_{i=1}^n x_i \leq t\},
\end{equation}
que conta quantas visitas ocorreram antes de $t$, veja Figura~\ref{f:ppp_reta}.

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=1]
    \clip (-1, -1) rectangle (8, 5);
    \draw[<->] (0, 4) -- (0,0) -- (9, 0);
    \edef\k{0};
    \foreach \z in {0,...,6}
    { \pgfmathrandominteger{\x}{20}{200}
      \pgfmathparse{max((2 * ln(200/\x)), .3) + \k}
      \xdef\j{\pgfmathresult}
      \draw[dashed] (\j, 0) -- (\j, \z);
      \draw[thick] (\k, \z) -- (\j, \z);
      \draw[fill, color = white] (\j, \z) circle (.04);
      \draw[color = black] (\j, \z) circle (.04);
      \draw[fill, color = black] (\k, \z) circle (.04);
      \pgfmathparse{int(\z + 1)}
      \xdef\n{\pgfmathresult}
      \node[below] at (\j, 0) {$t_{\n}$};
      \xdef\k{\j}
    }
  \end{tikzpicture}
  \caption{A função $N_t$ definindo o número de chegadas do Processo de pontos de Poisson.
  Note que $N$ é càdlàg.\label{f:ppp_reta}}
\end{figure}

Poderíamos nos perguntar qual é a $\sigma$-álgebra que estamos considerando no espaço $\mathcal{D}\big( [0, \infty) \big)$, essa é uma interessante questão que deve ser abordada em estudos mais profundos desse espaço.
Mas por enquanto será suficiente considerarmos a $\sigma$-álgebra induzida pelo mapa $\Gamma$ (a maior que ainda o deixa mensurável).

Estamos prontos agora pra definir o nosso processo.

\begin{definition}
  Fixado $\lambda > 0$, definimos um Processo de Poisson em $\mathbb{R}$ com parâmetro $\lambda$ como a lei $\mathbb{P}_\lambda$ em $\mathcal{D}\big( [0, \infty) \big)$, dada por $\Gamma \circ \Exp(\lambda)^{\otimes \mathbb{N}}$.
  Ou em outras palavras, o processo de contagem de chegadas $N_t$, no qual os intervalos entre chegadas são independentes e distribuídos como $\Exp(\lambda)$.
\end{definition}

Lembramos que como de costume definimos $X_1, X_2, \dots$ como sendo as projeções canônicas em $\mathbb{R}^\mathbb{N}$ onde definimos $\Exp(\lambda)^{\otimes \mathbb{N}}$.
Como esses representam os intervalos entre chegadas, definimos também
\begin{equation}
  T_k = \sum_{i=1}^k X_i, \text{ para $k \geq 1$}.
\end{equation}

Podemos agora enunciar o primeiro lema, que nos fornece a distribuição do número de chegadas em um dado tempo $t \geq 0$.

\begin{lemma}
  Se $\lambda > 0$ e $t \geq 0$, então $N_t \distr \Poisson(\lambda t)$ sob $\mathbb{P}_\lambda$.
\end{lemma}

\begin{proof}
  Vamos primeiramente ver que
  \begin{equation}
    \mathbb{P}_\lambda [N_t = 0] = \mathbb{P}_\lambda[X_1 > t] = e^{-\lambda t},
  \end{equation}
  que coincide com o caso poissoniano.

  Para verificar o caso arbitrário $[N_t = k]$, utilizaremos indução e os resultados de esperança condicional regular que vimos anteriormente.
  Primeiro, observe que se $x_1 > s$, então
  \begin{equation}
    \Gamma(x_1, x_2, \dots)(r - s) = \Gamma(x_1 - s, x_2, \dots)(r).
  \end{equation}
  Logo,
  \begin{equation*}
    \begin{array}{e}
      \mathbb{P}_\lambda[N_t = k] & = & \mathbb{P}_\lambda [X_1 \leq t, \Gamma(X_2, X_3, \dots)(t - X_1) = k - 1]\\
      & = & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \mathbb{P}_\lambda[\Gamma(X_2, X_3, \dots)(t - X_1) = k - 1 | X_1] \Big]\\
      & \overset{\textnormal{Subst.}}= & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \mathbb{P}_\lambda[\Gamma(X_2, X_3, \dots)(t - x_1) = k - 1 | X_1 = x_1] \circ X_1 \Big]\\
      & \overset{\textnormal{induc.}}= & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \big(\Poisson(\lambda(t - x_1))(\{k-1\})\big) \circ X_1 \Big]\\
      & = & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \frac{(\lambda(t - X_1))^{k-1} e^{-\lambda(t - X_1)}}{(k-1)!} \Big]\\
      & = & \int_0^t \frac{(\lambda(t - x_1))^{k-1} e^{-\lambda(t - x_1)}}{(k-1)!} \lambda e^{-\lambda x_1} \d x_1 = \frac{\lambda^k e^{-\lambda t}}{(k-1)!} \frac{t^k}k,
    \end{array}
  \end{equation*}
  como queríamos demonstrar.
\end{proof}

\newpage

Um outro resultado importante sobre esses processos se relaciona ao fato de reiniciar o sistema em tempo $t > 0$.
Isso é feito com o seguinte mapa $\theta_t: \mathcal{D}\big( [0, \infty) \big) \to \mathcal{D}\big( [0, \infty) \big)$, que leva $N$ em
\begin{equation}
  \theta_t(N)(s) = N_{s + t} - N_t.
\end{equation}

\begin{exercise}
  Mostre que o mapa $\theta_t$ é mensurável.
\end{exercise}

\begin{lemma}
  Fixe $\lambda, t > 0$ e seja $N$ um processo de Poisson de taxa $\lambda$.
  Então, para $k \in \mathbb{Z}_+$ e $A$ mensurável,
  \begin{equation}
    \mathbb{P}_\lambda[N_t = k, \theta_t \circ N \in A] = \mathbb{P}_\lambda[N_t = k] \mathbb{P}_\lambda[N \in A].
  \end{equation}
\end{lemma}

Em particular, isso mostra que a distribuição do processo de Poisson $N$ é invariante pelo mapa $\theta_t$.

\begin{proof}
  Começamos reescrevendo o evento e condicionando em $T_k$ como abaixo
  \begin{equation*}
    \begin{split}
      \mathbb{P}_\lambda & [N_t = k, \theta_t \circ N \in A] \\
      & = \mathbb{P}_\lambda[T_k \leq t, T_{k + 1} > t , \theta_t \circ N \in A] \\
      & = \mathbb{E}_\lambda \big[ {\bf 1}_{T_k \leq t} \mathbb{E}_\lambda [X_{k + 1} > t - t_k, \theta_t \circ N \in A | T_k = t_k ] \circ T_k \big] \\
      & = \mathbb{E}_\lambda \Big[ {\bf 1}_{T_k \leq t} \mathbb{E}_\lambda \big[X_{k + 1} > t - t_k, \Gamma (X_{k + 1} - (t - t_k), X_{k + 2}, X_{k + 3}, \dots ) \in A | T_k = t_k \big] \circ T_k \Big], \\
      \intertext{que, usando que $X_i$ são independentes e $X_{k + 1}$ não tem sem memória, é igual a}
      & = \mathbb{E}_\lambda \Big[ {\bf 1}_{T_k \leq t} \mathbb{P}_\lambda \big[X_{k + 1} > t - t_k | T_k = t_k \big] \circ T_k \Big] \mathbb{P}_\lambda [N \in A] \\
      & = \mathbb{P}_\lambda[ N_t = t ] \mathbb{P}_\lambda [N \in A],
    \end{split}
  \end{equation*}
  terminando a prova do lema.
\end{proof}

Como corolário do lema acima, podemos deduzir que um processo de Poisson possui incrementos independentes.
Mais precisamente,

\begin{corollary}
  Seja $N$ um Processo de Poisson $N$ com taxa $\lambda > 0$.
  Considerando também tempos $0 = t_0 < t_1 < \dots < t_j$, e inteiros $k_1, \dots, k_j \geq 0$ temos
  \begin{equation*}
    \mathbb{P}_\lambda \big[ N_{t_1} = k_1, \dots, N_{t_j} - N_{t_{j - 1}} = k_j \big] = \mathbb{P}_\lambda [N_{t_1} = k_1] \cdots \mathbb{P}_\lambda [N_{t_j - t_{j - 1}} = k_j]
  \end{equation*}
\end{corollary}

\begin{proof}
  Basta observar que
  \begin{equation}
    [ N_{t_2} - N_{t_1}, \dots, N_{t_j} - N_{t_{j - 1}}] = [ N_{t_2 - t_1}, \dots, N_{t_j - t_1} - N_{t_{j - 1} - t_1}] \circ \theta_{t_1}
  \end{equation}
  e aplicar o lema para obter
  \begin{equation*}
    \begin{split}
      \mathbb{P}_\lambda \big[ & N_{t_1} = k_1, \dots, N_{t_j} - N_{t_{j - 1}} = k_j \big] \\
      & = \mathbb{P}_\lambda [ N_{t_1} = k_1] \mathbb{P}_\lambda [N_{t_2 - t_1} = k_2 , \dots N_{t_j - t_1} - N{t_{j - 1} - t_1} = k_j].
    \end{split}
  \end{equation*}
  Repetindo essa operação iterativamente, obtemos o resultado desejado.
\end{proof}



\begin{equation}
  T_1, \dots, T_k \text{ under } \mathbb{P}^{t, k}_\lambda \overset{d}\sim
\end{equation}


$x_1 = t_1$, $x_2 = t_2 - t_1, \dots, x_k = t_k - t_{k - 1}$
\begin{equation}
  \begin{split}
    \rho^{t, k}_\rho (t_1, \dots, t_k) & = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{1}{\mathbb{P}_\lambda [N_t = k]}
    \lambda e^{-\lambda x_1} \lambda e^{-\lambda x_2} \cdots e^{ - \lambda x_k} e^{ - \lambda (t - t_k) }\\
    & = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{k!}{e^{-\lambda t} (\lambda t)^k} \lambda^k e^{-\lambda t} = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{k!}{t^k}.
\end{split}
\end{equation}
Note que não depende de $\lambda$.


Considere variáveis uniformes $U_1, \dots, U_k$ no intervalo $[0, t]$
\begin{equation}
  \rho^{t, k} (u_1, \dots, u_k) = {\bf 1}_{\tilde{u}_1, \dots, \tilde{u}_k \in [0, t]} \; \frac{1}{t^k}
\end{equation}

Seja $\tilde{U}_1 < \dots < \tilde{U}_k$ a versão ordenada das $U_i$'s.
\begin{equation}
  (\tilde{U}_1, \dots, \tilde{U}_k) \overset{q.c.}= \sum_{\sigma \text{ perm. de $\{1, \dots, k\}$}} (U_{\sigma_1}, \dots, U_{\sigma_k}) {\bf 1}_{0 \leq U_{\sigma_1} \leq \dots \leq U_{\sigma_k} \leq t}
\end{equation}

Então,
\begin{equation}
  \begin{split}
    \tilde{\rho}^{t, k} & = {\bf 1}_{0 \leq \tilde{u}_1 \leq \dots \leq \tilde{u}_k \leq t} \; \frac{1}{t^k} \sum_{\sigma \text{ perm. de $\{1, \dots, k\}$}} \rho^{t, k}(\tilde{u}_{\sigma_1}, \dots, \tilde{u}_{\sigma_k}) \\
    & = {\bf 1}_{0 \leq \tilde{u}_1 \leq \dots \leq \tilde{u}_k \leq t} \; \frac{k!}{t^k} 
  \end{split}
\end{equation}

\end{topics}

\todosec{Tópico: Processos de Markov em tempo contínuo}{fazer...}

\todosec{Tópico: Sistemas de partículas}{fazer...}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Notas_de_aula"
%%% End:
