\chapter{Esperança condicional}

\section{Esperança condicional}

Como já foi dito anteriormente, a estrutura de $\sigma$-álgebra tem um papel muito importante em probabilidade.
Durante o curso de Teoria da Medida, muitas vezes o conceito de $\sigma$-álgebra parece uma tecnicalidade que simplesmente dificulta nosso acesso ao conteúdo realmente interessante do curso.
Em alguns momentos, chegamos a desejar que tudo fosse mensurável e não tivéssemos que nos preocupar com tais formalidades.

Contudo, no estudo que iniciaremos agora, nos restringiremos a $\sigma$-álgebras menores de maneira proposital.
Ficará claro em particular, que o estudo de mensurabilidade não é uma mera tecnicalidade, mas sim uma ferramenta importante.

Esse interesse, vem da necessidade de representar situações de ``informação incompleta'', onde podemos apenas observar uma parte da realidade.
Isso certamente é de suma importância em diversas aplicações, desde a estatística, física e computação até a teoria de jogos.
Vamos começar com um exemplo simples.

Suponha que $\Omega = \mathbb{R}^2$ é dotado da $\sigma$-álgebra de Borel e denotamos por $X_1, X_2$ as coordenadas canônicas.
Como podemos representar matematicamente a afirmação ``uma pessoa somente conhece o valor de $X_1$ e não de $X_2$''?
Digamos por exemplo que essa pessoa deverá tomar uma decisão (por exemplo escolher um elemento de $E$) baseando-se apenas nessa informação incompleta.
A maneira que modelamos isso matemáticamente é dizendo que a decisão da pessoa deve ser uma função $f: \Omega \to E$ mensurável com respeito a $\sigma(X_1)$.

Nossa primeira utilização desse conceito será feita agora ao introduzirmos a noção de esperaça condicional, que generaliza o conceito de esperança.
Relembrando o cálculo \eqref{e:EX_aproxima}, nós podemos pensar em $E(X)$ como uma boa maneira de aproximar $X$ por um número real.
Isso por exemplo poderia ser útil se não temos nenhuma informação sobre o que ocorreu, mas ainda sim temos que tentar adivinhar o valor de $X$.
Mas vamos agora imaginar uma outra situação, onde temos um pouco de informação sobre o que ocorreu.

Voltando ao exemplo em que $\Omega = \mathbb{R}^2$, digamos que nós podemos observar o valor de $X_1$, mas gostaríamos de estimar o valor de $X_2$.
De acordo com o que discutimos acima, nossa estimativa agora não precisa mais ser apenas um número real, podendo ser qualquer função mensurável com respeito a $\sigma(X_1)$.

Vamos no que segue tornar esse discussão rigorosa, mas antes lembramos um lema básico de Teoria da Medida.

\begin{lemma}
  \label{l:f_igual_fp}
  Se $f, f'$ são funções mensuráveis tais que
  \begin{equation}
    \int_A f \d \mu = \int_A f' \d \mu, \text{ para todo $A \in \mathcal{F}'$,}
  \end{equation}
  então $f = f'$ $\mu$-quase certamente.
\end{lemma}

\begin{proof}
  Aplicando a hipótese para $A = [f > f']$, vemos que
  \begin{equation}
    \int_A f - f' \d \mu = 0,
  \end{equation}
  mas no conjunto $A$ acima, o integrando é positivo.
  Portanto, $f = f'$, $\mu$-quase certamente em $A$.
  Aplicando o mesmo raciocínio para $[f < f']$ obtemos que $f = f'$ quase certamente.
\end{proof}

O lema acima nos diz que se soubermos integrar $f$ em todos os eventos $A$, então podemos recuperar a função $f$ propriamente dita.
O que aconteceria se soubéssemos integrar $f$ apenas para eventos $A$ em uma sub-$\sigma$-álgebra?
É isso que estudaremos à partir de agora.

\begin{definition}
  \label{d:esperanca_condicional}
  Seja uma variável aleatória $X \in \mathcal{L}^1(P)$ e uma sub-$\sigma$-álgebra $\mathcal{F}' \subseteq \mathcal{F}$.
  Dizemos que uma variável aleatória $Y$ é a esperança condicional \index{esperanca@esperança!condicional} de $X$ com respeito a $\mathcal{F}'$ (ou a esperança condicional de $X$ dada $\mathcal{F}'$) se
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $E(X \1_{A}) = E(Y \1_{A})$ para todo $A \in \mathcal{F}'$.
  \end{enumerate}
  Nesse caso, escrevemos
  \begin{equation}
    Y = E(X | \mathcal{F}').
  \end{equation}
\end{definition}

Observe que faz sentido escrever $E\big(Y|\mathcal{F}'\big)(\omega)$, pois $E(X|\mathcal{F}')$ é uma variável aleatória.

Interpretamos informalmente a definição acima como ``$Y$ é a melhor aproximação $\mathcal{F}'$-mensurável de $X$''.
Ou $Y$ é a melhor aproximação que podermos fazer de $X$ se ``conhecemos apenas $\mathcal{F}'$''.

\begin{example}
  \label{x:EXF_trivial}
  Se $\mathcal{F}' = \{\varnothing, \Omega\}$, então $Y = E(X)$ (uma variável aleatória constante) é esperança condicional de $X$ dado $\mathcal{F}'$, pois
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável (por ser constante). Além disso
  \item $E(X \1_\varnothing) = 0 = E(Y \1_\varnothing)$ e $E(X \1_\Omega) = E(X) = E(Y \1_\Omega)$.
  \end{enumerate}
\end{example}

Uma propriedade muito importante que segue da Definição~\ref{d:esperanca_condicional} é dada pela seguinte

\begin{proposition}
  \label{p:ec_em_L1}
  Se $Y$ satisfaz as $a)$ e $b)$ em Definição~\ref{d:esperanca_condicional}, então $Y \in \mathcal{L}^1(P)$.
\end{proposition}

\begin{proof}
  Tomamos $A = [Y \geq 0]$ e $A' = [Y < 0]$ que estão em $\mathcal{F}'$ e estimamos
  \begin{equation}
    \int |Y| \d P = \int_A Y \d P + \int_{A'} Y \d P = \int_A X \d P + \int_{A'} X \d P \leq \int |X| \d P < \infty
  \end{equation}
  O que mostra a proposição.
\end{proof}

Além caso trivial dado acima pelo Exemplo~\ref{x:EXF_trivial}, quando podemos esperar que existam esperanças condicionais?

\begin{theorem}
  Dada $X \in \mathcal{L}^1(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$ uma $\sigma$-álgebra, então existe a esperança condicional $E(X|\mathcal{F}')$.
  Além disso ela é única $P$-quase certamente.
\end{theorem}

\begin{proof}
  Vamos primeiro mostrar a unicidade quase certa.
  Para isso, supomos que existam $Y$ e $Y'$ satisfazendo as condições da Definição~\ref{d:esperanca_condicional} (logo em $\mathcal{L}^1$).
  Iremos proceder como no Lema~\ref{l:f_igual_fp} acima, definindo $A = [Y > Y']$, donde concluímos que
  \begin{equation}
    E\big( (Y - Y')\1_{A} \big) = E(Y \1_{A}) - E(Y' \1_{A}) = 0.
  \end{equation}
  Mas como $Y > Y'$ em $A$, vemos que $Y \leq Y'$ quase certamtente.
  A prova da unicidade pode ser completa trocando os papéis de $Y$ e $Y'$ acima.

  Vamos agora para a prova da existência.
  Como $X \in \mathcal{L}^1(P)$, podemos introduzir
  \begin{equation}
    \mu(A) = E(X \1_{A}),
  \end{equation}
  que define uma medida com sinal em $(\Omega, \mathcal{F})$, com variação total finita.

  Caso o leitor não se sinta familiarizado com o conceito de medida com sinal, poderá decompor $X$ em partes positiva e negativa e proceguir sem problemas.

  Um passo importante da prova é observar que $\mu$ também define uma medida no espaço $(\Omega, \mathcal{F}')$.
  Estamos portanto propositalmente restringindo nossa $\sigma$-álgebra.
  Como $P(A) = 0$ implica que $\mu(A) = 0$, temos que $\mu \ll P$ e podemos aplicar o Teorema de Radon-Nikodim para obter uma derivada $Y:\Omega \to \mathbb{R}$ tal que
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável e
  \item $\mu(A) = \int_A Y \d P$.
  \end{enumerate}
  Agora é só observar que as afirmações acima correspondem às condições da Definição~\ref{d:esperanca_condicional}.
\end{proof}

Observe que a condição de $\mathcal{F}'$-mensurabilidade é essencial para a unicidade.
De fato, $X$ obviamente satisfaz a segunda condição da Definição~\ref{d:esperanca_condicional}, mas não necessariamente a primeira.

\begin{exercise}
  Mostre que se $X \in \mathcal{F}'$, então $E(X|\mathcal{F}') = X$ quase certamente.
\end{exercise}

\begin{exercise}
  Seja $P$ a probabilidade uniforme em $\{(x_1, x_2) \in [0,1]^2; x_1 \geq x_2\}$.
  Calcule $E(X_2|X_1)$.
\end{exercise}

\begin{exercise}
  Seja $E$ enumerável com uma $\sigma$-álgebra $\mathcal{F}'$.
  Mostre que
  \begin{equation}
    \mathcal{F}' = \sigma(A_i, i \geq 1), \text{ com $A_i \subseteq E$ disjuntos}.
  \end{equation}
  Suponha que todos conjuntos $A_i$ tem probabilidade positiva e mostre que
  \begin{equation}
    E(X|\mathcal{F}') = \sum_i E^i(X) \1_{A_i},
  \end{equation}
  onde $E^i$ é a esperança com respeito à probabilidade $P(\cdot|A_i)$.

\end{exercise}


\section{Propriedades básicas da esperança condicional}

Nessa seção justificaremos, em certa medida, a nomenclatura ``esperança condicional''.
Faremos isso mostrando que ela satisfaz várias propriedades que já conhecemos para a esperança tradicional.

Mas como podemos mostrar propriedades simples tais como a linearidade da esperança condicional?
Vamos começar com um exemplo

\begin{proposition}
  \index{esperanca@esperança!condicional!aditividade}
  Se $X, X' \in \mathcal{L}^1(P)$, então
  \begin{equation}
    E(X + X'|\mathcal{F}') = E(X|\mathcal{F}') + E(X'|\mathcal{F}'), \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

Note que a igualdade acima é uma igualdade entre variáveis aleatórias.

\begin{proof}
  Sabemos que $Y = E(X|\mathcal{F}') + E(X'|\mathcal{F}')$ é uma variável aleatória bem definida.
  Mais do que isso, sabemos que ela é uma candidata muito boa a $E(X + X'|\mathcal{F}')$.
  Logo, por unicidade da esperança condicional, basta verificar que $Y$ satisfaz as condições da Definição~\ref{d:esperanca_condicional} com respeito a $X + X'$.
  De fato
  \begin{enumerate}[\quad a)]
  \item $Y$ é $\mathcal{F}'$-mensurável, por ser uma soma de duas variáveis $\mathcal{F}'$-mensuráveis e
  \item por linearidade da esperança (não da esperança condicional), temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E\big( E(X|\mathcal{F}')\1_A + E(X'|\mathcal{F}')\1_A \big)\\
        & = E\big( E(X|\mathcal{F}')\1_A\big) + E\big(E(X'|\mathcal{F}')\1_A \big)\\
        & = E(X \1_A) + E(X' \1_A) = E\big( (X + X') \1_A \big).
      \end{split}
    \end{equation}
  \end{enumerate}
  Isso termina a prova do proposição.
\end{proof}

\begin{exercise}
  Dados $X \in \mathcal{L}^1$ e $\alpha \in \mathbb{R}$, mostre que $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$.
\end{exercise}

Uma outra propriedade bem simples da esperança condicional é a monotonicidade.

\begin{lemma}
  \index{esperanca@esperança!condicional!monotonicidade}
  \label{l:ec_mono}
  Se $X \geq X'$ em $\mathcal{L}^1(P)$, então
  \begin{equation}
    E(X|\mathcal{F}') \geq E(X'|\mathcal{F}'), \text{$P$-quase certamente.}
  \end{equation}
  Em particular, se $X \geq 0$, então $E(X|\mathcal{F}') \geq 0$ quase certamente.
\end{lemma}

\begin{proof}
  Seja $A = [E(X'|\mathcal{F}') - E(X|\mathcal{F}') > 0]$, que pertence a $\mathcal{F}'$.
  Então
  \begin{equation}
    0 \leq E\big( (E(X'|\mathcal{F}') - E(X|\mathcal{F}')) \1_A \big) = E\big((X' - X) \1_A\big) \leq 0,
  \end{equation}
  o que implica que $P(A) = 0$.
\end{proof}

\begin{proposition}
  \label{p:EZX_ZEX}
  Se $X, ZX \in \mathcal{L}^1(P)$, com $Z \in \mathcal{F}'$, temos
  \begin{equation}
    E(XZ|\mathcal{F}') = Z E(X|\mathcal{F}') \text{ $P$-quase certamente}.
  \end{equation}
  Em particular, $E(\alpha X|\mathcal{F}') = \alpha E(X|\mathcal{F}')$, para todo $\alpha \in \mathbb{R}$.
  Uma outra consequência interessante é que $Z E(X|\mathcal{F}')$ estará automaticamente em $\mathcal{L}^1$.
\end{proposition}

De maneira bastante informal, vamos dar uma intuição para o resultado acima.
Ao considerarmos a esperança condicional dada $\mathcal{F}'$, nós já conhecemos as variáveis aleatórias $\mathcal{F}'$-mensuráveis, portanto elas se comportam como constantes.

\begin{proof}
  Mais uma vez, basta verificar que $Z E(X|\mathcal{F}')$ satisfaz as condições que definem a esperança condicional.
  A primeira é trivial, pois $Z E(X|\mathcal{F}')$ é $\mathcal{F}'$-mensurável por ser um produto de funções $\mathcal{F}'$-mensuráveis.

  Para provar a segunda condição, começamos com o caso $Z = \1_B$, implicando que $B \in \mathcal{F}'$, donde
  \begin{equation*}
    E\big(ZE(X|\mathcal{F}') \1_A \big) = E\big( E(X|\mathcal{F}') \1_{A \cap B}\big) = E(X \1_{A \cap B}) = E(ZX \1_A).
  \end{equation*}
  Por linearidade, já sabemos que o resultado vale para funções $Z$ simples e gostaríamos de extender para quaisquer $Z$ positivas via Teorema da Convergência Monótona.
  Um problema aqui é que mesmo que $Z$ seja positiva, não sabemos se $E(X|\mathcal{F}')$ também será positiva.

  Portanto, trataremos primeiramente do caso $X \geq 0$.
  Para tais $X$, sabemos pelo Lema~\ref{l:ec_mono} que $E(X|\mathcal{F}') \geq 0$ quase certamente.
  Daí, podemos concluir que $Z E(X|\mathcal{F}') = E(ZX|\mathcal{F}')$ para toda $Z \geq 0$, podemos aproximá-la por baixo por $Z_n$ simples e, pelo Teorema da Convergência Monótona,
  \begin{equation}
    \begin{array}{e}
      E\big( Z E(X|\mathcal{F}') \big) & \overset{\text{TCM}}= & \lim_n E\big( Z_n E(X|\mathcal{F}') \big)\\
      & = & \lim_n E\big( E(Z_n X|\mathcal{F}') \big) \overset{\text{TCM}}= E\big( E(ZX|\mathcal{F}') \big).
    \end{array}
  \end{equation}
  O que mostra o resultado sempre que $X \geq 0$.

  Além disso, pela Proposição~\ref{p:ec_em_L1}, sabemos que $Z E(X|\mathcal{F}') \in \mathcal{L}^1$.
  Podemos finalmente concluir a prova por linearidade decompondo $X = X_+ - X_-$.
\end{proof}

O próximo resultado tenta corroborar nossa afirmação que a esperança condicional é uma boa maneira de aproximar uma variável aleatória.

\begin{lemma}
  Se $X \in \mathcal{L}^2(P)$ e $\mathcal{F}' \subseteq \mathcal{F}$, então $E(X|\mathcal{F}')$ é a projeção ortogonal de $X$ no espaço vetorial $H_{\mathcal{F}'}$.
  Onde $H_{\mathcal{F}'} = \{Y \in \mathcal{L}^2; Y \text{ é $\mathcal{F}'$-mensurável}\}$.
\end{lemma}

\begin{proof}
  Temos que verificar que $X - E(X|\mathcal{F}')$ é ortogonal a $H_{\mathcal{F}'}$.
  Ou seja, mostrar que para todo $Z \in H_{\mathcal{F}'}$, temos
  \begin{equation}
    E\big( XZ - E(X|\mathcal{F}') Z \big) = 0.
  \end{equation}
  Note que não é claro que essa esperança faz sentido, pois não sabemos que $ZE(X|\mathcal{F}') \in \mathcal{L}^1$.
  Mas isso segue facilmente da Proposição~\ref{p:EZX_ZEX}.

  Mas $E\big( E(X|\mathcal{F}') Z \big) = Z E\big( E(X | \mathcal{F}') \1_\Omega \big) = Z E\big( X \1_\Omega \big)$, provando o resultado.
  \todo{Adicionar footnote.}
\end{proof}

Uma outra propriedade que a esperança condicional herda da integral é a

\begin{proposition}[Desigualdade de Jensen]
  \index{esperanca@esperança!condicional!desigualdade de Jensen}
  Se $\phi:\mathbb{R} \to \mathbb{R}$ é convexa, $X, \phi(X) \in \mathcal{L}^1(P)$, então
  \begin{equation}
    \phi\big( E(X|\mathcal{F}') \big) \leq E\big( \phi(X) | \mathcal{F}' \big).
  \end{equation}
\end{proposition}

\begin{proof}
  Se $\phi$ for uma função linear, o resultado segue da linearidade que já provamos para a esperança condicional.
  Além disso, se temos uma função $\psi:\mathbb{R} \to \mathbb{R}$ linear e tal que $\psi(x) \leq \phi(x)$ para todo $x \in \mathbb{R}$, então
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq E\big( \psi(X) | \mathcal{F}' \big) = \psi \big( E(X|\mathcal{F}') \big).
  \end{equation}
  Tomamos finalmente o supremo em todas as $\psi$ lineares com $\psi \leq \phi$ dos dois lados da desigualdade acima, obtendo
  \begin{equation}
    E\big( \phi(X) | \mathcal{F}' \big) \geq \sup_{\substack{\psi \leq \phi\\\psi \text{ linear}}} \psi \big( E(X|\mathcal{F}') \big) = \phi \big( E(X|\mathcal{F}') \big),
  \end{equation}
  terminando a prova da proposição.
\end{proof}

\begin{corollary}
  Se $X \in \mathcal{L}^1(P)$, então $\big| E(X|\mathcal{F}') \big| \leq E\big(|X| \big| \mathcal{F}' \big)$.
\end{corollary}

Uma outra propriedade interessante da esperança condicional diz respeito a sua relação com independência.

\begin{proposition}
  Se $X \in \mathcal{L}^1(P)$ é independente de $\mathcal{F}'$, então
  \begin{equation}
    E(X|\mathcal{F}') = E(X) \text{ $P$-quase certamente.}
  \end{equation}
\end{proposition}

\begin{proof}
  Funções constantes são sempre mensuráveis. Além disso, se $A \in \mathcal{F}'$, então
  \begin{equation}
    E(X \1_A) = E(X) P(A) = E\big( E(X) \1_A \big),
  \end{equation}
  concluindo a prova.
\end{proof}

Terminamos essa seção com o que chamamos da propriedade de torre da esperança condicional.

\begin{proposition}
  \index{esperanca@esperança!condicional!torre}
  Se $\mathcal{F}' \subseteq \mathcal{F}''$ são ambas sub-$\sigma$-álgebras de $\mathcal{F}$, então para $X \in \mathcal{L}^1(P)$, temos
  \begin{equation}
    \label{e:ec_torre}
    E\big( E(X|\mathcal{F}') \big| \mathcal{F}'' \big) = E(X|\mathcal{F}') = E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big),
  \end{equation}
  ou em outras palavras, independentemente da ordem, prevalece a condição na menor $\sigma$-álgebra.
  Consequentemente, $E\big( E(X|\mathcal{F}') \big) = E(X)$.
\end{proposition}

\begin{proof}
  Como $E(X|\mathcal{F}')$ é $\mathcal{F}''$-mensurável, a Proposição~\ref{p:EZX_ZEX}, aplicada com $X = 1$, mostra a primeira igualdade em \eqref{e:ec_torre}.

  Falta mostrar que $E\big( E(X|\mathcal{F}'') \big| \mathcal{F}'\big)$ é a esperança condicional de $X$ dada $\mathcal{F}'$.
  Obviamente ela é $\mathcal{F}'$-mensurável, e nos resta verificar a segunda condição.
  Mas para todo $A \in \mathcal{F}'$, lembrando que $A$ também pertence a $\mathcal{F}''$ e usando a definição de esperança condicional duas vezes,
  \begin{equation}
    E\Big( E\big( E(X|\mathcal{F}'') \big| \mathcal{F}' \big) \1_A \Big) = E\big( E(X | \mathcal{F}'')  \1_A \big) = E(X \1_A).
  \end{equation}
  O que termina a prova da proposição.
\end{proof}


\section{Teoremas classicos de convergência para esperança condicional}
Vimos acima uma metodologia que se repete frequentemente.
Digamos que queremos provar que uma determinada expressão nos dá a esperança condicional de algo.
Podemos começar provando esse resultado para funções indicadoras, depois para funções simples usando a linearidade provada acima.
Porém ainda falta um ingrediente bastante importante para construir ou verificar que determinadas variáveis são esperanças condicionais.

\begin{theorem}[Convergência Monótona para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.M.}
  \label{t:TCM_EC}
  Se as variáveis $X_n$ satisfazem $X_n \uparrow X$ e estão todas em $\mathcal{L}^1(P)$, então
  \begin{equation}
    \lim_{n\to \infty} E(X_n|\mathcal{F}') = E(X|\mathcal{F}').
  \end{equation}
\end{theorem}

\begin{proof}[Demonstração do Teorema~\ref{t:TCM_EC}]
  Sabemos que $E(X_{n+1} | \mathcal{F}') \geq E(X_n|\mathcal{F}')$, donde concluímos que $E(X_n|\mathcal{F}') \uparrow Y$.
  Vamos demosntrar que $Y = E(X|\mathcal{F}')$.
  \begin{enumerate}[\quad a)]
  \item Por ser um limite de funções $\mathcal{F}'$ mensuráveis, $Y$ é $\mathcal{F}'$-mensurável.
  \item Dado $A \in \mathcal{F}'$, temos
    \begin{equation}
      \begin{split}
        E(Y \1_A) & = E(\lim_n E(X_n |\mathcal{F}') \1_A) \overset{\text{TCM}}= \lim_n E\big( E(X_n|\mathcal{F}') \1_A \big)\\
        & = \lim_n E(X_n \1_A) \overset{\text{TCM}}= E(X \1_A).
      \end{split}
    \end{equation}
  \end{enumerate}
  O que termina a prova do teorema.
\end{proof}









Um outro resultado bastante importante é o seguinte

\begin{theorem}[Teorema da Convergência Dominada para Esperanças Condicionais]
  \index{esperanca@esperança!condicional!T.C.D.}
  Se $X_n \to X$ e existe $Y \in \mathcal{L}^1(P)$ tal que $|X_n| \leq Y$ para todo $n$, então
  \begin{equation}
    E(X_n | \mathcal{F}) \to E(X|\mathcal{F}) \text{ $P$-quase certamente.}
  \end{equation}
\end{theorem}

\begin{proof}
Primeiro, observamos que pelo Teorema de Convergência dominada (usual), o limite $X$ e integrável.\\


  Seja $Z_n = \sup_{k \geq n} |X_k - X|$ o erro máximo à partir de $n$.
  Claramente, $Z_n \downarrow 0$ quase certamente e além disso
  \begin{equation}
    |Z_n| \leq \sup_{k \geq 1} |X_k| + |X| \leq 2 Y,
  \end{equation}
  donde $E(Z_n) \to E(0) = 0$, quase certamente pelo Teorema da Convergência Dominada.
Obviamente $E(Z_n|\mathcal{F})$ é uma sequência positiva e não-crescente, logo decresce quase certamente para algum $Z$.
  Daí,
  \begin{equation}
    \big| E(X_n | \mathcal{F}) - E(X | \mathcal{F}) \big| \leq E(Z_n | \mathcal{F}) \downarrow Z \geq 0.
  \end{equation}
  Mas $E(Z) \leq E\big( E(Z_n|\mathcal{F}) \big) = E(Z_n)$.
  Como $E(Z_n)$ vai a zero pelo Teorema da Convergência Dominada, temos que $Z = 0$ quase certamente como gostaríamos.
\end{proof}



\subsection{Condicionamento com respeito a um elemento aleatorio.}

No caso onde $\cF'$ e a $\sigma$-algebrà gerada por uma variavel (o elemento) aleatoria(o) $Z$, 
muitas vezes escreveremos $E(X|Z)$ para representar a esperança condicional $E(X|\sigma(Z))$.


\begin{lemma}
  \label{l:f_g_circ_X}
  Se $X: \Omega \to E$ é um elemento aleatório e $Y:\Omega \to \mathbb{R}$ é uma variável aleatoria $\sigma(X)$-mensurável, 
  então existe uma $g:E \to \mathbb{R}$ mensurável tal que $Y = g(X)$.
\end{lemma}

\begin{proof}
  Como de costume, consideramos primeiramente o caso $Y = \1_A$
  Claramente $A$ tem que pertencer a $\sigma(X)$, ou seja $A = X^{-1}(B)$ para algum $B \in \mathcal{A}$.
  Neste caso colocamos $g = \1_B$, donde obtemos $Y(\omega) = 1 \Leftrightarrow \omega \in A \Leftrightarrow X(\omega) \in B \Leftrightarrow g \circ X = 1$.

  No caso em que $Y$ é simples, temos $Y = \sum_i a_i (g_i (X)) = (\sum_i a_i g_i)(X)$.
  Se $Y$ é positiva, então ela é um limite crescente de funções simples $Y_n$ que podem se ser exprimidas como $g_n(X)$. 
  Além disso podemos escolher $g_n$ crescentes, pois se não for o caso definindo $\tilde g_n= \max_{k\le n}g_k$ temos
  tambem $Y_n=\tilde g_n(X)$, pois por indução
  \begin{equation}
    Y_{n+1} = \max(Y_{n+1}, Y_{n}) = \max(g_{n+1}(X) , \tilde g_n(X)) = \tilde g_{n+1}(X).
  \end{equation}
Se $g$ for o limite de $\tilde g_n$, temos $Y=g(X)$.

\medskip

  Finalmente usamos a linearidade da composição novamente para resolver o caso geral $f = f_+ - f_-$.
\end{proof}







Se $X: \Omega \to E$ é elemento aleatório, então $E(Y|\sigma(X))$ é $\sigma(X)$-mensurável e mensurável por definição e temos
$E[Y| X] = g(X)$ para alguma $g: E \to \mathbb{R}$.
Nesse caso ``calcular'' a esperança de $Y$ conditionada a $\sigma(X)$ corresponde a achar uma expressão para essa função. 

\begin{exercise}
  Mostre que $g$ é única modulo modificações em conjuntos de probabilidade zero para $P_X$. 
\end{exercise}

No caso onde a distribuição $X$ tem supporte discreto, a função $g$ tem que ser definida por 
$$g(x)=E[Y \, | \, X = x]= \frac{E[Y\1_{\{X=x\}}]}{P[X=x]}$$


% 
% Gostaríamos de extender essa noção $E(Y|X = x)$ satisfaz alguma propriedade que justifique essa notação.
% Apesar de que apenas na próxima seção poderemos justificar completamente essa nomenclatura, nesse momento já podemos mostrar a seguinte relação
% \begin{equation*}
%   E(Y) = E\big( E(Y | X) \big) = E\big( E(Y | X = x) \circ X \big) = \int E(Y| X = x) (X \circ P) (\d x).
% \end{equation*}
% Em outras palavras, para integrar $Y$, basta conhecermos a distribuição de $X$ e a esperança condicional de $Y$, dado que $X = x$.

\begin{exercise}
  Sejam $X$ e $Y$ as coordenadas canônicas em $E_1 \times E_2$, com a probabilidade $P = \mu_1 \otimes \mu_2$ e seja $f:E_1 \times E_2 \to \mathbb{R}$
  em $\mathcal{L}^1(P)$.
  Mostre que
  \begin{equation}
     E[ f(X,Y) \,| \, X] = \int f(X, y) \mu_2(\d y).
  \end{equation}
\end{exercise}

\begin{exercise}
  Se $K$ é um núcleo de transição entre $E_1$ e $\mathbb{R}$ e $P_1$ é uma probabilidade em $E_1$, mostre que se $P=P_1 \star K$ temos
  \begin{equation}
    E[ X_2 \, | \, X_1] = \int x_2 K(X_1, \d x_2).
  \end{equation}
\end{exercise}


\begin{exercise}
  Sejam $X_1$ e $X_2$ as coordenadas canônicas em $\mathbb{R} \times E$ e definimos a probabilidade $\d P = \rho(x,y) \d \mu_1 \d \mu_2$, onde $\rho:\mathbb{R} \times E \to \mathbb{R}_+$ é uma densidade.
  Dê sentido à expressão abaixo e mostre que elá é $E(X_1|X_2)$:
  \begin{equation}
     \frac{\int x\rho(x, X_2) \mu_1(\d x)}{\int \rho(x, X_2) \mu_1(\d x)}.
  \end{equation}
\end{exercise}




\begin{exercise}
  Sejam $Z_1, Z_2, \dots$ variáveis aleatórias \iid em $\mathcal{L}^1(P)$ com $E(Z_1) = 0$.
  \begin{enumerate}[\quad a)]
  \item Defina $X_0 = 0$ e
    \begin{equation}
      X_n = \sum_{i = 1}^n Z_i, \text{ para $n \geq 1$.}
    \end{equation}
    Mostre que $E(X_{n + 1} | Z_1, \dots, Z_n) = X_n$.
  \item Supondo agora que $Z_1 \in \mathcal{L}^2(P)$ e $E(Z) = 0$, defina $Y_0 = 0$ e
    \begin{equation}
      Y_n = \Big( \sum_{i = 1}^n Z_i \Big)^2 - n E(Z_1^2)
    \end{equation}
    Mostre que $E(Y_{n + 1} | Z_1, \dots, Z_n) = Y_n$.
  \end{enumerate}
\end{exercise}


\todosec{Tópico: Martingais a tempo discreto}{fazer...}

\todosec{Tópico: Propriedade fraca de Markov}{mostrar que cadeias = processos...}

\todosec{Tópico: Recorrência e transiência}{markov recorrência/transiência + periodicidade...}

\section{Probabilidade Condicional Regular}

Já sabemos definir por exemplo $E(\1_A|X = x)$.
Gostaríamos porém de garantir que essa expressão definisse uma probabilidade em $A$, e chamaríamos essa probabilidade de $P(A|X = x)$.
Mas certamente gostaríamos que $P(\cdot|X = x)$ fosse uma função $\sigma$-aditiva.
Essa especulação parece promissora, por exemplo se $A$ e $B$ são disjuntos,
\begin{equation*}
  P(A \cup B |\mathcal{F}') = E(\1_{A \cup B} | \mathcal{F}') = E(\1_A|\mathcal{F}') + E(\1_{B}|\mathcal{F}') = P(A|\mathcal{F}') + P(B|\mathcal{F}').
\end{equation*}
Ótimo, mas ainda temos o seguinte problema.

Lembramos que a equação acima está bem definida apenas quase certamente.
Poderíamos portanto garantir que para uma classe enumerável de conjuntos $A \in \mathcal{F}$, essa aditividade fosse satisfeita.
Porém, a $\sigma$-álgebra $\mathcal{F}$ é frequentemente não enumerável, portanto não conseguimos a $\sigma$-aditividade plena.
Isso pode ser contornado se o espaço for canônico, como afirma o nosso próximo resultado.

Ele nos ajudará bastante ao fazermos cálculos usando condicionais, de maneira semelhante à Lei da Probabilidade Total.
Esse é o conteúdo do seguinte resultado.

\begin{theorem}[Teorema da Desintegração] \index{Teorema!da Desintegracao@da Desintegração}
  \label{desintegracao}
  Sejam espaços mensuráveis $(\Omega, \mathcal{F})$ e $(E, \mathcal{A})$, com $E$ canônico.
  Se $P$ é uma probabilidade no espaço produto $(\Omega \times E, \mathcal{F} \otimes \mathcal{A})$ e denotamos por $P_1 = P_{X_1}$ a 
  distribuição marginal da primeira coordenada, então existe um núcleo de transição $K: \Omega \times \mathcal{A} \to [0,1]$ satisfazendo
  \begin{equation}
    P = P_1 \star K,
  \end{equation}
  Em particular,
  \begin{equation}
    \label{e:prob_cond_reg_prod}
    P(A \times B) = \int_A K(\omega, B) P_1 (\d \omega) \text{ para todo $A \in \mathcal{F}$, $B \in \mathcal{A}$}.
  \end{equation}
 Nesse caso podemos definir 
 $$P[X_2 \in B | X_1 = \omega]:=K(\omega, B)$$ 
 (como de costume $X_i$ denota a $i$-ésima coordenada canônica).
\end{theorem}

\begin{proof}
  Como de costume, basta resolver o caso $(E, \mathcal{A}) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
  De fato, se assumimos a validade do teorema para a reta, podemos usar a função bi-mensurável $\phi: E \to B \in \mathcal{B}(\mathbb{R})$ para concluir o caso geral.

  Nos restringiremos agora ao espaço $(\Omega \times \mathbb{R}, \mathcal{F} \otimes \mathcal{B}(\mathbb{R}), P)$.
  Para cada $q \in \mathbb{Q}$, definimos $P^q_\Omega : \mathcal{F} \to [0,1]$ por
  \begin{equation}
    P^q_1 (A) = P\big(  A  \times (-\infty, q]\big).
  \end{equation}
  Observando que $P^q_1$ é absolutamente contínua com respeito a $P_1$, podemos definir
  \begin{equation}
    F(\omega, q) = \frac{\d P^q_1}{\d P_1}(\omega).
  \end{equation}
  Observamos as seguintes propriedades de $F$:
  \begin{enumerate}[\quad a)]
  \item para cada $q \in \mathbb{Q}$, $F(\cdot, q) \in [0,1]$, $P_\Omega$-quase certamente, pois $P^q_1(A) \leq P_1(A)$ para todo $A \in \mathcal{F}$,
  \item para $q < q' \in \mathbb{Q}$, $F(\cdot, q) \leq F(\cdot, q')$, $P_1$-quase certamente, pois $P^q_1(A) \leq P^{q'}_\Omega(A)$ para todo $A \in \mathcal{F}$ e
  \item $F(\cdot, n) \to 1$ (analogamente $F(\cdot, -n) \to 0$) quando $n$ tende a infinito, $P_1$-quase certamente.
    Para ver isso, note que a sequência de variáveis aleatórias $F(\cdot, n)$ é quase certamente monótona não decrescente, logo converge $P_\Omega$-quase certamente.
    Sendo limitada, converge em $\mathcal{L}^1$ e como sua integral em $P_\Omega$ converge para um, $F(\cdot, n) \to 1$, quase certamente (analogamente para $F(\cdot, -n)$).
  \end{enumerate}
  Existe pois um conjunto $\Omega' \in \mathcal{F}$ com $P_\Omega(\Omega') = 1$ no qual as três hipóteses acima são satisfeitas.
  Definimos $\hat{F}(\omega, q)$ como sendo igual a $F(\omega, q)$ em $\Omega'$ e igual a $F_0(q)$ (uma função de distribuição fixa) caso contrário (que claramente será mensurável).
  Finalmente podemos definir $\tilde{F}(\omega, x) = \inf_{q \in \mathbb{Q}; q \downarrow x} \hat{F}(\omega, q)$, que satisfaz para todo $\omega$ as hipóteses do Teorema~\ref{t:existe_prob_R}.
  Logo, existe para cada $\omega \in \Omega$ uma medida $K(\omega, \cdot)$ em $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ satisfazendo $K(\omega,(-\infty, q]) = F(\omega, q)$ $P_\Omega$-quase certamente.

  Precisamos mostrar que $K$ é um núcleo, e para isso basta observar que $F(\omega, q)$ são mensuráveis e a família $\{(-\infty, q]; q \in \mathbb{Q}\}$ forma um $\pi$-sistema que gera $\mathcal{B}(\mathbb{R})$.

  Finalmente, vamos verificar \eqref{e:prob_cond_reg_prod}, notando que se $A \in \mathcal{F}$ e $B = (-\infty, q]$,
  \begin{equation}
    \int_A K(\omega, B) P_\Omega(\d \omega) = \int_A F(\omega, q) P_\Omega (\d \omega) = P^q_\Omega(A) = P(A \times B).
  \end{equation}
  Como a classe $B$ é um $\pi$-sistema gerando $\mathcal{B}(\mathbb{R})$ terminamos a prova.
\end{proof}

Interpretamos $P[X_2 \in B | X_1 = \omega]$ da seguinte forma.
Se alguém tiver acesso à $\sigma$-álgebra $\sigma(X_1)$, ou seja, essa pessoa é capaz de observar o valor de $\omega$, ela pode não saber o valor de $X_2$, mas já pode atualizar sua distribuição para $P(X_2 \in \cdot| X_1 = \omega)$.

Uma das grandes vantagens de ter um núcleo de transição a determinar uma distribuição conjunta, como foi feito acima, é que podemos usar a versão generalizada de Fubini.
Antes, nós somente podiamos usar Fubini para espaços construídos através de um núcleo.

\begin{exercise}
  Se $\Omega = E_1 \times E_2$ com $E_2$ canônico é dotado da probabilidade $\d P = \rho(x_1, x_2) \mu_1 \otimes \mu_2 (\d x_1 \d x_2)$, mostre que
  \begin{equation}
    P(X_2 \in A|X_1 = x_1) = \frac{\int_A \rho(x_1, x_2) \mu_2(\d x_2)}{\int \rho(x_1, x_2) \mu_2(\d x_2)},
  \end{equation}
  $(P_{X_1})$-quase certamtente.
\end{exercise}

\begin{exercise}
  \label{x:prob_cond_reg_indep}
  Sejam $X_1$ e $X_2$ as projeções canônicas em um espaço produto $\Omega \times E$, com $E$ canônico.
  Então, se $X_1$ e $X_2$ são independentes com respeito a $P$, vale
  \begin{equation}
    P[X_2 \in B | X_1 = \omega] = P[X_2 \in B] \text{ para $P_{X_1}$-quase todo $\omega$}.
  \end{equation}
\end{exercise}

\begin{exercise}
  Considere em $(\mathbb{R}^2, \mathcal{B}(\mathbb{R}^2))$ as projeções canônicas $X_1$ e $X_2$.
  Calcule, em cada um dos exemplos abaixo, a probabilidade condicional regular $P[X_1 \in \cdot|X_2 = x_2]$, justificando sua resposta,
  \begin{enumerate}[\quad a)]
  \item Quando $P$ é a medida uniforme em $T = \{(x,y) \in [0,1]^2; x \leq y\}$ (ou seja, a medida de Lebesgue em $\mathbb{R}^2$ restrita a $T$ e normalizada para ser uma probabilidade).
  \item Quando $P$ é a medida $U_{S^1}$ (uniforme em $S^1$).
  \end{enumerate}
\end{exercise}

\section{Princípio da substituição}

O Teorema~\ref{desintegracao} é bastante poderoso e nos permite definir e calcular diversas probabilidades, como faremos à seguir.
Nessa seção construiremos nossa última versão de probabilidade condicional regular que não se restringe a espaços produtos e nos fornecerá o que chamamos de Princípio da Substituição. \index{Principio@Princípio!da Substituicao@da Substituição}

\begin{theorem}
  \label{t:princ_substit}
  Sejam $(\Omega, \mathcal{F}, P)$ e $(E, \mathcal{A})$ espaços mensuráveis canônicos.
  Considere também $X: \Omega \to E$ um elemento aleatório, então existe um núcleo de transição $K$ de $E$ a $\Omega$ tal que
  \begin{equation}
    \label{e:reg_cond_prob_givenX}
    K(X(\omega), F) = E[\1_{F} | X], \text{ para todo $F \in \mathcal{F}$}.
  \end{equation}
  Também denotamos esse núcleo como $K(x, F) = P[F | X = x]$, que é único no sentido que se $K'$ 
  também satisfaz \eqref{e:reg_cond_prob_givenX}, então $K(x, F) = K'(x, F)$ para $(P_X)$-quase todo $x \in E$.

  Além disso vale o que chamamos de Princípio da Substituição:
  \begin{equation}
    \label{e:princ_substit}
    K(x, [X = x]) = 1, \quad \text{$P_X$-quase certamente}.
  \end{equation}
  Que pode ser dito de maneira estranha: $P[X = x|X = x] = 1$, quase certamente.
\end{theorem}

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=3]
    \draw[->,gray,very thin] (0, -.8) -- (0,1.2) node[left, black] {$\Omega$};
    \draw[->,gray,very thin] (-0.2, 0.08) -- (1.3, 0.08) node[above,black] {$E$};
    \draw[domain=-.8:1.2,smooth,variable=\x,blue] plot ({ 1/(1 + 10 * \x * \x) }, {\x});
    \draw[-,dashed,gray,very thin] (0, {-sqrt(1 / 7 - 0.1)}) -- (0.7, {-sqrt(1 / 7 - 0.1)}) -- (0.7, {sqrt(1 / 7 - 0.1)}) -- (0, {sqrt(1 / 7 - 0.1)});
    \draw[thick] (0.7, .06) -- (0.7, .1);
    \node[below, right] at (.7, 0) {$x$};
    \draw[thick] (0, {-sqrt(1 / 7 - 0.1)}) circle (.01);
    \draw[thick] (0, {sqrt(1 / 7 - 0.1)}) circle (.01);
    \node[below] at (-.24, .32) {$[X = x]$};
  \end{tikzpicture}
  \caption{O gráfico do elemento aleatório $X$ representado horizontalmente.
    Os pontos marcados no eixo vertical representam o conjunto $[X = x]$ que possui medida um segundo $P[\; \cdot \; | X = x]$ de acordo com o Teorema~\ref{t:princ_substit}}
\end{figure}

\begin{proof}
  Defina o elemento aleatório $W: \Omega \to E \times \Omega$, dado por $W(\omega) = (X(\omega), \omega)$, que percorre o gráfico de $X$ (representado horizontalmente).
  Observe que a medida $P_W P$ possui marginais $(X_1)_* P_W = X_* P$ e $(X_2)_* P_W = P$.
  Como $P_W$ satisfaz as condições do Teorema~\ref{desintegracao}, existe um núcleo $K: E \times \mathcal{F} \to [0,1]$ tal que para todo $A \in \mathcal{A}$, $F \in \mathcal{F}$,
  \begin{equation}
    P_W(A \times F) = \int_A K(x, F) P_X (\d x).
  \end{equation}
  Fixado $F \in \mathcal{F}$, $K(X(\omega), F)$ é obviamente $\sigma(X)$ mensurável, por ser uma composição de uma função mensurável em $E$ com $X$.
  Logo, para provar \eqref{e:reg_cond_prob_givenX}, basta mostrar a segunda propriedade de esperanças condicionais.
  Se $B \in \sigma(X)$, podemos escrever $B = [X \in A]$ para algum $A \in \mathcal{A}$, donde
  \begin{equation}
    \begin{split}
      E\big[ K(X, F) \1_B \big] & = E\big[ K(X, F) \1_{[X \in A]} \big] = \int_A K(x, F) P_X(\d x)\\
      & = P_W (A \times F) = E[\1_{X \in A} \1_F] = E[\1_B \1_F],
    \end{split}
  \end{equation}
  concluindo a prova de \eqref{e:reg_cond_prob_givenX}.

  Para mostrarmos o Princípio da Substituição, vamos usar o seguinte lema.

  \begin{lemma}
    Se $X : \Omega \to E$ é um elemento aleatódio tomando valores em um espaço $E$ canônico, então seu gráfico $G = \{(\omega, X(\omega)); \omega \in \Omega\}$ é mensurável na $\sigma$-álgebra produto $\mathcal{F} \otimes \mathcal{A}$.
  \end{lemma}

  \begin{proof}
    Primeiramente, consideramos o caso $(E, \mathcal{A}) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
    Neste caso, vemos que
    \begin{equation}
      G = \bigcap_{n \geq 1} \bigcup_{j \in \mathbb{Z}} [X \in \big(j/2^n, (j+1)/2^n \big]] \times \big( j/2^n, (j+1)/2^n \big],
    \end{equation}
    que é mensurável.

    Caso $E$ seja outro espaço canônico qualquer, existe $\phi: E \to B \in \mathcal{B}(\mathbb{R})$ bi-mensurável e $G = \Phi^{-1}(G_{\phi(X)})$, onde 
    $G_{\phi(X)}$ é o gráfico de $\phi(X)$ e $\Phi(\omega, x) = (\omega, \phi(x))$.
    Logo $G$ também é mensurável nesse caso.
  \end{proof}

  Retornando à prova de \eqref{e:princ_substit}, já sabemos que $G' = \{(X(\omega), \omega); \omega \in \Omega\}$ é mensurável.
  Além disso, por definição $P_W(G') = P[(X(\omega), \omega) \in G'] = P(\Omega) = 1$, ou seja a medida $P_W$ tem suporte em $G'$.

  Logo podemos escrever
  \begin{equation}
    \begin{split}
      1 = P_W(G') & = \int \int \1_{G'} (x, \omega) K(x, \d \omega)  P_X (\d x)\\
      & = \int K(x, [X = x]) P_X (\d x).
    \end{split}
  \end{equation}
  Mas como o integrado acima pertence a $[0,1]$, essa integral só pode ser um se $K(x, [X = x]) = 1$, $P_X$-quase certamente, como desejado.
\end{proof}

\begin{exercise}
  Sejam $X: \Omega \to E$ e $Y: \Omega \to E'$ elementos aleatórios com $E$ canônico.
  Então existe um núcleo de transição $K$ entre $E$ e $E'$ tal que
  \begin{equation}
    \label{e:regular_cond_prob_givenX}
    K(X(\omega), B) = E[\1_{Y \in B} | X], \text{ para todo $B \in \mathcal{A}'$}.
  \end{equation}
  Poderíamos chamar esse núcleo de $K(x, B) = P[Y \in B | X = x]$.
\end{exercise}

\begin{exercise}
  Mostre que se $K(x, F) = P[F| X = x]$, então
  \begin{equation}
    \label{e:reg_cond_exp_givenX}
    \int f(\omega') K(X(\omega), \d \omega') = E(f | X)(\omega), \text{ para toda $f \in \mathcal{F}$}.
  \end{equation}
\end{exercise}

% \begin{exercise}
%   Se $Y$ é variável aleatória e $X: \Omega \to E$ é um elemento aleatório canônico, mostre que
%   \begin{equation}
%     E(Y|X) = \int y P(Y \in \d y|X = \cdot) \circ X, \text{ $P$-q.c.}
%   \end{equation}
% \end{exercise}

Vamos agora mostrar uma aplicação do que foi feito acima, tentando justificar o nome Princípio da Substituição.

\begin{proposition}
  Se $X, Y$ são variáveis aleatórias independentes, então a função de distribuição acumulada $F$ de $X + Y$ é dada por
  \begin{equation}
    F(z) = P[X + Y \leq z] = \int_{-\infty}^\infty F_Y(z - x) P_X (\d x),
  \end{equation}
  onde $F_Y(y) = P[Y \leq y]$.
\end{proposition}

Esse lema pode ser visto como uma generalização do Exercício~\ref{x:convolucao_densidade} para o caso não absolutamente contínuo.
Vale a pena tentar diferenciar (não rigorosamente) a equação acima em $z$.

\begin{proof}
  Vamos calcular
  \begin{equation}
    \begin{split}
      P[X + Y \leq z] & = E\big( E(\1_{[X + Y \leq z]} | X) \big)\\
      & = \int_{-\infty}^\infty P[X + Y \leq z \ | \ X = x\cdot) P_X(\dd x)\\
      & = \int_{-\infty}^\infty P[ Y \leq z-x  \ | \ X = x\cdot) P_X(\dd x).
     \end{split}
  \end{equation}
  Agora vamos usar a hipótese que $X$ e $Y$ são independentes.
  Isso equivale a dizer que a distribuição conjunta desse par é igual a $P_X \otimes P_Y$ e pela unicidade da probabilidade condicional regular 
  temos que $P[Y \in F | X = x] = P[Y \in F]$, $(P_X)$-quase certamente, veja Exercício~\ref{x:prob_cond_reg_indep}.
  Portanto,
  \begin{equation}
    P[X + Y \leq z] = \int_{-\infty}^\infty F_Y(z - x)  P_X (\d x),
  \end{equation}
  terminando a prova do lema.
\end{proof}


\begin{exercise}
  Considere as medidas
  \begin{equation}
    \mu_a = \frac{\delta_{-1} + \delta_1}{2}, \qquad \text{e} \qquad \mu_b = \mathcal{N}(0, 1).
  \end{equation}
  e $K:\mathbb{R} \times \mathcal{B}(\mathbb{R}) \to [0,1]$ dada por
  \begin{equation}
    K(x, A) =
    \begin{cases}
      \mu_a (A - x), & \text{ se $x < 0$,}\\
      \mu_b (A - x), & \text{ se $x \geq 0$,}
    \end{cases}
  \end{equation}
  Mostre que
  \begin{enumerate}[\quad a)]
  \item $K$ define um núcleo de transição entre $\mathbb{R}$ em $\mathbb{R}$.
  \item Se $X_1, X_2, \dots$ for uma cadeia de Markov em $\mathbb{R}$ com núcleo de transição $K$, então calcule
    \begin{enumerate}[\qquad i)]
    \item $E(X_i)$, para todo $i \geq 1$ e
    \item $\text{Var}(X_i)$, para todo $i \geq 1$.
    \item Mostre que
      \begin{equation}
        \frac{\sum_{i = 1}^n X_i}{\sqrt{n}} \Rightarrow \mathcal{N}(0,1).
      \end{equation}
    \end{enumerate}
  \end{enumerate}
\end{exercise}

\begin{topics}

\section{Tópico: Processos de Poisson em \texorpdfstring{$\mathbb{R}$}{R}}

Nessa seção aplicaremos o conceito de Probabilidade Condicional Regular e do Princípio da Substituição \index{Principio@Princípio!da Substituicao@da Substituição} para estudarmos um importante processo de chegadas chamado Processo de Poisson. \index{Processo de Poisson}

O Tenente Boavista está encarregado de vigiar o Sargento Pimenta, que frequentemente dorme durante sua vigília.
Para isso, Boavista tem que decidir os momentos $t_1, t_2, \dots \in \mathbb{R}$ que ele irá verificar se Pimenta está cochilando.
Uma primeira estratégia poderia ser tomar intervalos igualmente espaçados, $t_1 = 1, \dots, t_k = k$, mas o Sargento certamente iria dormir nos intevalos $(k + \varepsilon, k + 1 - \varepsilon)$ sem se preocupar.

Dado esse problema, o Tenente decide escolher tempos aleatórios $T_1, T_2, \dots$
Mas é importante lembrar que não são todas as distribuições que funcionarão bem, por exemplo se $T_k - T_{k-1} \geq a$ quase certamente o Sargento irá se aproveitar desse intervalinho.

A primeira simplificação que o Tenente imagina para esse problema é a seguinte: dado que houve uma vistoria no instante $t_k$, então o que acontecerá à partir daí será o mesmo processo com o qual ele começou.
Isso pode ser traduzido de maneira rigorosa como
\begin{equation}
  \label{e:Poisson_incr_ind}
  P\big[ (T_{k+1} - t_k, T_{k+2} - t_k, \dots ) \in A | T_k = t_k \big] = P\big[ (T_1, T_2, \dots ) \in A \big],
\end{equation}
$T_k \circ P$-quase certamente.
Não iremos entrar muito em detalhes sobre qual é essa esperança condicional, pois no momento ainda estamos trabalhando heuristicamente, mas já podemos dizer que:
\begin{equation}
  \label{e:increm_poisson}
  \begin{split}
    P\big[ T_1 \in A_1, T_2 - T_1 \in A_2 \big] & = E\big[ \1_{T_1 \in A_1} P[T_2 - T_1 \in A_2 | T_1 = t_1] \circ T_1 \big]\\
    & \overset{\eqref{e:Poisson_incr_ind}}= E\big[ \1_{T_1 \in A_1} P[T_1 \in A_2] \big] = P[T_1 \in A_1] P[T_1 \in A_2].
  \end{split}
\end{equation}
Procedendo de maneira análoga, podemos concluir que $(T_1, T_2 - T_1, T_3 - T_2, \dots)$ são uma coleção \iid.
Agora o Tenente Boavista somente precisa escolher a distribuição de $T_1$.

Para essa escolha, ele sabe que se ele não chegar em tempo $t$, então o Sargento Pimenta sabe que sua próxima chegada terá distribuição $P[T_1 - t \in A | T_1 > t]$.
Como o Tenente Boavista gostaria que essa essa informação fosse inútil para o Sargento Pimenta, ele escolherá
\begin{equation}
  P[T_1 - t \in A | T_1 > t] = P[T_1 \in A].
\end{equation}
E sabemos que as distribuições $\Exp(\lambda)$, para $\lambda > 0$ satisfazem isso, portanto já temos um candidato ao nosso processo de vistorias, mas antes vamos introduzir algumas notações.

Já podemos perceber por \eqref{e:increm_poisson} que mais importante que os tempos $T_k$, serão os intervalos entre visitas $X_k = T_k - T_{k-1}$.

Seja $\mathcal{D}\big( [0, \infty) \big)$ o espaço de todas as funções càdlàg em $\mathbb{N}$, ou seja
\begin{equation*}
  \mathcal{D}\big( [0, \infty) \big) = \big\{ f:\mathbb{R}_+ \to \mathbb{N}: f \text{ é contínua à direita e com limite à esquerda} \big\}.
\end{equation*}
Definiremos $\Gamma: \mathbb{R}^\mathbb{N} \to \mathcal{D}\big( [0, \infty) \big)$ da seguinte forma: dados $(x_1, x_2, \dots) \in \mathbb{R}^\mathbb{N}$, seja $\Gamma(x_1, \dots) = N$, tal que
\begin{equation}
  N_t = \max\{n; \sum_{i=1}^n x_i \leq t\},
\end{equation}
que conta quantas visitas ocorreram antes de $t$, veja Figura~\ref{f:ppp_reta}.

\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[scale=1]
    \clip (-1, -1) rectangle (8, 5);
    \draw[<->] (0, 4) -- (0,0) -- (9, 0);
    \edef\k{0};
    \foreach \z in {0,...,6}
    { \pgfmathrandominteger{\x}{20}{200}
      \pgfmathparse{max((2 * ln(200/\x)), .3) + \k}
      \xdef\j{\pgfmathresult}
      \draw[dashed] (\j, 0) -- (\j, \z);
      \draw[thick] (\k, \z) -- (\j, \z);
      \draw[fill, color = white] (\j, \z) circle (.04);
      \draw[color = black] (\j, \z) circle (.04);
      \draw[fill, color = black] (\k, \z) circle (.04);
      \pgfmathparse{int(\z + 1)}
      \xdef\n{\pgfmathresult}
      \node[below] at (\j, 0) {$t_{\n}$};
      \xdef\k{\j}
    }
  \end{tikzpicture}
  \caption{A função $N_t$ definindo o número de chegadas do Processo de pontos de Poisson.
  Note que $N$ é càdlàg.\label{f:ppp_reta}}
\end{figure}

Poderíamos nos perguntar qual é a $\sigma$-álgebra que estamos considerando no espaço $\mathcal{D}\big( [0, \infty) \big)$, essa é uma interessante questão que deve ser abordada em estudos mais profundos desse espaço.
Mas por enquanto será suficiente considerarmos a $\sigma$-álgebra induzida pelo mapa $\Gamma$ (a maior que ainda o deixa mensurável).

Estamos prontos agora pra definir o nosso processo.

\begin{definition}
  Fixado $\lambda > 0$, definimos um Processo de Poisson em $\mathbb{R}$ com parâmetro $\lambda$ como a lei $\mathbb{P}_\lambda$ em $\mathcal{D}\big( [0, \infty) \big)$, dada por $\Gamma \circ \Exp(\lambda)^{\otimes \mathbb{N}}$.
  Ou em outras palavras, o processo de contagem de chegadas $N_t$, no qual os intervalos entre chegadas são independentes e distribuídos como $\Exp(\lambda)$.
\end{definition}

Lembramos que como de costume definimos $X_1, X_2, \dots$ como sendo as projeções canônicas em $\mathbb{R}^\mathbb{N}$ onde definimos $\Exp(\lambda)^{\otimes \mathbb{N}}$.
Como esses representam os intervalos entre chegadas, definimos também
\begin{equation}
  T_k = \sum_{i=1}^k X_i, \text{ para $k \geq 1$}.
\end{equation}

Podemos agora enunciar o primeiro lema, que nos fornece a distribuição do número de chegadas em um dado tempo $t \geq 0$.

\begin{lemma}
  Se $\lambda > 0$ e $t \geq 0$, então $N_t \distr \Poisson(\lambda t)$ sob $\mathbb{P}_\lambda$.
\end{lemma}

\begin{proof}
  Vamos primeiramente ver que
  \begin{equation}
    \mathbb{P}_\lambda [N_t = 0] = \mathbb{P}_\lambda[X_1 > t] = e^{-\lambda t},
  \end{equation}
  que coincide com o caso poissoniano.

  Para verificar o caso arbitrário $[N_t = k]$, utilizaremos indução e os resultados de esperança condicional regular que vimos anteriormente.
  Primeiro, observe que se $x_1 > s$, então
  \begin{equation}
    \Gamma(x_1, x_2, \dots)(r - s) = \Gamma(x_1 - s, x_2, \dots)(r).
  \end{equation}
  Logo,
  \begin{equation*}
    \begin{array}{e}
      \mathbb{P}_\lambda[N_t = k] & = & \mathbb{P}_\lambda [X_1 \leq t, \Gamma(X_2, X_3, \dots)(t - X_1) = k - 1]\\
      & = & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \mathbb{P}_\lambda[\Gamma(X_2, X_3, \dots)(t - X_1) = k - 1 | X_1] \Big]\\
      & \overset{\textnormal{Subst.}}= & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \mathbb{P}_\lambda[\Gamma(X_2, X_3, \dots)(t - x_1) = k - 1 | X_1 = x_1] \circ X_1 \Big]\\
      & \overset{\textnormal{induc.}}= & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \big(\Poisson(\lambda(t - x_1))(\{k-1\})\big) \circ X_1 \Big]\\
      & = & \mathbb{E}_\lambda \Big[\1_{X_1 \leq t} \frac{(\lambda(t - X_1))^{k-1} e^{-\lambda(t - X_1)}}{(k-1)!} \Big]\\
      & = & \int_0^t \frac{(\lambda(t - x_1))^{k-1} e^{-\lambda(t - x_1)}}{(k-1)!} \lambda e^{-\lambda x_1} \d x_1 = \frac{\lambda^k e^{-\lambda t}}{(k-1)!} \frac{t^k}k,
    \end{array}
  \end{equation*}
  como queríamos demonstrar.
\end{proof}

\newpage

Um outro resultado importante sobre esses processos se relaciona ao fato de reiniciar o sistema em tempo $t > 0$.
Isso é feito com o seguinte mapa $\theta_t: \mathcal{D}\big( [0, \infty) \big) \to \mathcal{D}\big( [0, \infty) \big)$, que leva $N$ em
\begin{equation}
  \theta_t(N)(s) = N_{s + t} - N_t.
\end{equation}

\begin{exercise}
  Mostre que o mapa $\theta_t$ é mensurável.
\end{exercise}

\begin{lemma}
  Fixe $\lambda, t > 0$ e seja $N$ um processo de Poisson de taxa $\lambda$.
  Então, para $k \in \mathbb{Z}_+$ e $A$ mensurável,
  \begin{equation}
    \mathbb{P}_\lambda[N_t = k, \theta_t \circ N \in A] = \mathbb{P}_\lambda[N_t = k] \mathbb{P}_\lambda[N \in A].
  \end{equation}
\end{lemma}

Em particular, isso mostra que a distribuição do processo de Poisson $N$ é invariante pelo mapa $\theta_t$.

\begin{proof}
  Começamos reescrevendo o evento e condicionando em $T_k$ como abaixo
  \begin{equation*}
    \begin{split}
      \mathbb{P}_\lambda & [N_t = k, \theta_t \circ N \in A] \\
      & = \mathbb{P}_\lambda[T_k \leq t, T_{k + 1} > t , \theta_t \circ N \in A] \\
      & = \mathbb{E}_\lambda \big[ {\bf 1}_{T_k \leq t} \mathbb{E}_\lambda [X_{k + 1} > t - t_k, \theta_t \circ N \in A | T_k = t_k ] \circ T_k \big] \\
      & = \mathbb{E}_\lambda \Big[ {\bf 1}_{T_k \leq t} \mathbb{E}_\lambda \big[X_{k + 1} > t - t_k, \Gamma (X_{k + 1} - (t - t_k), X_{k + 2}, X_{k + 3}, \dots ) \in A | T_k = t_k \big] \circ T_k \Big], \\
      \intertext{que, usando que $X_i$ são independentes e $X_{k + 1}$ não tem sem memória, é igual a}
      & = \mathbb{E}_\lambda \Big[ {\bf 1}_{T_k \leq t} \mathbb{P}_\lambda \big[X_{k + 1} > t - t_k | T_k = t_k \big] \circ T_k \Big] \mathbb{P}_\lambda [N \in A] \\
      & = \mathbb{P}_\lambda[ N_t = t ] \mathbb{P}_\lambda [N \in A],
    \end{split}
  \end{equation*}
  terminando a prova do lema.
\end{proof}

Como corolário do lema acima, podemos deduzir que um processo de Poisson possui incrementos independentes.
Mais precisamente,

\begin{corollary}
  Seja $N$ um Processo de Poisson $N$ com taxa $\lambda > 0$.
  Considerando também tempos $0 = t_0 < t_1 < \dots < t_j$, e inteiros $k_1, \dots, k_j \geq 0$ temos
  \begin{equation*}
    \mathbb{P}_\lambda \big[ N_{t_1} = k_1, \dots, N_{t_j} - N_{t_{j - 1}} = k_j \big] = \mathbb{P}_\lambda [N_{t_1} = k_1] \cdots \mathbb{P}_\lambda [N_{t_j - t_{j - 1}} = k_j]
  \end{equation*}
\end{corollary}

\begin{proof}
  Basta observar que
  \begin{equation}
    [ N_{t_2} - N_{t_1}, \dots, N_{t_j} - N_{t_{j - 1}}] = [ N_{t_2 - t_1}, \dots, N_{t_j - t_1} - N_{t_{j - 1} - t_1}] \circ \theta_{t_1}
  \end{equation}
  e aplicar o lema para obter
  \begin{equation*}
    \begin{split}
      \mathbb{P}_\lambda \big[ & N_{t_1} = k_1, \dots, N_{t_j} - N_{t_{j - 1}} = k_j \big] \\
      & = \mathbb{P}_\lambda [ N_{t_1} = k_1] \mathbb{P}_\lambda [N_{t_2 - t_1} = k_2 , \dots N_{t_j - t_1} - N{t_{j - 1} - t_1} = k_j].
    \end{split}
  \end{equation*}
  Repetindo essa operação iterativamente, obtemos o resultado desejado.
\end{proof}



\begin{equation}
  T_1, \dots, T_k \text{ under } \mathbb{P}^{t, k}_\lambda \overset{d}\sim
\end{equation}


$x_1 = t_1$, $x_2 = t_2 - t_1, \dots, x_k = t_k - t_{k - 1}$
\begin{equation}
  \begin{split}
    \rho^{t, k}_\rho (t_1, \dots, t_k) & = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{1}{\mathbb{P}_\lambda [N_t = k]}
    \lambda e^{-\lambda x_1} \lambda e^{-\lambda x_2} \cdots e^{ - \lambda x_k} e^{ - \lambda (t - t_k) }\\
    & = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{k!}{e^{-\lambda t} (\lambda t)^k} \lambda^k e^{-\lambda t} = {\bf 1}_{0 \leq t_1 \leq \dots \leq t_k \leq t} \; \frac{k!}{t^k}.
\end{split}
\end{equation}
Note que não depende de $\lambda$.


Considere variáveis uniformes $U_1, \dots, U_k$ no intervalo $[0, t]$
\begin{equation}
  \rho^{t, k} (u_1, \dots, u_k) = {\bf 1}_{\tilde{u}_1, \dots, \tilde{u}_k \in [0, t]} \; \frac{1}{t^k}
\end{equation}

Seja $\tilde{U}_1 < \dots < \tilde{U}_k$ a versão ordenada das $U_i$'s.
\begin{equation}
  (\tilde{U}_1, \dots, \tilde{U}_k) \overset{q.c.}= \sum_{\sigma \text{ perm. de $\{1, \dots, k\}$}} (U_{\sigma_1}, \dots, U_{\sigma_k}) {\bf 1}_{0 \leq U_{\sigma_1} \leq \dots \leq U_{\sigma_k} \leq t}
\end{equation}

Então,
\begin{equation}
  \begin{split}
    \tilde{\rho}^{t, k} & = {\bf 1}_{0 \leq \tilde{u}_1 \leq \dots \leq \tilde{u}_k \leq t} \; \frac{1}{t^k} \sum_{\sigma \text{ perm. de $\{1, \dots, k\}$}} \rho^{t, k}(\tilde{u}_{\sigma_1}, \dots, \tilde{u}_{\sigma_k}) \\
    & = {\bf 1}_{0 \leq \tilde{u}_1 \leq \dots \leq \tilde{u}_k \leq t} \; \frac{k!}{t^k} 
  \end{split}
\end{equation}

\end{topics}

\todosec{Tópico: Processos de Markov em tempo contínuo}{fazer...}

\todosec{Tópico: Sistemas de partículas}{fazer...}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Notas_de_aula"
%%% End:
